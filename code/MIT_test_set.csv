Question Index,Department,Course Number,Course Name,Prerequisites,Corequisites,Assignment,Topic,Question Number,Part Number,Percentage of Total Grade,Question Type,Question,Solution Type,Solution,Few shot question 1,Few shot solution 1,Few shot question 2,Few shot solution 2,Few shot question 3,Few shot solution 3
73,Mathematics,18.3,Principles of Continuum Applied Mathematics,"18.02, 18.03",None,Problem Set 5,Traveling Waves,1,a,1.09375,Text,"Imagine that someone tells you that the following equation is a model for traffic flow:
$$
c_{t}+c c_{x}=\nu c_{x t},
$$
where $\boldsymbol{\nu}>\mathbf{0}$ is ""small"" and $c$ is the the wave velocity - related to the car density via $\boldsymbol{c}=\frac{d Q}{d \boldsymbol{\rho}}$. The objective of this problem is to ascertain if (1.1) makes sense as model for Traffic Flow. To this end, answer the two questions below.
Does the model have acceptable traveling wave ""shock"" solutions $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \cdot c=\boldsymbol{F}(\boldsymbol{z})$,
where $\ldots \ldots \ldots \ldots \ldots \ldots \ldots z= \frac{x - Ut}{\nu}$ and $\boldsymbol{U}$ is a constant?
Here ""acceptable"" means the following
1a. The function $F$ has finite limits as $z \rightarrow \pm \infty$, i.e.: $\quad c_{L}=\lim _{z \rightarrow-\infty} F(z) \quad$ and $\quad c_{R}=\lim _{z \rightarrow+\infty} F(z)$. Further: the derivatives of $F$ vanish as $z \rightarrow \pm \infty$, and $c_{L} \neq c_{R}$.
This means that, as $\nu \rightarrow 0$, the solution $c$ becomes a discontinuity traveling at speed $U$, with $c=c_{L}$ for $x<U t$ and $c=c_{R}$ for $x>U$. That is, a shock wave.
1b. The solution satisfies the Rankine-Hugoniot jump conditions $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots U = \frac{[Q]}{[\rho]}$
where $\rho_{L}$ and $\rho_{R}$ are related to $c_{L}$ and $c_{R}$ via $c_{L}=\frac{d Q}{d \rho}\left(\rho_{L}\right)$ and $c_{R}=\frac{d Q}{d \rho}\left(\rho_{R}\right)$.
Assume that $Q=Q(\rho)$ is a quadratic traffic flow function - see remark 1.1.
1c. The solution satisfies the Entropy condition $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \boldsymbol{c}_{\boldsymbol{L}}>\boldsymbol{U}>\boldsymbol{c}_{\boldsymbol{R}}$.
To answer this question:
\begin{itemize}
\item Find all the solutions satisfying 1a. Get explicit formulas for $\boldsymbol{F}$ and $\boldsymbol{U}$ in terms of $c_{L}, c_{R}$, and $z$.
\item Check if the solutions that you found satisfy $\mathbf{1 b}$.
\item Check if the solutions that you found satisfy 1c.
\item Finally, given $\mathbf{A}-\mathbf{C}$ : Does, so far, the equation make sense as a model for traffic flow?
\end{itemize}
Hints.
\begin{itemize}
\item Find the ode $F$ satisfies. Show it can be reduced to the form $F^{\prime}=P(F)$, where $P=$ second order polynomial.
\item Write $P$ in terms of its two zeroes, $c_{1}$ and $c_{2}$, and express all the constants (e.g.: $U$ ) in terms of $c_{1}$ and $c_{2}$.
\item Solve now the equation, and relate $c_{1}$ and $c_{2}$ to $c_{L}$ and $c_{R}$. You are now ready to proceed with $\mathbf{A}-\mathbf{D}$.
\item Remember that, while the density $\rho$ has to be non-negative, wave speeds can have any sign.
\end{itemize}",Open,"Substituting $c=F(z)$, where $z=\frac{x-U t}{\nu}$, into the pde gives the ode
$$
(F-U) F^{\prime}=-U F^{\prime \prime},
$$
where the primes indicate differentiation with respect to $z$. This equation can be integrated once, to obtain
$$
U F^{\prime}=U F-\frac{1}{2} F^{2}+\kappa,
$$
where $\kappa$ is a constant of integration. The right hand side in this equation is a quadratic function of $F$, with maximum value at $F=U$, where it reaches the value $\frac{1}{2} U^{2}+\kappa$. Therefore, for $\kappa$ large enough, the right hand side in (1.5) has two real zeros, and the equation can be written in the form
$$
U F^{\prime}=-\frac{1}{2}\left(F-c_{1}\right)\left(F-c_{2}\right),
$$
where $c_{1} \geq c_{2}$ are constants,
$$
U=\frac{1}{2}\left(c_{1}+c_{2}\right), \quad \text { and } \quad \kappa=-\frac{1}{2} c_{1} c_{2} .
$$
As long as $U \neq 0$, the appropriate (and explicit) solutions to (1.6) follow from the hyperbolic tangent - since $y=\tanh (s)$ satisfies $y^{\prime}=1-y^{2}$. That is
$$
F=U+\frac{c_{1}-c_{2}}{2} \tanh \left(\frac{c_{1}-c_{2}}{4 U} z\right) .
$$
Assume that $c_{1}>c_{2}$, since the case $c_{1}=c_{2}$ is trivial. Then, with $\boldsymbol{c}_{\boldsymbol{L}}=\lim _{\boldsymbol{z} \rightarrow-\infty} \boldsymbol{F}(\boldsymbol{z})$ and $\boldsymbol{c}_{\boldsymbol{R}}=\lim _{\boldsymbol{z} \rightarrow+\infty} \boldsymbol{F}(\boldsymbol{z})$,
$$
\begin{array}{ll}
\text { If } U>0, & c_{L}=c_{2} \text { and } c_{R}=c_{1} . \text { Thus } c_{L}<U<c_{R} . \\
\text { If } U<0, & c_{L}=c_{1} \text { and } c_{R}=c_{2} . \text { Thus } c_{L}>U>c_{R} .
\end{array}
$$
Thus the model has traveling solutions satisfying 1 a for all values of $U$, except $U=0$ (note that equation (1.5) yields $F=$ constant for $U=0$ ). However:
1. Rankine-Hugoniot jump conditions: satisfied, since the wave velocity is given as the average of the characteristic velocities, which is correct for a quadratic flow function - see remark 1.1.
2. Entropy condition: violated when $\boldsymbol{U}>\mathbf{0}$, as shown by (1.9).
Thus, we must conclude that (1.1) is NOT a good model for traffic flow. But we have the derivation in remark 1.1, or so it seems. However, note:
It is, indeed reasonable to assume that the drivers respond to the rate of change of the density. But, why should they respond to $\rho_{t}$ alone, as in (1.2)? The rate of change of the density a driver sees is $r=\rho_{t}+\boldsymbol{u} \boldsymbol{\rho}_{\boldsymbol{x}}$, not $\rho_{t}$ ! The drivers should also respond to the local gradient of the density $\rho_{x}$, specially when it is large.
Since $\rho_{t} \approx-c \rho_{x}$ (at least away from shocks), it follows that $r=\rho_{t}+u \rho_{x} \approx(u-c) \rho_{x}$. But $u \geq c$, so $\rho_{x}$ and $r$ have the same sign. Thus a model with $q=Q(\rho)-\nu \rho_{x}$ will behave properly [this model is actually used], but one based in (1.2) will not. In fact $r \approx-\frac{u-c}{c} \rho_{t}$, so that (1.2) gives the wrong sign for the correction whenever positive wave speeds are involved!
Let us now consider solutions of the form $c=c_{0}+u$, where $c_{0}$ is a constant and $u$ is very small. Then
$$
u_{t}+c_{0} u_{x}=\nu u_{x t}.
$$
This has solutions of the form $u=e^{i k x+\lambda t}$, provided that
$$
\lambda=\frac{-i c_{0} k}{1-i \nu k}=\frac{\nu c_{0} k^{2}}{1+\nu^{2} k^{2}}-i \frac{c_{0} k}{1+\nu^{2} k^{2}} .
$$
If $c_{0}>0$, these solutions grow (exponentially), which means that any uniform traffic flow with $c_{0}>0$ is unstable at least according to this model. ${ }^{3}$ This is rather strange, since $c_{0}>0$ corresponds to light traffic. Another indication that this is not a good model for traffic flow.","Consider the traffic flow equation
$$
\rho_{t}+q_{x}=0,
$$
for a flow $q=Q(\rho)$ that is a quadratic function of $\rho$. In this case $c=\mathrm{d} Q / \mathrm{d} \rho$ is a conserved quantity as well (why?). Thus the problem (including shocks, if any) can be entirely formulated in terms of $c$, which satisfies
$$
c_{t}+\left(\frac{1}{2} c^{2}\right)_{x}=0 .
$$
Consider the initial value problem determined by $(5.2)$ and ${ }^{1}$
$$
c(x, 0)=0 \text { for } x \leq 0 \text { and } c(x, 0)=2 \sqrt{x} \geq 0 \text { for } x \geq 0 .
$$
Without actually solving the problem, argue that the solution to this problem must have the form
$$
c=t f\left(x / t^{2}\right) \text { for } t>0, \text { for some function } f \text {. }
$$
Hint. Let $c=c(x, t)$ be the solution. For any constant $a>0$, define $\mathcal{C}=\mathcal{C}(x, t)$ by $\mathcal{C}=\frac{1}{a} \boldsymbol{c}\left(\mathbf{a}^{\mathbf{2}} \boldsymbol{x}, \boldsymbol{a} \boldsymbol{t}\right)$. What problem does $\mathcal{C}$ satisfy? Use now the fact that the solution to (5.2-5.3) is unique to show that (5.4) must apply, by selecting the constant $\boldsymbol{a}$ appropriately at any fixed time $t>0$.","Now we proceed with the answer to the problem. Note that
$$
\mathcal{C}_{t}=c_{t} \quad \text { and } \quad\left(\mathcal{C}^{2}\right)_{x}=\left(c^{2}\right)_{x}
$$
where $c$ and its derivatives evaluated at $\left(a^{2} x, a t\right)$. Further:
$\mathcal{C}(x, 0)=c(x, 0)$. It follows that $\mathcal{C}=c$, that is:
Now, evaluate (5.6) at $t=1 / a$.
Since $a>0$ is arbitrary, it follows that
which is (5.4) with $f(\xi)=c(\xi, 1)$.
$$
\begin{array}{r}
c(x, t)=\frac{1}{a} c\left(a^{2} x, a t\right) \quad \text { for any } a>0 . \\
c(x, t)=t c\left(x / t^{2}, 1\right) \quad \text { for any } t>0
\end{array}
$$","Consider the traffic flow equation
$$
\rho_{t}+q_{x}=0,
$$
for a flow $q=Q(\rho)$ that is a quadratic function of $\rho$. In this case $c=\mathrm{d} Q / \mathrm{d} \rho$ is a conserved quantity as well (why?). Thus the problem (including shocks, if any) can be entirely formulated in terms of $c$, which satisfies
$$
c_{t}+\left(\frac{1}{2} c^{2}\right)_{x}=0 .
$$
For the solution obtained in item 2 , evaluate $c_{\boldsymbol{x}}$ at $\boldsymbol{x}=\mathbf{0}$ for $\boldsymbol{t}>\mathbf{0}$. Note that this derivative is discontinuous there, so it has two values (left and right).","Finally, from (5.8-5.9), at $x=0$ and $t>0$,
$$
\boldsymbol{c}_{\boldsymbol{x}}=\mathbf{0} \text { from the left, and } \boldsymbol{c}_{\boldsymbol{x}}=\mathbf{1} / \boldsymbol{t} \text { from the right. }
$$","Consider the traffic flow equation
$$
\rho_{t}+q_{x}=0,
$$
for a flow $q=Q(\rho)$ that is a quadratic function of $\rho$. In this case $c=\mathrm{d} Q / \mathrm{d} \rho$ is a conserved quantity as well (why?). Thus the problem (including shocks, if any) can be entirely formulated in terms of $c$, which satisfies
$$
c_{t}+\left(\frac{1}{2} c^{2}\right)_{x}=0 .
$$
Use the method of characteristics to solve the problem in (5.2-5.3). Write the solution explicitly for all $\boldsymbol{t}>\mathbf{0}$, and verify that it satisfies (5.4). Warning: the solution involves a square root. Be careful to select the correct sign, and to justify your choice.","Next we solve (5.2-5.3) using characteristics. For $\zeta \leq 0$ we obtain $c=0$ along $x=\zeta$. Hence these characteristics give
$$
c=0 \text { for } x \leq 0 .
$$
On the other hand, for $\zeta \geq 0$ the characteristics give ${ }^{2} c=2 \sqrt{\zeta}$ along $x=2 \sqrt{\zeta} t+\zeta$. Thus
$$
c=2\left(\sqrt{x+t^{2}}-t\right)=2 t\left(\sqrt{1+\frac{x}{t^{2}}}-1\right) \text { for } x \geq 0 .
$$
s $\zeta$ varies from $\zeta=0$ to $\zeta=\infty$, the characteristics $x=2 \sqrt{\zeta} t+\zeta$ cover the entire region $x \geq 0$. Further, they do so one-to-one, since $\partial_{\zeta} x=1+t / \sqrt{\zeta}>0$. Hence we can solve for $\zeta$ as a function of $(x, t)$. To do so we write these characteristics in the form $(t+\sqrt{\zeta})^{2}=x+t^{2}$, so that $\sqrt{\zeta}=-t+\sqrt{x+t^{2}}$. Note that, since $\sqrt{\zeta} \geq 0$ is required, the positive square root $\sqrt{x+t^{2}}$ must be selected.
The solution to $(5.2-5.3)$ is given by $(5.8-5.9)$. This clearly satisfies (5.4), with $f(z)=0$ for $z<0$, and $f(z)=2(\sqrt{1+z}-1)$ for $z>0$."
121,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Midterm Exam 1,Binary Arithmetic,1,d,0.9,Text,"Using 8-bit 2's complement encoding, compute $((\sim(0xAB \& 0x55)) / / 0x04) * 0x04$, where "" $\sim$ "" represents bitwise negation, ""\&"" represents a bitwise AND, ""//"" represents integer division (ignores remainder), and ""*” represents multiplication.
For performing // and $*$, the only operations allowed are $>>_{a},>_{1},<<_{1}$ which correspond to arithmetic right shift, logical right shift and logical left shift respectively. Clearly specify which operation to use for performing // and *. Write the intermediate and final answers in 8-bit 2's complement.",Open,"$\sim(0xAB \& 0x55)$: $0b1111\_1110$.
Operation used for performing ""//"": $>>>_{a}$.
Operation used for performing ""* "": ${<<}_{1}$ 
$((\sim(0xAB \& 0x55)) / / 0x04) * 0x04$: $0b1111\_1100$.","Write -3 and -4 in 4-bit 2's complement notation, then add them together using fixed width 2's complement arithmetic. Show your work. Provide your result in binary, and decimal. For each computation also specify whether or not overflow occurred.","Sum in binary: $0b1001$
Sum in decimal: -7
Did overflow occur? (Yes/No): No","Write 7 and 4 in 4-bit 2's complement notation, then add them together using fixed width 2's complement arithmetic. Show your work. Provide your result in binary, and decimal. For each computation also specify whether or not overflow occurred.","Sum in binary: $0b1011$
Sum in decimal: $-5$
Did overflow occur? (Yes/No): Yes","You are given the truth table for a circuit that takes a 3-bit unsigned binary input ( $\mathrm{X}$ $=\mathrm{ABC})$, multiplies it by $2 \bmod 8$ and adds $1 \bmod 8$ to it to produce a 3-bit unsigned binary output $\left(\mathrm{Y}=\mathrm{A}^{\prime} \mathrm{B}^{\prime} \mathrm{C}\right.$ ' $)$.
\begin{tabular}{|c|c|c|c|c|c|}
\hline $\mathrm{A}$ & $\mathrm{B}$ & $\mathrm{C}$ & $\mathrm{A}^{\prime}$ & $\mathrm{B}^{\prime}$ & $\mathrm{C}^{\prime}$ \\
\hline 0 & 0 & 0 & 0 & 0 & 1 \\
\hline 0 & 0 & 1 & 0 & 1 & 1 \\
\hline 0 & 1 & 0 & 1 & 0 & 1 \\
\hline 0 & 1 & 1 & 1 & 1 & 1 \\
\hline 1 & 0 & 0 & 0 & 0 & 1 \\
\hline 1 & 0 & 1 & 0 & 1 & 1 \\
\hline 1 & 1 & 0 & 1 & 0 & 1 \\
\hline 1 & 1 & 1 & 1 & 1 & 1 \\
\hline
\end{tabular}
For the above truth table, write out a minimal sum-of-products for each function $\mathrm{A}^{\prime}(\mathrm{A}, \mathrm{B}, \mathrm{C}), \mathrm{B}^{\prime}(\mathrm{A}, \mathrm{B}, \mathrm{C})$, and $\mathrm{C}^{\prime}(\mathrm{A}, \mathrm{B}, \mathrm{C})$.","Minimal sum-of-products for $A^{\prime}(A, B, C)=$ B.
Minimal sum-of-products for $\mathrm{B}^{\prime}(\mathrm{A}, \mathrm{B}, \mathrm{C})=$ C.
Minimal sum-of-products for $C^{\prime}(A, B, C)=$ 1."
31,Mathematics,18.01,Calculus I,None,None,Problem Set 1,Tangent Lines,14,b,0.07919746568,Text,"The tangent line is closely related to linear approximation. This little problem should help clarify that. Let $f(x)=x^{2}$ and consider the tangent line to the graph at $x=1$. This line has the form $y=L(x)$, and you computed $L(x)$ in the last problem.
Compute $L(1.2)$ and $L(1.4)$. ",Numerical,"At $x=1$, using the results of Problem 13, the tangent line is
$$
L(x)=2 x-1 .
$$
Using $L(x)$ to approximate $f(x)$ :
$$
f(1.2) \approx 2 \times 1.2-1=1.4 \text {, }
$$
and
$$
f(1.4) \approx 2 \times 1.4-1=1.8 \text {. }
$$
These results agree with the linear approximations in part (a), as they should because the tangent line is the linear approximation.","The tangent line is closely related to linear approximation. This little problem should help clarify that. Let $f(x)=x^{2}$ and consider the tangent line to the graph at $x=1$. This line has the form $y=L(x)$, and you computed $L(x)$ in the last problem.
Use the linear approximation of $f$ around $x=1$ to approximate $f(1.2)$ and $f(1.4)$.","The linear approximation to $f(x)=x^{2}$ at $x=1$ is
$$
f(1+\Delta x) \approx 1+2 \Delta x .
$$
Thus,
$$
f(1.2) \approx 1+2 \times 0.2=1.4,
$$
and
$$
f(1.4) \approx 1+2 \times 0.4=1.8.
$$","Let $f(x)=x^{2}$. Compute the tangent line to the graph of $f$ at $x=-1$, at $x=0$, and at $x=1$. Write each line in the form $y=m x+b$. Then sketch the graph of $f(x)$ and the three tangent lines.","With $f(x)=x^{2}, f^{\prime}(x)=2 x$. The equation of the tangent line at $x=a$ is
$$
L(x)=f(a)+f^{\prime}(a)(x-a) .
$$
In $m x+b$ form, it's
$$
L(x)=f_{m}^{\prime}(a) x+\underbrace{\left(f(a)-a f^{\prime}(a)\right)}_{b} .
$$
With $a=-1, f(a)=1$, and $f^{\prime}(a)=-2$. Thus,
$$
L(x)=-2 x+(1-(-1) \times(-2))=-2 x-1 .
$$
With $a=0, f(a)=0$, and $f^{\prime}(a)=0$. Thus, $L(x)=0$.
With $a=1, f(a)=1$, and $f^{\prime}(a)=2$. Thus,
$$
L(x)=2 x-1 .
$$
Here is a graph of $f$ with the three tangent lines below.","Suppose that $L(x)=f(1)+f^{\prime}(1)(x-1)$ is the linear approximation of $f(x)$ around $x=1$. Here is a picture of the graph of $f^{\prime}(x)$ and the graph of $L^{\prime}(x)$ below.
Here $f^{\prime}(1)=10$ and so $L^{\prime}(x)=10$ for all $x$.
Compare your answer to b with the bound from Taylor's theorem.","The bound from Taylor's theorem requires us to find $M$ which is an upper bound for $\left|f^{\prime \prime}(x)\right|$ when $1 \leq x \leq 1.1$. Since the $f^{\prime}$ is steepest when $x=1$, $\left|f^{\prime \prime}(x)\right| \leq\left|f^{\prime \prime}(1)\right| \approx 3$ when $1 \leq x \leq 1.1$. Taylor's theorem gives the error bound of $\frac{1}{2} 3(.1)^{2}=.015$, which is exactly what we obtained in (b)."
138,Mathematics,18.02,Calculus II,18.01,None,Final Exam,Double Integrals,10,nan,1.8,Text,"Set up the integral $\iint_R f(x, y) d A$ where $R$ is the region bounded by the four curves $x^2 y=4, x^2 y=9, \frac{y}{x}=1$, and $\frac{y}{x}=2$ as a double integral in the variables $u=x^2 y$ and $v=\frac{y}{x}$. (Your answer should be completely ready to integrate, once the function $f$ is given.)
Note: the inverse transformation is given by $\quad x=u^{\frac{1}{3}} v^{-\frac{1}{3}}, \quad y=u^{\frac{1}{3}} v^{\frac{2}{3}}$.",Expression,"$$
\int_R f(x, y) d A=i n t_1^2 \int_4^9 f\left(u^{1 / 3} v^{-1 / 3}, u^{1 / 3} v^{2 / 3}\right)\left(\frac{1}{3} u^{-1 / 3} v^{-2 / 3}\right) d u d v
$$","$\iint_R f d A=\int_0^2 \int_{x^2}^{2 \sqrt{2 x}} f(x, y) d y d x$. 
Sketch the region $R$.",The sketch is below.,"$\iint_R f d A=\int_0^2 \int_{x^2}^{2 \sqrt{2 x}} f(x, y) d y d x$. 
Rewrite the double integral as an iterated integral with the order interchanged.","$$
R=\left\{\begin{array}{l}
y^2 / 8 \leq x \leq \sqrt{y} \\
0 \leq y \leq 4
\end{array} \Rightarrow \iint_R f d A=\int_0^4 \int_{y^2 / 8}^{\sqrt{y}} f(x, y) d x d y\right.
$$","Using the coordinate change $u=x y, v=y / x$, set up and evaluate an iterated integral for the moment of inertia around the $z$-axis of the region bounded by the hyperbola $x y=1$, the $x$-axis, and the two lines $x=1$ and $x=2$. Choose the order of integration which makes the limits simplest.","The inertia is
$$
\begin{aligned}
\iint_{R}\left(x^{2}+y^{2}\right) d A &=\iint_{S}\left(\frac{u}{v}+u v\right) \frac{d A}{2 v} \\
&=\frac{1}{2} \int_{0}^{1} \int_{u / 4}^{u}\left(\frac{u}{v^{2}}+u\right) d v d u \\
&=\frac{1}{2} \int_{0}^{1}\left(\frac{3}{4} u^{2}+3\right) d u \\
&=\frac{13}{8} .
\end{aligned}
$$"
84,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Exercise 12,Q-Learning,1,aii,0.01157407407,Text,"Let's simulate the Q-learning algorithm! Assume there are states $(0,1,2,3)$ and actions ('b', 'c'), and discount factor $\gamma=0.9$. Furthermore, assume that all the $\mathrm{Q}$ values are initialized to 0 (for all state-action pairs) and that the learning rate $\alpha=0.5$.
Experience is represented as a list of 4-element tuples: the $t$ th element of the experience corresponds to a record of experience at time $t:\left(s_{t}, a_{t}, s_{t+1}, r_{t}\right)$ (state, action, next state, reward).
After each step $t$, indicate what update $Q\left(s_{t}, a_{t}\right) \leftarrow q$ will be made by the Q learning algorithm based on $\left(s_{t}, a_{t}, s_{t+1}, r_{t}\right)$. You will want to keep track of the overall table $Q\left(s_{t}, a_{t}\right)$ as these updates take place, spanning the multiple parts of this question.
As a reminder, the Q-learning update formula is the following:
$$
Q(s, a) \leftarrow(1-\alpha) Q(s, a)+\alpha\left(r+\gamma \max _{a^{\prime}} Q\left(s^{\prime}, a^{\prime}\right)\right)
$$
You are welcome to do this problem by hand, by drawing a table specifying $Q(s, a)$ for all possible $s$ and $as$. Alternatively, you may write a program which takes in the following history of experience:
experience = [(0, 'b', 2, 0), #t = 0
(2, 'b', 3, 0),
(3, 'b', 0, 2),
(0, 'b', 2, 0), #t = 3
(2, 'b', 3, 0),
(3, 'c', 0, 2),
(0, 'c', 1, 0), #t = 6
(1, 'b', 0, 1),
(0, 'b', 2, 0),
(2, 'c', 3, 0), #t = 9
(3, 'c', 0, 2),
(0, 'c', 1, 0)]
What is the action in the state-action pair that is updated?",Multiple Choice,"b.
Since we observe an experience in state 0, we update the $Q$ value for state 0.","Let's simulate the Q-learning algorithm! Assume there are states $(0,1,2,3)$ and actions ('b', 'c'), and discount factor $\gamma=0.9$. Furthermore, assume that all the $\mathrm{Q}$ values are initialized to 0 (for all state-action pairs) and that the learning rate $\alpha=0.5$.
Experience is represented as a list of 4-element tuples: the $t$ th element of the experience corresponds to a record of experience at time $t:\left(s_{t}, a_{t}, s_{t+1}, r_{t}\right)$ (state, action, next state, reward).
After each step $t$, indicate what update $Q\left(s_{t}, a_{t}\right) \leftarrow q$ will be made by the Q learning algorithm based on $\left(s_{t}, a_{t}, s_{t+1}, r_{t}\right)$. You will want to keep track of the overall table $Q\left(s_{t}, a_{t}\right)$ as these updates take place, spanning the multiple parts of this question.
As a reminder, the Q-learning update formula is the following:
$$
Q(s, a) \leftarrow(1-\alpha) Q(s, a)+\alpha\left(r+\gamma \max _{a^{\prime}} Q\left(s^{\prime}, a^{\prime}\right)\right)
$$
You are welcome to do this problem by hand, by drawing a table specifying $Q(s, a)$ for all possible $s$ and $as$. Alternatively, you may write a program which takes in the following history of experience:
experience = [(0, 'b', 2, 0), #t = 0
(2, 'b', 3, 0),
(3, 'b', 0, 2),
(0, 'b', 2, 0), #t = 3
(2, 'b', 3, 0),
(3, 'c', 0, 2),
(0, 'c', 1, 0), #t = 6
(1, 'b', 0, 1),
(0, 'b', 2, 0),
(2, 'c', 3, 0), #t = 9
(3, 'c', 0, 2),
(0, 'c', 1, 0)]
What is the action of the state-action pair that is updated?","b.
Since action $b$ was used in this experience, we update the Q value for action b.","Let's simulate the Q-learning algorithm! Assume there are states $(0,1,2,3)$ and actions ('b', 'c'), and discount factor $\gamma=0.9$. Furthermore, assume that all the $\mathrm{Q}$ values are initialized to 0 (for all state-action pairs) and that the learning rate $\alpha=0.5$.
Experience is represented as a list of 4-element tuples: the $t$ th element of the experience corresponds to a record of experience at time $t:\left(s_{t}, a_{t}, s_{t+1}, r_{t}\right)$ (state, action, next state, reward).
After each step $t$, indicate what update $Q\left(s_{t}, a_{t}\right) \leftarrow q$ will be made by the Q learning algorithm based on $\left(s_{t}, a_{t}, s_{t+1}, r_{t}\right)$. You will want to keep track of the overall table $Q\left(s_{t}, a_{t}\right)$ as these updates take place, spanning the multiple parts of this question.
As a reminder, the Q-learning update formula is the following:
$$
Q(s, a) \leftarrow(1-\alpha) Q(s, a)+\alpha\left(r+\gamma \max _{a^{\prime}} Q\left(s^{\prime}, a^{\prime}\right)\right)
$$
You are welcome to do this problem by hand, by drawing a table specifying $Q(s, a)$ for all possible $s$ and $as$. Alternatively, you may write a program which takes in the following history of experience:
experience = [(0, 'b', 2, 0), #t = 0
(2, 'b', 3, 0),
(3, 'b', 0, 2),
(0, 'b', 2, 0), #t = 3
(2, 'b', 3, 0),
(3, 'c', 0, 2),
(0, 'c', 1, 0), #t = 6
(1, 'b', 0, 1),
(0, 'b', 2, 0),
(2, 'c', 3, 0), #t = 9
(3, 'c', 0, 2),
(0, 'c', 1, 0)]
Putting it all together, what is the new Q-value for the state-action pair that is updated?","0.
We will make use of the Q-learning update rule for an action $a$ that takes state $s$ to $s^{\prime}$ with reward $r$:
$$
\begin{gathered}
Q(s, a)=(1-\alpha) Q(s, a)+\alpha\left(r+\gamma \max _{a^{\prime}} Q\left(s^{\prime}, a^{\prime}\right)\right) . \\
Q_{n e w}(0, b)=0.5 \cdot Q_{\text {old }}(0, b)+0.5\left(0+0.9 \cdot \max _{a^{\prime}} Q_{\text {old }}\left(2, a^{\prime}\right)\right)=0
\end{gathered}
$$","Let's simulate the Q-learning algorithm! Assume there are states $(0,1,2,3)$ and actions ('b', 'c'), and discount factor $\gamma=0.9$. Furthermore, assume that all the $\mathrm{Q}$ values are initialized to 0 (for all state-action pairs) and that the learning rate $\alpha=0.5$.
Experience is represented as a list of 4-element tuples: the $t$ th element of the experience corresponds to a record of experience at time $t:\left(s_{t}, a_{t}, s_{t+1}, r_{t}\right)$ (state, action, next state, reward).
After each step $t$, indicate what update $Q\left(s_{t}, a_{t}\right) \leftarrow q$ will be made by the Q learning algorithm based on $\left(s_{t}, a_{t}, s_{t+1}, r_{t}\right)$. You will want to keep track of the overall table $Q\left(s_{t}, a_{t}\right)$ as these updates take place, spanning the multiple parts of this question.
As a reminder, the Q-learning update formula is the following:
$$
Q(s, a) \leftarrow(1-\alpha) Q(s, a)+\alpha\left(r+\gamma \max _{a^{\prime}} Q\left(s^{\prime}, a^{\prime}\right)\right)
$$
You are welcome to do this problem by hand, by drawing a table specifying $Q(s, a)$ for all possible $s$ and $as$. Alternatively, you may write a program which takes in the following history of experience:
experience = [(0, 'b', 2, 0), #t = 0
(2, 'b', 3, 0),
(3, 'b', 0, 2),
(0, 'b', 2, 0), #t = 3
(2, 'b', 3, 0),
(3, 'c', 0, 2),
(0, 'c', 1, 0), #t = 6
(1, 'b', 0, 1),
(0, 'b', 2, 0),
(2, 'c', 3, 0), #t = 9
(3, 'c', 0, 2),
(0, 'c', 1, 0)]
t: S A S' R
---------------
1: 2 'b' 3 0
The $t=1$ step of Q-learning will update the Q value of some state-action pair based on the experience tuple $\left(s_{1}, a_{1}, s_{2}, r_{1}\right)$.
After observing this tuple, what is the state of the state-action pair that is updated?","2.
Since we observe an experience in state 2, we update the Q value for state 2."
362,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Problem Set 1,NumPy,1,cvii,0.01157407407,Text,"The shape of the resulting array is different depending on if you use indexing or slicing. Indexing refers to selecting particular elements of an array by using a single number (the index) to specify a particular row or column. Slicing refers to selecting a subset of the array by specifying a range of indices.
If you're unfamiliar with these terms, and the indexing and slicing rules of arrays, please see the indexing and slicing sections of this link: Numpy. Overview (Same as the Numpy Overview link from the introduction). You can also look at the official numpy documentation here.
In the following questions, let A = np.array([[5,7,10,14],[2,4,8,9]]). Tell us what the output would be for each of the following expressions. Use brackets [] as necessary. If the operation is invalid, write the python string ""none"".
Note: Remember that Python uses zero-indexing and thus starts counting from 0, not 1. This is different from R and MATLAB.
Reminder: A = np.array([[5,7,10,14],[2,4,8,9]])
A[:, 1:2]",Expression,"[[7], [4]]","The shape of the resulting array is different depending on if you use indexing or slicing. Indexing refers to selecting particular elements of an array by using a single number (the index) to specify a particular row or column. Slicing refers to selecting a subset of the array by specifying a range of indices.
If you're unfamiliar with these terms, and the indexing and slicing rules of arrays, please see the indexing and slicing sections of this link: Numpy. Overview (Same as the Numpy Overview link from the introduction). You can also look at the official numpy documentation here.
In the following questions, let A = np.array([[5,7,10,14],[2,4,8,9]]). Tell us what the output would be for each of the following expressions. Use brackets [] as necessary. If the operation is invalid, write the python string ""none"".
Note: Remember that Python uses zero-indexing and thus starts counting from 0, not 1. This is different from R and MATLAB.
Reminder: A = np.array([[5,7,10,14],[2,4,8,9]])
A[:, 1]","[7, 4]","The shape of the resulting array is different depending on if you use indexing or slicing. Indexing refers to selecting particular elements of an array by using a single number (the index) to specify a particular row or column. Slicing refers to selecting a subset of the array by specifying a range of indices.
If you're unfamiliar with these terms, and the indexing and slicing rules of arrays, please see the indexing and slicing sections of this link: Numpy. Overview (Same as the Numpy Overview link from the introduction). You can also look at the official numpy documentation here.
In the following questions, let A = np.array([[5,7,10,14],[2,4,8,9]]). Tell us what the output would be for each of the following expressions. Use brackets [] as necessary. If the operation is invalid, write the python string ""none"".
Note: Remember that Python uses zero-indexing and thus starts counting from 0, not 1. This is different from R and MATLAB.
Reminder: A = np.array([[5,7,10,14],[2,4,8,9]])
A[1:,:2]","[[2, 4]]","The shape of the resulting array is different depending on if you use indexing or slicing. Indexing refers to selecting particular elements of an array by using a single number (the index) to specify a particular row or column. Slicing refers to selecting a subset of the array by specifying a range of indices.
If you're unfamiliar with these terms, and the indexing and slicing rules of arrays, please see the indexing and slicing sections of this link: Numpy. Overview (Same as the Numpy Overview link from the introduction). You can also look at the official numpy documentation here.
In the following questions, let A = np.array([[5,7,10,14],[2,4,8,9]]). Tell us what the output would be for each of the following expressions. Use brackets [] as necessary. If the operation is invalid, write the python string ""none"".
Note: Remember that Python uses zero-indexing and thus starts counting from 0, not 1. This is different from R and MATLAB.Reminder: A = np.array([[5,7,10,14],[2,4,8,9]])
A[0:1,1:3]","[[7, 10]]"
10,EECS,6.100A,Introduction to Computer Science Programming in Python,None,None,Finger Exercise Lecture 8,Classes,1,nan,1.428571429,Text,"In this problem, you will implement three classes according to the specification below: one Container class, one Stack class (a subclass of Container), and one Queue class (a subclass of Container). Our Container class will initialize an empty list. The two methods we will have are to calculate the size of the list and to add an element. The second method will be inherited by the two subclasses. We now want to create two subclasses of this generic Container class so that we can add more functionality -- the ability to remove
elements from the list. A Stack and a Queue will add elements to the list in the same way, but will behave differently when removing an element.
A stack is a last in, first out data structure. Think of a stack of pancakes. As you make pancakes, you create a stack of them with older pancakes going on the bottom and newer pancakes on the top. As you start eating the pancakes, you pick one off the top so you are removing the newest pancake added to the stack. When implementing your Stack class, you will have to think about which end of your list contains the element that has been in the list the shortest amount of time. This is the element you will want to remove and return.
A queue is a first in, first out data structure. Think of a store checkout queue. The customer who has been in the line the longest gets the next available cashier. When implementing your Queue class, you will have to think about which end of your list contains the element that has been in the list the longest. This is the element you will want to remove and return.
   class Container(object):
           """"""
           A container object is a list and can store elements of any type
           """"""
           def __init__(self):
                  """"""
                  Initializes an empty list
                  """"""
                  self.myList = []
          def size(self):
                 """"""
                 Returns the length of the container list
                 """"""
                 # Your code here
          def add(self, elem):
                 """"""
                 Adds the elem to one end of the container list, keeping the end
                 you add to consistent. Does not return anything
                 """"""
                 # Your code here
   class Stack(Container):
           """"""
           A subclass of Container. Has an additional method to remove elements.
           """"""
           def remove(self):
                  """"""
                  The newest element in the container list is removed
                  Returns the element removed or None if the queue contains no elements
                  """"""
                  # Your code here",Programming,"class Container(object):
        """"""
        A container object is a list and can store elements of any type
        """"""
        def __init__(self):
               """"""
               Initializes an empty list
               """"""
               self.myList = []
       def size(self):
              """"""
              Returns the length of the container list
              """"""
              # Your code here
              return len(self.myList)
       def add(self, elem):
              """"""
              Adds the elem to one end of the container list, keeping the end
              you add to consistent. Does not return anything
              """"""
              # Your code here
              self.myList.append(elem)
class Stack(Container):
        """"""
        A subclass of Container. Has an additional method to remove elements.
        """"""
        def remove(self):
               """"""
               The newest element in the container list is removed
               Returns the element removed or None if the queue contains no elements
               """"""
               # Your code here
               if self.size() == 0:
                  return None
            return self.myList.pop() ","In this problem, we’ll explore an interesting kind of data structure called a \textit{cycle}. Cycles are like lists in that they represent an ordered collection of elements. Unlike lists, though, cycles have no beginning or end; the elements in a cycle repeat endlessly, with the first element following the last.
For this problem, we will represent cycles as a particular kind of linked list. Similarly to our representation from lab 9, we can represent regular linked lists as two-element Python lists, where the first element represents the first value in the linked list, and where the second element represents the remainder of the linked list (either as None, representing the empty list, or as another linked list). For example, we would represent a linked list containing 1, 1, 2, 3, and 5 (in that order) as: [1, [1, [2, [3, [5, None]]]]].
In our environment diagram notation, this linked list would look like the following.
A \textit{cycle} containing those same elements looks very similar, but with one key difference: the first node in the list follows from the last node, leading to the following circular structure.
Answer the questions on the following pages about various operations on cycles.
We would also like to be able to modify cycles. To this end, we will implement a function delete_node(node), which should mutate the cycle that the given node belongs to (and/or the node itself) such that the node is no longer part of the cycle and the node no longer points back into the cycle. For example, using the test cycle from the previous page, the following REPL transcript shows the desired behavior:
>>> x = next_node(test_cycle)
>>> y = next_node(x)
>>> value(x)
8
>>> delete_node(x)
>>> value(test_cycle)
4
>>> value(next_node(test_cycle))
15
>>> next_node(test_cycle) is y
True
>>> next_node(x) is y
False
Fill in the definition of delete_node below. You may assume that the given node is part of a well-formed, cycle with at least 2 nodes. For full credit, your code should not use any built-in list manipulations, but rather should only use the helper functions defined throughout this problem (you may assume working versions of all helper functions from part 1, and a working version of prev_node).","def delete_node(node):
       set_next(prev_node(node), next_node(node))
       set_next(node, None)","In this problem set, we will be using a provided Node object in tree.py to represent trees.
The following simple tree can be initialized with the Node object as follows:
example_tree = Node(1, Node(2), Node(5, Node(7), Node(8)))
A brief explanation of the Node class is below.
• You can initialize a node with the following Node(value, left_child, right_child). value holds the value held in the node, left_child optionally holds the Node constructing the left subtree, right_child does the same for the right subtree. If there is not a subtree either do not input that parameter or pass in None
• You can get the Node object holding the left or right subtrees with get_left_child() or get_right_child respectively. If there is no child this function returns None.
• You can get the value held by a Node with get_value().
We will practice initializing trees in this part. For the trees shown below, create objects accurately representing the data. Put them into the variables at the top of ps4a.py, named tree1, tree2, and tree3.
tree1 = None #TODO
tree2 = None #TODO
tree3 = None #TODO","tree1 = Node(8, Node(2, Node(1), Node(5)), Node(10)) #TODO
tree2 = Node(7, Node(2, Node(1), Node(5, Node(4), Node(6))), Node(9, Node(8), Node(10))) #TODO
tree3 = Node(5, Node(3, Node(2), Node(4)), Node(14, Node(12), Node(21, Node(19), Node(26)))) #TODO","In this problem, we’ll explore an interesting kind of data structure called a \textit{cycle}. Cycles are like lists in that they represent an ordered collection of elements. Unlike lists, though, cycles have no beginning or end; the elements in a cycle repeat endlessly, with the first element following the last.
For this problem, we will represent cycles as a particular kind of linked list. Similarly to our representation from lab 9, we can represent regular linked lists as two-element Python lists, where the first element represents the first value in the linked list, and where the second element represents the remainder of the linked list (either as None, representing the empty list, or as another linked list). For example, we would represent a linked list containing 1, 1, 2, 3, and 5 (in that order) as: [1, [1, [2, [3, [5, None]]]]].
In our environment diagram notation, this linked list would look like the following.
A \textit{cycle} containing those same elements looks very similar, but with one key difference: the first node in the list follows from the last node, leading to the following circular structure.
Answer the questions on the following pages about various operations on cycles.
Consider the following set of functions designed to operate on linked lists and/or cycles.
def value(node):
      # Return the value associated with the given node
      return node[0]
def next_node(node):
      # Return the node that follows from the given node in the cycle containing
      # that node
      return node[-1]
def set_value(node, val):
       # Mutate the given node such that its value
       node[0] = val
def set_next(node, target):
      # Mutate the first argument (a node) such that it is now followed by the
      # second argument (another node)
      node[-1] = target
def last(inp):
      # Return the last element in a non-cyclic linked list (not expected to work
      # for cycles), without mutating the given input.
      n = next_node(inp)
      if n is None:
           return inp
      return last(n)
def make_cycle(inp):
      # Create a cycle containing all of the elements from the given input (a
      # non-cyclic linked list), without mutating the given input.
      out = inp
      set_next(last(out), out)
      return out
Note that the is keyword can be used to perform an identity check. For example, x is y will evaluate to True if x and y refer to exactly the same object in memory (i.e., if they are aliases of the each other).
Each of the functions on the facing page includes a comment at the top describing its intended behavior. Are all of these functions implemented in ways that are consistent with their stated behavior (from the
comments)?
If not, please specify which functions are inconsistent with their comments, and briefly describe the issue with each:","No.
Most of these functions are indeed completely correct. 
However, there is a slight issue with make_cycle. It produces the correct output, but it also mutates its input, which is inconsistent with the documentation."
615,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Final Exam,Convolutional Neural Networks,8,h,0.35,Text,"MIT grad student Rec Urrent would like to submit an entry to win this year's Grand ML Tetris Competition, which gives awards to the smallest neural networks which can identify tetris pieces with the highest accuracy. Rec seeks to make a convolutional neural network that can accurately classify single-channel $3 \times 3$ images of $2 \mathrm{D}$ tetris pieces as being either a line-shaped piece, or a corner-shaped piece, using just one $2 \times 2$ filter. Let's help Rec win this competition.
If Rec instead labeled line-shaped pieces as ""1"" and corner-shaped pieces as ""0"" then what values of $\mathrm{w}$ and $\mathrm{b}$ of the output layer give perfect classification and outputs that are close to 0 for corners and close to 1 for lines?",Open,The same as above with opposite sign.,"MIT grad student Rec Urrent would like to submit an entry to win this year's Grand ML Tetris Competition, which gives awards to the smallest neural networks which can identify tetris pieces with the highest accuracy. Rec seeks to make a convolutional neural network that can accurately classify single-channel $3 \times 3$ images of $2 \mathrm{D}$ tetris pieces as being either a line-shaped piece, or a corner-shaped piece, using just one $2 \times 2$ filter. Let's help Rec win this competition.
Rec labels corner-shaped tetris pieces as ""1"" and line-shaped tetris pieces as ""0"". Using this labeling, what values of $\mathrm{w}$ and $\mathrm{b}$ of the output layer give perfect classification and outputs that are close to 1 for corners and close to 0 for lines? (Assume the examples in (e) are representative of the entire dataset.)","$\sigma(2.95) \rightarrow 0.95$, so we need to have our output be at least $\sim 3$ for corners and equal to or less than $-3$ for lines. The max and min value of a_sum for lines is 0 and for corners the max is 2 and the min is 1 . Therefore, distance between 0 and 1 needs to be 6 , so we scale by 6 and subtract by 3 . Therefore, $w>6$ with $b=w / 2$. Full credit will be given for ""large and positive"" for $w$ and $b=-w / 2$.","MIT grad student Rec Urrent would like to submit an entry to win this year's Grand ML Tetris Competition, which gives awards to the smallest neural networks which can identify tetris pieces with the highest accuracy. Rec seeks to make a convolutional neural network that can accurately classify single-channel $3 \times 3$ images of $2 \mathrm{D}$ tetris pieces as being either a line-shaped piece, or a corner-shaped piece, using just one $2 \times 2$ filter. Let's help Rec win this competition.
What are dimensions of $\mathrm{w}$ and $\mathrm{b}$ for i) binary classification vs. ii) $k$-class classification? ","For binary classification $\mathrm{w}$ is: $[1,1] \quad$ and $\mathrm{b}$ is: $[1]$.
For $k$-class classification $\mathrm{w}$ is: $[1, \mathrm{k}] \quad$ and $\mathrm{b}$ is: $[\mathrm{k}]$.","MIT grad student Rec Urrent would like to submit an entry to win this year's Grand ML Tetris Competition, which gives awards to the smallest neural networks which can identify tetris pieces with the highest accuracy. Rec seeks to make a convolutional neural network that can accurately classify single-channel $3 \times 3$ images of $2 \mathrm{D}$ tetris pieces as being either a line-shaped piece, or a corner-shaped piece, using just one $2 \times 2$ filter. Let's help Rec win this competition.
Using your answers from above, write an expression for gradient of the loss with respect to $\mathrm{w}$ and $\mathrm{b}$ of the output layer. You may express your answers in terms of a_sum.","$\frac{\partial \mathcal{L}}{\partial w}=z 1_{\text {sum }}(g-y)$.
$\frac{\partial \mathcal{L}}{\partial b}=(g-y)$."
388,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Problem Set 2,Regression,1,c,0.03472222222,Text,"You are given the following data, where $d=1, n=4$.
$$
D=\{[[1], 2],[[2], 7],[[3],-3],[[4], 1]\}
$$
You want to use analytic linear regression to solve the problem.
Using Python and numpy (you might want to fire up a co-lab session), compute the $\theta, \theta_{0}$ that minimize MSE on this data. Provide your answer as a list.
As a reminder, you can use np.linalg.inv to take inverses in numpy.",Open,"[-1.3, 5]","You are given the following data, where $d=1, n=4$.
$$
D=\{[[1], 2],[[2], 7],[[3],-3],[[4], 1]\}
$$
You want to use analytic linear regression to solve the problem.
What is the $Y$ vector? Provide a list of lists that would be an argument to np.array().","[[2, 7, -3, 1]]","You are given the following data, where $d=1, n=4$.
$$
D=\{[[1], 2],[[2], 7],[[3],-3],[[4], 1]\}
$$
You want to use analytic linear regression to solve the problem.
What is the $X$ matrix? Remember to include an extra input dimension that always has the value 1. Provide a list of lists that would be an argument to np. array(), where each data point is a column.","[[1, 2, 3, 4], [1, 1, 1, 1]]","You are given the following data, where $d=1, n=4$.
$$
D=\{[[1], 2],[[2], 7],[[3],-3],[[4], 1]\}
$$
You want to use analytic linear regression to solve the problem.
What is the MSE of the hypothesis you found on the data (any answer within the right order of magnitude will be fine)?",10.575
21,Mathematics,18.2,Principles of Discrete Applied Mathematics,None,18.C06,Problem Set 4,Generating Function,3,nan,2.037037037,Text,"Solve the following recurrence using generating functions:
$$
a_{n}=3 a_{n-1}+4 a_{n-2} \text { for } n \geq 2
$$
with the initial conditions $a_{0}=3, a_{1}=2$.",Open,"We let
$$
A(x)=a_{0}+a_{1} x+a_{2} x^{2}+\ldots=\sum_{i=0}^{\infty} a_{i} x^{i}
$$
be the generating function for our sequence $\left\{a_{i}\right\}_{i \in \mathbb{N}}$. Then we get that
$$
A(x)=3 x A(x)+4 x^{2} A(x)-7 x+3.
$$
Rearranging the terms, we get that
$$
A(x)\left(1-3 x-4 x^{2}\right)=-7 x+3,
$$
or equivalently,
$$
A(x)=\frac{-7 x+3}{1-3 x-4 x^{2}}.
$$
We have the factorization $1-3 x-4 x^{2}=(1-4 x)(1+x)$, so we will get a partial fraction decomposition of the form
$$
A(x)=\frac{A}{1-4 x}+\frac{B}{1+x}.
$$
This tells us that $A+B=3$ and $A-4 B=-7$. Solving these equations, we get $A=1$ and $B=2$, so
$$
A(x)=\frac{1}{1-4 x}+\frac{2}{1+x}.
$$
Recalling that $\frac{1}{1-x}=\sum_{i=0}^{\infty} x^{i}$, we get that
$$
A(x)=\sum_{i=0}^{\infty}\left(4^{i}+2 \times(-1)^{i}\right) x^{i}
$$
Thus, we find that $a_{i}=4^{i}+2 \times(-1)^{i}$.","Find the generating function of the following sequence $\left(a_{n}\right)_{n \geq 0}$, where $a_{0}=1$, $a_{1}=3$, and $a_{n}=6 a_{n-1}-6 a_{n-2}$ for $n \geq 2$. (You do not need to find a formula for $a_{n}$.)","We have that
$$
\begin{aligned}
A(x) & =a_{0}+a_{1} x+a_{2} x^{2}+a_{3} x^{3}+\ldots \\
x A(x) & =0+a_{0} x+a_{1} x^{2}+a_{2} x^{3}+\ldots \\
x^{2} A(x) & =0+0 x+a_{0} x^{2}+a_{1} x^{3}+\ldots \\
\left(1-6 x+6 x^{2}\right) A(x) & =a_{0}+\left(a_{1}-6 a_{0}\right) x=1-3 x \\
A(x) & =\frac{1-3 x}{1-6 x+6 x^{2}}
\end{aligned}
$$","Define the Tribonacci Sequence as $a_{1}=a_{2}=a_{3}=1$ and $a_{n}=a_{n-1}+a_{n-2}+a_{n-3}$ for $n \geq 4$. Prove, using strong induction, that $a_{n}<2^{n}$ for all $n>0$.","We prove, by strong induction, that $(*) a_{n}<2^{n}$.
The base cases for $n \leq 3$ are clearly true. Assume that $\left(^{*}\right)$ holds for $k<n$. Then,
$$
\begin{aligned}
a_{n} & =a_{n-1}+a_{n-2}+a_{n-3} \\
& <2^{n-1}+2^{n-2}+2^{n-3} \\
& =2^{n} \cdot\left(\frac{1}{2}+\frac{1}{4}+\frac{1}{8}\right) \\
& =\frac{7}{8} 2^{n} \\
& <2^{n}
\end{aligned}
$$","In this problem we will be interested in the recurrence
$$
x_{k}=3 x_{k-1}+\beta x_{k-2}
$$
where $\beta$ is a nonnegative parameter to be chosen later.
What is the largest value of $\beta$ for which the recurrence satisfies the growth condition
$$
x_{k} \leq C 4^{k}
$$
for any initial condition? Note: The constant $C$ can depend on the initial condition itself.","Using the expression for $A$ above, we compute the eigenvalues through the trace and determinant. In particular we have $\lambda_{1}+\lambda_{2}=3$ and $\lambda_{1} \lambda_{2}=-\beta$. Substituting for $\lambda_{2}$ we obtain
$$
\lambda_{1}\left(3-\lambda_{1}\right)=-\beta
$$
and using the quadratic equation we obtain
$$
\lambda_{1}=\frac{3 \pm \sqrt{9+4 \beta}}{2}
$$
Thus we get that $\beta \leq 4$ is a necessary condition (since otherwise $\lambda_{1}$ would be too big). We can check that for this value we $\lambda_{2}=-1$ and thus neither eigenvalue is too big. "
9,Mathematics,18.704,Seminar in Algebra,18.701,None,Problem Set 2,Linear Representation,2,nan,1.5,Text,"Let $\rho: G \rightarrow \mathrm{GL}(V)$ be a representation and let
$$
V^{*}:=\left\{v^{*}: V \rightarrow \mathbb{C} \mid v^{*} \text { is linear }\right\}
$$
be the dual of $V$. For $x \in V, x^{*} \in V^{*}$, let $\left\langle x, x^{*}\right\rangle$ denote the value of the linear form $x^{*}$ at $x$. Show that there exists a unique linear representation $\rho^{*}: G \rightarrow \operatorname{GL}\left(V^{*}\right)$ such that
$$
\left\langle\rho_{s} x, \rho_{s}^{*} x^{*}\right\rangle=\left\langle x, x^{*}\right\rangle \quad \text { for } s \in G, x \in V, x^{*} \in V^{*} \text {. }
$$",Open,"Define $\rho^{*}: G \rightarrow \mathrm{GL}\left(V^{*}\right)$ such that $\rho_{s}^{*} x^{*}=x^{*} \circ \rho_{s^{-1}}$.
Claim. $\rho^{*}$ is a representation.
Proof. $\rho_{s}^{*}$ is linear since the scalars can be factered out from the composition, and composition distributes over addition. $\rho_{s}^{*}$ is invertible since it's inverse is $\left(\rho_{s}^{*}\right)^{-1} x^{*}=x^{*} \circ \rho_{s}$. Check:
$$
\begin{aligned}
\left(\left(\rho_{s}^{*}\right)^{-1} \rho_{s}^{*}\right) x^{*} & =\left(\rho_{s}^{*}\right)^{-1}\left(\rho_{s}^{*} x^{*}\right) \\
& =\left(\rho_{s}^{*}\right)^{-1}\left(x^{*} \circ \rho_{s^{-1}}\right) \\
& =x^{*} \circ \rho_{s^{-1}} \circ \rho_{s} \\
& =x^{*} \\
& =x^{*} \circ \rho_{s} \circ \rho_{s^{-1}} \\
& =\rho_{s}^{*}\left(\left(\rho_{s}^{*}\right)^{-1} x^{*}\right) \\
& =\left(\rho_{s}^{*}\left(\rho_{s}^{*}\right)^{-1}\right) x^{*}
\end{aligned}
$$
Thus, $\left(\rho_{s}^{*}\right)^{-1} \rho_{s}^{*}=\mathrm{Id}=\rho_{s}^{*}\left(\rho_{s}^{*}\right)^{-1}$, so $\rho_{s}^{*} \in \mathrm{GL}\left(V^{*}\right)$. The group operation is also preserved.
$$
\begin{aligned}
\left(\rho^{*} g\right)\left(\rho^{*} h\right) x^{*} & =\rho_{g}^{*}\left(x^{*} \circ \rho_{h^{-} 1}\right) \\
& =x^{*} \circ \rho_{h^{-1}} \circ \rho_{g^{-} 1} \\
& =x^{*} \circ\left(\rho_{h^{-1}} \rho_{g^{-1}}\right) \\
& =x^{*} \circ \rho_{(g h)^{-1}} \\
& =\left(\rho^{*}(g h)\right) x^{*}
\end{aligned}
$$
Thus $\rho^{*}$ is a representation.
Claim. $\rho^{*}$ satisfies the given equation.
Proof.
$$
\begin{aligned}
\left\langle\rho_{s} x, \rho_{s}^{*} x^{*}\right\rangle & =\left(\rho_{s}^{*} x^{*}\right)\left(\rho_{s} x\right) \\
& =\left(x^{*} \circ \rho_{s^{-1}}\right)\left(\rho_{s} x\right) \\
& =x^{*} x \\
& =\left\langle x, x^{*}\right\rangle
\end{aligned}
$$
Claim. If there exists a representation that satisfies the equation, then it is unique.
Proof. Suppose that the representations $\rho^{*}$ and $\sigma^{*}$ both satisfy the equation. Then
$$
\left\langle\rho_{s} x, \rho_{s}^{*} x^{*}\right\rangle=\left\langle\rho_{s} x, \sigma_{s}^{*} x^{*}\right\rangle \quad \forall s \in G, x \in V, x^{*} \in V^{*}
$$
Let $x^{\prime}=\rho_{s} x$. Since $\rho_{s}$ is invertible, the equation becomes
$$
\left\langle x^{\prime}, \rho_{s}^{*} x^{*}\right\rangle=\left\langle x^{\prime}, \sigma_{s}^{*} x^{*}\right\rangle \quad \forall s \in G, x^{\prime} \in V, x^{*} \in V^{*}
$$
Applying,
$$
\left(\rho_{s}^{*} x^{*}\right) x^{\prime}=\left(\sigma_{s}^{*} x^{*}\right) x^{\prime} \quad \forall s \in G, x^{\prime} \in V, x^{*} \in V^{*}
$$
Since it's true for all elements in their domains, the functions are equal.
$$
\rho_{s}^{*} x^{*}=\sigma_{s}^{*} x^{*} \quad \forall s \in G, x^{*} \in V^{*}
$$
Since it's true again, the functions are equal.
$$
\rho_{s}^{*}=\sigma_{s}^{*} \quad \forall s \in G
$$
One more time.
$$
\rho^{*}=\sigma^{*}
$$
Thus, the representations are equal, so a representation that satisfies the equation is unique.
Thus the defined $\rho^{*}$ is the unique representation which satisfies the equation.","Let $X$ be a finite set on which $G$ acts. Let $V$ be a vector space with a basis $\left(e_{x}\right)_{x \in X}$ indexed by the elements of $X$. For $g \in G$, let $\rho_{g}$ be the linear map of $V$ into $V$ which sends $e_{x}$ to $e_{g * x}$.
Prove that $g \mapsto \rho_{g}$ defines a representation $\rho$ of $G$. (That is, prove that the map $G \rightarrow \operatorname{GL}(V)$ given by $g \mapsto \rho_{g}$ is a group homomorphism.)","Proof. It suffices to check (i) $\rho_{g} \in G L(V)$ for all $g \in G$ and the homomorphism axioms, namely (ii) $\rho_{1_{G}}=1_{G L(V)}$ and (iii) $\rho_{a b}=\rho_{a} \rho_{b}$ for all $a, b \in G$.
Since $\rho_{g}$ permutes the set $E:=\left\{e_{x} \mid x \in X\right\}$, it maps $E$, which is a basis for $V$, to itself, which is again a basis for $V$. Hence it is inev 2 able and this proves (i).
(ii) is trivial as $\rho_{1}$ acts on $E$, the basis, as identity.
Finally, for (iii), it suffices to note that
$$
\rho_{a b}\left(e_{x}\right)=e_{(a b) * x}=e_{a *(b * x)}=\rho_{a}\left(e_{b * x}\right)=\rho_{a}\left(\rho_{b}\left(e_{x}\right)\right)=\left(\rho_{a} \rho_{b}\right)\left(e_{x}\right), \forall x \in X,
$$
which proves (iii) and thus finishes the proof. ","Let $G$ be a finite abelian group and let $\rho: G \rightarrow \operatorname{GL}(V)$ be any complex representation (""complex representation"" means that $V$ is a $\mathbb{C}$-vector space). Prove that there exists a basis $\mathcal{B}$ of $V$ such that for all $g \in G$, the matrix $[\rho(g)]_{\mathcal{B}}$ is diagonal.","Consider the corresponding $F G$-module $V$ with multiplication $v g=v(g \rho)$ for $v \in V, g \in G$. Since our field is $\mathbb{C}$ and $G$ is finite, we know by Theorem $8.7$ that we can decompose
$$
V=U_{1} \oplus \cdots \oplus U_{n},
$$
where each $U_{i}$ is an irreducible submodule of $V$.
By Theorem 9.5, we know that since $G$ is also abelian, each $U_{i}$ has dimension 1. If we let $U_{i}=\operatorname{span}\left(u_{i}\right)$ for each $i$, then from our definition of direct sum (2.9), we know that $\mathcal{B}=\left\{u_{1}, \ldots, u_{n}\right\}$ forms a basis of $V$.
Returning back to our representation, we consider the matrix of the transformation $g \rho$ for an arbitrary $g \in G$ with respect to $\mathcal{B}$. For $u_{i} \in \mathcal{B}$, since $U_{i}$ is closed (stable), we must have that $u_{i}(g \rho)$ gets sent to a vector also in $U_{i}$, and since $u_{i}$ is the basis vector, we can express the result vector as $\lambda_{i} u_{i}$. Hence the matrix is diagonal:
$$
[g \rho]_{\mathcal{B}}=\left[\begin{array}{lll}
\lambda_{1} & & \\
& \ddots & \\
& & \lambda_{n}
\end{array}\right].
$$","Let $G$ be a finite group and let $G$ act on itself by right multiplication. Let $V$ be a vector space with basis $\left(e_{x}\right)_{x \in G}$ indexed by the elements of $G$. For $g \in G$, let $\rho_{g}$ be the linear map of $V$ into $V$ which sends $e_{x}$ to $e_{x g}$. Recall that we proved on the previous problem set that the $\operatorname{map} \rho: G \rightarrow \operatorname{GL}(V)$ defined as $g \mapsto \rho_{g}$ is a representation of $G$. Prove that the $F G$-module corresponding to $\rho$ (in the sense of Theorem 4.4(1)) is isomorphic to the regular $F G$-module.","Let $\vartheta: V \rightarrow F G$ be the linear map such that $e_{x} \vartheta=x$ for all $x \in G$. This is clearly a bijection, since each basis element in $V$ gets sent to the corresponding basis element in $F G$. Furthermore, we have
$$
\left(e_{x} g\right) \vartheta=\rho_{g}\left(e_{x}\right) \vartheta=e_{x g} \vartheta=x g=\left(e_{x} \vartheta\right) g
$$
for all $g \in G$. Since $\rho_{g}$ and $\vartheta$ are linear, we have $(v g) \vartheta=(v \vartheta) g$ for all $g \in G, v \in V$, so $\vartheta$ is a bijective homomorphism, and $V$ is isomorphic to $F G$. "
42,EECS,6.122,Design and Analysis of Algorithms,6.121,None,Problem Set 4,Probability,2,c,0.2727272727,Text,"Sophie Germain is organizing a dinner party where $n$ guests are seated around a round table with $N=2 n$ seats, numbered 1 through $N$ clockwise.
The guests arrive one by one, and each guest takes his or her seat before the next guest arrives. To optimize the amount of networking between the guests, Sophie has come up with an unusual way of seating them. Namely, to find his or her seat, each guest $i$ first receives a seat number $r_i$ chosen uniformly and independently at random. Then, if seat $r_i$ is not currently occupied, the guest sits there; otherwise, the guest walks clockwise around the table until he or she finds the first unoccupied seat, and sits there.
A block is a set of consecutive seats that are all occupied but with the seats before and after it being unoccupied. Let $p_{j, k}$ be the probability that after all the guests have taken their seats there is a block of length $k$ starting at seat $j$, i.e. that $\{j, \ldots, j+k-1\}$ is a block in the final configuration.
Show that $\operatorname{Pr}\left[E_{j, k}\right] \leq \frac{1}{c^k}$ for some constant $c>1$ independent of the problem parameters. Hint: Consider random variables $X_i$, for each guest $i$, where $X_i=1$ if $r_i \in\{j, \ldots, j+$ $k-1\}$ and $X_i=0$, otherwise; and recall that $e>1$.",Open,"Defining random variables as in the hint, we see that $\mathbb{E}\left[X_i\right]=\frac{k}{N}$ and thus letting $X=X_1+\ldots+X_n$ we have $\mathbb{E}[X]=\frac{n k}{N}=\frac{k}{2}$ by linearity of expectation. We thus want to bound the probability that
$$
\operatorname{Pr}[X \geq k]=\operatorname{Pr}[X \geq(1+1) \mathbb{E}[X]]
$$
We will use (the multiplicative form of) the Chernoff bound for that. Note that since $\beta=1$ here, either the form for $\beta \leq 1$ or $\beta \geq 1$ works here. With this, we get
$$
\operatorname{Pr}[X \geq k] \leq e^{-k / 6}=\frac{1}{\left(e^{1 / 6}\right)^k}
$$
so we can use $c=e^{1 / 6}>1$.","Sophie Germain is organizing a dinner party where $n$ guests are seated around a round table with $N=2 n$ seats, numbered 1 through $N$ clockwise.
The guests arrive one by one, and each guest takes his or her seat before the next guest arrives. To optimize the amount of networking between the guests, Sophie has come up with an unusual way of seating them. Namely, to find his or her seat, each guest $i$ first receives a seat number $r_i$ chosen uniformly and independently at random. Then, if seat $r_i$ is not currently occupied, the guest sits there; otherwise, the guest walks clockwise around the table until he or she finds the first unoccupied seat, and sits there.
A block is a set of consecutive seats that are all occupied but with the seats before and after it being unoccupied. Let $p_{j, k}$ be the probability that after all the guests have taken their seats there is a block of length $k$ starting at seat $j$, i.e. that $\{j, \ldots, j+k-1\}$ is a block in the final configuration.
Let $E_{j, k}$ be the event that at least $k$ of the random numbers $r_1, \ldots, r_n$ given to the guests lie in the set $\{j, \ldots, j+k-1\}$. Argue that $p_{j, k} \leq \operatorname{Pr}\left[E_{j, k}\right]$.","Denote $B=\{j, \ldots, j+k-1\}$. Suppose that $B$ is a block in the final configuration. Then nobody who got an $r_i \notin B$ is sitting in any of the seats $B$. Indeed, otherwise they would have passed seat $j-1$ by, which would mean that there was someone sitting there, whereas we know that seat $j-1$ is empty in the final configuration, and was thus empty during the entire seating process. Thus, all the people sitting in the seats $B$ had their $r_i$ 's in B, which means that there were exactly $k$ of the $r_i{ }^{\prime}$ 's which were in the set $B$. So we showed that the event that $B$ is a block implies that the event $E_{j, k}$ happened, hence $p_{j, k} \leq \operatorname{Pr}\left[E_{j, k}\right]$.","Sophie Germain is organizing a dinner party where $n$ guests are seated around a round table with $N=2 n$ seats, numbered 1 through $N$ clockwise.
The guests arrive one by one, and each guest takes his or her seat before the next guest arrives. To optimize the amount of networking between the guests, Sophie has come up with an unusual way of seating them. Namely, to find his or her seat, each guest $i$ first receives a seat number $r_i$ chosen uniformly and independently at random. Then, if seat $r_i$ is not currently occupied, the guest sits there; otherwise, the guest walks clockwise around the table until he or she finds the first unoccupied seat, and sits there.
A block is a set of consecutive seats that are all occupied but with the seats before and after it being unoccupied. Let $p_{j, k}$ be the probability that after all the guests have taken their seats there is a block of length $k$ starting at seat $j$, i.e. that $\{j, \ldots, j+k-1\}$ is a block in the final configuration.
After all the guests have taken their seats, Sophie finally joins them and heads for her favorite seat (which of course is number 1). However, it is quite possible that by that time there is already somebody sitting there because nobody saved Sophie's favorite seat!
Show that if Sophie follows the same protocol for resolving this problem (i.e., walk clockwise until the first unoccupied seat), with probability at least $1-\frac{1}{N^2}$, the number of the seat she ends up taking will be $O(\log n)$. 
Hint: Prove that with probability at least $1-\frac{1}{N^2}$, there is no block of length $C \cdot \log n$ at the table, for some sufficiently large constant $C$.","The hint asks us to prove a stronger claim than necessary, but in doing so, we'll have solved the original problem with nicer bounds.
Let $q_{j, k}$ denote the probability that there exists a block of length at least $k$ starting at seat $j$. Then,
$$
q_{j, k} \leq \sum_{r=k}^n p_{j, r} \leq \sum_{r=k}^n \frac{1}{c^r} \leq \frac{d}{c^k}
$$
by Union Bound and part (b), where $d=\frac{1}{1-1 / c}$ is a constant.
Let $s_k$ be the probability that there exists a block of length at least $k$ anywhere at the table. Taking another Union Bound over all possible start indices for the block, we have
$$
s_k \leq \sum_{j=1}^N q_{j, k}=N \frac{d}{c^k} .
$$
Plugging in $k=4 \log _c N=O\left(\log n\right.$ ) (or more precisely, $k=3 \log _c N+\log _c d)$, we have
$$
s_{C \log n} \leq \frac{1}{N^2}
$$
for sufficiently large $C$.","Sophie Germain is organizing a dinner party where $n$ guests are seated around a round table with $N=2 n$ seats, numbered 1 through $N$ clockwise.
The guests arrive one by one, and each guest takes his or her seat before the next guest arrives. To optimize the amount of networking between the guests, Sophie has come up with an unusual way of seating them. Namely, to find his or her seat, each guest $i$ first receives a seat number $r_i$ chosen uniformly and independently at random. Then, if seat $r_i$ is not currently occupied, the guest sits there; otherwise, the guest walks clockwise around the table until he or she finds the first unoccupied seat, and sits there.
A block is a set of consecutive seats that are all occupied but with the seats before and after it being unoccupied. Let $p_{j, k}$ be the probability that after all the guests have taken their seats there is a block of length $k$ starting at seat $j$, i.e. that $\{j, \ldots, j+k-1\}$ is a block in the final configuration.
Suppose $n=4$. Given the following sequences $r_i = \left(r_1, r_2, r_3, r_4\right) = (1, 3, 1, 1)$, what is the size of the maximum block?",4
120,EECS,6.122,Design and Analysis of Algorithms,6.121,None,Midterm Exam 2,Linear Programming,3,b,2.5,Text,"Let $G=(V, E)$ be a weighted directed graph, where all weights are non-negative. Let $w_{u v}$ denote the weight of each edge $(u, v) \in E$. Alicia wrote down the following linear program with variables $\left\{x_{v}: v \in V\right\}$ that she claims computes the length of the shortest path from a source vertex $s$ to a target vertex $t$. (By convention, if there is no path from $s$ to $t$, the shortest path length is $\infty$.)
$$
\begin{array}{lll}
\operatorname{maximize} & x_{t} & \\
\text { subject to } & x_{v}-x_{u} \leq w_{u v} & \text { for all edges }(u, v) \in E \\
& x_{v} \geq 0 & \text { for all vertices } v \in V . \\
& x_{s}=0 &
\end{array}
$$
Is Alicia's claim correct? If yes, prove that the optimal solution to her linear program is indeed the length of a shortest path from $s$ to $t$. If not, correct the linear program and prove that your (corrected) LP computes the shortest path length from $s$ to $t$.",Open,"Alicia's claim is correct. The correct linear program for the shortest path somewhat counter-intuitively maximizes $x_{t}$ subject to the given constraints. Think of each edge as a string of length $w_{u v}$. The constraints tell us how far the vertex $v$ can get from the source given the values $x_{u}$ of its in-neighbors and the weights $w_{u v}$ of its in-edges. The problem then is to see how far the target $t$ can get. A rigorous argument follows.
Let $d(u, v)$ denote the length of the shortest path between $u$ and $v$. Then, $x_{u}=d(s, u)$ for all $u$ is a feasible solution to the LP because $x_{v}=d(s, v) \geq 0$ and $x_{s}=d(s, s)=0$.
$x_{u}-x_{v}=d(s, u)-d(s, v) \leq w_{u v}$ because otherwise the path $s \longrightarrow v \longrightarrow u$ would be shorter than $d(s, u)$. As this gives a feasible solution where $x_{t}=d(s, t)$ and this is a maximization LP, we have shown that the optimal $x_{t} \geq d(s, t)$.
Now, we show it must hold that $x_{t} \leq d(s, t)$. If there were a solution with $x_{t}>d(s, t)$ then if $v_{1}, v_{2}, \ldots, v_{n}$ is the shortest path between $s$ and $t$, then
$$
\begin{gathered}
x_{t}=x_{t}-x_{s}=x_{v_{n}}-x_{v_{1}} \\
=\left(x_{v_{n}}-x_{v_{n-1}}\right)+\left(x_{v_{n-1}}-x_{v_{n-2}}\right)+\cdots+\left(x_{v_{2}}-x_{v_{1}}\right) \\
\leq w_{v_{n-1} v_{n}}+w_{v_{n-2} v_{n-1}}+\cdots+w_{v_{1} v_{2}} \\
=d(s, t)
\end{gathered}
$$
We get a contradiction. Therefore, $d(s, t)$ is the optimal value of the LP. ","You are given a weighted directed graph $G=(V, E, w)$ where each node $v$ has a color v.color (which is part of the input). Assume that there are $k$ possible colors and that the weights can be both positive and negative. Describe an algorithm that computes the length of the shortest path from a designated source $s$ to a given destination $t$, where every time the path repeats colors, you incur a cost of $\ell$. Here, we say that a path repeats colors if two consecutive nodes in the path have the same color. So, for example, going RED, BLUE, RED does not repeat colors but going RED, BLUE, BLUE does. You can assume that there is at least one path from $s$ to $t$.
For full credit, provide a short description of the algorithm and an analysis of its run time. The runtime should be expressed in terms of $|V|,|E|$ and/or $k$. Faster algorithms will receive more credit. You can invoke any algorithm discussed in lecture, recitation or p-sets.",Change the weights to add $l$ to the weight of any edge between nodes of the same color. Run BF. The cost is $O(|V| \cdot|E|)$.,"Consider a directed graph $G$ with non-negative weights with two vertices $s$ and $t$ connected via a shortest path $p$ which goes through vertices $a$ and $b$. That is, the path $p$ starts at $s$, eventually reaches $a$, then $b$ and ends at $t$. Which of the following sub-paths are shortest paths as well?
$\mathrm{a} \quad s \rightarrow a$.
$\mathrm{b} \quad a \rightarrow b$.
$\mathrm{c} \quad s \rightarrow b$.
$\mathrm{d} \quad b \rightarrow t$.
$\mathrm{e} \quad a \rightarrow t$.","All of the above.
Indeed, any sub-path of a shortest path is a shortest path. ","Please select True or False for the following.
Suppose that an undirected graph $G=(V, E)$ with positive edge weights has a minimum spanning tree of weight $W$. For all pairs of nodes $u, v \in V$ the shortest path between $u$ and $v$ in $G$ has length less than or equal to $W$.","True. We can walk from any point to any other point using only edges on the MST. The edges we don't use in the MST have total weight greater than or equal to 0, thus the cost of the path we walk is at most $W$."
112,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 3,Propositional Proof,4,bii,0.2232142857,Text,"There are three suspects for a murder: Adams, Brown, and Clark.
1. Adams says ""I didn't do it. The victim was an old acquaintance of Brown's. But Clark hated him.""
2. Brown states ""I didn't do it. I didn't know the guy. Besides I was out of town all week.""
3. Clark says ""I didn't do it. I saw both Adams and Brown in town around the victim that day; one of them must have done it.""
4. We know that exactly one of the suspects is guilty.
Assume that the two innocent people are telling the truth, but that the guilty people might not be. So, the statements from the suspects can be encoded as ""If suspect_is_innocent, then some other facts are true"".
Let the propositional variables have the following definitions:
\begin{itemize}
\item $A=$ Adams is innocent
\item $B=$ Brown is innocent
\item $C=$ Clark is innocent
\item $X=$ Brown knew the victim
\item $Y=$ Brown was out of town
\item $Z=$ Adams was out of town
\item $W=$ Clark hated the victim
\end{itemize}
Now, enter the steps in a valid resolution proof. Each step will indicate the indices of two parent clauses (as integers) and the resolvent clause (as a list of literal strings), e.g. [3, 4, [ $\left.\left.\sim X^{\prime}, ' A^{\prime}\right]\right]$. The resolvent clause in each of the steps entered can be used in subsequent steps by using its index, starting with 13. Indicate a contradiction by entering an empty list for the clause, e.g. [1, 2, [] ]
The entries below illustrate the format; the number of required steps in the proof is not necessarily as indicated.
proof = [
[0, 0, ['A']], # 13
[0, 0, ['B']], # 14
[0, 0, ['C']], # 15
[0, 0, ['D']], # 16
[0, 0, ['E']], # 17
[0, 0, []'], # 18
]",Open,"proof = [[3, 12, [""~X""]], [1, 13, [""~A""]], [4, 12, [""Y""]], [5, 15, [""~C""]], [8, 16, [""A""]], [14, 17, []]]","There are three suspects for a murder: Adams, Brown, and Clark.
1. Adams says ""I didn't do it. The victim was an old acquaintance of Brown's. But Clark hated him.""
2. Brown states ""I didn't do it. I didn't know the guy. Besides I was out of town all week.""
3. Clark says ""I didn't do it. I saw both Adams and Brown in town around the victim that day; one of them must have done it.""
4. We know that exactly one of the suspects is guilty.
Assume that the two innocent people are telling the truth, but that the guilty people might not be. So, the statements from the suspects can be encoded as ""If suspect_is_innocent, then some other facts are true"".
Let the propositional variables have the following definitions:
\begin{itemize}
\item $A=$ Adams is innocent
\item $B=$ Brown is innocent
\item $C=$ Clark is innocent
\item $X=$ Brown knew the victim
\item $Y=$ Brown was out of town
\item $Z=$ Adams was out of town
\item $W=$ Clark hated the victim
\end{itemize}
We will continue our investigation of the Adams, Brown and Clark affair. In this episode, we prove conclusively that Brown is guilty. We will do that by using resolution refutation starting from the set of clauses that we derived in the previous episode.
\begin{tabular}{|l|l|}
\hline 1 & $\neg A \vee X$ \\
\hline 2 & $\neg A \vee W$ \\
\hline 3 & $\neg B \vee \neg X$ \\
\hline 4 & $\neg B \vee Y$ \\
\hline 5 & $\neg C \vee \neg Y$ \\
\hline 6 & $\neg C \vee \neg Z$ \\
\hline 7 & $\neg C \vee \neg A \vee \neg B$ \\
\hline 8 & $A \vee C$ \\
\hline 9 & $A \vee B$ \\
\hline 10 & $B \vee C$ \\
\hline 11 & $A \vee B \vee C$ \\
\hline
\end{tabular}
Note that we have dropped a duplicate clause that we derived from both the third and fourth of the original axioms.
In addition to the clauses derived from the original axioms, what additional clause do we need to add so as to be able to conclude that Brown is guilty using resolution refutation?
Enter clause 12 as a list of literal strings.",['B'],"There are three suspects for a murder: Adams, Brown, and Clark.
1. Adams says ""I didn't do it. The victim was an old acquaintance of Brown's. But Clark hated him.""
2. Brown states ""I didn't do it. I didn't know the guy. Besides I was out of town all week.""
3. Clark says ""I didn't do it. I saw both Adams and Brown in town around the victim that day; one of them must have done it.""
4. We know that exactly one of the suspects is guilty.
Assume that the two innocent people are telling the truth, but that the guilty people might not be. So, the statements from the suspects can be encoded as ""If suspect_is_innocent, then some other facts are true"".
Let the propositional variables have the following definitions:
\begin{itemize}
\item $A=$ Adams is innocent
\item $B=$ Brown is innocent
\item $C=$ Clark is innocent
\item $X=$ Brown knew the victim
\item $Y=$ Brown was out of town
\item $Z=$ Adams was out of town
\item $W=$ Clark hated the victim
\end{itemize}
We can write down propositional logic axioms for each of the four statements defining this problem. For propositional resolution, we need to convert these sentences to CNF. We will ask you to convert one sentence at a time. Enter one CNF formula corresponding to the specified sentence in each of the answer spaces below.
Enter each CNF formula as a list of lists of literal strings. A literal string is either a propositional symbol, e.g. 'A' or the negation of a propositional symbol, e.g. ' $A$ '. A typical clause will look like: $\left[{ }^{\prime} A ', ' \sim B\right.$ ', ' $\left.\sim C '\right]$. And a CNF formula is a list of clauses. Do not include any spaces in the strings. 
The second axiom is: $B \Rightarrow(\neg X \wedge Y)$
Enter the CNF as a formula following the syntax described above.","[['~B', '~X'], ['~B', 'Y']]","There are three suspects for a murder: Adams, Brown, and Clark.
1. Adams says ""I didn't do it. The victim was an old acquaintance of Brown's. But Clark hated him.""
2. Brown states ""I didn't do it. I didn't know the guy. Besides I was out of town all week.""
3. Clark says ""I didn't do it. I saw both Adams and Brown in town around the victim that day; one of them must have done it.""
4. We know that exactly one of the suspects is guilty.
Assume that the two innocent people are telling the truth, but that the guilty people might not be. So, the statements from the suspects can be encoded as ""If suspect_is_innocent, then some other facts are true"".
Let the propositional variables have the following definitions:
\begin{itemize}
\item $A=$ Adams is innocent
\item $B=$ Brown is innocent
\item $C=$ Clark is innocent
\item $X=$ Brown knew the victim
\item $Y=$ Brown was out of town
\item $Z=$ Adams was out of town
\item $W=$ Clark hated the victim
\end{itemize}
We can write down propositional logic axioms for each of the four statements defining this problem. For propositional resolution, we need to convert these sentences to CNF. We will ask you to convert one sentence at a time. Enter one CNF formula corresponding to the specified sentence in each of the answer spaces below.
Enter each CNF formula as a list of lists of literal strings. A literal string is either a propositional symbol, e.g. 'A' or the negation of a propositional symbol, e.g. ' $A$ '. A typical clause will look like: $\left[{ }^{\prime} A ', ' \sim B\right.$ ', ' $\left.\sim C '\right]$. And a CNF formula is a list of clauses. Do not include any spaces in the strings. 
The first axiom is: $A \Rightarrow(X \wedge W)$
Enter the CNF as a formula following the syntax described above.","[['~A', 'X'], ['~A', 'W']]"
16,Mathematics,18.03,Differential Equations,None,18.02,Problem Set 2,Complex Numbers,2,b,0.1608579088,Text,"Express the following complex numbers in polar form $r e^{i \theta}$ with $\theta \in(-\pi, \pi]$.
$1-i$.",Expression,The modulus is $|1-i|=\sqrt{1^{2}+(-1)^{2}}=\sqrt{2}$. The argument is $\arctan \frac{-1}{1}=\frac{7 \pi}{4}$. So $1-i=\sqrt{2} e^{i \frac{7 \pi}{4}}$.,"Express the following complex numbers in polar form $r e^{i \theta}$ with $\theta \in(-\pi, \pi]$.
$1+i \sqrt{3}$.",The modulus is $|1+i \sqrt{3}|=\sqrt{1^{2}+\sqrt{3}^{2}}=\sqrt{4}=2$. The $\operatorname{argument}$ is $\arctan \frac{\sqrt{3}}{1}=$ $\frac{\pi}{3}$. So $1+i \sqrt{3}=2 e^{i \frac{\pi}{3}}$.,"Compute the real and imaginary parts of the following complex numbers. Simplify as much as possible.
$1+e^{-\frac{\pi i}{6}}$.","$$
\begin{gathered}
1+e^{-\frac{\pi i}{6}}=1+\cos \left(-\frac{\pi}{6}\right)+i \sin \left(-\frac{\pi}{6}\right)=1+\frac{\sqrt{3}}{2}-i \frac{1}{2} \\
\operatorname{Re}\left(1+e^{-\frac{\pi i}{6}}\right)=1+\frac{\sqrt{3}}{2}, \quad \operatorname{Im}\left(1+e^{-\frac{\pi i}{6}}\right)=-\frac{1}{2}
\end{gathered}
$$","Answer the following questions without the use of a calculator or computer. Briefly explain your answers.
Determine the real and imaginary parts of $1 /\left(e^{j 3 \pi / 4}+\frac{1}{\sqrt{2}} e^{j \pi / 2}\right)$.","We can simplify the denominator by converting each of the complex exponentials to cartesian form:
$$
\frac{1}{e^{j 3 \pi / 4}+\frac{1}{\sqrt{2}} e^{j \pi / 2}}=\frac{1}{-\frac{1}{\sqrt{2}}+\frac{j}{\sqrt{2}}+\frac{j}{\sqrt{2}}}=\frac{1}{\frac{-1+2 j}{\sqrt{2}}}=\frac{\sqrt{2}}{-1+2 j} .
$$
Then multiply by $\frac{-1-2 j}{-1-2 j}$ to make the denominator real:
$$
\left(\frac{\sqrt{2}}{-1+2 j}\right)\left(\frac{-1-2 j}{-1-2 j}\right)=-\frac{\sqrt{2}}{5}(1+2 j)
$$
Thus the real part is $-\frac{\sqrt{2}}{5}$ and the imaginary part is $-\frac{2 \sqrt{2}}{5}$."
32,Mathematics,18.2,Principles of Discrete Applied Mathematics,None,18.C06,Problem Set 6,Linear Program,2,c,0.6790123457,Text,"Consider the LP
$$
\begin{aligned}
\max & 4 x_{1}+x_{2} \\
\text { s.t. } & x_{1}-x_{2} \leq 2 \\
& x_{1}+x_{2} \leq 8 \\
& x_{1}, x_{2} \geq 0
\end{aligned}
$$
Write the dual LP for the original problem in $x_{1}, x_{2}$, and use complementary slackness to determine the optimal solution for this dual.",Expression,"The dual LP is given by
$$
\begin{array}{cl}
\min & 2 y_{1}+8 y_{2} \\
\text { s.t. } & y_{1}+y_{2} \geq 4 \\
& -y_{1}+y_{2} \geq 1 \\
& y_{1}, y_{2} \geq 0 .
\end{array}
$$
The optimum value of the original problem will be achieved at one of the vertices of its feasible region. Testing all four vertices, one gets that the optimal value of 23 at $\left(x_{1}, x_{2}\right)=(5,3)$. We have that $x_{1}-x_{2}=2$ and $x_{1}+x_{2}=8$, so we don't need the $y_{i}$ to be zero. Since $x_{1}$ and $x_{2}$ are nonzero, we must have $y_{1}+y_{2}=4$ and $-y_{1}+y_{2}=1$. Solving this gives us $y_{1}=3 / 2$ and $y_{2}=5 / 2$.","Consider the LP
$$
\begin{aligned}
\max & 4 x_{1}+x_{2} \\
\text { s.t. } & x_{1}-x_{2} \leq 2 \\
& x_{1}+x_{2} \leq 8 \\
& x_{1}, x_{2} \geq 0
\end{aligned}
$$
Convert the linear program to standard form, and construct a basic feasible solution.","Adding slack variables $s_{1}$ and $s_{2}$ to the first and second equations respectively, we get
$$
\begin{aligned}
\max & 4 x_{1}+x_{2} \\
\text { s.t. } & x_{1}-x_{2}+s_{1}=2 \\
& x_{1}+x_{2}+s_{2}=8 \\
& x_{1}, x_{2}, s_{1}, s_{2} \geq 0
\end{aligned}
$$
If we take the basis consisting of $s_{1}$ and $s_{2}$, then we get a basic feasible solution with $\left(x_{1}, x_{2}, s_{1}, s_{2}\right)=(0,0,2,8)$.","Consider the LP
$$
\begin{aligned}
\max & 4 x_{1}+x_{2} \\
\text { s.t. } & x_{1}-x_{2} \leq 2 \\
& x_{1}+x_{2} \leq 8 \\
& x_{1}, x_{2} \geq 0
\end{aligned}
$$
Draw a graphical representation of the feasible region of this LP (in terms of $x_{1}$ and $\left.x_{2}\right)$.","The region given by the constraints is the quadrilateral with vertices $(0,0),(0,8),(5,3)$, and $(2,0)$.","Consider the following linear program and its dual
$$
\begin{array}{ccrl}
\operatorname{maximize} & 6 x+6 y & \text { minimize } & a+2 b \\
\text { subject to } & x+2 y=1 & \text { subject to } & a+3 b \geq 6, \\
& 3 x+y=2, & & 2 a+b \geq 6, \\
& x, y \geq 0, & &
\end{array}
$$
Suppose we add the constraint $a+b \geq 4$ to the dual. Fill in the corresponding primal
$$
\begin{array}{r}
\text { maximize } \\
\text { subject to }
\end{array}
$$
$$
\begin{array}{cc}
\operatorname{minimize} & a+2 b \\
\text { subject to } & a+3 b \geq 6, \\
& 2 a+b \geq 6, \\
& a+b \geq 4,
\end{array}
$$","The new primal and dual are
$$
\begin{aligned}
& \text { maximize } 6 x+6 y+4 z \quad \text { minimize } a+2 b \\
& \text { subject to } x+2 y+z=1 \quad \text { subject to } a+3 b \geq 6 \text {, } \\
& 3 x+y+z=2 \quad 2 a+b \geq 6 . \\
& x, y, z \geq 0, \quad a+b \geq 4,
\end{aligned}
$$"
148,Mathematics,18.6,Probability and Random Variables,18.02,None,Final Exam,Central Limit Theorem,5,b,1.25,Text,"In this problem, we'll try to approximate $\pi$ by throwing darts at a dartboard. To do this, suppose we have a square dartboard with sides of length 5. Inside it, we'll draw a circle with radius 1.
When I throw a dart, suppose that the spot where it hits is uniformly distributed over the dartboard. The probability that it lands inside the circle is thus given by
$$
\mathrm{P}(\text { lands in circle })=\frac{\text { Area }(\text { circle })}{\text { Area }(\text { dartboard })}=\frac{\pi}{25} .
$$
Use the Central Limit Theorem to approximate the probability that $Z \in[\pi-0.1, \pi+$ 0.1]. Write your answer in terms of $\Phi(x)$, the CDF of a standard normal.",Expression,"Let $\sigma=\sqrt{\operatorname{Var}(Z)}$, (using the value we computed in part (a)). By the Central Limit Theorem, we can approximate $Z$ by a normal with parameters $\left(\mu, \sigma^{2}\right)$, and thus $(Z-\pi) / \sigma$ is approximately a standard normal. This gives us
$$
\begin{aligned}
P(Z \in[\pi-0.1, \pi+0.1]) & =P\left(\frac{Z-\pi}{\sigma} \in\left[\frac{-0.1}{\sigma}, \frac{0.1}{\sigma}\right]\right) \approx \Phi\left(\frac{0.1}{\sigma}\right)-\Phi\left(\frac{-0.1}{\sigma}\right) \\
& =2 \Phi\left(\frac{0.1}{\sigma}\right)-1.
\end{aligned}
$$","In this problem, we'll try to approximate $\pi$ by throwing darts at a dartboard. To do this, suppose we have a square dartboard with sides of length 5. Inside it, we'll draw a circle with radius 1.
When I throw a dart, suppose that the spot where it hits is uniformly distributed over the dartboard. The probability that it lands inside the circle is thus given by
$$
\mathrm{P}(\text { lands in circle })=\frac{\text { Area }(\text { circle })}{\text { Area }(\text { dartboard })}=\frac{\pi}{25} .
$$
Suppose I throw 1000 darts independently, and I let
$$
X_{i}= \begin{cases}1 & \text { if the } i^{\text {th }} \text { dart lands in the circle, and } \\ 0 & \text { otherwise. }\end{cases}
$$
My estimate of $\pi$ will be given by
$$
Z=\left(X_{1}+X_{2}+\cdots+X_{1000}\right) / 40
$$
Compute the expectation and variance of $Z$.","$$
E[Z]=\frac{1}{40} \sum_{i=1}^{1000} E\left[X_{i}\right]=\frac{1000}{40} \frac{\pi}{25}=\pi.
$$
$X_{i}$ is a Bernoulli random variable with parameter $\pi / 25$, so
$$
\operatorname{Var}\left(X_{i}\right)=\left(\frac{\pi}{25}\right)\left(1-\frac{\pi}{25}\right).
$$
Since the $X_{i}$ are independent, we have
$$
\begin{aligned}
\operatorname{Var}(Z) & =\operatorname{Var}\left(\frac{\sum_{i=1}^{1000} X_{i}}{40}\right)=\frac{1}{40^{2}} \sum_{i=1}^{1000} \operatorname{Var}\left(X_{i}\right) \\
& =\frac{1000}{40^{2}}\left(\frac{\pi}{25}\right)\left(1-\frac{\pi}{25}\right)=\frac{\pi}{40}\left(1-\frac{\pi}{25}\right).
\end{aligned}
$$","In this problem, we'll try to approximate $\pi$ by throwing darts at a dartboard. To do this, suppose we have a square dartboard with sides of length 5. Inside it, we'll draw a circle with radius 1.
When I throw a dart, suppose that the spot where it hits is uniformly distributed over the dartboard. The probability that it lands inside the circle is thus given by
$$
\mathrm{P}(\text { lands in circle })=\frac{\text { Area }(\text { circle })}{\text { Area }(\text { dartboard })}=\frac{\pi}{25} .
$$
Suppose that I drew two overlapping radius 1 circles, $C_{1}$ and $C_{2}$, on the dartboard. Let
$$
Y_{i}= \begin{cases}1 & \text { if the } i^{\text {th }} \text { dart lands in } C_{1}, \text { and } \\ 0 & \text { otherwise }\end{cases}
$$
and let
$$
Z_{i}= \begin{cases}1 & \text { if the } i^{\text {th }} \text { dart lands in } C_{2}, \text { and } \\ 0 & \text { otherwise }\end{cases}
$$
Let $t=\operatorname{area}\left(C_{1} \cap C_{2}\right)$. Compute $\operatorname{Cov}\left(Y_{i}, Z_{i}\right)$.","Note that the variable $Y_{i} Z_{i}$ is 1 if the dart lands in both circles and 0 otherwise. It has expected value $t / 25$. We therefore have
$$
\operatorname{Cov}\left(Y_{i}, Z_{i}\right)=E\left[Y_{i} Z_{i}\right]-E\left[Y_{i}\right] E\left[Z_{i}\right]=\frac{t}{25}-\left(\frac{\pi}{25}\right)^{2}.
$$","In this problem, we'll try to approximate $\pi$ by throwing darts at a dartboard. To do this, suppose we have a square dartboard with sides of length 5. Inside it, we'll draw a circle with radius 1.
When I throw a dart, suppose that the spot where it hits is uniformly distributed over the dartboard. The probability that it lands inside the circle is thus given by
$$
\mathrm{P}(\text { lands in circle })=\frac{\text { Area }(\text { circle })}{\text { Area }(\text { dartboard })}=\frac{\pi}{25} .
$$
Is there some $t$ for which $Y_{i}$ and $Z_{i}$ are independent? If so, you now get two independent variables with just one dart. Does this mean that you can get as good an estimate as in parts (a) and (b) while only throwing 500 darts? And, if so, could you get the same quality estimate by drawing 1000 circles and just throwing 1 dart? Why or why not?","Yes, there is such a value. Indicator variables are independent when the associated events are independent, i.e., when
$$
P\left(\text { dart lands in } C_{1} \cap C_{2}\right)=P\left(\text { dart lands in } C_{1}\right) P\left(\text { dart lands in } C_{2}\right) \text {. }
$$
The left-hand side equals $t / 25$, and the right-hand side equals $(\pi / 25)^{2}$, so this occurs when $t=\pi^{2} / 25$. (One needs to check that it is possible to achieve this intersection. This is possible since we can achieve any $t$ between 0 and $\pi$, and $t \approx 0.395$.)
This actually does mean that you can get the same quality estimate by throwing only 500 darts. However, you can't just draw 1000 circles and throw 1 dart, because it won't be possible to make all 1000 events independent. You can't even do it with 3 circles. To see this, note that if you take three circles $C_{1}, C_{2}$, and $C_{3}$ and make
$$
\operatorname{area}\left(C_{1} \cap C_{2}\right)=\operatorname{area}\left(C_{1} \cap C_{3}\right)=\operatorname{area}\left(C_{2} \cap C_{3}\right)=t,
$$
this determines the area $A=C_{1} \cap C_{2} \cap C_{3}$. If the three corresponding events were independent, we'd need $A=\left(\frac{\pi}{25}\right)^{3}$, and it doesn't equal this value. (And, in fact, you can't even draw 4 circles such that the area of $C_{i} \cap C_{j}$ equals $t$ for all $i$ and $j$.) "
422,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Problem Set 2,Regression,6,a,0.05208333333,Text,"We will now try to synthesize what we've learned in order to perform ridge regression on the DataCommons public health dataset that we explored in Lab 2. Unlike in Lab 2, where we did some simple linear regressions, here we now employ and explore regularization, with the goal of building a model which generalizes better (than without regularization) to unseen data.
The overall objective function for ridge regression is
$$
J_{\text {ridge }}\left(\theta, \theta_{0}\right)=\frac{1}{n} \sum_{i=1}^{n}\left(\theta^{T} x^{(i)}+\theta_{0}-y^{(i)}\right)^{2}+\lambda\|\theta\|^{2}
$$
Remarkably, there is an analytical function giving $\Theta=\left(\theta, \theta_{0}\right)$ which minimizes this objective, given $X, Y$, and $\lambda$. But how should we choose $\lambda$?
To choose an optimum $\lambda$, we can use the following approach. Each particular value of $\lambda$ gives us a different linear regression model. And we want the best model: one which balances providing good predictions (fitting well to given training data) with generalizing well (avoiding overfitting training data). And as we saw in the notes on Regression, we can employ cross-validation to evaluate and compare different models.
Let us begin by implementing this algorithm for cross-validation:
CROSS-VALIDATE $(\mathcal{D}, k)$
1 divide $\mathcal{D}$ into $k$ chunks $\mathcal{D}_{1}, \mathcal{D}_{2}, \ldots \mathcal{D}_{k}$ (of roughly equal size)
2 for $i=1$ to $k$
3 train $h_{i}$ on $\mathcal{D} \backslash \mathcal{D}_{i}$ (withholding chunk $\mathcal{D}_{i}$ )
4 compute ""test"" error $\mathcal{E}_{\mathfrak{i}}\left(h_{i}\right)$ on withheld data $\mathcal{D}_{i}$
5 return $\frac{1}{k} \sum_{i=1}^{k} \varepsilon_{i}\left(h_{i}\right)$
Let's implement the cross-validation algorithm as the procedure cross_validate, which takes the following input arguments:
\begin{itemize}
\item $\mathrm{x}$ : the list of data points $(d \times n)$
\item $\mathrm{Y}$ : the true values of the responders $(1 \times n)$
\item n_splits: the number of chunks to divide the dataset into
\item lam: the regularization parameter
\item learning_algorithm: a function that takes $X, Y$, and 1 lam, and returns th, th $\theta$
\item loss_function: a function that takes $X, Y$, th, and th $\theta$, and returns a $1 \times 1$ array
\end{itemize}
cross_validate should return a scalar, the cross-validation error of applying the learning algorithm on the list of data points.
Note that this is a generic version of cross-validation, that can be applied to any learning algorithm and any loss function. Later in this problem, we will use cross-validation specifically for ridge regression and mean square loss.
You have the following function available to you:
def make_splits(X, Y, n_splits):
'''
Splits the dataset into n_split chunks, creating n_split sets of
cross-validation data.
Returns a list of n_split tuples (X_train, Y_train, X_test, Y_test).
For the ith returned tuple:
*X_train and Y_train include all data except the ith chunk, and
* X_test and Y_test are the ith chunk.
X : d x n numpy array (d = #features, n = #data points)
Y : 1 x n numpy array
n_splits : integer
'''
def cross_validate(X, Y, n_splits, lam,
learning_algorithm, loss_function):
pass",Programming,"def cross_validate(X, Y, n_splits, lam,
learning_algorithm, loss_function):
test_errors = []
for (X_train, Y_train, X_test, Y_test) in make_splits(X, Y, n_splits):
th, th0 = learning_algorithm(X_train, Y_train, lam)
test_errors.append(loss_function(X_test, Y_test, th, th0))
return np.array(test_errors).mean()","We will now try to synthesize what we've learned in order to perform ridge regression on the DataCommons public health dataset that we explored in Lab 2. Unlike in Lab 2, where we did some simple linear regressions, here we now employ and explore regularization, with the goal of building a model which generalizes better (than without regularization) to unseen data.
The overall objective function for ridge regression is
$$
J_{\text {ridge }}\left(\theta, \theta_{0}\right)=\frac{1}{n} \sum_{i=1}^{n}\left(\theta^{T} x^{(i)}+\theta_{0}-y^{(i)}\right)^{2}+\lambda\|\theta\|^{2}
$$
Remarkably, there is an analytical function giving $\Theta=\left(\theta, \theta_{0}\right)$ which minimizes this objective, given $X, Y$, and $\lambda$. But how should we choose $\lambda$?
To choose an optimum $\lambda$, we can use the following approach. Each particular value of $\lambda$ gives us a different linear regression model. And we want the best model: one which balances providing good predictions (fitting well to given training data) with generalizing well (avoiding overfitting training data). And as we saw in the notes on Regression, we can employ cross-validation to evaluate and compare different models.
Let us begin by implementing this algorithm for cross-validation:
CROSS-VALIDATE $(\mathcal{D}, k)$
1 divide $\mathcal{D}$ into $k$ chunks $\mathcal{D}_{1}, \mathcal{D}_{2}, \ldots \mathcal{D}_{k}$ (of roughly equal size)
2 for $i=1$ to $k$
3 train $h_{i}$ on $\mathcal{D} \backslash \mathcal{D}_{i}$ (withholding chunk $\mathcal{D}_{i}$ )
4 compute ""test"" error $\mathcal{E}_{\mathfrak{i}}\left(h_{i}\right)$ on withheld data $\mathcal{D}_{i}$
5 return $\frac{1}{k} \sum_{i=1}^{k} \varepsilon_{i}\left(h_{i}\right)$
Below, X and Y are sample data, and lams is a list of possible values of lambda. Write code to set errors as a list of corresponding cross-validation errors. Use the cross_validate function above to run cross-validation with three splits. Use the following functions (which we implement for you, per the specifications below) as the learning algorithm and loss function:
def ridge_analytic(X_train, Y_train, lam):
'''Applies analytic ridge regression on the given training data.
Returns th, th0.
X : d x n numpy array (d = # features, n = # data points)
Y : 1 x n numpy array
lam : (float) regularization strength parameter
th : d x 1 numpy array
th0 : 1 x 1 numpy array'''
def mse(x, y, th, th0):
'''Calculates the mean-squared loss of a linear regression.
Returns a scalar.
x : d x n numpy array
y : 1 x n numpy array
th : d x 1 numpy array
th0 : 1 x 1 numpy array'''
X = np.array([[4, 6, 8, 2, 9, 10, 11, 17],
[1, 1, 6, 0, 5, 8, 7, 9],
[2, 2, 2, 6, 7, 4, 9, 8],
[1, 2, 3, 4, 5, 6, 7, 8]])
Y = np.array([[1, 3, 3, 4, 7, 6, 7, 7]])
lams = [0, 0.01, 0.02, 0.1]
errors = [] # your code here","X = np.array([[4, 6, 8, 2, 9, 10, 11, 17],
[1, 1, 6, 0, 5, 8, 7, 9],
[2, 2, 2, 6, 7, 4, 9, 8],
[1, 2, 3, 4, 5, 6, 7, 8]])
Y = np.array([[1, 3, 3, 4, 7, 6, 7, 7]])
lams = [0, 0.01, 0.02, 0.1]
errors = [cross_validate(X, Y, 3, lam, ridge_analytic, mse) for lam in lams]","We will now try to synthesize what we've learned in order to perform ridge regression on the DataCommons public health dataset that we explored in Lab 2. Unlike in Lab 2, where we did some simple linear regressions, here we now employ and explore regularization, with the goal of building a model which generalizes better (than without regularization) to unseen data.
The overall objective function for ridge regression is
$$
J_{\text {ridge }}\left(\theta, \theta_{0}\right)=\frac{1}{n} \sum_{i=1}^{n}\left(\theta^{T} x^{(i)}+\theta_{0}-y^{(i)}\right)^{2}+\lambda\|\theta\|^{2}
$$
Remarkably, there is an analytical function giving $\Theta=\left(\theta, \theta_{0}\right)$ which minimizes this objective, given $X, Y$, and $\lambda$. But how should we choose $\lambda$?
To choose an optimum $\lambda$, we can use the following approach. Each particular value of $\lambda$ gives us a different linear regression model. And we want the best model: one which balances providing good predictions (fitting well to given training data) with generalizing well (avoiding overfitting training data). And as we saw in the notes on Regression, we can employ cross-validation to evaluate and compare different models.
Let us begin by implementing this algorithm for cross-validation:
CROSS-VALIDATE $(\mathcal{D}, k)$
1 divide $\mathcal{D}$ into $k$ chunks $\mathcal{D}_{1}, \mathcal{D}_{2}, \ldots \mathcal{D}_{k}$ (of roughly equal size)
2 for $i=1$ to $k$
3 train $h_{i}$ on $\mathcal{D} \backslash \mathcal{D}_{i}$ (withholding chunk $\mathcal{D}_{i}$ )
4 compute ""test"" error $\mathcal{E}_{\mathfrak{i}}\left(h_{i}\right)$ on withheld data $\mathcal{D}_{i}$
5 return $\frac{1}{k} \sum_{i=1}^{k} \varepsilon_{i}\left(h_{i}\right)$
As the number of data points increases,
We tend to see:
(a) The optimal increase
(b) The optimal decrease
(c) The minimum cross-validation error increase
(d) The minimum cross-validation error decrease","(b) The optimal decrease
(d) The minimum cross-validation error decrease","We will now try to synthesize what we've learned in order to perform ridge regression on the DataCommons public health dataset that we explored in Lab 2. Unlike in Lab 2, where we did some simple linear regressions, here we now employ and explore regularization, with the goal of building a model which generalizes better (than without regularization) to unseen data.
The overall objective function for ridge regression is
$$
J_{\text {ridge }}\left(\theta, \theta_{0}\right)=\frac{1}{n} \sum_{i=1}^{n}\left(\theta^{T} x^{(i)}+\theta_{0}-y^{(i)}\right)^{2}+\lambda\|\theta\|^{2}
$$
Remarkably, there is an analytical function giving $\Theta=\left(\theta, \theta_{0}\right)$ which minimizes this objective, given $X, Y$, and $\lambda$. But how should we choose $\lambda$?
To choose an optimum $\lambda$, we can use the following approach. Each particular value of $\lambda$ gives us a different linear regression model. And we want the best model: one which balances providing good predictions (fitting well to given training data) with generalizing well (avoiding overfitting training data). And as we saw in the notes on Regression, we can employ cross-validation to evaluate and compare different models.
Let us begin by implementing this algorithm for cross-validation:
CROSS-VALIDATE $(\mathcal{D}, k)$
1 divide $\mathcal{D}$ into $k$ chunks $\mathcal{D}_{1}, \mathcal{D}_{2}, \ldots \mathcal{D}_{k}$ (of roughly equal size)
2 for $i=1$ to $k$
3 train $h_{i}$ on $\mathcal{D} \backslash \mathcal{D}_{i}$ (withholding chunk $\mathcal{D}_{i}$ )
4 compute ""test"" error $\mathcal{E}_{\mathfrak{i}}\left(h_{i}\right)$ on withheld data $\mathcal{D}_{i}$
5 return $\frac{1}{k} \sum_{i=1}^{k} \varepsilon_{i}\left(h_{i}\right)$
Based on our observations, does regularization have a larger effect when we have more or less data?
Regularization is much more important when we have:
(a) more data
(b) less data
(c) around the same for both",(b) less data
303,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Lab 12,Reinforcement Learning,2,av,0.04166666667,Text,"Now, we'll take a look at Q-learning in a simple 2D grid setting but with a single goal location. We'll adopt the same state space and action space as in MDP lab.
Specifically, our state space is a 10-by-10 grid, with the bottom-left state indexed as state $(0,0)$, and our four possible actions are moving North, South, East or West (note that if the robot tries to move off the board, it cannot; it just stays in the same state). Our single goal is at state $(3,6)$.
Remember that for Q-learning, the transition probabilities and reward values are not known in advance by the method-the agent just gets to observe state, action, and reward values as it moves through the domain.
Some notes (please read!):
\begin{itemize}
\item A new episode is started by sampling the first state uniformly at random.
\item The agent follows an epsilon-greedy policy with $\epsilon=0.1$.
\item Every action taken from the goal state leads to a zero-reward state that can never be escaped. Thus, to continue learning, we repeat the steps above. Note that we start a new/reset episode only after the agent reaches the goal state.
\item In the case of a tie in the value $\max _{a} Q(s, a)$ across actions $a$, we choose the ""best"" action randomly.
\item All transitions are noisy; that is, there is some non-zero probability of the agent moving somewhere different from its desired destination. For example, say the agent in in state $(0,0)$ and takes a ""North"" action, there is a non-zero chance that it actually ends up in state $(1,1)$.
\item Our $\gamma$ (discount factor) is set to $0.9$ and our $\alpha$ (learning rate) is set to $0.5$.
\end{itemize}
Note that the scale of the colors changes across the different plots, per the bar on the right of each plot.
At iteration 10,000, how close are the values plotted (our estimates of the true value of taking the best actions starting at the given state) to the actual value of taking the best actions starting from the given state?
In particular, what should the value of the bottom-right corner be? (To make this easier to think about, you can assume that the transitions are deterministic; that is, the robot always moves in the direction it is ""aiming"".) ",Open,"State $(9,0)$ is 12 steps away from the goal, and so, without any errors, the robot will reach the goal in 12 steps. Given the discount factor of $0.9$, if we get a reward of 100 after 12 steps, the state has a value of about $100 * 0.9 \wedge 12=28$. The value in our table seems to be pretty close. It makes sense that it's slightly under, because we have a learning rate of 0.5. (If our learning rate was 1 , it'd be much closer to 28 .)","Now, we'll take a look at Q-learning in a simple 2D grid setting but with a single goal location. We'll adopt the same state space and action space as in MDP lab.
Specifically, our state space is a 10-by-10 grid, with the bottom-left state indexed as state $(0,0)$, and our four possible actions are moving North, South, East or West (note that if the robot tries to move off the board, it cannot; it just stays in the same state). Our single goal is at state $(3,6)$.
Remember that for Q-learning, the transition probabilities and reward values are not known in advance by the method-the agent just gets to observe state, action, and reward values as it moves through the domain.
Some notes (please read!):
\begin{itemize}
\item A new episode is started by sampling the first state uniformly at random.
\item The agent follows an epsilon-greedy policy with $\epsilon=0.1$.
\item Every action taken from the goal state leads to a zero-reward state that can never be escaped. Thus, to continue learning, we repeat the steps above. Note that we start a new/reset episode only after the agent reaches the goal state.
\item In the case of a tie in the value $\max _{a} Q(s, a)$ across actions $a$, we choose the ""best"" action randomly.
\item All transitions are noisy; that is, there is some non-zero probability of the agent moving somewhere different from its desired destination. For example, say the agent in in state $(0,0)$ and takes a ""North"" action, there is a non-zero chance that it actually ends up in state $(1,1)$.
\item Our $\gamma$ (discount factor) is set to $0.9$ and our $\alpha$ (learning rate) is set to $0.5$.
\end{itemize}
Note that the scale of the colors changes across the different plots, per the bar on the right of each plot.
At iteration 1000, how many more times do you think the agent reached the goal state?","The value of the goal state is now something like 85. This would happen if it entered the goal state two more times. Why? Because after entering one time, as we saw above, the $Q$ value was 50 . When it enters again, the new $Q$ value will be $0.5 * 50+0.5 * 100=75$. When it enters the third time, the new $Q$ value will be $0.5 * 75+0.5 * 100=87.5$.","Now, we'll take a look at Q-learning in a simple 2D grid setting but with a single goal location. We'll adopt the same state space and action space as in MDP lab.
Specifically, our state space is a 10-by-10 grid, with the bottom-left state indexed as state $(0,0)$, and our four possible actions are moving North, South, East or West (note that if the robot tries to move off the board, it cannot; it just stays in the same state). Our single goal is at state $(3,6)$.
Remember that for Q-learning, the transition probabilities and reward values are not known in advance by the method-the agent just gets to observe state, action, and reward values as it moves through the domain.
Some notes (please read!):
\begin{itemize}
\item A new episode is started by sampling the first state uniformly at random.
\item The agent follows an epsilon-greedy policy with $\epsilon=0.1$.
\item Every action taken from the goal state leads to a zero-reward state that can never be escaped. Thus, to continue learning, we repeat the steps above. Note that we start a new/reset episode only after the agent reaches the goal state.
\item In the case of a tie in the value $\max _{a} Q(s, a)$ across actions $a$, we choose the ""best"" action randomly.
\item All transitions are noisy; that is, there is some non-zero probability of the agent moving somewhere different from its desired destination. For example, say the agent in in state $(0,0)$ and takes a ""North"" action, there is a non-zero chance that it actually ends up in state $(1,1)$.
\item Our $\gamma$ (discount factor) is set to $0.9$ and our $\alpha$ (learning rate) is set to $0.5$.
\end{itemize}
Note that the scale of the colors changes across the different plots, per the bar on the right of each plot.
At iteration 500, why does the state at $(3,6)$ have value 50?","Recall that the learning rate is $0.5$ ! So the robot finally randomly entered the goal state once and did a Q-learning update based on the fact that it got a reward of 100 . Since the old $Q$ value was 0 , the updated value is $.5 * 0+.5 * 100=$ 50.","Now, we'll take a look at Q-learning in a simple 2D grid setting but with a single goal location. We'll adopt the same state space and action space as in MDP lab.
Specifically, our state space is a 10-by-10 grid, with the bottom-left state indexed as state $(0,0)$, and our four possible actions are moving North, South, East or West (note that if the robot tries to move off the board, it cannot; it just stays in the same state). Our single goal is at state $(3,6)$.
Remember that for Q-learning, the transition probabilities and reward values are not known in advance by the method-the agent just gets to observe state, action, and reward values as it moves through the domain.
Some notes (please read!):
\begin{itemize}
\item A new episode is started by sampling the first state uniformly at random.
\item The agent follows an epsilon-greedy policy with $\epsilon=0.1$.
\item Every action taken from the goal state leads to a zero-reward state that can never be escaped. Thus, to continue learning, we repeat the steps above. Note that we start a new/reset episode only after the agent reaches the goal state.
\item In the case of a tie in the value $\max _{a} Q(s, a)$ across actions $a$, we choose the ""best"" action randomly.
\item All transitions are noisy; that is, there is some non-zero probability of the agent moving somewhere different from its desired destination. For example, say the agent in in state $(0,0)$ and takes a ""North"" action, there is a non-zero chance that it actually ends up in state $(1,1)$.
\item Our $\gamma$ (discount factor) is set to $0.9$ and our $\alpha$ (learning rate) is set to $0.5$.
\end{itemize}
Note that the scale of the colors changes across the different plots, per the bar on the right of each plot.
These are plots of the maximum $\mathrm{Q}$ values of the states $\max _{a} Q(s, a)$ using the SSP formulation as we run 10,000 iterations of Q-value learning, plotting at specific iterations. Note that the scale of the colors changes across the different plots, per the bar on the right of each plot.
At iteration 10,000, how close are the values plotted (our estimates of the true value of taking the best actions starting at the given state) to the actual value of taking the best actions starting from the given state? Roughly what should the value in the bottom right corner be? (Assume that the transitions are deterministic.)","This state is still 12 steps from the goal. That means 12 steps on hot lava (ouch, ouch, ouch...). But, lucky for us, lava in the future doesn't seem to bad as lava in the present (coz of discounting negative reward). So, we end up with the value being a discounted sum of 12 rewards, each of which is $-1$. So, the value should be $-1^{*}\left(0.9^{\wedge} 0+0.9^{\wedge} 1+\ldots+\right.$ $\left.0.9 \wedge^{\wedge} 11\right)=-7.17$, and the value is close. (Same comment about learning rate from $2.1 .5$ applies.)"
81,Mathematics,18.2,Principles of Discrete Applied Mathematics,None,18.C06,Midterm Exam 3,Miller-Rabin Test,2,b,1.25,Text,"Consider the following three numbers:
$$
N_{1}=257=2^{8}+1, \quad N_{2}=4097=2^{12}+1, \quad N_{3}=1537=3 \cdot 2^{9}+1.
$$
For each of these three numbers, we would like to test whether it is a prime or not.
Let $a_{2}=233$. For each $k=1,2,4,8,16,32,64,128,256,512,1024,2048,4096$, we compute $a_{2}^{k}$ modulo $N_{2}=4097$. The results of the computation are:
$$
233,1028,3855,1206,1,1,1,1,1,1,1,1,1.
$$
Based on these results, do you think $N_{2}$ is a prime? explain.",Open,"Here we fail the Miller-Rabin test, because the last element preceding a 1 is 1206 , which is not 1 or $-1$ modulo 4097 . So $N_{2}=4097$ is composite.","Consider the following three numbers:
$$
N_{1}=257=2^{8}+1, \quad N_{2}=4097=2^{12}+1, \quad N_{3}=1537=3 \cdot 2^{9}+1.
$$
For each of these three numbers, we would like to test whether it is a prime or not.
Let $a_{3}=2$. For each $k=3,6,12,24,48,96,192,384,768,1536$ we compute $a_{3}^{k}$ modulo $N_{3}=1537$. The results are:
$$
8,64,1022,861,487,471,513,342,152,49
$$
Again, do you think $N_{3}$ is a prime? Explain.","Here the Fermat test fails, since $2^{1536}$ is not 1 modulo 1537. So 1537 is composite.","Consider the following three numbers:
$$
N_{1}=257=2^{8}+1, \quad N_{2}=4097=2^{12}+1, \quad N_{3}=1537=3 \cdot 2^{9}+1.
$$
For each of these three numbers, we would like to test whether it is a prime or not.
Let $a_{1}=51$. For each $k=1,2,4,8,16,32,64,128,256$ (i.e., all powers of two up to $2^{8}$ ), we compute $a_{1}^{k}$ modulo $N_{1}=257$. The results of the computation are given below.
$$
51,31,190,120,8,64,241,256,1.
$$
Based on these results, do you think $N_{1}$ is a prime? Explain.","The pair $N_{1}=257$ and $a_{1}=51$ passes both the Fermat test (since $\left.a_{1}^{256} \equiv 1 \bmod 257\right)$ and the Miller-Rabin test (since right before the first occurrence of 1 we have $256 \equiv-1$ $\bmod 257$. So as far as we can tell, 257 looks like a prime. And indeed, 257 turns out to be a prime!","One has the factorization of $340561=13 \times 17 \times 23 \times 67$. Show that for any integer $a$ relatively prime to 340561, one has
$$
a^{340560} \equiv 1 \quad \bmod 340561 .
$$","By the Chinese-Remainder Theorem, it suffices to show that
$$
a^{340560} \equiv 1 \quad \bmod p
$$
for $p=13,17,23,67$ and $a$ relatively prime to $p$. One can compute that 340560 is divisible by 12,16,22,66 so Fermat's little theorem shows that the equation holds."
91,Mathematics,18.01,Calculus I,None,None,Problem Set 3,Integration,2,a,0.03959873284,Text,"On Problem Set 2, Problem 1, you estimated the area of an annulus, where the inner circle has radius $r$ and the outer circle has radius $r+\Delta r$. When $\Delta r$ is small, you showed that the area is approximately $2 \pi r \Delta r$. If you want a reminder about this, you could read the solution to pset 2. We're going to build on that in an integration problem.
Suppose we have a disk of radius 3 meters. The disk has variable density. Near a point at distance $r$ from the center, the disk has density $4-r$ kilograms per square meter. So the densest part of the disk is at the center, where the density is $4 \mathrm{~kg} / \mathrm{m}^{2}$. The least dense part of the disk is at the edge, where the density is $1 \mathrm{~kg} / \mathrm{m}^{2}$.
Approximate the mass of the part of the disk where the distance to the center is between 2 meters and $2.1$ meters. (This part of the disk is an annulus with inner radius 2 and outer radius 2.1.) Which is the best approximation: $8 \pi k g$ or $4 \pi k g$ or $2 \pi k g$ or $(.8) \pi k g$ or (.4) $\pi k g$ or $(.2) \pi k g$?",Multiple Choice,The approximate area for this annulus is $2 \pi(2)(2.1-2)=0.4 \pi$ (units are $m^{2}$). The density on this annulus is approximately equal to $4-(2)=2$ (units are $\mathrm{kg} / \mathrm{m}^{2}$ ). Multiply the density times the area to get approximate mass of the annulus equal to $0.8 \pi$ (units are $\mathrm{kg}$).,"On Problem Set 2, Problem 1, you estimated the area of an annulus, where the inner circle has radius $r$ and the outer circle has radius $r+\Delta r$. When $\Delta r$ is small, you showed that the area is approximately $2 \pi r \Delta r$. If you want a reminder about this, you could read the solution to pset 2. We're going to build on that in an integration problem.
Suppose we have a disk of radius 3 meters. The disk has variable density. Near a point at distance $r$ from the center, the disk has density $4-r$ kilograms per square meter. So the densest part of the disk is at the center, where the density is $4 \mathrm{~kg} / \mathrm{m}^{2}$. The least dense part of the disk is at the edge, where the density is $1 \mathrm{~kg} / \mathrm{m}^{2}$.
Approximate the mass of the part of the disk where the distance to the center is between $r$ meters and $r+\Delta r$ meters.","Repeating the steps in part a, the approximate area is $2 \pi r \Delta r$ and the approximate density is $4-r$, so the approximate mass is $2 \pi r(\Delta r)(4-r)$.","On Problem Set 2, Problem 1, you estimated the area of an annulus, where the inner circle has radius $r$ and the outer circle has radius $r+\Delta r$. When $\Delta r$ is small, you showed that the area is approximately $2 \pi r \Delta r$. If you want a reminder about this, you could read the solution to pset 2. We're going to build on that in an integration problem.
Suppose we have a disk of radius 3 meters. The disk has variable density. Near a point at distance $r$ from the center, the disk has density $4-r$ kilograms per square meter. So the densest part of the disk is at the center, where the density is $4 \mathrm{~kg} / \mathrm{m}^{2}$. The least dense part of the disk is at the edge, where the density is $1 \mathrm{~kg} / \mathrm{m}^{2}$.
Write an integral for the total mass of the disk.",$\int_{0}^{3} 2 \pi r(4-r) d r$.,"On Problem Set 2, Problem 1, you estimated the area of an annulus, where the inner circle has radius $r$ and the outer circle has radius $r+\Delta r$. When $\Delta r$ is small, you showed that the area is approximately $2 \pi r \Delta r$. If you want a reminder about this, you could read the solution to pset 2. We're going to build on that in an integration problem.
Suppose we have a disk of radius 3 meters. The disk has variable density. Near a point at distance $r$ from the center, the disk has density $4-r$ kilograms per square meter. So the densest part of the disk is at the center, where the density is $4 \mathrm{~kg} / \mathrm{m}^{2}$. The least dense part of the disk is at the edge, where the density is $1 \mathrm{~kg} / \mathrm{m}^{2}$.
Evaluate the integral to find the total mass.","$$
\begin{aligned}
2 \pi \int_{0}^{3}\left(4 r-r^{2}\right) d r & =2 \pi\left[\frac{4 r^{2}}{2}-\frac{r^{3}}{3}\right]_{0}^{3} \\
& =2 \pi\left[\frac{4 \cdot 3^{2}}{2}-\frac{3^{3}}{3}\right]=2 \pi(18-9)=18 \pi
\end{aligned}
$$
where the units are $k g$."
56,Mathematics,18.02,Calculus II,18.01,None,Problem Set 6,Vector Fields,5,a,0.3205128205,Text,"Let $C$ be the unit circle, oriented counterclockwise, and consider the field $\vec{F}=\hat{i}+\hat{j}$. Which portions of $C$ contribute positively to the line integral of $\vec{F} ?$ Which portions contribute negatively?",Open,"Consider the parametrization $(x, y)=(\cos t, \sin t)$. The velocity vector $\vec{v}$ at a point $(x, y)$ on the curve $C$ is
$$
\vec{v}(x, y)=(-\sin t) \hat{i}+(\cos t) \hat{j}=-y \hat{i}+x \hat{j} \text {. }
$$
Thus, $\vec{F} \cdot \vec{v}(x, y)>0$ if and only if $-y+x>0$; and $\vec{F} \cdot \vec{v}(x, y)<0$ if and only if $-y+x<0$. That is to say, the portion $\left\{(\cos t, \sin t) \in C:-\frac{3 \pi}{4}<t<\frac{\pi}{4}\right\}$ contributes positively to the flux, while the portion $\left\{(\cos t, \sin t) \in C: \frac{\pi}{4}<t<\frac{5 \pi}{4}\right\}$ contributes negatively.","Let $C$ be the unit circle, oriented counterclockwise, and consider the field $\vec{F}=x^{2} y \hat{i}+x y^{2} \hat{j}$. Which portions of $C$ contribute positively to the line integral of $\vec{F} ?$ Which portions contribute negatively?","Since $\vec{F} \cdot \vec{v}(x, y)=x^{2} y \cdot(-y)+x y^{2} \cdot x=0$, at every point of $C$ the vector field $\vec{F}$ and the velocity vector $\vec{v}(x, y)$ are perpendicular to each other. Thus, the line integral is zero and every point on $C$ contributes zero to the line integral.","$\mathbf{F}(x, y)=x(\mathbf{i}+\mathbf{j}), \quad$ and let $C$ be the closed curve in the xy-plane formed by the triangle with vertices at the origin and the points $(1,0)$ and $(0,1)$. 
Give a rough sketch of the field $\mathbf{F}$ in the first quadrant, and use it to predict whether the net flux out of the region $R=$ the interior of $C$ will be positive or negative.",Net flux out of $R$ will be positive (more flow out than into $R$ ).,"Consider the vector field
$$
\vec{F}(x, y)=\frac{-y \hat{i}+x \hat{j}}{x^{2}+y^{2}} .
$$
Suppose $C$ is a smooth curve in the right half-plane $x>0$ joining two points $A=\left(x_{1}, y_{1}\right)$ and $B=\left(x_{2}, y_{2}\right)$. Express $\int_{C} \vec{F} \cdot d \vec{r}$ in terms of the polar coordinates $\left(r_{1}, \theta_{1}\right)$ and $\left(r_{2}, \theta_{2}\right)$ of $A$ and $B$.","The fundamental theorem of calculus for line integrals gives
$$
\int_{C} \vec{F} \cdot d \vec{r}=\theta\left(x_{2}, y_{2}\right)-\theta\left(x_{1}, y_{1}\right)=\theta_{2}-\theta_{1}
$$"
42,EECS,6.102,Elements of Software Construction,6.101,None,Midterm Exam 2,Concurrency,3,c,0.48,Text,"/**
* Immutable type representing a strand of DNA.
*/
class DNA {
       /** omitted */
       public constructor(bases: string) {
       // omitted
}
       /**
        * @returns zero-based index of first occurence of `dna` as a substring of this strand,
        * or undefined if `dna` never occurs.
        */
       public find(dna: DNA): number|undefined {
             // omitted
       }
       /**
        * @returns true iff this and that are observationally equivalent
        */
       public equalValue(that: DNA): boolean {
              // omitted
       }
       // other code omitted
}
/**
* Immutable type representing a gene-editing process.
*/
interface Crispr {
      /**
       * Simulates this gene-editing process entirely in software, without using chemicals or a lab.
       * @returns DNA strand that would result from this process
       */
      simulate(): DNA;
     /**
      * Run this gene-editing process using the given `lab`.
      * @returns the tube of `lab` in which the final DNA from this process
      * can be found.
      */
      async fabricate(lab: Lab): Promise<Tube>;
      // other code omitted
}
/**
* Represents an already-existing DNA strand (a ""precursor"") in a gene-editing
* process. Precursors are bought premade from a supplier.
*/
class Precursor implements Crispr {
/**
* Make a gene-splicing step that results in the given `dna` strand.
*/
       public constructor(private readonly dna: DNA) {
       }
       // other code omitted
}
/**
* Represents a gene-splicing step in a gene-editing process,
* which replaces all instances of one gene with another.
*/
class Splice implements Crispr {
       /**
        * Make a gene-splicing step that finds all occurrences of
        * oldGene in target and substitutes newGene in place of each one.
        */
       public constructor(
       private readonly target: Crispr,
       private readonly oldGene: Crispr,
       private readonly newGene: Crispr
       ) {
       }
       // other code omitted
}
/**
* Mutable type controlling an automated gene-editing machine.
*/
class Lab {
/**
* Modifies the DNA in targetTube to replace all occurrences of the DNA from oldGeneTube with the
* DNA from newGeneTube.
* @returns a promise that fulfills with the same tube as targetTube, after the process is complet
*/
       public async splice(targetTube: Tube, oldGeneTube: Tube, newGeneTube: Tube): Promise<Tube> {
              // omitted
       }
       private tubeMap: Map<Tube, DNA> = new Map();
        /**
         * @returns a tube containing DNA strands corresponding to `dna`
         */
        public async get(dna: DNA): Promise<Tube> {
                for (const tube of this.tubeMap.keys()) {
                      if (this.tubeMap.get(tube).equalValue(dna)) {
                          return tube;
                      }
                 }
                 const tube = new Tube();
                 this.tubeMap.set(tube, dna);
                 await this.load(tube, dna); // ""line 6a"" is the load() call, ""line 6b"" is the await
                 return tube;
         }
         /**
          * Ask a human to order premade DNA from a supplier
          * and load it into the tube.
          * @returns a promise that fulfills once this tube contains `dna`.
          */
         private async load(tube: Tube, dna: DNA): Promise<void> {
               // omitted
         }
         // other code omitted
}
/**
* Mutable type representing a test tube containing DNA.
*/
class Tube {
       /** Make a new Tube. */
       public constructor() {
       }
       // other code omitted
}
Suppose that:
• two different gene-editing processes A and B are running asynchronously using the same Lab
• A and B both call lab.get(dnaX) for the same precursor dnaX
• no other asynchronous processes are using lab
For each of the following interleavings, referring to the line numbers 1-7 in get() in the provided code, decide whether the
interleaving is impossible, leads to a race condition or deadlock, or runs safely; then explain your answer in one sentence.
A runs lines 1, 4, 5, 6a; then B runs lines 1, 4, 5, 6a; then A finishes lines 6b and 7, then B finishes lines 6b and 7.",Open,"impossible; After A runs line 5, there will be at least one tube in tubeMap, so B must proceed from line 1 to line 2.","/**
* Immutable type representing a strand of DNA.
*/
class DNA {
       /** omitted */
       public constructor(bases: string) {
       // omitted
}
       /**
        * @returns zero-based index of first occurence of `dna` as a substring of this strand,
        * or undefined if `dna` never occurs.
        */
       public find(dna: DNA): number|undefined {
             // omitted
       }
       /**
        * @returns true iff this and that are observationally equivalent
        */
       public equalValue(that: DNA): boolean {
              // omitted
       }
       // other code omitted
}
/**
* Immutable type representing a gene-editing process.
*/
interface Crispr {
      /**
       * Simulates this gene-editing process entirely in software, without using chemicals or a lab.
       * @returns DNA strand that would result from this process
       */
      simulate(): DNA;
     /**
      * Run this gene-editing process using the given `lab`.
      * @returns the tube of `lab` in which the final DNA from this process
      * can be found.
      */
      async fabricate(lab: Lab): Promise<Tube>;
      // other code omitted
}
/**
* Represents an already-existing DNA strand (a ""precursor"") in a gene-editing
* process. Precursors are bought premade from a supplier.
*/
class Precursor implements Crispr {
/**
* Make a gene-splicing step that results in the given `dna` strand.
*/
       public constructor(private readonly dna: DNA) {
       }
       // other code omitted
}
/**
* Represents a gene-splicing step in a gene-editing process,
* which replaces all instances of one gene with another.
*/
class Splice implements Crispr {
       /**
        * Make a gene-splicing step that finds all occurrences of
        * oldGene in target and substitutes newGene in place of each one.
        */
       public constructor(
       private readonly target: Crispr,
       private readonly oldGene: Crispr,
       private readonly newGene: Crispr
       ) {
       }
       // other code omitted
}
/**
* Mutable type controlling an automated gene-editing machine.
*/
class Lab {
/**
* Modifies the DNA in targetTube to replace all occurrences of the DNA from oldGeneTube with the
* DNA from newGeneTube.
* @returns a promise that fulfills with the same tube as targetTube, after the process is complet
*/
       public async splice(targetTube: Tube, oldGeneTube: Tube, newGeneTube: Tube): Promise<Tube> {
              // omitted
       }
       private tubeMap: Map<Tube, DNA> = new Map();
        /**
         * @returns a tube containing DNA strands corresponding to `dna`
         */
        public async get(dna: DNA): Promise<Tube> {
                for (const tube of this.tubeMap.keys()) {
                      if (this.tubeMap.get(tube).equalValue(dna)) {
                          return tube;
                      }
                 }
                 const tube = new Tube();
                 this.tubeMap.set(tube, dna);
                 await this.load(tube, dna); // ""line 6a"" is the load() call, ""line 6b"" is the await
                 return tube;
         }
         /**
          * Ask a human to order premade DNA from a supplier
          * and load it into the tube.
          * @returns a promise that fulfills once this tube contains `dna`.
          */
         private async load(tube: Tube, dna: DNA): Promise<void> {
               // omitted
         }
         // other code omitted
}
/**
* Mutable type representing a test tube containing DNA.
*/
class Tube {
       /** Make a new Tube. */
       public constructor() {
       }
       // other code omitted
}
Suppose that:
• two different gene-editing processes A and B are running asynchronously using the same Lab
• A and B both call lab.get(dnaX) for the same precursor dnaX
• no other asynchronous processes are using lab
For each of the following interleavings, referring to the line numbers 1-7 in get() in the provided code, decide whether the
interleaving is impossible, leads to a race condition or deadlock, or runs safely; then explain your answer in one sentence.
A runs lines 1, 4, 5, 6a, then B runs lines 1, 2, 3, then A finishes lines 6b and 7.","race condition; B returns the tube that A is loading before the tube has finished loading, violating the postcondition of get().","/**
* Immutable type representing a strand of DNA.
*/
class DNA {
       /** omitted */
       public constructor(bases: string) {
       // omitted
}
       /**
        * @returns zero-based index of first occurence of `dna` as a substring of this strand,
        * or undefined if `dna` never occurs.
        */
       public find(dna: DNA): number|undefined {
             // omitted
       }
       /**
        * @returns true iff this and that are observationally equivalent
        */
       public equalValue(that: DNA): boolean {
              // omitted
       }
       // other code omitted
}
/**
* Immutable type representing a gene-editing process.
*/
interface Crispr {
      /**
       * Simulates this gene-editing process entirely in software, without using chemicals or a lab.
       * @returns DNA strand that would result from this process
       */
      simulate(): DNA;
     /**
      * Run this gene-editing process using the given `lab`.
      * @returns the tube of `lab` in which the final DNA from this process
      * can be found.
      */
      async fabricate(lab: Lab): Promise<Tube>;
      // other code omitted
}
/**
* Represents an already-existing DNA strand (a ""precursor"") in a gene-editing
* process. Precursors are bought premade from a supplier.
*/
class Precursor implements Crispr {
/**
* Make a gene-splicing step that results in the given `dna` strand.
*/
       public constructor(private readonly dna: DNA) {
       }
       // other code omitted
}
/**
* Represents a gene-splicing step in a gene-editing process,
* which replaces all instances of one gene with another.
*/
class Splice implements Crispr {
       /**
        * Make a gene-splicing step that finds all occurrences of
        * oldGene in target and substitutes newGene in place of each one.
        */
       public constructor(
       private readonly target: Crispr,
       private readonly oldGene: Crispr,
       private readonly newGene: Crispr
       ) {
       }
       // other code omitted
}
/**
* Mutable type controlling an automated gene-editing machine.
*/
class Lab {
/**
* Modifies the DNA in targetTube to replace all occurrences of the DNA from oldGeneTube with the
* DNA from newGeneTube.
* @returns a promise that fulfills with the same tube as targetTube, after the process is complet
*/
       public async splice(targetTube: Tube, oldGeneTube: Tube, newGeneTube: Tube): Promise<Tube> {
              // omitted
       }
       private tubeMap: Map<Tube, DNA> = new Map();
        /**
         * @returns a tube containing DNA strands corresponding to `dna`
         */
        public async get(dna: DNA): Promise<Tube> {
                for (const tube of this.tubeMap.keys()) {
                      if (this.tubeMap.get(tube).equalValue(dna)) {
                          return tube;
                      }
                 }
                 const tube = new Tube();
                 this.tubeMap.set(tube, dna);
                 await this.load(tube, dna); // ""line 6a"" is the load() call, ""line 6b"" is the await
                 return tube;
         }
         /**
          * Ask a human to order premade DNA from a supplier
          * and load it into the tube.
          * @returns a promise that fulfills once this tube contains `dna`.
          */
         private async load(tube: Tube, dna: DNA): Promise<void> {
               // omitted
         }
         // other code omitted
}
/**
* Mutable type representing a test tube containing DNA.
*/
class Tube {
       /** Make a new Tube. */
       public constructor() {
       }
       // other code omitted
}
Suppose that:
• two different gene-editing processes A and B are running asynchronously using the same Lab
• A and B both call lab.get(dnaX) for the same precursor dnaX
• no other asynchronous processes are using lab
For each of the following interleavings, referring to the line numbers 1-7 in get() in the provided code, decide whether the
interleaving is impossible, leads to a race condition or deadlock, or runs safely; then explain your answer in one sentence.
A runs lines 1 and 4, then B runs lines 1 and 4, then A runs lines 5, 6, 7, then B runs lines 5, 6, 7.","impossible; A cannot lose control to B after line 4, it can only lose control at the await in line 6.","/**
* Immutable type representing a strand of DNA.
*/
class DNA {
       /** omitted */
       public constructor(bases: string) {
       // omitted
}
       /**
        * @returns zero-based index of first occurence of `dna` as a substring of this strand,
        * or undefined if `dna` never occurs.
        */
       public find(dna: DNA): number|undefined {
             // omitted
       }
       /**
        * @returns true iff this and that are observationally equivalent
        */
       public equalValue(that: DNA): boolean {
              // omitted
       }
       // other code omitted
}
/**
* Immutable type representing a gene-editing process.
*/
interface Crispr {
      /**
       * Simulates this gene-editing process entirely in software, without using chemicals or a lab.
       * @returns DNA strand that would result from this process
       */
      simulate(): DNA;
     /**
      * Run this gene-editing process using the given `lab`.
      * @returns the tube of `lab` in which the final DNA from this process
      * can be found.
      */
      async fabricate(lab: Lab): Promise<Tube>;
      // other code omitted
}
/**
* Represents an already-existing DNA strand (a ""precursor"") in a gene-editing
* process. Precursors are bought premade from a supplier.
*/
class Precursor implements Crispr {
/**
* Make a gene-splicing step that results in the given `dna` strand.
*/
       public constructor(private readonly dna: DNA) {
       }
       // other code omitted
}
/**
* Represents a gene-splicing step in a gene-editing process,
* which replaces all instances of one gene with another.
*/
class Splice implements Crispr {
       /**
        * Make a gene-splicing step that finds all occurrences of
        * oldGene in target and substitutes newGene in place of each one.
        */
       public constructor(
       private readonly target: Crispr,
       private readonly oldGene: Crispr,
       private readonly newGene: Crispr
       ) {
       }
       // other code omitted
}
/**
* Mutable type controlling an automated gene-editing machine.
*/
class Lab {
/**
* Modifies the DNA in targetTube to replace all occurrences of the DNA from oldGeneTube with the
* DNA from newGeneTube.
* @returns a promise that fulfills with the same tube as targetTube, after the process is complet
*/
       public async splice(targetTube: Tube, oldGeneTube: Tube, newGeneTube: Tube): Promise<Tube> {
              // omitted
       }
       private tubeMap: Map<Tube, DNA> = new Map();
        /**
         * @returns a tube containing DNA strands corresponding to `dna`
         */
        public async get(dna: DNA): Promise<Tube> {
                for (const tube of this.tubeMap.keys()) {
                      if (this.tubeMap.get(tube).equalValue(dna)) {
                          return tube;
                      }
                 }
                 const tube = new Tube();
                 this.tubeMap.set(tube, dna);
                 await this.load(tube, dna); // ""line 6a"" is the load() call, ""line 6b"" is the await
                 return tube;
         }
         /**
          * Ask a human to order premade DNA from a supplier
          * and load it into the tube.
          * @returns a promise that fulfills once this tube contains `dna`.
          */
         private async load(tube: Tube, dna: DNA): Promise<void> {
               // omitted
         }
         // other code omitted
}
/**
* Mutable type representing a test tube containing DNA.
*/
class Tube {
       /** Make a new Tube. */
       public constructor() {
       }
       // other code omitted
}
Suppose that:
• two different gene-editing processes A and B are running asynchronously using the same Lab
• A and B both call lab.get(dnaX) for the same precursor dnaX
• no other asynchronous processes are using lab
For each of the following interleavings, referring to the line numbers 1-7 in get() in the provided code, decide whether the
interleaving is impossible, leads to a race condition or deadlock, or runs safely; then explain your answer in one sentence.
A runs lines 1, 4, 5, 6, 7, then B runs lines 1, 4, 5, 6, 7.","impossible; After A runs line 5, there will be at least one tube in tubeMap, so B must proceed from line 1 to line 2."
257,Mathematics,18.01,Calculus I,None,None,Problem Set 6,Taylor Series,10,b,0.07919746568,Text,"There is no formula for the antiderivative of $e^{-x^{2}}$, and so there is no formula for integrals like $\int_{0}^{\cdot 1} e^{-x^{2}} d x$. This type of integral is actually quite important in probability and statistics as we will see later. In this problem, we use Taylor series to approximate it.
There is a quicker way to find the Taylor series of $e^{-x^{2}}$. Earlier in the problem set you found the degree 3 Taylor series of $e^{-u}$ around $u=0$. Plug in $u=x^{2}$ and we get the Taylor series of $e^{-x^{2}}$ around $x=0$ to degree 6.",Expression,"Recall our formula for the degree 3 Taylor series $e^{-u}$ from earlier:
$$
1-u+\frac{1}{2} u^{2}-\frac{1}{6} u^{3}
$$
and plug in $u=x^{2}$ to get the degree 6 Taylor series for $e^{-x^{2}}$ :
$$
T(x)=1-x^{2}+\frac{1}{2} x^{4}-\frac{1}{6} x^{6} .
$$","There is no formula for the antiderivative of $e^{-x^{2}}$, and so there is no formula for integrals like $\int_{0}^{\cdot 1} e^{-x^{2}} d x$. This type of integral is actually quite important in probability and statistics as we will see later. In this problem, we use Taylor series to approximate it.
Using the Taylor series from part b, approximate $\int_{0}^{.1} e^{-x^{2}} d x$. At the end, you'll get a sum of fractions. Use a calculator to turn this into a decimal and record the first six digits.","$$
\begin{aligned}
\int_{0}^{.1} e^{-x^{2}} d x & \approx \int_{0}^{.1}\left(1-x^{2}+\frac{1}{2} x^{4}-\frac{1}{6} x^{6}\right) d x \\
& =\left[x-\frac{x^{3}}{3}+\frac{1}{2} \frac{x^{5}}{5}-\frac{1}{6} \frac{x^{7}}{7}\right]_{0}^{.1} \\
& =.1-\frac{(.1)^{3}}{3}+\frac{(.1)^{5}}{10}-\frac{(.1)^{7}}{42} \\
& \approx 0.0996676
\end{aligned}
$$","There is no formula for the antiderivative of $e^{-x^{2}}$, and so there is no formula for integrals like $\int_{0}^{\cdot 1} e^{-x^{2}} d x$. This type of integral is actually quite important in probability and statistics as we will see later. In this problem, we use Taylor series to approximate it.
Compute the first two derivatives of $e^{-x^{2}}$, and use them to find the degree 2 Taylor series of $e^{-x^{2}}$ around $x=0$.","We need $f(0), f^{\prime}(0), f^{\prime \prime}(0)$ :
$$
\begin{aligned}
f(x)=e^{-x^{2}} & \longrightarrow \quad f(0)=1 \\
f^{\prime}(x)=-2 x e^{-x^{2}} & \longrightarrow \quad f^{\prime}(0)=0 \\
f^{\prime \prime}(x)=-2 e^{-x^{2}}+4 x^{2} e^{-x^{2}} & \longrightarrow \quad f^{\prime \prime}(0)=-2
\end{aligned}
$$
Use the degree 2 Taylor formula to get
$$
T(x)=1+(0)(x-0)+)+\frac{1}{2}(-2)(x-0)^{2}=1-x^{2}.
$$","There is no formula for the antiderivative of $e^{-x^{2}}$, and so there is no formula for integrals like $\int_{0}^{\cdot 1} e^{-x^{2}} d x$. This type of integral is actually quite important in probability and statistics as we will see later. In this problem, we use Taylor series to approximate it.
Using the Taylor series from part b, approximate $e^{-.1^{2}}$. At the end, you will get a sum of fractions. Use a calculator to turn this into a decimal and record the first six digits.","$$
T(.1)=1-(.1)^{2}+\frac{1}{2}(.1)^{4}-\frac{1}{6}(.1)^{6} \approx 0.990049
$$"
55,EECS,6.18,Computer Systems Engineering,"6.1010, 6.1910",None,Midterm Exam 1,DCTCP and MapReduce,9,c,0.45,Text,"We have a large-scale web application using the partition/aggregate design pattern with many workers and real-time requirements. Assume there is NO background traffic (no other applications on the network) and the responses from workers are all small (1-2 packets each).
The MapReduce paper doesn't mention incast as an issue. Why not?
(a) Actually it does, but MapReduce talks about ""stragglers"" instead of ""incast.""
(b) The MapReduce paper doesn't describe many details of the reshuffling that happens between stages.
(c) Incast problems only started after the MapReduce paper had already been published.
(d) MapReduce operates in rigidly-scheduled stages, so it's impossible to have multiple messages arrive at a single switch at the same time.
(e) Google used exotic custom switches, described in the paper, to avoid these kinds of networking problems.",Multiple Choice,(b).,"We have a large-scale web application using the partition/aggregate design pattern with many workers and real-time requirements. Assume there is NO background traffic (no other applications on the network) and the responses from workers are all small (1-2 packets each).
Which of these problems is likely to be a concern in our network? Select ALL correct answers:
(a) Incast.
(b) Queue buildup.
(c) Buffer pressure.
(d) None of these problems is likely.",(a).,"We have a large-scale web application using the partition/aggregate design pattern with many workers and real-time requirements. Assume there is NO background traffic (no other applications on the network) and the responses from workers are all small (1-2 packets each).
Max has a bright idea of changing the aggregator structure for the partition/aggregate pattern. Instead of having one aggregator to aggregate the answer of 1000 workers, Max proposes using 10 aggregators each aggregating the answer from 100 workers, and then 1 aggregator to aggregate the answer from the 10 aggregators.
For our application, what is the most significant potential problem with this approach?
Select the BEST answer:
(a) It increases the number of machines required.
(b) It roughly doubles the time required for aggregation.
(c) It creates longer queues.
(d) It intensifies incast.",(b).,"We have a large-scale web application using the partition/aggregate design pattern with many workers and real-time requirements. Assume there is NO background traffic (no other applications on the network) and the responses from workers are all small (1-2 packets each).
TCP with RED/ECN has some similarities to DCTCP. What distinguishes DCTCP from TCP with RED/ECN? Select ALL correct statements on how DCTCP is DIFFERENT:
(a) DCTCP implements a central service to actively optimize the queue length of each switch.
(b) DCTCP can be implemented in commercially-available switches.
(c) DCTCP automatically determines the queue-length threshold $\mathrm{K}$.
(d) DCTCP does not adjust the size of the congestion window.
(e) DCTCP tries to minimize queue occupancy, but at the cost of lower throughput than TCP with RED/ECN.
(f) None of the above statements distinguishes DCTCP from TCP with RED/ECN. ",(f).
63,Mathematics,18.102,Introduction to Functional Analysis,"18.C06, 18.100B",None,Problem Set 9,Bounded Linear Operators,4,nan,0.5,Text,"Show that if $V \in \mathcal{C}^{0}[0, \pi]$ then the linear map
$$
Q_{V}: H_{0}^{2}([0, \pi]) \ni u \longmapsto-F_{2}+V u \in L^{2}(0, \pi)
$$
is bounded and reduces to
$$
u \longmapsto-u^{\prime \prime}+V u \text { on } \mathcal{C}_{0}^{2}([0, \pi])
$$",Open,"Let $\mathscr{H}=H_{0}^{2}(0, \pi), \mathscr{L}=L^{2}(0, \pi)$. The map $u \rightarrow-F_{2}$ is a bounded map from $\mathscr{H}$ to $\mathscr{L}$. In fact is maps $u=\sum c_{k} \sin k x$ to $-F_{2}=\sum k^{2} c_{k} \sin k x$ and $\|u\|_{\mathscr{H}}=\left\|F_{2}\right\|_{\mathscr{L}}$. The map $u \rightarrow u$ is a bounded map from $\mathscr{H}$ to $\mathscr{L}$ as $\|u\|_{\mathscr{H}} \geq\|u\|_{\mathscr{L}}$. Finally, multiplication by $V$ is a bounded map from $\mathscr{L}$ to $\mathscr{L}$. Combining the above, we conclude that $Q_{V}$ is a bounded map from $\mathscr{H}$ to $\mathscr{L}$. It reduces to $-u^{\prime \prime}+V u$ by Problem $9.3$.","With $F_{1}$ and $F_{2}$ as in (2) for $u \in H_{0}^{2}([0, \pi])$ show that
$$
\int_{(0, \pi)} u \phi^{\prime}=-\int_{(0, \pi)} F_{1} \phi, \int_{(0, \pi)} u \phi^{\prime \prime}=\int_{(0, \pi)} F_{2} \phi, \forall \phi \in \mathcal{C}_{0}^{2}([0, \pi])
$$
and show that if $u \in \mathcal{C}_{0}^{2}([0, \pi]) \subset H_{0}^{2}([0, \pi])$ then $F_{1}=u^{\prime}, F_{2}=u^{\prime \prime}$.","Since $u_{N}$ vanishes at 0 and $\pi$, and $u, F_{1}, \phi$ and $\phi^{\prime}$ are integrable, we can use Lebesgue dominated convergence to exchange limit and integration and conclude that
$$
\int_{0}^{\pi} u \phi^{\prime}=\int_{0}^{\pi} \lim _{N \rightarrow \infty} u_{N} \phi^{\prime}=\lim _{N \rightarrow \infty}\left[\left[u_{N} \phi\right]_{0}^{\pi}-\int_{0}^{\pi} \frac{d u_{N}}{d x} \phi\right]=-\int_{0}^{\pi} \lim _{N \rightarrow \infty} \frac{d u_{N}}{d x} \phi=-\int_{0}^{\pi} F_{1} \phi .
$$
Similarly,
$$
\int_{0}^{\pi} u \phi^{\prime \prime}=-\int_{0}^{\pi} F_{1} \phi^{\prime}=-\lim _{N \rightarrow \infty}\left[\left[F_{1}^{\prime} \phi\right]_{0}^{\pi}-\int_{0}^{\pi} \frac{d^{2} u_{N}}{d x} \phi\right]=\int_{0}^{\pi} \lim _{N \rightarrow \infty} \frac{d^{2} u_{N}}{d x} \phi=\int_{0}^{\pi} F_{2} \phi
$$
where the final equality holds because $\frac{d^{2} u_{N}}{d x} \rightarrow F_{2}$ in $\|\cdot\|_{2}$ and because integration with respect to $\phi$ is a continuous linear functional on $L^{2}(0, \pi)$. Finally, suppose $u \in C_{0}^{2}([0, \pi])$. Then
$$
-\int_{0}^{\pi} F_{1} \phi=\int_{0}^{\pi} u \phi^{\prime}=-\int_{0}^{\pi} u^{\prime} \phi
$$
for all $\phi \in C_{0}^{2}([0, \pi])$. This implies that $u^{\prime}=F_{1}$ in the $L^{2}$ sense, and since $u^{\prime}$ and $F_{1}$ are continuous, that $u=F_{1}$ everywhere. Similarly, we find
$$
\int_{0}^{\pi} F_{2} \phi=\int_{0}^{\pi} u^{\prime \prime} \phi
$$
and therefore that $F_{2}=u^{\prime \prime}$ in the $L^{2}$ sense.","Show (it is really a matter of recalling) that the inverse $Q_{0}^{-1}=A^{2}$ is the square of a compact self-adjoint non-negative operator on $L^{2}(0, \pi)$ and that
$$
Q_{V}^{-1}=A(\mathrm{Id}+A V A)^{-1} A
$$
(where we are assuming that $0 \leq V \in \mathcal{O}[0, \pi]$). Using results from class or the notes on the Dirichlet problem (or otherwise ..) show that if $V \geq 0$ then $Q_{V}$ is an isomorphism (meaning just a bounded bijection with bounded inverse) of $H_{0}^{2}([0, \pi])$ to $L^{2}(0, \pi)$.","Let $\mathscr{H}=H_{0}^{2}(0, \pi), \mathscr{L}=L^{2}(0, \pi)$. The only difference here is that we use the interval $[0, \pi]$ instead of $[0,2 \pi]$ in the textbook. We define $A$ by $A(\sin k x)=\frac{1}{k} \sin k x$. This extends to a bounded operator from $\mathscr{L} \rightarrow \mathscr{L}$ which is compact and self adjoint. By definition $Q_{0}^{-1}=A^{2}$ and the same deduction as in the textbook shows $Q_{V}^{-1}=A(1+A V A)^{-1} A$ (we use 1 to represent Id). The bounded operator $A V A$ is compact, self adjoint and since $V \geq 0$, its eigenvalues are non-negative. Therefore, by the spectral theorem of compact and self adjoint operator, we may diagonalize $A V A$ and find $(1+A V A)^{-1}=1+Q$ for a bounded and compact operator $Q$.
We need to show $Q=A F A$ for some bounded operator $F: \mathscr{L} \rightarrow \mathscr{L}$. By definition $(1+$ $A V A)(1+Q)=1$. Expanding this, we find
$$
\begin{aligned}
Q & =-(1+A V A)^{-1} A V A=-(1+A V A-A V A)(1+A V A)^{-1} A V A \\
& =-A V A+A V A(1+A V A)^{-1} A V A=A\left(-V+V A(1+A V A)^{-1} A V\right) A
\end{aligned}
$$
Therefore, the bounded operator $F=-V+V A(1+A V A)^{-1} A V$ will do the job. Finally, we need to show $Q_{V}^{-1}$ is bounded from $\mathscr{L}$ to $\mathscr{H}$. By the above computation, we find $Q_{V}^{-1}=A(1+A F A) A=A\left(A+A F A^{2}\right)=A^{2}\left(1+F A^{2}\right)$. Here $1+F A^{2}$ is a bounded operator from $\mathscr{L}$ to $\mathscr{L}$ and $A^{2}$ by its definition is a bounded operator from $\mathscr{L}$ to $\mathscr{H}$. We conclude $Q_{V}^{-1}$ is bounded from $\mathscr{L}$ to $\mathscr{H}$ and this finishes the proof.","Show that if $u \in H_{0}^{2}([0, \pi])$ and $u_{N}$ is the sum of the first $N$ terms in the Fourier-Bessel series for $u$ (which is in $\left.L^{2}(0, \pi)\right)$ then
$$
u_{N} \rightarrow u, \frac{d u_{N}}{d x} \rightarrow F_{1}, \frac{d^{2} u_{N}}{d x^{2}} \rightarrow F_{2}
$$
where in the first two cases we have convergence in supremum norm and in the third, convergence in $L^{2}(0, \pi)$. Deduce that $u \in \mathcal{C}^{0}[0, \pi], u(0)=u(\pi)=0$ and $F_{1} \in \mathcal{C}^{0}[0, \pi]$ whereas $F_{2} \in L^{2}(0, \pi)$.","After normalisation, the set $\left\{\sqrt{\frac{2}{\pi}} \sin k x,(k=1,2, \ldots)\right\}$ forms an orthonormal basis of $L^{2}(0, \pi)$. Let $u \in H_{0}^{2}([0, \pi])$ and $c_{k}=\int_{0}^{\pi} \sin k x u(x) d x$. We have $\sum\left|k^{2} c_{k}\right|^{2}<\infty$. Therefore there exists functions $F_{1}$ and $F_{2}$ in $L^{2}(0, \pi)$ such that the following equations holds in $L^{2}(0, \pi)$:
$$
u=\frac{2}{\pi} \sum_{k=1}^{\infty} c_{k} \sin k x, \quad F_{1}=\frac{2}{\pi} \sum_{k=1}^{\infty} k c_{k} \cos k x, \quad F_{2}=-\frac{2}{\pi} \sum_{k=1}^{\infty} k^{2} c_{k} \sin k x .
$$
This shows the convergence in (2) holds at least in $L^{2}$ sense. Our goal is to show the first two summations actually converge in supremum norm (uniform convergence of continuous functions). This will imply $u$ and $F_{1}$ are uniform limit of continuous functions and therefore are continuous and $u(0)=u(\pi)=0$.
We first show the summation defining $F_{1}$ converges at $x=0$. Namely, $\sum k c_{k}$ converges. This follows from the Cauchy-Schwartz inequality $\sum\left|k c_{k}\right| \leq\left(\sum\left|k^{2} c_{k}\right|^{2}\right)\left(\sum \frac{1}{k^{2}}\right)$. Now, we show the summation defining $F_{1}$ converges in the supremum norm. For any $x \in[0, \pi]$, we compute the summation from $N_{1}$ to $N_{2}$ terms
$$
\sum_{k=N_{1}}^{N_{2}} k c_{k} \cos k x=\sum_{k=N_{1}}^{N_{2}} k c_{k}(\cos k x-1)+\sum_{k=N_{1}}^{N_{2}} k c_{k}=-\sum_{k=N_{1}}^{N_{2}} k^{2} c_{k} \int_{0}^{x} \sin k x+\sum_{k=N_{1}}^{N_{2}} k c_{k}
$$
Now, taking absolute value and using $\sum\left|k^{2} c_{k}\right|^{2}<\infty$, we find this tends to 0 as long as $N_{1}, N_{2}$ is large (independent of $x$ ). This finishes the uniform convergence of $F_{1}$. Similarly, the summation defining $u$ converges at $x=0$ since every term equals 0 . For any $x \in[0, \pi]$, we compute
$$
\sum_{k=N_{1}}^{N_{2}} c_{k} \sin k x=\sum_{k=N_{1}}^{N_{2}} k c_{k} \int_{0}^{x} \cos k x
$$
This tends to 0 as long as $N_{1}, N_{2}$ is large (independent of $x$ ). This proves the uniform convergence of $u$."
103,Mathematics,18.102,Introduction to Functional Analysis,"18.C06, 18.100B",None,Final Exam,Orthogonal Complements,8,nan,4.5,Text,"Suppose that $f \in L^{2}(\mathbb{R})$ is such that there exists a function $v \in L^{2}(\mathbb{R})$ satisfying
$$
\int_{\mathbb{R}} f \phi^{\prime}=\int_{\mathbb{R}} v \widehat{\phi} \quad \forall \phi \in \mathcal{S}(\mathbb{R})
$$
where $\widehat{\phi}$ is the Fourier transform of $\phi$. Show that $f \in C_{0}(\mathbb{R}) \subset L^{2}(\mathbb{R})$, where $C_{0}(\mathbb{R})$ is the space of continuous functions on $\mathbb{R}$ with zero limit at $\pm \infty$.
You may use that if $h$ is a locally $L^{2}$ function on $\mathbb{R}$ such that $\int h \phi=0$ for every $\phi \in C_{c}^{\infty}(\mathbb{R})$ then $h=0$ a.e. (as $C_{c}^{\infty}(I)$ is dense in $L^{2}(I)$ for every interval $I$).",Open,"Let $\psi:=\widehat{\phi}$. Then $\phi(x)=\frac{1}{2 \pi} \widehat{\psi}(-x)$, so
$$
\int_{\mathbb{R}} f(-x) \widehat{i \xi \psi}(x)=\int v \psi \quad \forall \psi \in \mathcal{S}(\mathbb{R}).
$$
So
$$
\int_{\mathbb{R}} \widehat{f}(-\xi) i \xi \psi(\xi)=\int v \psi
$$
from which it follows that the locally $L^{2}$-function $h(\xi):=i \xi \widehat{f}(-\xi)-v(\xi)$ is orthogonal to $\mathcal{S}(\mathbb{R})$, hence to its subspace $C_{c}^{\infty}(\mathbb{R})$. Thus $h=0$ a.e., i.e., $\xi \widehat{f} \in L^{2}(\mathbb{R})$. This means $\widehat{f} \in L^{1}(\mathbb{R})$, since
$$
\left(\int|\widehat{f}|\right)^{2} \leq \int \frac{1}{1+\xi^{2}} \cdot \int\left(1+\xi^{2}\right)|\widehat{f}|^{2}=\pi \int\left(1+\xi^{2}\right)|\widehat{f}|^{2}<\infty.
$$
so $f$ is continuous and goes to zero at infinity.",Suppose that $f: \mathbb{R} \rightarrow \mathbb{C}$ is a locally $\mathcal{L}^{1}$ function and $\phi \in \mathcal{C}_{\mathrm{c}}(\mathbb{R})$. Explain why $f \phi \in \mathcal{L}^{1}(\mathbb{R})$.,"Suppose $\phi$ is supported on $[-R, R]$ and let $f_{R}(x)=f(x)$ if $x \in[-R, R]$ and $f(x)=0$ otherwise. Then $f_{R} \in \mathcal{L}^{1}(\mathbb{R})$ and $f \phi=f_{R} \phi$. So it suffices to show that if $f \in \mathcal{L}^{1}(\mathbb{R})$ then so is $f \phi$. But this is easy since if $u_{n}$ is an approximating sequence for $f$ then $u_{n} \phi$ is an approximating sequence for $f \phi$. Indeed, $u_{n}(x) \phi(x) \rightarrow f(x) \phi(x)$ a.e. and
$$
\sum_{n} \int\left|\left(u_{n}-u_{n-1}\right) \phi\right| \leq \max |\phi| \sum_{n} \int\left|u_{n}-u_{n-1}\right|<\infty
$$
(where $u_{n-1}=0$).","If $U \subset \mathbb{R}$ is measureable and $f \in \mathcal{L}^{1}(\mathbb{R})$ show that
$$
\int_{U} f=\int \chi_{U} f \in \mathbb{C}
$$
is well-defined. Prove that if $f \in \mathcal{L}^{1}(\mathbb{R})$ then
$$
I_{f}(x)= \begin{cases}\int_{(0, x)} f & x \geq 0 \\ -\int_{(x, 0)} f & x<0\end{cases}
$$
is a bounded continuous function on $\mathbb{R}$.","The integral is well-defined by Problem 4.3.3. The function $I_{f}(x)$ is well defined and bounded since $I_{|f|}(x)$ is bounded by $\int|f|<\infty$.
To prove continuity it is sufficient to check that the sequence $\int_{\left(x, x_{n}\right)} f$ for $x_{n}<x$ and $\int_{\left(x_{n}, x\right)} f$ for $x \leq x_{n}$ tends to 0 as $x_{n}$ tends to $x$. The sequence $\chi_{\left(x, x_{n}\right)} f$ (resp. $\chi_{\left(x_{n}, x\right)} f$ ) is dominated by $|f| \in \mathcal{L}^{1}(\mathbb{R})$ and its limit is 0 a.e. The statement now follows from dominated convergence theorem.","Define $\mathcal{L}^{\infty}(\mathbb{R})$ as the set of functions $g: \mathbb{R} \longrightarrow \mathbb{C}$ such that there exists $C>0$ and a sequence $v_{n} \in \mathcal{C}(\mathbb{R})$ with $\left|v_{n}(x)\right| \leq C$ and $v_{n}(x) \rightarrow g(x)$ a.e.
Show that if $g \in \mathcal{L}^{\infty}(\mathbb{R})$ and $f \in \mathcal{L}^{1}(\mathbb{R})$ then $g f \in \mathcal{L}^{1}(\mathbb{R})$ and that this defines a map
$$
L^{\infty}(\mathbb{R}) \times L^{1}(\mathbb{R}) \longrightarrow L^{1}(\mathbb{R})
$$
which satisfies $\|g f\|_{L^{1}} \leq\|g\|_{L^{\infty}}\|f\|_{L^{1}}$.","Proof. For $g$ we keep the notations from the definition. For $f$ let $w_{n}$ be the absolutely summable series converging to $f$ a.e.
Note that the sequence $u_{n}=v_{k} w_{n}$ is absolutely summable as $\sum_{n} \int\left|v_{k} w_{n}(x)\right| \leq C \sum_{n} \int\left|w_{n}(x)\right|<\infty$ and converges to $v_{k} f$ a.e. which is thus in $\mathcal{L}^{1}(\mathbb{R})$. Now $t_{n}=v_{n} f$ is dominated by $C|f|$ and converges to $f g \in \mathcal{L}^{1}(\mathbb{R})$.
If either $f$ or $g$ is in $\mathcal{N}$ then $f g \in \mathcal{N}$, which ensure passing from $\mathcal{L}$ to $L$.
Finally, since $|g| \leq\|g\|_{L^{\infty}}$ a.e.
$$
\|g f\|_{L^{1}}=\int|g f| \leq \int\|g\|_{L^{\infty}}|f|=\|g\|_{L^{\infty}}\|f\|_{L^{1}}.
$$"
3,Mathematics,18.404,Theory of Computation,6.1210/18.200,None,Problem Set 1,Regular Expression,3,b,0.5555555556,Text,"For any regular expression $R$ and $k\ge0$, let $R^k$ be
$R$ self-concatenated $k$ times, $\smash{\underbrace{RR\cdots R}_k}$. \\
Let $\SS=\{\st0,\st1\}$. 
Let $B=\set{\st0^ku\st1^k} k\ge1$ and $ u\in\st1\SSS\setend$.
Show $B$ is not regular.",Open,"Assume for contradiction that $B$ is regular. Use the pumping lemma to get the pumping length $p$. Letting $s=0^{p} 11^{p}$ we have $s \in B$ (here $u=1$ ) and so we can divide up $s=x y z$ according to the conditions of the pumping lemma. By condition 3, $x y$ has only 0s, hence the string $x y y z$ is $0^{l} 11^{p}$ for some $l>p$. But then $0^{l} 11^{p}$ isn't equal to $0^{k} 1 u 1^{k}$ for any $u \in \Sigma^{*}$ and $k$, because the left-hand part of the string requires $k=l$ and the right-hand part requires $k \leq p$. Both together are impossible, because $l>p$. That contradicts the pumping lemma and we conclude that $B$ isn't regular.","For any regular expression $R$ and $k\ge0$, let $R^k$ be
$R$ self-concatenated $k$ times, $\smash{\underbrace{RR\cdots R}_k}$. \\
Let $\SS=\{\st0,\st1\}$. 
Let $A=\set{\st0^ku\st1^k} k\ge1$ and $ u\in\SSS\setend$.
Show $A$ is regular.",Any string that doesn't begin with 0 and end with 1 obviously cannot be a member of $A$. If string $w$ does begin with 0 and end with 1 then $w=0 u 1$ for some string $u$. Hence $A=0 \Sigma^{*} 1$ and therefore $A$ is regular.,"Let $\SS = \{\st0,\!\st1\}$.  For $k\ge1$, let $E_k=\set{w}
|w| \ge k$ and the $k$th symbol from the end of $w$ is~a~\st1\setend.
Here, $|w|$ means the length of $w$.
Given $k$, describe a regular expression for $E_k$. 
You may use the exponentation notation given in problem 4.",$\Sigma^{*} 1 \Sigma^{k-1}$.,"Let $\SS = \{\st0,\!\st1\}$.  For $k\ge1$, let $E_k=\set{w}
|w| \ge k$ and the $k$th symbol from the end of $w$ is~a~\st1\setend.
Here, $|w|$ means the length of $w$.
Prove that for each $k$, no \dfa\ can recognize $E_k$ with fewer than $2^k$ states.","Assume for contradiction that DFA $C$ recognizes $E_{k}$ with fewer than $2^{k}$ states. Consider all $2^{k}$ strings of length $k$. When $C_{k}$ reads each of these strings, it must end up in the same state for at least two of them, $s=s_{1} s_{2} \cdots s_{k}$ and $t=t_{1} t_{2} \cdots t_{k}$. For some $i$ we have $s_{i} \neq t_{i}$. Let $s^{\prime}=s 0^{i-1}$ and $t^{\prime}=t 0^{i-1}$. The $k$ th symbols from the ends of $s^{\prime}$ and $t^{\prime}$ are unequal, hence only one of $s^{\prime}$ and $t^{\prime}$ is in $E_{k}$. However, $C$ ends up in the same state on $s$ and $t$ so it also ends up in the same state on $s^{\prime}$ and $t^{\prime}$, so $C$ acts the same on $s$ ' and $t$ ', i.e., it accepts both or rejects both, a contradiction."
72,Mathematics,18.03,Differential Equations,None,18.02,Problem Set 6,Linear Algebra,4,b,0.2412868633,Text,"Let $S_{3}$ be the vector space of polynomials of degree at most 3 . Consider the linear map $T: S_{3} \rightarrow \mathbb{R}^{2}$ defined by
$$
T(p)=\left(p(0), p^{\prime}(1)\right)
$$
You may assume this map is linear (it follows from problem (4)).
Find a basis for $\operatorname{Ker}(T):=\left\{p \in S_{3}: T(p)=0\right\}$ and compute the dimension of this vector space. Note in particular that we have the equality
$$
\operatorname{dim} \operatorname{Ker}(T)+\operatorname{dim} \operatorname{Im}(T)=\operatorname{dim} S_{3}
$$",Open,"Let $p(x)=a_{3} x^{3}+a_{2} x^{2}+a_{1} x+a_{0}$ be an element of $S_{3}$. Notice that $T(p)=\left(a_{0}, 3 a_{3}+\right.$ $\left.2 a_{2}+a_{1}\right)$. Hence, if $p$ belongs to the kernel of $T$, we have $a_{0}=0$ and $a_{1}=-3 a_{3}-2 a_{2}$. Consequently, we have $p(x)=a_{3}\left(x^{3}-3 x\right)+a_{2}\left(x^{2}-2 x\right)$. We see that the kernel of $T$ is included in the span of $x^{3}-3 x$ and $x^{2}-2 x$. Reciprocally, it follows from our computation above that $x^{3}-3 x$ and $x^{2}-2 x$ belongs to the kernel of $T$. Thus, the kernel of $T$ is exactly the span of $x^{3}-3 x$ and $x^{2}-2 x$.
Let us prove that $x^{3}-3 x$ and $x^{2}-2 x$ are linearly independent. Let $\lambda$ and $\mu$ be real numbers such that $\lambda\left(x^{3}-3 x\right)+\mu\left(x^{2}-2 x\right)=0$ for every $x \in \mathbb{R}$. Differentiating this equality three times and evaluating at $x=1$, we find that $\lambda=0$. Hence, we have $\mu\left(x^{2}-2 x\right)=0$, and evaluating at $x=1$, we find that $\mu=0$. We proved that $\lambda=\mu=0$, it follows that $x^{3}-3 x$ and $x^{2}-2 x$ are linearly independent.
Consequently, $x^{3}-3 x$ and $x^{2}-2 x$ form a basis of the kernel of $T$, which is thus of dimension 2. It follows from the previous question that the dimension of the image of $T$ is 2 , so that we have
$$
\operatorname{dim} \operatorname{Ker}(T)+\operatorname{dim} \operatorname{Im}(T)=2+2=4=\operatorname{dim} S_{3} .
$$","Let $S_{3}$ be the vector space of polynomials of degree at most 3 . Consider the linear map $T: S_{3} \rightarrow \mathbb{R}^{2}$ defined by
$$
T(p)=\left(p(0), p^{\prime}(1)\right)
$$
You may assume this map is linear (it follows from problem (4)).
Show that this map is surjective. Concretely, for any $\left(a_{1}, a_{2}\right) \in \mathbb{R}^{2}$, find a polynomial $p$ so that $T(p)=\left(a_{1}, a_{2}\right)$.","For $\left(a_{1}, a_{2}\right) \in \mathbb{R}^{2}$, let $p$ be the polynomial $p(x)=a_{2} x+a_{1}$ and notice that $T(p)=\left(a_{1}, a_{2}\right)$. The map $T$ is consequently surjective.","Let $x$ be a real variable and for $k \geq 0$ consider
$$
S_{k}=\{\text { real polynomials } p(x) \text { with degree } \leq k\} .
$$
Show that $S_{k}$ is a vector space (over $\mathbb{R}$ ), find a basis for $S_{k}$ and compute $\operatorname{dim} S_{k}$.","Let us define the space $S_{k}$ more precisely as the set of all polynomials $p(x)$ that can be expressed as $p(x)=\sum_{n=0}^{k} p_{n} x^{n}$, where each $p_{n} \in \mathbb{R}$. To check that $S_{k}$ is a vector space over $\mathbb{R}$, we only need to check three requirements. The mathematical statement will be provided, and then a translation in more regular English.
1. If $v, w \in S_{k}$, then $v+w \in S_{k}$. In other words, the sum of two polynomials degree each not exceeding $k$ is a polynomial with degree not exceeding $k$.
2. If $v \in S_{k}, c \in \mathbb{R}$, then $c \cdot v \in S_{k}$. In other words, the product of a real number and a polynomial degree not exceeding $k$ is a polynomial with degree not exceeding $k$
3. There exists an element $\mathbf{0}$ in $S_{k}$ such that $v+\mathbf{0}=v \quad \forall v \in S_{k}$. In other words, there is a 0 polynomial with degree not exceeding $k$.
To facilitate checking of the requirements, write $v(x)=\sum_{n=0}^{k} v_{n} x^{n}, w(x)=\sum_{n=0}^{k} w_{n} x^{n}$. Then, we can check each requirement in turn.
1. $v+w=\sum_{n=0}^{k}\left(v_{n}+w_{n}\right) x^{n} \in S_{k}$.
2. $c \cdot v=\sum_{n=0}^{k}\left(c v_{n}\right) x^{n} \in S_{k}$
3. We can construct $\mathbf{0}=\sum_{n=0}^{k} p_{n} x^{n}$ with $p_{n}=0 \forall n$. Then, see that $v+\mathbf{0}=$ $\sum_{n=0}^{k} v_{n} x^{n}+\sum_{n=0}^{k} 0 x^{n}=\sum_{n=0}^{k} v_{n} x^{n}=v$ for any $v \in S_{k}$.
One basis for $S_{k}$ is given by $\left\{1, x, x^{2}, x^{3} \ldots x^{k}\right\}$, which contains $k+1$ terms, and so the dimension of $S_{k}$ is $k+1$.","Recall the definition of a linear map: If $V_{1}, V_{2}$ are vector spaces, both over $\mathbb{R}$, or both over $\mathbb{C}$, then a map $T: V_{1} \rightarrow V_{2}$ is said to be linear if: for any scalars $c_{1}, c_{2}$ and any vectors $\vec{v}_{1}, \vec{v}_{2}$ we have
$$
T\left(c_{1} \vec{v}_{1}+c_{2} \vec{v}_{2}\right)=c_{1} T\left(\vec{v}_{1}\right)+c_{2} T\left(\vec{v}_{2}\right)
$$
Let $S_{k}:=\{p(x)$ polynomials of degree $\leq k\}$. Show that the following maps are linear:
Consider the basis $\left\{1, x, x^{2}, x^{3}\right\}$ of $S_{3}$. With this choice of basis we may identify a polynomial $p(x) \in S_{3}$ with a vector as follows:
$$
p(x)=a_{0}+a_{1} x+a_{2} x^{2}+a_{3} x^{3} \longleftrightarrow\left(\begin{array}{l}
a_{0} \\
a_{1} \\
a_{2} \\
a_{3}
\end{array}\right)
$$
Similarly, let $\left\{1, x, x^{2}\right\}$ be a basis of $S_{2}$. Then we may identify a polynomial $q(x) \in S_{2}$ with a vector as
$$
q(x)=b_{0}+b_{1} x+b_{2} x^{2} \longleftrightarrow\left(\begin{array}{l}
b_{0} \\
b_{1} \\
b_{2}
\end{array}\right)
$$
With these choices, express the map $D: S_{3} \rightarrow S_{2}$ as a $3 \times 4$ matrix.","Suppose $A$ is the matrix representation of $D$ with respect to the bases above. Let $A_{i}$ be the $i$-th column of $A$ for $1 \leq i \leq 4$. Then we have
$$
\begin{aligned}
&A_{1}=A \cdot\left[\begin{array}{l}
1 \\
0 \\
0 \\
0
\end{array}\right] \longleftrightarrow D(1)=0 \longleftrightarrow\left[\begin{array}{l}
0 \\
0 \\
0
\end{array}\right] \\
&A_{2}=A \cdot\left[\begin{array}{l}
0 \\
1 \\
0 \\
0
\end{array}\right] \longleftrightarrow D(x)=1 \longleftrightarrow\left[\begin{array}{l}
1 \\
0 \\
0
\end{array}\right] \\
&A_{3}=A \cdot\left[\begin{array}{l}
0 \\
0 \\
1 \\
0
\end{array}\right] \longleftrightarrow D\left(x^{2}\right)=2 x \longleftrightarrow\left[\begin{array}{l}
0 \\
2 \\
0
\end{array}\right] \\
&A_{4}=A \cdot\left[\begin{array}{l}
0 \\
0 \\
0 \\
1
\end{array}\right] \longleftrightarrow D\left(x^{3}\right)=3 x^{2} \longleftrightarrow\left[\begin{array}{l}
0 \\
0 \\
3
\end{array}\right]
\end{aligned}
$$
Therefore, $A=\left[\begin{array}{llll}0 & 1 & 0 & 0 \\ 0 & 0 & 2 & 0 \\ 0 & 0 & 0 & 3\end{array}\right]$."
74,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Exercise 10,State Machines,1,a,0.1041666667,Text,"For each of the following state machines, provide the output sequence $\left[y_{1}, y_{2}, \ldots, y_{T}\right]$ given the input sequence $\left[x_{1}, x_{2}, \ldots, x_{T}\right]$. Notice that the inputs start with subscript 1:
Input: $[0,1,2,1]$
$s_{0}=0$
$s_{t}=f_{s}\left(s_{t-1}, x_{t}\right)=\max \left(s_{t-1}, x_{t}\right)$
$y_{t}=f_{o}\left(s_{t}\right)=2 \times s_{t}$ 
Enter a Python list of four numbers:",Expression,"[0, 2, 4, 4].
Passing in $x_{1}$:
$s_{0}=0$
$s_{1}=f_{s}\left(s_{0}, x_{1}\right)=\max (0,0)=0$
$y_{1}=f_{o}\left(s_{1}\right)=2 \times 0=0$
Passing in $x_{2}$:
$s_{1}=0$
$s_{2}=f_{s}\left(s_{1}, x_{2}\right)=\max (0,1)=1$
$y_{2}=f_{o}\left(s_{2}\right)=2 \times 1=2$
Similar calculations for $x_{3}$ and $x_{4}$.
You can also solve the problem with code:
def f_s(s, x_t):
return max(s, x_t)
def f_o(s):
return s * 2
s = 0
inputs = [0, 1, 2, 1]
outputs = []
for x in inputs:
s = f_s(s, x)
y = f_o(s)
outputs.append(y)
print(outputs)","For each of the following state machines, provide the output sequence $\left[y_{1}, y_{2}, \ldots, y_{T}\right]$ given the input sequence $\left[x_{1}, x_{2}, \ldots, x_{T}\right]$. Notice that the inputs start with subscript 1:
Input: $[0,1,2,1]$
$s_{0}=(0,0)$
$s_{t}=f_{s}\left(s_{t-1}, x_{t}\right)=\left(s_{t-1}[0]+x_{t}, s_{t-1}[1]+1\right)$
$y_{t}=f_{o}\left(s_{t}\right)=s_{t}[0] / s_{t}[1]$ 
Note that the state is two-dimensional.
Enter a Python list of four numbers:","[0, 0.5, 1, 1].
Passing in $x_{1}$:
$s_{0}=(0,0)$
$s_{1}=f_{s}\left(s_{0}, x_{1}\right)=(0+0,0+1)=(0,1)$
$y_{1}=f_{o}\left(s_{1}\right)=s_{1}[0] / s_{1}[1]=0 / 1=0$
Passing in $x_{2}$:
$s_{1}=(0,1)$
$s_{2}=f_{s}\left(s_{1}, x_{2}\right)=(0+1,1+1)=(1,2)$
$y_{1}=f_{o}\left(s_{2}\right)=s_{2}[0] / s_{2}[1]=1 / 2=0.5$
Similar calculations for $x_{3}$ and $x_{4}$.
You can also solve the problem with code:
def f_s(s, x_t):
return s[0] + x_t, s[1] + 1
def f_o(s):
return s[0] / s[1]
s = (0, 0)
inputs = [0, 1, 2, 1]
outputs = []
for x in inputs:
s = f_s(s, x)
y = f_o(s)
outputs.append(y)
print(outputs)","As in the last problem, suppose that $x_{1}(t)$ obeys $x_{1}^{\prime}(t)=-x_{1}(t)$ and $x_{2}(t)$ obeys $x_{2}^{\prime}(t)=-x_{2}(t)^{2}$. Suppose that $x_{1}(0)=x_{2}(0)=1$.
Compute $x_{1}(T)$. ",You can just guess it: $x_{1}(T)=e^{-T}$. It satisfies $x_{1}^{\prime}=-x_{1}$ and $x_{1}(0)=1$.,"Let $\Sigma=\{0,1,2\}$ be the alphabet for the languages in all parts of this problem.
Let $A=\left\{0^{i} 1^{j} 2^{k} \mid i, j, k \geq 0\right\}$. Give the state diagram of a DFA with 4 states that recognizes $\bar{A}$, the complement of $A$.","Here's a description of the diagram. Put self-loops on each of the states $q_{0}, q_{1}, q_{2}$, and $q_{3}$ with labels $0,1,2$, and $\{0,1,2\}$ respectively. Additional transitions are: $q_{0}$ to $q_{1}$ labeled $1, q_{0}$ to $q_{2}$ labeled 2 , $q_{1}$ to $q_{2}$ labeled $2, q_{1}$ to $q_{3}$ labeled 0 , and $q_{2}$ to $q_{3}$ labeled $\{0,1\}$. The start state is $q_{0}$, and $q_{3}$ is the only accept state."
382,Mathematics,18.01,Calculus I,None,None,Problem Set 8,Variance,10,a,0.1583949314,Text,"Suppose that we flip a coin a hundred times and count how many heads we get. On average the number of heads is 50 . On the other hand, if we flip a coin a hundred times, it's unlikely that we will get exactly 50 heads. Usually the number of heads will be somewhat above average or somewhat below average. The variance helps understand how far away the number of heads typically is from the mean. (Remember, mean is another word for average.)
If we have a probability distribution for $x$ with mean $M$, then the variance is the average value of $(x-M)^{2}$. Let's illustrate this with an example.
Example. Suppose we slip a coin two times and count the number of heads. The probability distribution for the number of heads is
\begin{tabular}{|c|c|}
\hline Number of heads & Probability \\
\hline 0 & $1 / 4$ \\
\hline 1 & $1 / 2$ \\
\hline 2 & $1 / 4$ \\
\hline
\end{tabular}
The average number of heads is $M=1$. To find the variance, we want to find the average value of (The number of heads $-M)^{2}$. To compute we first include this information on our table:
\begin{tabular}{|c|c|c|}
\hline Number of heads & Probability & (The number of heads $-M)^{2}$ \\
\hline 0 & $1 / 4$ & $(0-1)^{2}=1$ \\
\hline 1 & $1 / 2$ & $(1-1)^{2}=0$ \\
\hline 2 & $1 / 4$ & $(2-1)^{2}=1$ \\
\hline
\end{tabular}
The variance is the average value of (The number of heads $-M)^{2}$ which is (1/4) . $1+(1 / 2) \cdot 0+(1 / 4) \cdot 1=(2 / 4)$.
Suppose we flip a coin three times and count the number of heads. Find the mean and the variance.",Numerical,"The mean value $M$ is $0(1 / 8)+1(3 / 8)+2(3 / 8)+3(1 / 8)=3 / 2$.
The variance is $(9 / 4)(1 / 8)+(1 / 4)(3 / 8)+(1 / 4)(3 / 8)+(9 / 4)(1 / 8)=\frac{9+3+3+9}{32}=$ $\frac{24}{32}=3 / 4$.","Suppose that we flip a coin a hundred times and count how many heads we get. On average the number of heads is 50 . On the other hand, if we flip a coin a hundred times, it's unlikely that we will get exactly 50 heads. Usually the number of heads will be somewhat above average or somewhat below average. The variance helps understand how far away the number of heads typically is from the mean. (Remember, mean is another word for average.)
If we have a probability distribution for $x$ with mean $M$, then the variance is the average value of $(x-M)^{2}$. Let's illustrate this with an example.
Example. Suppose we slip a coin two times and count the number of heads. The probability distribution for the number of heads is
\begin{tabular}{|c|c|}
\hline Number of heads & Probability \\
\hline 0 & $1 / 4$ \\
\hline 1 & $1 / 2$ \\
\hline 2 & $1 / 4$ \\
\hline
\end{tabular}
The average number of heads is $M=1$. To find the variance, we want to find the average value of (The number of heads $-M)^{2}$. To compute we first include this information on our table:
\begin{tabular}{|c|c|c|}
\hline Number of heads & Probability & (The number of heads $-M)^{2}$ \\
\hline 0 & $1 / 4$ & $(0-1)^{2}=1$ \\
\hline 1 & $1 / 2$ & $(1-1)^{2}=0$ \\
\hline 2 & $1 / 4$ & $(2-1)^{2}=1$ \\
\hline
\end{tabular}
The variance is the average value of (The number of heads $-M)^{2}$ which is (1/4) . $1+(1 / 2) \cdot 0+(1 / 4) \cdot 1=(2 / 4)$.
Suppose we flip a coin one time and count the number of heads. Find the mean and the variance.","The mean is $(0)(1 / 2)+(1)(1 / 2)=1 / 2$. 
The variance is $(0-1 / 2)^{2}(1 / 2)+$ $(1-1 / 2)^{2}(1 / 2)=1 / 4$.","Finally, we write down a general Gaussian, with an arbitrary mean and variance. A Gaussian with mean $M$ and variance $V$ is given by the following formula: $\frac{1}{\sqrt{2 \pi V}} e^{-\frac{(x-M)^{2}}{2 V}} d x$
As we discussed in class, if we flip a coin 100 times and count the number of heads, the probability distribution for the number of heads is very close to a Gaussian. Find that Gaussian. Recall that if we flip a coin $N$ times, the mean number of heads is $N / 2$, and the variance in the number of heads is $N / 4$.","We want a Gaussian distribution with mean equal to $\frac{100}{2}=50$ and variance equal to $\frac{100}{4}=25$. The Gaussian distribution with mean $M$ and variance $V$ is $\frac{1}{\sqrt{2 \pi V}} e^{-\frac{(x-M)^{2}}{2 V}} d x$. Plug in $M=50$ and $V=25$ to get the distribution
$$
\frac{1}{\sqrt{50 \pi}} e^{-\frac{(x-50)^{2}}{50}} d x
$$","The average value of a probability distribution $f(x) d x$ is $\int_{-\infty}^{\infty} x f(x) d x$. If you imagine a biased spinner which spins a number $x$ according to the probability distribution $f(x) d x$, then this integral is the average value of $x$. The average value of a probability distribution is also called the mean value.
Here is a picture of a probability density function $f(x)$ below.
Suppose that $\int_{-\infty}^{\infty} x f(x) d x=M$ (so the mean value of $f(x) d x$ is $\left.M\right)$. Suppose that $g(x)=f(x-2)$. Find the mean value of the probability distribution $g(x) d x$. In other words, compute $\int_{-\infty}^{\infty} x g(x) d x$. Give your answer in terms of $M$.","Note that
$$
\int_{-\infty}^{\infty} x g(x) d x=\int_{-\infty}^{\infty} x f(x-2) d x .
$$
Do the substitution $u=x-2, d u=d x$ to get
$$
\int_{-\infty}^{\infty}(u+2) f(u) d u .
$$
Split this integral into
$$
\int_{-\infty}^{\infty} u f(u) d u+\int_{-\infty}^{\infty} 2 f(u) d u .
$$
The first integral is the average value of $f(x) d x$, which is $M$. Since $f$ is a probability density function, $\int_{-\infty}^{\infty} f(u) d u=1$. Thus the average value of $g(x) d x$ is $M+2$."
28,Mathematics,18.6,Probability and Random Variables,18.02,None,Problem Set 3,Cumulative Distribution Function,3,b,0.25,Text,"Let $X$ be a random variable with cumulative distribution function $F$.
What is the cumulative distribution function of $aX+b$, where $a$ and $b$ are constants and $a \neq 0$? (Remember that $a$ could be positive or negative.)",Expression,"Let $Y = aX + b$.
\textbf{Case 1}: $a > 0$.
$F_Y(c) = P\{Y \leq c\} = P\{aX + b \leq c\} = P\{X \leq \frac{c - b}{a}\} = F_X(\frac{c - b}{a})$.
\textbf{Case 2}: $a < 0$.
$F_Y(c) = P\{Y \leq c\} = P\{aX + b \leq c\} = P\{X \geq \frac{c - b}{a}\} = 1 - P\{X < \frac{c - b}{a}\} = 1 - P\{X \leq \frac{c - b}{a}\} + P\{X = \frac{c - b}{a}\} = 1 - F_X(\frac{c - b}{a}) + p_X(\frac{c - b}{a})$.","Let $X$ be a random variable with cumulative distribution function $F$.
What is the cumulative distribution function of $e^X$?","Let $Y = e^X$.
\textbf{Case 1}: $c > 0$.
$F_Y(c) = P\{Y \leq c\} = P\{e^X \leq c\} = P\{X \leq ln$ $c)\} = F_X(ln$ $c)$.
\textbf{Case 2}: $c \leq 0$.
$F_Y(c) = 0$.","Let $X$ be a continuous random variable have cumulative distribution function $F$. Define the random variable $Y$ by $Y = F(X)$. Show that $Y$ is uniformly distributed over $(0, 1)$.","Since $F_X$ is a cumulative distribution function of a continuous random variable, $0 \leq F_X \leq 1$ and $0 \leq Y \leq 1$. When $0 < x < 1$, $F_Y(x) = P\{Y \leq x\} = P\{F_X(X) \leq x\} = P\{X \leq F_X^{-1}(x)\} = F_X(F_X^{-1}(x)) = x$. Thus, $Y$ has the cumulative distribution function of a uniform random variable, so $Y$ is uniformly distributed over $(0, 1)$.",Let $X$ have probability density $f_X$. Find the probability density function of the random variable $Y$ defined by $Y = aX + b$.,"\textbf{Case 1}: $a = 0$.
$F_Y(c) = P\{Y = b\} = 1$.
\textbf{Case 2}: $a < 0$.
$F_Y(c) = P\{Y \leq c\} = P\{aX + b \leq c\} = P\{X \geq \frac{c - b}{a}\} = 1 - P\{X < \frac{c - b}{a}\} = 1 - P\{X \leq \frac{c - b}{a}\} + P\{X = \frac{c - b}{a}\} = 1 - F_X(\frac{c - b}{a}) + p_X(\frac{c - b}{a})$.
$f_Y(t) = \frac{\dv{d}}{\dv{dt}}(1 - F_X(\frac{t - b}{a}) = -\frac{1}{a}f_X(\frac{t-b}{a})$.
\textbf{Case 3}: $a > 0$.
$F_Y(c) = P\{Y \leq c\} = P\{aX + b \leq c\} = P\{X \leq \frac{c - b}{a}\} = F_X(\frac{c - b}{a})$.
$f_Y(t) = \frac{\dv{d}}{\dv{dt}} F_X(\frac{t - b}{a}) = \frac{1}{a}f_X(\frac{t-b}{a})$. "
417,Mathematics,18.01,Calculus I,None,None,Midterm Exam 1,Critical Points,3,a,0.3333333333,Text,"Suppose that $f(x)=4 x^{3}-6 x^{2}+1$.
Find the values of $x$ where $f^{\prime}(x)=0$. These are called the critical points of $f$.",Numerical,"First we calculate $f^{\prime}(x)$. We find that $f^{\prime}(x)=3 \times 4 x^{3-1}-2 \times 6 x^{2-1}+0=12 x^{2}-12 x$. You might be able to see straight away that $12\left(x^{2}-x\right)=0$ at $x=0$ and $x=1$. Otherwise we can solve by plugging in the quadratic formula, giving:
$$
x=\frac{-(-12) \pm \sqrt{(-12)^{2}-4 \times 12 \times 0}}{2 \times 12}=\frac{12 \pm \sqrt{12^{2}}}{24}=\frac{12 \pm 12}{24}=0,1
$$","Let $f(x)=(1 / 3) x^{3}-x$.
Find all the values of $x$ where $f^{\prime}(x)=0$. These are called critical points of $f$. For each critical point $x$, compute $f(x)$.","Now $f(x)=x^{3} / 3-x$.
$f^{\prime}(x)=0$ when $x=\pm 1$. At $x=-1, f(x)=2 / 3$. At $x=+1, f(x)=-2 / 3$.","Suppose that $f(x)=4 x^{3}-6 x^{2}+1$.
Label the critical point of $f$ on the x-axis, and then label the places where $f^{\prime}(x)>0$ and where $f^{\prime}(x)<0$.","As we found in part a, $f^{\prime}(x)=12 x^{2}-12 x$. This means that when $x<0$ both $12 x^{2}$ and $-12 x$ are positive, so that $12 x^{2}-12 x>0$. When $0<x<1$ we have by multiplying through by $x$ that $0 \times x<x \times x<1 \times x \Rightarrow x^{2}<x \Rightarrow 12 x^{2}<12 x \Rightarrow 12 x^{2}-12 x<0$. Lastly, when $x>1$ we get that $x^{2}>x$ so that again $12 x^{2}>12 x$ and $12 x^{2}-12 x>0$. The critical points we get from part a.
In the graph below there is a thickened line to indicate critical points. Plus for $f^{\prime}(x)>0$ and minus for $f^{\prime}(x)<0$.","Suppose that $f(x)=4 x^{3}-6 x^{2}+1$.
Compute $f(x)$ for each critical point $x$.","$$
f(0)=4 \times 0^{3}-6 \times 0^{2}+1=0+0+1=1 \text { and } f(1)=4 \times 1^{3}-6 \times 1^{2}+1=4-6+1=-1
$$"
51,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 1,Monte-Carlo Tree Search,4,bi,0.1302083333,Text,"Consider MCTS on a problem where the initial state $s_{0}$ has actions two actions $a_{0}$ and $a_{1}$. The UCB parameter $C$ is $1.4$. Suppose the search has completed 8 full iterations:
\begin{itemize}
\item It selected action $a_{0} 3$ times, receiving utilities $[0.1,0.7,0.3]$.
\item It selected action $a_{1} 5$ times, receiving utilities $[0.4,0.4,0.4,0.4,0.4]$.
\end{itemize}
On the 9-th iteration, what is the UCB value for action $a_{0}$ when expanding from $s_{0}$? (Enter a number accurate to 2 decimal places).",Numerical,1.532.,"Consider MCTS on a problem where the initial state $s_{0}$ has actions two actions $a_{0}$ and $a_{1}$. The UCB parameter $C$ is $1.4$. Suppose the search has completed 8 full iterations:
\begin{itemize}
\item It selected action $a_{0} 3$ times, receiving utilities $[0.1,0.7,0.3]$.
\item It selected action $a_{1} 5$ times, receiving utilities $[0.4,0.4,0.4,0.4,0.4]$.
\end{itemize}
On the 9-th iteration, what is the UCB value for action $a_{1}$ when expanding from $s_{0}$? (Enter a number accurate to 2 decimal places).",1.303.,"Consider MCTS on a problem where the initial state $s_{0}$ has actions two actions $a_{0}$ and $a_{1}$. The UCB parameter $C$ is $1.4$. Suppose the search has completed 8 full iterations:
\begin{itemize}
\item It selected action $a_{0} 3$ times, receiving utilities $[0.1,0.7,0.3]$.
\item It selected action $a_{1} 5$ times, receiving utilities $[0.4,0.4,0.4,0.4,0.4]$.
\end{itemize}
Which of the two actions will be selected on the 9-th iteration?
(a) $a_{0}$
(b) $a_{1}$",(a) $a_{0}$,"Consider a tiny MDP with states $(0,1,2,3)$ and actions $(b, c)$.
Given the reward and transition functions below with an infinite horizon and a discount factor of $0.9$, compute three iterations of value iteration. Don't assume a particular policy. Assume that:
\begin{itemize}
\item All the value estimates start at 0: meaning, at iteration $0, Q(s, a)=0$ for all $s, a$ pairs.
\item You operate synchronously: that is, on iteration $t$ of value iteration, you only use values that were computed on iteration $t-1$.
\end{itemize}
We recommend you compute the Q-value iteration by hand to get a better understanding of the algorithm.
For each iteration, enter eight numbers corresponding to our value function estimate, expressed as
$$
[Q(0, b), Q(0, c), Q(1, b), Q(1, c), Q(2, b), Q(2, c), Q(3, b), Q(3, c)]
$$
at that iteration, accurate to three decimal places.
Here are the reward and transition functions:
$$
\begin{gathered}
R(s, a)=\left\{\begin{array}{lll}
1 & \text { if } s=1 \\
2 & \text { if } s=3 \\
0 & \text { otherwise }
\end{array}\right. \\
T\left(s_{t}, \mathrm{~b}, s_{t+1}\right)=\left[\begin{array}{llll}
0.0 & 0.9 & 0.1 & 0.0 \\
0.9 & 0.1 & 0.0 & 0.0 \\
0.0 & 0.0 & 0.1 & 0.9 \\
0.9 & 0.0 & 0.0 & 0.1
\end{array}\right] \\
T\left(s_{t}, \mathrm{c}, s_{t+1}\right)=\left[\begin{array}{llll}
0.0 & 0.1 & 0.9 & 0.0 \\
0.9 & 0.1 & 0.0 & 0.0 \\
0.0 & 0.0 & 0.1 & 0.9 \\
0.9 & 0.0 & 0.0 & 0.1
\end{array}\right]
\end{gathered}
$$
After the third iteration, what action would you select in state 0?","Action c.
$Q(0, c)>Q(0, b)$."
32,EECS,18.C06,Linear Algebra and Optimization,18.02,None,Problem Set 2,Vector Spaces,2,c,0.06172839506,Text,"Is the following set a vector space (with the usual definitions of multiplication by real scalars and addition)?
The set of vectors that solve the equation $A x=b$ for some fixed nonzero $b$.",Open,"False. In general, this set does not include the origin, so it cannot be a subspace.","Is the following set a vector space (with the usual definitions of multiplication by real scalars and addition)?
Given a subspace $V$ of $\mathbb{R}^{n}$ and an $m \times n$ matrix $A$, the set of all vectors $A x$, where $x \in V$.",True. If we take two vectors $u=A x$ and $v=A y$ then $u+v$ is also in the set because $u+v=A x+A y=A(x+y)$. A similar argument works for scalar multiplication.,"Is the following set a vector space (with the usual definitions of multiplication by real scalars and addition)?
The set of $m \times n$ real matrices.","True. You can always multiply a matrix by a scalar. And as long as the dimensions match, you can add matrices too. Thus the axioms of being a vector space are satisfied.","Is the following set a vector space (with the usual definitions of multiplication by real scalars and addition)?
The set of vectors in $\mathbb{R}^{5}$ whose first two coordinates are equal.",True. Suppose $x$ and $y$ are in the set and their first and second coordinates are $a$ and $b$ respectively. Then the first and second coordinate of $x+y$ are both $a+b$. Similarly scalar multiplication does not change the fact that the first and second coordinates match. Thus the axioms of being a vector space are satisfied.
416,Mathematics,18.01,Calculus I,None,None,Midterm Exam 1,Linear Approximation,2,b,0.8333333333,Text,Approximate the cube root of the number $8.24$. Is the true value closest to 2.02 or $2.03$ or $2.04$ or $2.06 ?$ Explain your reasoning.,Open,"As above, we have the linear approximation $(2+\Delta x)^{3} \approx 8+12 \Delta x$. We are looking for $(2+\Delta x)^{3} \approx 8.24$ so we solve $8.24 \approx 8+12 \Delta x \Rightarrow .24=12 \Delta x \Rightarrow \Delta x=.02$. This gives us $\sqrt[3]{8.24} \approx 2+.02=2.02$.",Approximate $(2.01)^{3}$. Is the true value closest to $8.04$ or $8.06$ or $8.08$ or $8.12$ ? Briefly explain your reasoning.,We have that $(2.01)^{3}=(2+.01)^{3}$. So we use linear approximation of $f(x)=x^{3}$ near $x=2$. We use that $f^{\prime}(x)=\left(x^{3}\right)^{\prime}=3 x^{2}$. This gives $f(2+\Delta x) \approx f(2)+f^{\prime}(2) \Delta x=$ $2^{3}+3 \times 2^{2} \Delta x=8+12 \Delta x$. Since $\Delta x=.01$ this is $8+.12=8.12$.,"Using the linear approximation of $x^{2}$ around 2, estimate the square root of $4.1$.","Here $f^{\prime}(x)=2 x$, so $f^{\prime}(2)=4$. Thus, the linear approximation to $f(x)$ around $x=2$ is
$$
f(2+\Delta x) \approx \underset{f(2)}{4}+\underset{f^{\prime}(2)}{4} \cdot \Delta x .
$$
Here you still use $f(x)=x^{2}$ but invert the linear approximation. To make $4+4 \Delta x$ equal 4.1, the $4 \Delta x$ must be 0.1. So, $\Delta x=0.025$. Thus,
$$
\sqrt{4.1} \approx 2.025 .
$$","Using the linear approximation of $x^{2}$ around $x=2$, estimate the square root of $3.9$.","Again we use
$$
f(2+\Delta x) \approx 4+4 \Delta x .
$$
Now invert the linear approximation to find $\Delta x$.
$$
\begin{aligned}
& f(2+\Delta x) \approx 4+4 \Delta x=3.9, \\
& \text { so } 4 \Delta x=-0.1 \text {, and } \\
& \Delta x=-0.025 .
\end{aligned}
$$
In other words,
$$
(2-0.025)^{2} \approx 3.9 .
$$
Taking the square root of both sides,
$$
\sqrt{3.9} \approx 2-0.025=1.975 \text {. }
$$"
85,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 2,Propositional Logic,3,biii,0.0744047619,Text,"Consider a domain with propositions $\mathrm{A}, \mathrm{B}, \mathrm{C}$, and $\mathrm{D}$, and the particular model $m=\{A=t, B=f, C=t, D=f\}$. For each of these sentences, indicate whether it is valid, unsatisifiable, not valid but true in $\mathrm{m}$, or not unsatisifiable but false in $\mathrm{m}$.
$$
B \Rightarrow C \wedge D
$$",Multiple Choice,"not valid, but true in m.","Consider a domain with propositions $\mathrm{A}, \mathrm{B}, \mathrm{C}$, and $\mathrm{D}$, and the particular model $m=\{A=t, B=f, C=t, D=f\}$. For each of these sentences, indicate whether it is valid, unsatisifiable, not valid but true in $\mathrm{m}$, or not unsatisifiable but false in $\mathrm{m}$.
$A \Rightarrow C \wedge D$","not unsatisfiable, but false in m.","Consider a domain with propositions $\mathrm{A}, \mathrm{B}, \mathrm{C}$, and $\mathrm{D}$, and the particular model $m=\{A=t, B=f, C=t, D=f\}$. For each of these sentences, indicate whether it is valid, unsatisifiable, not valid but true in $\mathrm{m}$, or not unsatisifiable but false in $\mathrm{m}$.
$$
\begin{aligned}
& (A \wedge C) \Leftrightarrow(B \wedge D)\\
\end{aligned}
$$","not unsatisfiable, but false in m.","Consider a domain with propositions $\mathrm{A}, \mathrm{B}, \mathrm{C}$, and $\mathrm{D}$, and the particular model $m=\{A=t, B=f, C=t, D=f\}$. For each of these sentences, indicate whether it is valid, unsatisifiable, not valid but true in $\mathrm{m}$, or not unsatisifiable but false in $\mathrm{m}$.
$$
D \Leftrightarrow \neg D
$$",unsatisfiable.
61,Mathematics,18.6,Probability and Random Variables,18.02,None,Problem Set 5,Probability,6,b,0.35,Text,"Suppose that $A$, $B$, $C$, are independent random variables, each being uniformly distributed over $(0,1)$.
What is the probability that all of the roots of the equation $Ax^2 + Bx + C = 0$ are real?",Numerical,"The roots of the equation $Ax^2 + Bx + C = 0$ are real if $B^2 - 4AC \geq 0$. The desired probability, $P\{B^2 - 4AC \geq 0\}$, is obtained as follows
$P\{B^2 - 4AC \geq 0\} = 1 - P\{B^2 - 4AC < 0\} = 1 - \iiint_{B^2 - 4AC < 0} f(x, y, z) \,dx\,dy\,dz = 1 - \int_{0}^{1} \int_{\frac{y^2}{4}}^{1} \int_{\frac{y^2}{4z}}^{1} \,dx\,dz\,dy = 1 - \int_{0}^{1} \int_{\frac{y^2}{4}}^{1} (1 - \frac{y^2}{4z}) \,dz\,dy = 1 - \int_{0}^{1} (1 - \frac{y^2}{4} + \frac{y^2}{4}\ln({\frac{y^2}{4}})) \,dy = \frac{1}{6}\ln({2}) + \frac{5}{36}$.","Suppose that $A$, $B$, $C$, are independent random variables, each being uniformly distributed over $(0,1)$.
What is the joint cumulative distribution function of $A$, $B$, $C$?","\[
F_{A, B, C}(x, y, z) = P\{A \leq x, B \leq y, C \leq z\} =
\begin{cases} 
0 & \mbox{if } x < 0 \mbox{ or } y < 0 \mbox{ or } z < 0\\
\mbox{min}(1, x) \mbox{ min}(1, y) \mbox{ min}(1, z) & otherwise
\end{cases}
\]","Suppose that $A$ and $B$, and $C$ are independent random variables, where
• $A$ and $B$ are normal with mean 2 and variance 1.
• $C$ is uniform on $(0,3)$.
Let $X=4 A-3 B$, and let $Y=A-2 B+2 C$.
Compute $P(X>0)$. You should write your answer as $\Phi(a)$ for some $a>0$, where $\Phi(x)=\int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi}} e^{-t^{2} / 2} d t$ is the CDF of a standard normal random variable.","$X$ is normal with $E[X]=4 E[A]-3 E[B]=4 \cdot 2-3 \cdot 2=2$ and (using the fact that $A$ and $B$ are independent) $\operatorname{Var}(X)=4^{2} \cdot \operatorname{Var}(A)+(-3)^{2} \operatorname{Var}(B)=16 \cdot 1+9 \cdot 1=25=5^{2}$. We can thus write $X$ as $5 Z+2$, where $Z$ is a standard normal, so
$$
P(X>0)=P(5 Z+2>0)=P\left(Z>-\frac{2}{5}\right)
$$
By the symmetry of the normal distribution,
$$
P\left(Z>-\frac{2}{5}\right)=P\left(Z<\frac{2}{5}\right)=P\left(Z \leq \frac{2}{5}\right)=\boldsymbol{\Phi}\left(\frac{\mathbf{2}}{\mathbf{5}}\right) .
$$
Alternatively, instead of using symmetry, one could obtain this answer by noting that $-Z$ is also a standard normal, and $P\left(Z>-\frac{2}{5}\right)=P\left(-Z<\frac{2}{5}\right)$.","Suppose that $A$ and $B$, and $C$ are independent random variables, where
• $A$ and $B$ are normal with mean 2 and variance 1.
• $C$ is uniform on $(0,3)$.
Let $X=4 A-3 B$, and let $Y=A-2 B+2 C$.
Compute the CDF of the variable $W=\min (A, B)$.","We first note that $A$ and $B$ have the same distribution, and $A-2$ and $B-2$ are both standard normal random variables, so
$$
F_{A}(t)=F_{B}(t)=P(B \leq t)=P(B-2 \leq t-2)=\Phi(t-2) .
$$
Using the fact that $A$ and $B$ are independent, we can thus write the CDF of $W$ as
$$
\begin{aligned}
F_{W}(t) & =P(W \leq t)=P(\min (A, B) \leq t)=1-P((A>t) \cap(B>t)) \\
& =1-P(A>t) P(B>t)=1-(1-P(A \leq t))(1-P(B \leq t)) \\
& =1-\left(1-F_{A}(t)\right)\left(1-F_{B}(t)\right)=\mathbf{1}-(\mathbf{1}-\mathbf{\Phi}(\mathbf{t}-\mathbf{2}))^{\mathbf{2}} .
\end{aligned}
$$"
48,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Prelab Questions 4,Conditionals,2,b,0.05,Text,"Now consider the following code.
function Bit#(1) conditional(Bit#(1) a, Bit#(1) b);
         Bit#(1) ret = 0;
         Integer c=1;
         if(c==1) begin
             ret = comb(a, b);
         end else begin
             ret = comb2(a, b);
         end
         return ret;
endfunction
How many instances of comb and comb2 will be synthesized for this specification of conditional?
(a) 1 comb and 0 comb2.
(b) 0 comb and 1 comb2.
(c) 1 comb and 1 comb2.",Multiple Choice,"(a) 1 comb and 0 comb2.
In this function, the type Integer is used for the c variable. Integer types cannot be synthesized into hardware, thus their value must be known at compile time so that the Integer can be replaced with an actual value. In this minispec code, the Integer c is defined to be 1. Thus c is replaced by 1 and the conditional statement is simplified to only instantiate the if clause, or the comb circuit but not the comb2 circuit.","Consider the following code.
function Bit#(1) conditional(Bit#(1) a, Bit#(1) b, Bool c);
         Bit#(1) ret = 0;
         if(c) begin
             ret = comb(a, b);
         end else begin
             ret = comb2(a, b);
         end
         return ret;
endfunction
How many instances of comb and comb2 will be synthesized for the conditional circuit?
(a) 1 comb and 0 comb2.
(b) 0 comb and 1 comb2.
(c) 1 comb and 1 comb2.
(d) depends on what the value of c is.","(c) 1 comb and 1 comb2.
It is important to note that Minispec conditional code does not work like conditional code in a software program. In a software program only one of the two conditional paths will be executed. In hardware, both paths must be synthesized and then a mux is used to select the output of one of the two paths. At synthesis time, it is unknown what the value of c is so the hardware must be able to execute both conditional paths.","Consider the following code.
function Bit#(1) for_loop(Bit#(4) a);
         Bit#(1) ret = a[0];
         for(Integer i = 1; i < 4 ; i = i +1) begin
             ret = comb(ret, a[i]);
         end
         return ret;
endfunction
How many instances of comb will be synthesized for the for_loop circuit?
(a) 1 comb.
(b) 3 comb.
(c) depends on what the value of a is.","(b) 3 comb.
Minispec unrolls loops. This means that it effectively replaces the for loop with multiple instances of the code inside the for loop. The effect of this is that for each value of i, there is an additional instantiation of the comb circuit.","Consider the following code
function Bit#(1) complex_circuit(Bit#(1) a, Bit#(1) b, Bit#(1) c, Bit#(1) d);
         return comb(comb(comb(a, b), c), d);
endfunction
where comb is an unspecified combinational circuit that takes in 2 1-bit inputs and outputs a 1-bit output.
The following longer code is equivalent to the code above.
function Bit#(1) complex_circuit(Bit#(1) a, Bit#(1) b, Bit#(1) c, Bit#(1) d);
         Bit#(1) ab = comb(a, b);
         Bit#(1) abc = comb(ab, c);
         Bit#(1) abcd = comb(abc, d);
         return abcd;
endfunction
You might find the longer code more helpful to answer the following questions.
Now suppose comb is defined to be an xor gate which is known to be an associative function, what circuit will minispec produce pre-optimization?
(a)
(b)","(a).
The idea here is that the serial circuit implementation is directly encoded in how the circuits variables are defined regardless of the underlying functionality of comb. So, pre-optimization, the answer must remain the same. The second picture is achievable after the optimizer looks at the circuit and realizes that comb is actaully associative and be combined in a tree-like manner.
However, the optimizer may not be able to recognize all associative combinational circuits. Hence, it is always best to describe your circuits in minispec in a way that can more easily lead to optimized circuit implementations."
15,EECS,6.100A,Introduction to Computer Science Programming in Python,None,None,Problem Set 2,Hangman,1,a,1.875,Text,"Implement the function has_player_won according to its docstrings. This function will be useful in determining when the hangman game has been won (i.e. the user has guessed all the letters in the secret word).
Example Usage:
>>> secret_word = 'apple'
>>> letters_guessed = ['e', 'i', 'k', 'p', 'r', 's']
>>> print(has_player_won(secret_word, letters_guessed))
False
Testing: Navigate to the test_ps2_student.py file and run it in Spyder. This will run a series of unit tests on your code. Note that this file contains tests for functions you will implement later on in this pset, so not all of them will pass right away. Examine the tests that start with test_has_player_won. If your function is correct, you should see the following printout:
test_has_player_won (__main__.TestPS2) ... ok
test_has_player_won_empty_list (__main__.TestPS2) ... ok
test_has_player_won_empty_string (__main__.TestPS2) ... ok
test_has_player_won_repeated_letters (__main__.TestPS2) ... ok
def has_player_won(secret_word, letters_guessed):
    '''
    secret_word: string, the lowercase word the user is guessing
    letters_guessed: list (of lowercase letters), the letters that have been
        guessed so far
    returns: boolean, True if all the letters of secret_word are in letters_guessed,
        False otherwise
    '''
    # FILL IN YOUR CODE HERE AND DELETE ""pass""
    pass",Programming,"def has_player_won(secret_word, letters_guessed):
    '''
    secret_word: string, the lowercase word the user is guessing
    letters_guessed: list (of lowercase letters), the letters that have been
        guessed so far
    returns: boolean, True if all the letters of secret_word are in letters_guessed,
        False otherwise
    '''
    # FILL IN YOUR CODE HERE AND DELETE ""pass""
    for character in secret_word:
        if character not in letters_guessed:
            return False
    return True","Next, implement the function get_word_progress according to its docstrings. This should be fairly similar to
has_player_won.
Hint: Think about...
• if you need to store information as you loop over a data structure
• how you want to add information to your accumulated result
Example Usage:
>>> secret_word = 'apple'
>>> letters_guessed = ['e', 'i', 'k', 'p', 'r', 's']
>>> print(get_word_progress(secret_word, letters_guessed))
+pp+e
Testing: Run test_ps2_student.py. If your function is correct, the test printout should read:
test_get_word_progress (__main__.TestPS2) ... ok
test_get_word_progress_empty_list (__main__.TestPS2) ... ok
test_get_word_progress_empty_string (__main__.TestPS2) ... ok
test_get_word_progress_repeated_letters (__main__.TestPS2) ... ok
def get_word_progress(secret_word, letters_guessed):
    '''
    secret_word: string, the lowercase word the user is guessing
    letters_guessed: list (of lowercase letters), the letters that have been
        guessed so far
    returns: string, comprised of letters and plus signs (+) that represents
        which letters in secret_word have not been guessed so far
    '''
    # FILL IN YOUR CODE HERE AND DELETE ""pass""
    pass","def get_word_progress(secret_word, letters_guessed):
    '''
    secret_word: string, the lowercase word the user is guessing
    letters_guessed: list (of lowercase letters), the letters that have been
        guessed so far
    returns: string, comprised of letters and plus signs (+) that represents
        which letters in secret_word have not been guessed so far
    '''
    # FILL IN YOUR CODE HERE AND DELETE ""pass""
    display_word = []
    for character in secret_word:
        display_word.append(""+"")
    for character in range(len(secret_word)):
        if secret_word[character] in letters_guessed:
            display_word[character] = secret_word[character]
    return """".join(display_word)","1. The secret_word along with the boolean with_help are passed into the hangman function as parameters.
2. At the start of the game, display how many letters the computer's word contains.
3. Users start with 10 guesses.
Example Game Implementation:
Loading word list from file...
55900 words loaded.
Welcome to Hangman!
I am thinking of a word that is 4 letters long.
1. Before each guess, you should display to the user:
• Some dashes (--------------) to separate individual guesses from each other. Leaving out the row of dashes will cause the tester to fail - however, just make sure the number of dashes is at least 3.
• How many guesses they have remaining
• All the letters that have not yet been guessed
2. Ask the user to supply one guess at a time.
• The user can type any number, symbol, or letter. Your code should only accept capital and lowercase single letters as valid guesses!
• If the game is played with help, your code should also accept the help character (!)
3. Immediately after each guess, you should display:
• Whether or not the letter is in the secret word
• The word with guessed letters revealed and unguessed letters as plus signs ( + )
Example Game Implementation:
Loading word list from file...
55900 words loaded.
Welcome to Hangman!
I am thinking of a word that is 4 letters long.
--------------
You have 10 guesses left.
Available letters: abcdefghijklmnopqrstuvwxyz
Please guess a letter: a # This is the user input
Good guess: +a++
--------------
You have 10 guesses left.
Available letters: bcdefghijklmnopqrstuvwxyz
Please guess a letter: b # This is the user input
Oops! That letter is not in my word: +a++
--------------
You have 9 guesses left.
Available letters: cdefghijklmnopqrstuvwxyz
Please guess a letter: 2 # This is the user input
Oops! That is not a valid letter. Please input a letter from
the alphabet: +a++
--------------
You have 9 guesses left.
Available letters: cdefghijklmnopqrstuvwxyz
Please guess a letter: foo # This is the user input
Oops! That is not a valid letter. Please input a letter from
the alphabet: +a++
--------------
You have 9 guesses left.
Available letters: cdefghijklmnopqrstuvwxyz
Please guess a letter: & # This is the user input
Oops! That is not a valid letter. Please input a letter from
the alphabet: +a++
Hints:
1. Use calls to the input() function to get the user's guess.
• Check that the user input is an alphabet letter (or the help character if the game is played with help).
• If the user does not input a valid letter/character, tell them they can only input a letter from the alphabet.
2. Since the words in words.txt are lowercase, we suggest converting user input to lowercase so program only needs to handle lowercase characters.
3. You may find the string functions str.isalpha() and str.lower() helpful! You can type help(str.isalpha) or help(str.lower) in the Spyder shell to see documentation for the functions.
>> my_string = ""HeLLoWoRlD""
>> my_string.isalpha()
True
>> my_string.lower()
'helloworld'
If the user inputs:
1. Anything besides a letter in the alphabet (e.g. symbols or numbers), tell the user that they can only input an alphabet letter. The user loses no guesses. Note: When the game is being played with help, the '!' is also a valid input.
2. A letter that has already been guessed, print a message telling the user the letter has already been guessed before. The user loses no guesses.
3. Any letter that hasn't been guessed before and the letter is in the secret word, the user loses no guesses.
4. Consonants: If the user inputs a consonant that hasn't been guessed and the consonant is not in the secret word, the user loses one guess.
5. Vowels: If the user inputs a vowel that hasn't been guessed and the vowel is not in the secret word, the user loses two guesses. Vowels are a, e, i, o, and u. The letter y does not count as a vowel. Note: if a user inputs an incorrect vowel that hasn't been guessed and there is only one guess remaining, the user loses and the game is over.
Example Game Implementation (continued):
You have 9 guesses left.
Available letters: bcdefghijklmnopqrtuvwxyz
Please guess a letter: t
Good guess: ta+t
--------------
You have 9 guesses left.
Available letters: bcdefghijklmnopqruvwxyz
Please guess a letter: e
Oops! That letter is not in my word: ta+t
--------------
You have 7 guesses left.
Available letters: bcdfghijklmnopqruvwxyz
Please guess a letter: e
Oops! You've already guessed that letter: ta+t
It isn't always easy to beat the computer, especially when it selects an esoteric word. It might be nice if you could ask for some help.
To do this you will create a feature of the game that works as follows:
• If you type the special character ""!"", the computer will provide you with one of the missing letters in the secret word at a cost of three guesses. This word should be the only non-letter-character input that your game accepts as a guess.
• If you do not have at least three guesses remaining, the computer will warn you of this and let you try again. You lose no guesses.
Note: The user can play the game with this feature only when the with_help parameter is True.
As a starting point, we suggest writing a helper function that chooses a letter to reveal. It should take two arguments: the secret word and the string of available letters (from get_available_letters). This helper function should create a string choose_from, containing the unique letters that are in both the secret word and the available letters. You can then use the
following statements to pick a random character revealed_letter from that string:
new = random.randint(0, len(choose_from)-1)
revealed_letter = choose_from[new]
Your helper function should then return this revealed_letter. Back in your original game logic, you'll need to add a conditional statement to catch the case of the user inputting ""!"". This case, if triggered, can add the letter returned by your helper function to letters_guessed, show the new guessed word, decrement the remaining guesses by 3, and continue the gameplay.
Example Implementation:
Welcome to Hangman!
I am thinking of a word that is 7 letters long.
--------------
You currently have 10 guesses left.
Available letters: abcdefghijklmnopqrstu
Please guess a letter: !
Letter revealed: r
r+++++r
--------------
You currently have 7 guesses left.
Available letters: abcdefghijklmnopqrstu
Please guess a letter: !
Letter revealed: a
ra+++ar
--------------
You currently have 4 guesses left.
Available letters: abdefghijklmnopqrstu
Please guess a letter: !
Letter revealed: e
ra+e+ar
--------------
You currently have 1 guess left.
Available letters: abdefghijklmnopqstu
Please guess a letter: !
Oops! Not enough guesses left: ra+e+ar
Please refer to the appendix at the end of this handout for an example of a complete game of hangman with help.
1. The game ends when the user guesses all the letters in secret_word or has 0 guesses.
2. If the user wins, print a congratulatory message, and tell the user their score.
• Total score = (4 * number of unique letters in secret_word * guesses_remaining) + (2 * length of secret_word)
• Example: For a game with secret word “asleep” with 6 guesses remaining, there are a total of 5 unique letters (i.e. 'a', 's', 'l', 'e', and 'p'). Then, the final score is: (4 * 5 * 6) + (2 * 6) = 132.
3. If the player runs out of guesses before completing the word, tell them they lost and reveal the word to the user when the game ends.
Example Implementation (win):
You have 5 guesses left.
Available letters: abcgnqrstuvwxyz
Please guess a letter: n
Good guess: dolphin
--------------
Congratulations, you won!
Your total score for this game is: 154
Example Implementation (Lose):
You have 1 guess left.
Available Letters: ghijklmnopqrstuvwxyz
Please guess a letter: i
Oops! That letter is not in my word: e++e
--------------
Sorry, you ran out of guesses. The word was else.
Look carefully at the example hangman games in the handout appendix and make your print statements as close to the
example games as possible! If you run into issues, try consulting the debugging hints.
If you scroll to the bottom of hangman.py, you will see the lines below:
if __name__ == ""__main__"":
# secret_word = choose_word(wordlist)`
# with_help = False
# hangman(secret_word, with_help)
Uncomment the bottom three lines to choose a random secret word and play hangman with the provided secret word. Feel free to pass in your own secret word when testing your program.
2.6.1) Student Tester
In order to test if your game runs properly, please run test_ps2_student.py. If your function is correct, you should see the following in the test printout:
test_play_game_short (__main__.TestPS2) ... ok
test_play_game_short_fail (__main__.TestPS2) ... ok
test_play_game_with_help (__main__.TestPS2) ... ok
You might see some additional messages printed out between the ... and the ok. For example, you might see the following:
Problem Set 2 Unit Test Results:
All correct!
Points for these tests: 5/5
(Please note that this is not your final pset score, additional test cases will be run on submissions)
ok
This is fine.
Appendix
Hangman Example (Winning Game)
Loading word list from file...
55900 words loaded.
Welcome to Hangman!
I am thinking of a word that is 4 letters long.
--------------
You have 10 guesses left.
Available letters: abcdefghijklmnopqrstuvwxyz
Please guess a letter: a
Good guess: +a++
--------------
You have 10 guesses left.
Available letters: bcdefghijklmnopqrstuvwxyz
Please guess a letter: a
Oops! You've already guessed that letter: +a++
--------------
You have 10 guesses left.
Available letters: bcdefghijklmnopqrstuvwxyz
Please guess a letter: s
Oops! That letter is not in my word: +a++
--------------
You have 9 guesses left.
Available letters: bcdefghijklmnopqrtuvwxyz
Please guess a letter: $
Oops! That is not a valid letter. Please input a letter from the alphabet: +a++
--------------
You have 9 guesses left.
Available letters: bcdefghijklmnopqrtuvwxyz
Please guess a letter: t
Good guess: ta+t
--------------
You have 9 guesses left.
Available letters: bcdefghijklmnopqruvwxyz
Please guess a letter: e
Oops! That letter is not in my word: ta+t
--------------
You have 7 guesses left.
Available letters: bcdfghijklnopquvwxyz
Please guess a letter: c
Good guess: tact
--------------
Congratulations, you won!
Your total score for this game is: 92
Hangman Example (Losing Game)
Loading word list from file...
55900 words loaded.
Welcome to Hangman!
I am thinking of a word that is 4 letters long
--------------
You have 10 guesses left.
Available Letters: abcdefghijklmnopqrstuvwxyz
Please guess a letter: a
Oops! That letter is not in my word: ++++
--------------
You have 8 guesses left.
Available Letters: bcdefghijklmnopqrstuvwxyz
Please guess a letter: b
Oops! That letter is not in my word: ++++
--------------
You have 7 guesses left.
Available Letters: cdefghijklmnopqrstuvwxyz
Please guess a letter: c
Oops! That letter is not in my word: ++++
--------------
You have 6 guesses left.
Available Letters: defghijklmnopqrstuvwxyz
Please guess a letter: 2
Oops! That is not a valid letter. Please input a letter from the alphabet: ++++
--------------
You have 6 guesses left.
Available Letters: defghijklmnopqrstuvwxyz
Please guess a letter: d
Oops! That letter is not in my word: ++++
--------------
You have 5 guesses left.
Available Letters: efghijklmnopqrstuvwxyz
Please guess a letter: u
Oops! That letter is not in my word: ++++
--------------
You have 3 guesses left.
Available Letters: efghijklmnopqrstvwxyz
Please guess a letter: e
Good guess: e++e
--------------
You have 3 guesses left.
Available Letters: fghijklmnopqrstuvwxyz
Please guess a letter: f
Oops! That letter is not in my word: e++e
--------------
You have 2 guesses left.
Available Letters: ghijklmnopqrstuvwxyz
Please guess a letter: o
Oops! That letter is not in my word: e++e
--------------
Sorry, you ran out of guesses. The word was else.
Hangman with Help
Loading word list from file...
55900 words loaded.
Welcome to Hangman!
I am thinking of a word that is 7 letters long
--------------
You currently have 10 guesses left
Available letters: abcdefghijklmnopqrstuvwxyz
Please guess a letter: r
Good guess: r+++++r
--------------
You currently have 10 guesses left
Available letters: abcdefghijklmnopqstuvwxyz
Please guess a letter: !
Letter revealed: c
r+c+c+r
--------------
You currently have 7 guesses left
Available letters: abdeghijklmnopqstuvwxyz
Please guess a letter: !
Letter revealed: a
rac+car
--------------
You currently have 4 guesses left
Available letters: bdeghijklmnopqstuvwxyz
Please guess a letter: e
Good guess: racecar
--------------
Congratulations, you won!
Your total score for this game is: 78
def hangman(secret_word, with_help):
    '''
    secret_word: string, the secret word to guess.
    with_help: boolean, this enables help functionality if true.
    Starts up an interactive game of Hangman.
    * At the start of the game, let the user know how many
      letters the secret_word contains and how many guesses they start with.
    * The user should start with 10 guesses.
    * Before each round, you should display to the user how many guesses
      they have left and the letters that the user has not yet guessed.
    * Ask the user to supply one guess per round. Remember to make
      sure that the user puts in a single letter (or help character '!'
      for with_help functionality)
    * If the user inputs an incorrect consonant, then the user loses ONE guess,
      while if the user inputs an incorrect vowel (a, e, i, o, u),
      then the user loses TWO guesses.
    * The user should receive feedback immediately after each guess
      about whether their guess appears in the computer's word.
    * After each guess, you should display to the user the
      partially guessed word so far.
    -----------------------------------
    with_help functionality
    -----------------------------------
    * If the guess is the symbol !, you should reveal to the user one of the
      letters missing from the word at the cost of 3 guesses. If the user does
      not have 3 guesses remaining, print a warning message. Otherwise, add
      this letter to their guessed word and continue playing normally.
    Follows the other limitations detailed in the problem write-up.
    '''
    # FILL IN YOUR CODE HERE AND DELETE ""pass""
    pass","def get_revealed_letter(secret_word, avail_letters):
    choose_from = """"  
    for i in secret_word:
        if i in avail_letters and i not in choose_from:
            choose_from += i
    revealed_letter = choose_from[random.randint(0, len(choose_from) - 1)]    
    return revealed_letter

def hangman(secret_word, with_help):
    '''
    secret_word: string, the secret word to guess.
    with_help: boolean, this enables help functionality if true.
    Starts up an interactive game of Hangman.
    * At the start of the game, let the user know how many
      letters the secret_word contains and how many guesses they start with.
   * The user should start with 10 guesses.
   * Before each round, you should display to the user how many guesses
      they have left and the letters that the user has not yet guessed.
  * Ask the user to supply one guess per round. Remember to make
      sure that the user puts in a single letter (or help character '!'
      for with_help functionality)
  * If the user inputs an incorrect consonant, then the user loses ONE guess,
      while if the user inputs an incorrect vowel (a, e, i, o, u),
      then the user loses TWO guesses.
  * The user should receive feedback immediately after each guess
      about whether their guess appears in the computer's word.
   * After each guess, you should display to the user the
      partially guessed word so far.
  -----------------------------------
    with_help functionality
    -----------------------------------
    * If the guess is the symbol !, you should reveal to the user one of the
      letters missing from the word at the cost of 3 guesses. If the user does
      not have 3 guesses remaining, print a warning message. Otherwise, add
      this letter to their guessed word and continue playing normally.
   Follows the other limitations detailed in the problem write-up.
    '''
    # FILL IN YOUR CODE HERE AND DELETE ""pass""
    num_letters = len(secret_word)
    num_guesses = 10
    letters_guessed = []
    dash = ""-------------------""
    print(""Welcome to Hangman!"")
    print(""I am thinking of a word that is"", num_letters, ""letters long."")
    while num_guesses > 0:
        print(dash)
        if has_player_won(secret_word, letters_guessed):
            print(""Congratulations, you won!"")
            unique_letters = 0
            letters_seen = """"
            for i in range(len(secret_word)): 
                if secret_word[i] not in letters_seen:
                    unique_letters += 1
                    letters_seen += secret_word[i]
            guesses_remaining = num_guesses
            total_score = 4 * unique_letters * guesses_remaining + 2 * len(secret_word)
            print(""Your total score for this game is:"", total_score)
            break
        else:
            print(""You have"", num_guesses, ""guesses left."")
            print(""Available letters:"", get_available_letters(letters_guessed))
            user_guess = input(""Please guess a letter: "")
            if user_guess == ""!"" and with_help:
                if num_guesses <= 3:
                    print (""Oops! Not enough guesses left:"", get_word_progress(secret_word, letters_guessed))
                else:
                    num_guesses -= 3
                    avail_letters = get_available_letters(letters_guessed)
                    letter_revealed = get_revealed_letter(secret_word, avail_letters)
                    print(""Letter revealed:"", letter_revealed)
                    letters_guessed.append(letter_revealed)
                    print(get_word_progress(secret_word, letters_guessed))
            if not user_guess.isalpha or len(user_guess)>1:
                print(""Oops! That is not a valid letter. Please input a letter from the alphabet: "")
            elif user_guess.isalpha():
                user_guess.lower() 
                if user_guess not in secret_word and user_guess in ""aeiou"":
                    print(""Oops! That letter is not in my word:"", get_word_progress(secret_word, letters_guessed))
                    num_guesses -= 2
                    letters_guessed.append(user_guess)
                elif user_guess not in secret_word and user_guess not in ""aeiou"":
                    print(""Oops! That letter is not in my word:"", get_word_progress(secret_word, letters_guessed))    
                    num_guesses -= 1
                    letters_guessed.append(user_guess)
                elif user_guess in letters_guessed:
                    print(""Oops! You've already guessed that letter:"", get_word_progress(secret_word, letters_guessed))
                elif user_guess in secret_word:
                    letters_guessed.append(user_guess) 
                    print(""Good guess:"", get_word_progress(secret_word, letters_guessed))
    print(dash)
    if num_guesses == 0:
        print(""Sorry, you ran out of guesses. The word was"", secret_word)","Next, implement the function get_available_letters according to its docstring. This function should return the letters in alphabetical order.
Hint: You might consider using string.ascii_lowercase, which is a string comprised of all lowercase letters:
>>> import string
>>> print(string.ascii_lowercase)
abcdefghijklmnopqrstuvwxyz
Example Usage:
>>> letters_guessed = ['e', 'i', 'k', 'p', 'r', 's']
>>> print(get_available_letters(letters_guessed))
abcdfghjlmnoqtuvwxyz
Testing: Run test_ps2_student.py. If your function is correct, the test printout should read:
test_get_available_letters (__main__.TestPS2) ... ok
test_get_available_letters_empty_list (__main__.TestPS2) ... ok
test_get_available_letters_empty_string (__main__.TestPS2) ... ok
def get_available_letters(letters_guessed):
    '''
    letters_guessed: list (of lowercase letters), the letters that have been
        guessed so far
    returns: string, comprised of letters that represents which
      letters have not yet been guessed. The letters should be returned in
      alphabetical order
    '''
    # FILL IN YOUR CODE HERE AND DELETE ""pass""
    pass","def get_available_letters(letters_guessed):
    '''
    letters_guessed: list (of lowercase letters), the letters that have been
        guessed so far
    returns: string, comprised of letters that represents which
      letters have not yet been guessed. The letters should be returned in
      alphabetical order
    '''
    # FILL IN YOUR CODE HERE AND DELETE ""pass""
    all_letters = []
    for character in string.ascii_lowercase:
        if character not in letters_guessed:
            all_letters.append(character)
    return """".join(all_letters)"
87,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Exercise 12,Q-Learning,1,av,0.01157407407,Text,"Let's simulate the Q-learning algorithm! Assume there are states $(0,1,2,3)$ and actions ('b', 'c'), and discount factor $\gamma=0.9$. Furthermore, assume that all the $\mathrm{Q}$ values are initialized to 0 (for all state-action pairs) and that the learning rate $\alpha=0.5$.
Experience is represented as a list of 4-element tuples: the $t$ th element of the experience corresponds to a record of experience at time $t:\left(s_{t}, a_{t}, s_{t+1}, r_{t}\right)$ (state, action, next state, reward).
After each step $t$, indicate what update $Q\left(s_{t}, a_{t}\right) \leftarrow q$ will be made by the Q learning algorithm based on $\left(s_{t}, a_{t}, s_{t+1}, r_{t}\right)$. You will want to keep track of the overall table $Q\left(s_{t}, a_{t}\right)$ as these updates take place, spanning the multiple parts of this question.
As a reminder, the Q-learning update formula is the following:
$$
Q(s, a) \leftarrow(1-\alpha) Q(s, a)+\alpha\left(r+\gamma \max _{a^{\prime}} Q\left(s^{\prime}, a^{\prime}\right)\right)
$$
You are welcome to do this problem by hand, by drawing a table specifying $Q(s, a)$ for all possible $s$ and $as$. Alternatively, you may write a program which takes in the following history of experience:
experience = [(0, 'b', 2, 0), #t = 0
(2, 'b', 3, 0),
(3, 'b', 0, 2),
(0, 'b', 2, 0), #t = 3
(2, 'b', 3, 0),
(3, 'c', 0, 2),
(0, 'c', 1, 0), #t = 6
(1, 'b', 0, 1),
(0, 'b', 2, 0),
(2, 'c', 3, 0), #t = 9
(3, 'c', 0, 2),
(0, 'c', 1, 0)]
t: S A S' R
---------------
1: 2 'b' 3 0
The $t=1$ step of Q-learning will update the Q value of some state-action pair based on the experience tuple $\left(s_{1}, a_{1}, s_{2}, r_{1}\right)$.
After observing this tuple, what is the state of the state-action pair that is updated?",Numerical,"2.
Since we observe an experience in state 2, we update the Q value for state 2.","Let's simulate the Q-learning algorithm! Assume there are states $(0,1,2,3)$ and actions ('b', 'c'), and discount factor $\gamma=0.9$. Furthermore, assume that all the $\mathrm{Q}$ values are initialized to 0 (for all state-action pairs) and that the learning rate $\alpha=0.5$.
Experience is represented as a list of 4-element tuples: the $t$ th element of the experience corresponds to a record of experience at time $t:\left(s_{t}, a_{t}, s_{t+1}, r_{t}\right)$ (state, action, next state, reward).
After each step $t$, indicate what update $Q\left(s_{t}, a_{t}\right) \leftarrow q$ will be made by the Q learning algorithm based on $\left(s_{t}, a_{t}, s_{t+1}, r_{t}\right)$. You will want to keep track of the overall table $Q\left(s_{t}, a_{t}\right)$ as these updates take place, spanning the multiple parts of this question.
As a reminder, the Q-learning update formula is the following:
$$
Q(s, a) \leftarrow(1-\alpha) Q(s, a)+\alpha\left(r+\gamma \max _{a^{\prime}} Q\left(s^{\prime}, a^{\prime}\right)\right)
$$
You are welcome to do this problem by hand, by drawing a table specifying $Q(s, a)$ for all possible $s$ and $as$. Alternatively, you may write a program which takes in the following history of experience:
experience = [(0, 'b', 2, 0), #t = 0
(2, 'b', 3, 0),
(3, 'b', 0, 2),
(0, 'b', 2, 0), #t = 3
(2, 'b', 3, 0),
(3, 'c', 0, 2),
(0, 'c', 1, 0), #t = 6
(1, 'b', 0, 1),
(0, 'b', 2, 0),
(2, 'c', 3, 0), #t = 9
(3, 'c', 0, 2),
(0, 'c', 1, 0)]
t: S A S' R
---------------
0: 0 'b' 2 0
The $t=0$ step of Q-learning will update the $\mathrm{Q}$ value of some state-action pair based on the experience tuple $\left(s_{0}, a_{0}, s_{1}, r_{0}\right)$. After observing this tuple, the Q-value for one specific state-action pair is updated. What is the state in this state-action pair?","0.
Since we observe an experience in state 0, we update the Q value for state 0.","Let's simulate the Q-learning algorithm! Assume there are states $(0,1,2,3)$ and actions ('b', 'c'), and discount factor $\gamma=0.9$. Furthermore, assume that all the $\mathrm{Q}$ values are initialized to 0 (for all state-action pairs) and that the learning rate $\alpha=0.5$.
Experience is represented as a list of 4-element tuples: the $t$ th element of the experience corresponds to a record of experience at time $t:\left(s_{t}, a_{t}, s_{t+1}, r_{t}\right)$ (state, action, next state, reward).
After each step $t$, indicate what update $Q\left(s_{t}, a_{t}\right) \leftarrow q$ will be made by the Q learning algorithm based on $\left(s_{t}, a_{t}, s_{t+1}, r_{t}\right)$. You will want to keep track of the overall table $Q\left(s_{t}, a_{t}\right)$ as these updates take place, spanning the multiple parts of this question.
As a reminder, the Q-learning update formula is the following:
$$
Q(s, a) \leftarrow(1-\alpha) Q(s, a)+\alpha\left(r+\gamma \max _{a^{\prime}} Q\left(s^{\prime}, a^{\prime}\right)\right)
$$
You are welcome to do this problem by hand, by drawing a table specifying $Q(s, a)$ for all possible $s$ and $as$. Alternatively, you may write a program which takes in the following history of experience:
experience = [(0, 'b', 2, 0), #t = 0
(2, 'b', 3, 0),
(3, 'b', 0, 2),
(0, 'b', 2, 0), #t = 3
(2, 'b', 3, 0),
(3, 'c', 0, 2),
(0, 'c', 1, 0), #t = 6
(1, 'b', 0, 1),
(0, 'b', 2, 0),
(2, 'c', 3, 0), #t = 9
(3, 'c', 0, 2),
(0, 'c', 1, 0)]
t: S A S' R
---------------
2: 3 'b' 0 2
The $t=2$ step of Q-learning will update the $\mathrm{Q}$ value of some state-action pair based on the experience tuple $\left(s_{2}, a_{2}, s_{3}, r_{2}\right)$.
What is the updated value that Q-learning makes for $t=2$? Recall that $\alpha=0.5$ and $\gamma=0.9$.","1.
$$
Q_{\text {new }}(3, b)=0.5 \cdot Q_{\text {old }}(3, b)+0.5\left(2+0.9 \cdot \max _{a^{\prime}} Q_{o l d}\left(0, a^{\prime}\right)\right)=0.5 \cdot 0+0.5 \cdot 2=1 .
$$","Let's simulate the Q-learning algorithm! Assume there are states $(0,1,2,3)$ and actions ('b', 'c'), and discount factor $\gamma=0.9$. Furthermore, assume that all the $\mathrm{Q}$ values are initialized to 0 (for all state-action pairs) and that the learning rate $\alpha=0.5$.
Experience is represented as a list of 4-element tuples: the $t$ th element of the experience corresponds to a record of experience at time $t:\left(s_{t}, a_{t}, s_{t+1}, r_{t}\right)$ (state, action, next state, reward).
After each step $t$, indicate what update $Q\left(s_{t}, a_{t}\right) \leftarrow q$ will be made by the Q learning algorithm based on $\left(s_{t}, a_{t}, s_{t+1}, r_{t}\right)$. You will want to keep track of the overall table $Q\left(s_{t}, a_{t}\right)$ as these updates take place, spanning the multiple parts of this question.
As a reminder, the Q-learning update formula is the following:
$$
Q(s, a) \leftarrow(1-\alpha) Q(s, a)+\alpha\left(r+\gamma \max _{a^{\prime}} Q\left(s^{\prime}, a^{\prime}\right)\right)
$$
You are welcome to do this problem by hand, by drawing a table specifying $Q(s, a)$ for all possible $s$ and $as$. Alternatively, you may write a program which takes in the following history of experience:
experience = [(0, 'b', 2, 0), #t = 0
(2, 'b', 3, 0),
(3, 'b', 0, 2),
(0, 'b', 2, 0), #t = 3
(2, 'b', 3, 0),
(3, 'c', 0, 2),
(0, 'c', 1, 0), #t = 6
(1, 'b', 0, 1),
(0, 'b', 2, 0),
(2, 'c', 3, 0), #t = 9
(3, 'c', 0, 2),
(0, 'c', 1, 0)]
What is the action of the state-action pair that is updated?","b.
Since action $b$ was used in this experience, we update the Q value for action b."
58,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 1,Monte-Carlo Tree Search,4,cv,0.05580357143,Text,"Now, for each of the problems defined in get_fractal_problems, let us compare the performances of MCTS vs. UCS empirically by running run_mcts_search and run_uniform_cost_search. In particular, you should:
\begin{itemize}
\item Fix step_budget for both algorithms to 2500. Set iteration_budget for MCTS to infinity.
\item Run MCTS 20 times and record the average cumulative reward.
\item Run UCS once:
\begin{itemize}
\item If it fails (due to running out of step budget), record the cumulative reward as 0 .
\item If it succeeds, record the obtained cumulative reward. Hint: you might need to recover rewards from path costs
\end{itemize}
\item Repeat the above for all three problems in get_fractal_problems.
\end{itemize}
What is the average cumulative reward obtained by MCTS in reward-field-3?",Numerical,1.2.,"Now, for each of the problems defined in get_fractal_problems, let us compare the performances of MCTS vs. UCS empirically by running run_mcts_search and run_uniform_cost_search. In particular, you should:
\begin{itemize}
\item Fix step_budget for both algorithms to 2500. Set iteration_budget for MCTS to infinity.
\item Run MCTS 20 times and record the average cumulative reward.
\item Run UCS once:
\begin{itemize}
\item If it fails (due to running out of step budget), record the cumulative reward as 0 .
\item If it succeeds, record the obtained cumulative reward. Hint: you might need to recover rewards from path costs
\end{itemize}
\item Repeat the above for all three problems in get_fractal_problems.
\end{itemize}
What is the average cumulative reward obtained by MCTS in reward-field-1?",4.2.,"Now, for each of the problems defined in get_fractal_problems, let us compare the performances of MCTS vs. UCS empirically by running run_mcts_search and run_uniform_cost_search. In particular, you should:
\begin{itemize}
\item Fix step_budget for both algorithms to 2500. Set iteration_budget for MCTS to infinity.
\item Run MCTS 20 times and record the average cumulative reward.
\item Run UCS once:
\begin{itemize}
\item If it fails (due to running out of step budget), record the cumulative reward as 0 .
\item If it succeeds, record the obtained cumulative reward. Hint: you might need to recover rewards from path costs
\end{itemize}
\item Repeat the above for all three problems in get_fractal_problems.
\end{itemize}
What is the average cumulative reward obtained by MCTS in reward-field-2?",3.1.,"Now, for each of the problems defined in get_fractal_problems, let us compare the performances of MCTS vs. UCS empirically by running run_mcts_search and run_uniform_cost_search. In particular, you should:
\begin{itemize}
\item Fix step_budget for both algorithms to 2500. Set iteration_budget for MCTS to infinity.
\item Run MCTS 20 times and record the average cumulative reward.
\item Run UCS once:
\begin{itemize}
\item If it fails (due to running out of step budget), record the cumulative reward as 0 .
\item If it succeeds, record the obtained cumulative reward. Hint: you might need to recover rewards from path costs
\end{itemize}
\item Repeat the above for all three problems in get_fractal_problems.
\end{itemize}
What is the obtained cumulative rewards by UCS in reward-field-3?",3.1911534984544563.
566,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Final Exam,Neural Networks,1,d,0.7,Text,"Mac O'Larnin is considering selling an app on Frugal Play. You have a friend with inside info at Frugal, and they're able to share data on how previous apps have performed on the store.
Mac decides that he will learn a neural network with no hidden layer (i.e., consisting only of the output layer). He needs help in figuring out the precise formulation for machine learning.
Mac's first attempt at machine learning to predict the sales volume (setup of (b)) uses all customer data from 2020 . He randomly partitions the data into train $(80 \%)$ and validation $(20 \%)$, and uses the same number of units, activation function(s), and loss function as in (b). To prevent overfitting, he uses ridge regularization of the weights $W$, minimizing the optimization objective
$$
J(W ; \lambda)=\sum_{i=1}^{n} \mathcal{L}\left(h\left(x^{(i)} ; W\right), y^{(i)}\right)+\lambda\|W\|^{2},
$$
where $\|W\|^{2}$ is the sum over the square of all output units' weights.
Mac discovers that it's possible to find a value of $W$ such that $J(W ; \lambda)=0$ even when $\lambda$ is very large, nearing $\infty$. Mac suspects that he might have an error in the code that he wrote to derive the labels (i.e., the monthly sales volumes). Let's see why. First, what can Mac conclude about $W$ from this finding? Second, what does this imply about the labels?",Open,"(1) Since the loss is always non-negative and the penalty is always nonnegative, the only way to get 0 here is for both to be equal to 0 . The only way the penalty can equal 0 is if every element of $W$ equals 0 .
(2) When $W$ has all entries equal to 0 , the prediction at every data point is a constant (the offset). The only way for the squared error to be 0 is for the label of every data point to equal that offset. It seems unlikely that every data label would be exactly the same in this data set, which we assume ranges over a wide number of apps.","Mac O'Larnin is considering selling an app on Frugal Play. You have a friend with inside info at Frugal, and they're able to share data on how previous apps have performed on the store.
Mac decides that he will learn a neural network with no hidden layer (i.e., consisting only of the output layer). He needs help in figuring out the precise formulation for machine learning.
Mac wants to predict the sales volume (how many times someone will purchase the app each month) for his new app. The sales volume can be negative if many people returned the app for a refund in a given month. What should Mac choose for the number of units in the output layer, the activation function(s) in the output layer (linear, ReLU, sigmoid, softmax), and the loss function (negative log likelihood, quadratic)?","One unit, because the output is an integer, a linear activation function, and a quadratic loss function.","Mac O'Larnin is considering selling an app on Frugal Play. You have a friend with inside info at Frugal, and they're able to share data on how previous apps have performed on the store.
Mac decides that he will learn a neural network with no hidden layer (i.e., consisting only of the output layer). He needs help in figuring out the precise formulation for machine learning.
The initial results look promising. Mac now wants to add in data from additional, earlier, years. (He is confident his customers have been behaving similarly over many years, so the earlier data is relevant.)
Before curating the older data, Mac decides to use the training data that he has to get a sense of whether more data would help. He creates a learning curve where on the horizontal axis he varies the amount of training data used and on the vertical axis he shows the validation error, using a fixed validation set across all settings considered. He experiments with $\lambda=1,10,100$, but again forgot to include a legend. Fill in the below legend by labeling the curves with the value of $\lambda$ that each corresponds to:",The plot is below.,"Mac O'Larnin is considering selling an app on Frugal Play. You have a friend with inside info at Frugal, and they're able to share data on how previous apps have performed on the store.
Mac decides that he will learn a neural network with no hidden layer (i.e., consisting only of the output layer). He needs help in figuring out the precise formulation for machine learning.
Mac experiments with even more training data and additional values of $\lambda$, but finds that he cannot decrease the validation error further. Are there changes to the neural network architecture that Mac could make to try to improve prediction performance? Explain.",Mac could add hidden layers with nonlinear activation functions to the neural network.
247,Mathematics,18.01,Calculus I,None,None,Problem Set 6,Approximations,6,c,0.05279831045,Text,"Taylor's theorem tells us that when the second derivative of a function is really big, then the linear approximation is not so accurate. Here's an example. Let $f(x)=\sin (100 x)$.
Compute $f^{\prime \prime}(x)$. Check that $f^{\prime \prime}(0)=0$. Let $M$ denote the maximum of $\left|f^{\prime \prime}(x)\right|$ for $0 \leq x \leq .1$. Find $M$.",Numerical,"$f^{\prime \prime}(x)=100^{2} \sin (100 x)$. When $x=0,100 x=0$ and when $x=.1,100 x=10$. Thus the input of sine goes between 0 and 10 when $0 \leq x \leq .1$. Since sine achieves its maximum at $\frac{\pi}{2}$ (which corresponds to taking $0 \leq x=\pi / 200 \leq .1$,
$$
\left|f^{\prime \prime}(x)\right| \leq 100^{2}|\sin (100 x)| \leq 100^{2}|\sin (100 \cdot \pi / 200)|=100^{2}
$$
whenever $0 \leq x \leq .1$. Thus $M=100^{2}=10^{4}$.","Taylor's theorem tells us that when the second derivative of a function is really big, then the linear approximation is not so accurate. Here's an example. Let $f(x)=\sin (100 x)$.
Approximate $f(.1)$ by taking the linear approximation of $f$ around $x=0$.","$f(0)=0, f^{\prime}(x)=100 \cos (100 x)$ and $f^{\prime}(0)=100$. The linear approximation is therefore
$$
f(.1) \approx f(0)+f^{\prime}(0)(.1)=100(.1)=10.
$$","Taylor's theorem tells us that when the second derivative of a function is really big, then the linear approximation is not so accurate. Here's an example. Let $f(x)=\sin (100 x)$.
Approximate the magnitude of the error in this linear approximation? Is it about $.1$ or 1 or 10 or 100 ? Hint: You don't need to compute $f(.1)$ exactly to do this!",Recall that $f(.1)=\sin (10)$ and $\sin$ takes values between $-1$ and 1 . Thus the difference between our approximation (which was 10) and the actual value of $f(.1)$ is between 9 and 11 . (So magnitude of error is about 10).,"Suppose that $L(x)=f(1)+f^{\prime}(1)(x-1)$ is the linear approximation of $f(x)$ around $x=1$. Here is a picture of the graph of $f^{\prime}(x)$ and the graph of $L^{\prime}(x)$ below.
Here $f^{\prime}(1)=10$ and so $L^{\prime}(x)=10$ for all $x$.
Compare your answer to b with the bound from Taylor's theorem.","The bound from Taylor's theorem requires us to find $M$ which is an upper bound for $\left|f^{\prime \prime}(x)\right|$ when $1 \leq x \leq 1.1$. Since the $f^{\prime}$ is steepest when $x=1$, $\left|f^{\prime \prime}(x)\right| \leq\left|f^{\prime \prime}(1)\right| \approx 3$ when $1 \leq x \leq 1.1$. Taylor's theorem gives the error bound of $\frac{1}{2} 3(.1)^{2}=.015$, which is exactly what we obtained in (b)."
25,EECS,18.C06,Linear Algebra and Optimization,18.02,None,Problem Set 1,Matrix Multiplication,9,a,0.1851851852,Text,"We want to compute the product $A B C$ of three matrices $A, B, C$. The matrices have dimensions $n \times m, m \times p$, and $p \times r$, respectively. Recall that matrix multiplication is an associative operation, i.e., $(A B) C=A(B C)$.
For this problem we will use the standard formula for multiplying matrices from class:
$$
\sum_{k} A_{i, k} B_{k, j},
$$
and when counting arithmetic operations (addition, multiplication) you should only aim to get the answer right up to a constant factor.
If we compute the product as $(A B) C$, how many arithmetic operations are required (as a function of $n, m, p, r)$?",Expression,"The number of operations to compute $A B$ is the number of entries $(n p)$ times the number of arithmetic operations we need to make to compute each entry ( $m$ multiplications $+(m-1)$ additions $=2 m-1$ operations $)$, for a total of $n p(2 m-1)$ operations. To compute $(A B) C$ now, we argue similarly to conclude that we make $n r(2 p-1)$ additional arithmetic operations. Adding these up, we get that the total number of arithmetic operations is $n(p(2 m-1)+r(2 p-1))$.","We want to compute the product $A B C$ of three matrices $A, B, C$. The matrices have dimensions $n \times m, m \times p$, and $p \times r$, respectively. Recall that matrix multiplication is an associative operation, i.e., $(A B) C=A(B C)$.
For this problem we will use the standard formula for multiplying matrices from class:
$$
\sum_{k} A_{i, k} B_{k, j},
$$
and when counting arithmetic operations (addition, multiplication) you should only aim to get the answer right up to a constant factor.
If we compute the product as $A(B C)$, how many arithmetic operations are required?","Arguing as before, we find that the total number of arithmetic operations is $r(m(2 p-$ 1) $+n(2 m-1))$.","We want to compute the product $A B C$ of three matrices $A, B, C$. The matrices have dimensions $n \times m, m \times p$, and $p \times r$, respectively. Recall that matrix multiplication is an associative operation, i.e., $(A B) C=A(B C)$.
For this problem we will use the standard formula for multiplying matrices from class:
$$
\sum_{k} A_{i, k} B_{k, j},
$$
and when counting arithmetic operations (addition, multiplication) you should only aim to get the answer right up to a constant factor.
Let $n=1000, m=20, p=1000, r=1$. How many operations each method needs? Which one of the two methods is faster (and by how much)?","One could give a quick and probably correct answer by thinking asymptotically, but here we have plenty of time to compute (and precise formulas at hand), and we will just compare those. For $(A B) C$, we plug into the formula we found in part (a) to find that we make 40999000 operations. As for $A(B C)$, we plug into the formula from (b) to find that we make 78980 operations. Computing this as $A(B C)$ turns out to be much faster.","We want to compute the product $A B C$ of three matrices $A, B, C$. The matrices have dimensions $n \times m, m \times p$, and $p \times r$, respectively. Recall that matrix multiplication is an associative operation, i.e., $(A B) C=A(B C)$.
For this problem we will use the standard formula for multiplying matrices from class:
$$
\sum_{k} A_{i, k} B_{k, j},
$$
and when counting arithmetic operations (addition, multiplication) you should only aim to get the answer right up to a constant factor.
Let's test numerically the associative property in Julia. For this, generate some random matrices $A, B, C$ of compatible dimensions using the command randn (e.g., $\operatorname{randn}(20,30)$, and compute the difference between the two results, i.e., $A(B C)-$ $(A B) C$. What do you expect to happen? What actually happens? Explain the results.","By associativity, $A(B C)-(A B) C=0$. However, we get some small floating point errors in Julia, and the output of $A(B C)-(A B) C$ is a matrix with entries that are very close to 0 (the absolute values of entries could be like $10^{-14}$). Here is some example code for testing this out:
$>A=r a n d n(20,30) ; B=r a n d n(30,40) ; C=r a n d n(40,10)$;
$>\mathrm{A} *(\mathrm{~B} * \mathrm{C})-(\mathrm{A} * \mathrm{~B}) * \mathrm{C}$"
192,EECS,18.C06,Linear Algebra and Optimization,18.02,None,Final Exam,Inverse Matrix,13,c,0.6956521739,Text,"Let $a, b$ be vectors in $\mathbb{R}^{n}$. In this problem we will find an expression for the inverse of $M=I-a b^{T}$ and explore some implications for optimization.
Recall that for any matrix $A$ with $\|A\|<1$ we have the identity
$$
(I-A)^{-1}=\sum_{k=0}^{\infty} A^{k}=I+A+A^{2}+\cdots
$$
Use this formula to compute $M^{-1}$ and simplify to get an expression of the form
$$
M^{-1}=I+\alpha a b^{T}
$$
What is the value of $\alpha$?",Expression,"Applying the formula, we have
$$
\begin{aligned}
\left(I-a b^{T}\right)^{-1} & =I+a b^{T}+\left(a b^{T}\right)\left(a b^{T}\right)+\left(a b^{T}\right)\left(a b^{T}\right)\left(a b^{T}\right)+\cdots \\
& =I+a b^{T}+\left(b^{T} a\right)\left(a b^{T}\right)+\left(b^{T} a\right)^{2}\left(a b^{T}\right)+\cdots \\
& =I+a b^{T}\left(1+\left(b^{T} a\right)+\left(b^{T} a\right)^{2}+\cdots\right) \\
& =I+a b^{T}\left(1-b^{T} a\right)^{-1},
\end{aligned}
$$
i.e., $\alpha=1 /\left(1-b^{T} a\right)$. ","Let $a, b$ be vectors in $\mathbb{R}^{n}$. In this problem we will find an expression for the inverse of $M=I-a b^{T}$ and explore some implications for optimization.
Suppose that $a^{T} b=1$. Find a nonzero vector in $N(M)$.","By the assumption, both $a$ and $b$ are nonzero. We have
$$
M a=\left(I-a b^{T}\right) a=a-a\left(b^{T} a\right)=\left(1-a^{T} b\right) a=0,
$$
so $a \in N(M)$.","Let $a, b$ be vectors in $\mathbb{R}^{n}$. In this problem we will find an expression for the inverse of $M=I-a b^{T}$ and explore some implications for optimization.
For the rest of the problem we will assume that $a^{T} b \neq 1$. Show that when $\|a\|<1$ and $\|b\|<1$ that $\left\|a b^{T}\right\|<1$.
Hint: Can you bound the maximum of $\left\|a b^{T} x\right\|$ over $x$ which is a unit vector?","We have
$$
\left\|a b^{T}\right\|=\max _{x:\|x\|=1}\left\|a b^{T} x\right\| \leq \max _{x:\|x\|=1}\|a\|\left|b^{T} x\right|=\|a\| \max _{x:\|x\|=1}\left|b^{T} x\right|=\|a\|\|b\|<1.
$$","Let $a, b$ be vectors in $\mathbb{R}^{n}$. In this problem we will find an expression for the inverse of $M=I-a b^{T}$ and explore some implications for optimization.
What is the minimum of $f(x)$ when $\|c\|>1$? Give a geometric interpretation. ","When $\|c\|>1$ the function is unbounded below, so the minimum is $-\infty$. To see this, notice that for $x=\lambda c$ we have
$$
f(\lambda c)=\lambda^{2}\left(c^{T} c\right)\left(1-c^{T} c\right)-\lambda d^{T} c,
$$
which goes to $-\infty$ as $\lambda \rightarrow \infty$."
143,EECS,6.122,Design and Analysis of Algorithms,6.121,None,Final Exam,Randomized Algorithms,1,o,0.375,Text,"Please select True or False for the following.
Consider the following algorithm for testing if a given list $L$ of $n>3$ distinct numbers is sorted:
Repeat $\Theta(\log n)$ times: Pick three indices $i<j<k$ uniformly at random and return NO if the following is false: $L_{i}<L_{j}<L_{k}$. At the end of the $\Theta(\log n)$ iterations, return YES.
Is it true that this algorithm always returns YES if $L$ is sorted and returns $\mathrm{NO}$ with probability at least $3 / 4$ if $L$ is not $\epsilon$-close to sorted for small constant $\epsilon$?",Multiple Choice,"False. Consider the list $L$ as follows, for $n$ divisible by 2 :
$$
2,1,4,3, \ldots, 2 i, 2 i-1, \ldots, n, n-1 .
$$
This list is definitely very far from sorted: it is not $\epsilon$-close to sorted for any $\epsilon<1 / 2$, as we need to remove at least half of the numbers to make it sorted.
In order for us to pick $L_{i}, L_{j}, L_{k}(i<j<k)$ such that the algorithm returns NO, we need to have either $i=j-1$, or $j=k-1$, as only consecutive indices are in the wrong order. The probability of this happening in a single iteration is at most $O(1 / n)$. Even if we repeat $O(\log n)$ times, by a union bound, the probability that it happens in one of the iterations is at most $O(\log n / n)$. So we definitely will not return NO with constant probability. ","Please select True or False for the following.
Consider an $O\left(n^{2}\right)$-time Monte Carlo randomized algorithm for some problem, which uses 1000 randomly generated integers between 1 and 1000, and gives the correct answer with probability $\frac{2}{3}$. Then, there is also a $O\left(n^{2}\right)$-time deterministic algorithm for the same problem.","True. Simply try all $1000^{1000}$ possible random integers, and then take the majority answer. The runtime is $O\left(n^{2}\right)$ times $1000^{1000}=O(1)$, which is still $O\left(n^{2}\right)$.","Please select True or False for the following.
A Las Vegas algorithm with expected $O(n)$ runtime may run in $\Omega\left(2^{n}\right)$ time in the worst case.",True.,"Please select True or False for the following. 
Suppose we have a recurrence $T(n)=T(0.9999 n)+T(0.0001 n)+O(n)$ with $T(n)=O(1)$ for small $n$. Then, the recurrence solves to $T(n)=\Theta(n \log n)$.","False. Because the $O(n)$ term can be zero, producing $T(n)=O(n)$."
13,Mathematics,18.102,Introduction to Functional Analysis,"18.C06, 18.100B",None,Problem Set 3,Lp Spaces,1,nan,0.5,Text,"Let $f(x)=x^{a} \log (x)^{b}$ for $x>2$ and $f(x)=0$ otherwise. For which real $a, b$ is $f$ in $\mathcal{L}^{1}(\mathbb{R})$? Justify your answer.",Open,"We first claim that $f(x) \in \mathcal{L}^{1}(\mathbb{R})$ iff $\lim _{R \rightarrow \infty} \int_{2}^{R} f(x) d x<\infty$ : Assuming $f(x) \in \mathcal{L}^{1}(\mathbb{R})$, then $\int_{2}^{R} f(x) d x<\int f(x)<\infty$, and therefore it converges. Conversely, assuming the integral converges, define $f_{n}(x)=f(x) \chi_{[0, n]}$, then $f_{n}(x)$ is a monotone sequence converging pointwise to $f(x)$, by Lemma $2.7$ we conclude $f(x) \in \mathcal{L}^{1}(\mathbb{R})$.
Therefore we need to check the convergence of the integral $\int_{2}^{\infty} f(x) d x$. We distinguish different cases:
(1) $a>-1$. We have $x^{a} \log (x)^{b}>x^{-1}$ when $x$ is large, therefore the integral diverges.
(2) $a<-1$. Choose any $a<c<-1$, we have $x^{a} \log (x)^{b}<x^{c}$ when $x$ is large, therefore the integral converges.
(3) $a=-1$. We compute directly,
$$
\int x^{-1} \log (x)^{b}= \begin{cases}\frac{\log (x)^{b+1}}{b+1} & b \neq-1 \\ \log (\log (x)) & b=-1\end{cases}
$$
Therefore, the integral diverges when $b \geq-1$ and converges when $b<-1$.
In summary, $f(x) \in \mathcal{L}^{1}(\mathbb{R})$ iff in the following cases:
\begin{itemize}
\item $a<-1$.
\item $a=-1$ and $b<-1$.
\end{itemize}",Give an example of a function $f: \mathbb{R} \rightarrow \mathbb{C}$ which is in $\mathcal{L}^{1}(\mathbb{R})$ but $f \log (1+|f|)$ is not in $\mathcal{L}^{1}(\mathbb{R})$ and another example of a function $f: \mathbb{R} \rightarrow \mathbb{C}$ such that $f \log (1+|f|)$ is in $\mathcal{L}^{1}(\mathbb{R})$ but $f \notin \mathcal{L}^{1}(\mathbb{R})$; justify both.,"The first example: $f(x)=\frac{1}{x \log ^{3 / 2}(x)}$ if $0<|x|<1 / 2$ and $f(x)=0$ if $x=0$ or $|x| \geq 1 / 2$. We have $\int|f|=\int f<\infty$ but
$$
\int|f| \log (1+|f|)=\infty.
$$
The second example: $f(x)=\frac{1}{1+|x|}$. We have $\int|f|=\int f=\infty$ but
$$
\int|f| \log (1+|f|)<\infty.
$$","Suppose that $f(x)=\ln \left(2 x^{4}-x^{3}\right)$. Remember that $\ln x$ is short for $\log _{e} x$, and $\frac{d}{d x} \ln x=\frac{1}{x}$
Suppose we want to approximate $f(1.01)$. It sounds pretty complicated at first, but we can do it using the things we know if we go in two steps.
Using linear approximation again, estimate the logarithm of the number you found in part a.","Write $p(x)=2 x^{4}-x^{3}$ such that $f(x)=\ln (p(x))$. The goal is then to approximate $\ln (p(1.01))$, so we begin by approximating $p(1.01)$.
$\ln (1)=0$ and $\ln ^{\prime}(1)=1$ implies $\ln (1.05) \approx \ln (1)+.05 \cdot \ln ^{\prime}(1)=.05$. Thus,
$$
f(1.01)=\ln (p(1.01)) \approx \ln (1.05) \approx .05 .
$$","Show that the function with $F(0)=0$ and
$$
F(x)= \begin{cases}0 & x>1 \\ \exp (i / x) & 0<|x| \leq 1 \\ 0 & x<-1\end{cases}
$$
is an element of $\mathcal{L}^{1}(\mathbb{R})$.","Let $f_{n}=\left(\chi_{\left[-1,-\frac{1}{n}\right]}+\chi_{\left[\frac{1}{n}, 1\right]}\right) F$; by Lemma $2.2, f_{n} \in \mathcal{L}^{1}(\mathbb{R})$. Moreover, $f_{n} \rightarrow F$ pointwise almost everywhere. Thus, because $\chi_{[-1,1]} \in$ $\mathcal{L}^{1}(\mathbb{R})$ and $\left|f_{n}(x)\right| \leq \chi_{[-1,1]}(x)$ everywhere, it follows by the Lebesgue dominated convergence theorem that $F \in \mathcal{L}^{1}(\mathbb{R})$."
172,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Midterm Exam 3,Caches,1,a,0.45,Text,"Cache Ketchum wants to design a cache to help keep track of his Pokedex entries. He’s enlisted your help as a talented 6.191 student!
Ketchum wants to build a direct-mapped cache with a block size of eight words. He also wants the cache to hold a total of $2^9 = 512$ data words. Which address bits should be used for the block offset, cache index, and tag? Assume that data words and addresses are 32 bits wide.",Numerical,"Address bits used for block offset: A[ __4__ : __2__ ]
Address bits used for cache index: A[ __10__ : __5__ ]
Address bits used for tag: A[ __31__ : __11__ ]","Cache Ketchum wants to design a cache to help keep track of his Pokedex entries. He’s enlisted your help as a talented 6.191 student!
Ketchum ponders over the design and decides that he wants to double the number of cache lines in his direct-mapped cache. However, he wants to keep the total number of words in the cache the same. How will the number of bits used to represent the block offset change as a result?
(a) UNCHANGED.
(b) +1.
(c) -1.
(d) 2x.
(e) 0.5x.
(f) CAN'T TELL.",(c) -1.,"Cache Ketchum wants to design a cache to help keep track of his Pokedex entries. He’s enlisted your help as a talented 6.191 student!
Ketchum decides he doesn’t want a direct-mapped cache at all! He wants a two-way set-associative cache.
The remainder of the problem will be considering this 2-way set-associative cache with a capacity of 32 words. Below is a snapshot of this cache during the execution of some unknown code. V is the valid bit and D is the dirty bit of each set. Assume an LRU replacement policy and that Way 0 is currently holds the LRU cache line for all sets.
Way 0
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline V & D & Tag & Word 0 & Word 1 & Word 2 & Word 3 \\
\hline 1 & 0 & 0x28 & 0xA65 & 0x521 & 0xA2C & 0x947 \\
\hline 1 & 1 & 0x1D & 0xB54 & 0xE95 & 0x9AA & 0xC7A \\
\hline 1 & 0 & 0x4D & 0xE71 & 0x2FE & 0xC58 & 0x4C4 \\
\hline 1 & 0 & 0x085 & 0xB6B & 0xD55 & 0x27D & 0xE1E \\
\hline
\end{tabular}
Way 1
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline V & D & Tag & Word 0 & Word 1 & Word 2 & Word 3 \\
\hline 1 & 1 & 0x093 & 0x2EA & 0x4CE & 0x42D & 0x462 \\
\hline 1 & 1 & 0x093 & 0x3C2 & 0x152 & 0xB9C & 0xC23 \\
\hline 1 & 0 & 0xAF & 0xC05 & 0xE81 & 0xCEA & 0x60B \\
\hline 1 & 0 & 0xA5 & 0x57B & 0xC5F & 0xA1F & 0xAF5 \\
\hline
\end{tabular}
Identify whether each of the following memory accesses is a hit or a miss. Consider each memory access independently. If it is a hit, specify what value is returned; if it is a miss, write N/A. In addition, if it is a miss, determine if any values need to be written back to main memory, and if so, to which location(s) in main memory? List all updated main memory word addresses. If no writes to main memory are needed, write N/A.
Load from address 0x2974
Load from address 0x11D8","Load from address 0x2974
0x2974 = 0010_1001_0111_0100
tag = 0xA5, index = 3, block offset = 1
Hit.
Returned value if hit or N/A if miss: __C5F_______
All updated main memory word addresses or N/A: ___N/A________________________________
Load from address 0x11D8
0x11D8 = 0001_0001_1101_1000
tag = 0x47, index = 1, block offset = 2
miss -> replaces way 0 line 1 which is dirty
must first write this cache line back to memory
if tag = 0x1D and index = 1, then memory addresses are 111_0101_XX00 = 0x750, 0x754, 0x758, 0x75C.
Miss.
Returned value if hit or N/A if miss: ___N/A______
All updated main memory word addresses or N/A: ___0x750, 0x754, 0x758, 0x75C _____________","Cache Ketchum wants to design a cache to help keep track of his Pokedex entries. He’s enlisted your help as a talented 6.191 student!
After testing, Ketchum decides to use the cache with the following RISC-V assembly program that
increments every element in an array and stores the changed elements in another array.
// Assume the following registers are initialized:
// x1 = 0xC0 (base address of input array)
// x2 = 0x80 (base address of output array)
// x3 = 4 (number of elements in input and output arrays)
. = 0x100 // The following code starts at address 0x100
slli x6, x3, 2
add x6, x1, x6 // address of end of input array
loop:
lw x4, 0(x1) // get array element
addi x4, x4, 1 // increment element
sw x4, 0(x2) // store element into output array
addi x1, x1, 4 // compute next address for input array
addi x2, x2, 4 // compute next address for output array
blt x1, x6, loop // continue looping
Answer the following questions about the behavior of the cache during execution of the above code. Note the cache has 2 ways and uses an LRU replacement policy. Assume that the cache is initially empty.
Ketchum wants to get the best performance out of his cache. He is considering modifying his current cache to double the number of cache lines while leaving all other parameters of the cache the same (2-way set associative and a block size of 4), thus doubling the total capacity of the cache. However, this new cache is a lot more expensive! Ketchum wants to choose the cheapest cache that maximizes the hit ratio. Which one should he choose? Explain your answer.","New Cache.
Currently, the memory accesses overwrite each other every time since the indices overlap. If we have three bits to represent the index instead of two, the indices will no longer conflict, reducing the misses to 2/8."
83,Mathematics,18.03,Differential Equations,None,18.02,Problem Set 7,Gaussian Elimination,5,a,0.08042895442,Text,"One of the black boxes we used in class was the theorem that an $n \times n$ matrix $A$ has $A \vec{v}=0$ for some non-zero vector $\vec{v} \in \mathbb{R}^{n}\left(\right.$ or $\mathbb{C}^{n}$ ) if and only if $\operatorname{det}(A)=0$ (see, e.g., MITx 20.7). The goal of this problem is to work out $w h y$ this is true (at least in the case of $3 \times 3$ matrices). The only blackbox we will use is the properties of the determinant. Recall that $\operatorname{dim} \operatorname{Ker}(A)=0$ means that $\operatorname{Ker}(A)$ contains only the zero vector.
(Story time begins) The way we are going to go about showing that a $3 \times 3$ matrix has $\operatorname{det} A=0$ if and only if $\operatorname{dim} \operatorname{Ker}(A)>0$ is by using Gaussian elimination to reduce the statement to the case of upper triangular (or rather, RREF) matrices. So, as a first step, we're going to check that the theorem is true for this model case. (Story time ends)
Suppose $A$ is a $3 \times 3$ matrix which is upper triangular; that is
$$
A=\left(\begin{array}{ccc}
p_{1} & a & b \\
0 & p_{2} & c \\
0 & 0 & p_{3}
\end{array}\right) \text {. }
$$
Show that $\operatorname{det} A=p_{1} p_{2} p_{3}$. In particular, $\operatorname{det}(A)=0$ if and only if at least one of $p_{1}, p_{2}, p_{3}$ is 0.",Open,"Using the Laplace expansion, the only non-zero term is $p_{1} \cdot\left|\left(\begin{array}{cc}p_{2} & c \\ 0 & p_{3}\end{array}\right)\right|=$ $p_{1} p_{2} p_{3}$. Or you may use the fact that eigenvalues are $p_{1}, p_{2}, p_{3}$ and the determinant is the product of them. ","One of the black boxes we used in class was the theorem that an $n \times n$ matrix $A$ has $A \vec{v}=0$ for some non-zero vector $\vec{v} \in \mathbb{R}^{n}\left(\right.$ or $\mathbb{C}^{n}$ ) if and only if $\operatorname{det}(A)=0$ (see, e.g., MITx 20.7). The goal of this problem is to work out $w h y$ this is true (at least in the case of $3 \times 3$ matrices). The only blackbox we will use is the properties of the determinant. Recall that $\operatorname{dim} \operatorname{Ker}(A)=0$ means that $\operatorname{Ker}(A)$ contains only the zero vector.
(Story time begins) The way we are going to go about showing that a $3 \times 3$ matrix has $\operatorname{det} A=0$ if and only if $\operatorname{dim} \operatorname{Ker}(A)>0$ is by using Gaussian elimination to reduce the statement to the case of upper triangular (or rather, RREF) matrices. So, as a first step, we're going to check that the theorem is true for this model case. (Story time ends)
Combine (b), (e) with (B) to show that $\operatorname{dim} \operatorname{Ker}(A)>0$ if and only if $\operatorname{det} A=0$.","$(\Rightarrow)$ Suppose that $\operatorname{dim} \operatorname{Ker}(A)>0$, that is there is a non-zero vector $\vec{v}$ such that $A v=0$. Note that (B) implies that $B \vec{v}=0$. Therefore $\operatorname{dim} \operatorname{Ker}(B)>0$ and it follows from (b) that $\operatorname{det}(B)=0$, which proves $\operatorname{det}(A)=0$.
$(\Leftarrow)$ Suppose that $\operatorname{det}(A)=0$, which implies $\operatorname{det}(B)=0$. It also follows from (b) that $\operatorname{dim} \operatorname{Ker}(B)>0$; otherwise $\operatorname{det}(B)=1$. This means there is a non-zero vector $\vec{v}$ such that $B \vec{v}=0$. Note that (B) implies $A \vec{v}=0$. Therefore $\operatorname{dim} \operatorname{Ker}(A)>0$. ","One of the black boxes we used in class was the theorem that an $n \times n$ matrix $A$ has $A \vec{v}=0$ for some non-zero vector $\vec{v} \in \mathbb{R}^{n}\left(\right.$ or $\mathbb{C}^{n}$ ) if and only if $\operatorname{det}(A)=0$ (see, e.g., MITx 20.7). The goal of this problem is to work out $w h y$ this is true (at least in the case of $3 \times 3$ matrices). The only blackbox we will use is the properties of the determinant. Recall that $\operatorname{dim} \operatorname{Ker}(A)=0$ means that $\operatorname{Ker}(A)$ contains only the zero vector.
(Story time begins) The way we are going to go about showing that a $3 \times 3$ matrix has $\operatorname{det} A=0$ if and only if $\operatorname{dim} \operatorname{Ker}(A)>0$ is by using Gaussian elimination to reduce the statement to the case of upper triangular (or rather, RREF) matrices. So, as a first step, we're going to check that the theorem is true for this model case. (Story time ends)
Now suppose that $B$ is a $3 \times 3$ matrix in reduced row echelon form. Show that
(i) If $\operatorname{dim} \operatorname{Ker}(B)=0$ then $\operatorname{det} B=1$. (Hint: It may be helpful to recall problem $(4))$
(ii) If $\operatorname{dim} \operatorname{Ker}(B)>0$, then $\operatorname{det} B=0$. (Hint: If $B$ is in rref then $B$ is upper triangular. What does $\operatorname{dim} \operatorname{Ker}(B)>0$ tell you about the pivots of $B$ ? Combine this with part (a).)","If $\operatorname{dim} \operatorname{Ker}(B)=0$, we have $\operatorname{Ker}(B)=\{0\}$ and this implies that $B$ is the identity matrix from (4). Therefore its determinant is 1.
Since $B$ is upper triangular, if all diagonals are non-zero, then those entries must be first non-zero element for each row and be leading ones, and thus all columns should be pivots.
On the other hand, it follows from the rank-nulity theorem that the number of pivots is $3-\operatorname{dim} \operatorname{Ker}(B)<3$. So not every diagonal can be non-zero, and there is some zero diagonal entry. By the part (a), the determinant is 0.","One of the black boxes we used in class was the theorem that an $n \times n$ matrix $A$ has $A \vec{v}=0$ for some non-zero vector $\vec{v} \in \mathbb{R}^{n}\left(\right.$ or $\mathbb{C}^{n}$ ) if and only if $\operatorname{det}(A)=0$ (see, e.g., MITx 20.7). The goal of this problem is to work out $w h y$ this is true (at least in the case of $3 \times 3$ matrices). The only blackbox we will use is the properties of the determinant. Recall that $\operatorname{dim} \operatorname{Ker}(A)=0$ means that $\operatorname{Ker}(A)$ contains only the zero vector.
(Story time begins) The way we are going to go about showing that a $3 \times 3$ matrix has $\operatorname{det} A=0$ if and only if $\operatorname{dim} \operatorname{Ker}(A)>0$ is by using Gaussian elimination to reduce the statement to the case of upper triangular (or rather, RREF) matrices. So, as a first step, we're going to check that the theorem is true for this model case. (Story time ends)
(Story time begins, again) Let's remember what Gauss-Jordan elimination tells us. Gauss-Jordan says that if we have a matrix $A$, then we can perform a sequence of row operations to bring $A$ into reduced row echelon form. Let's set $B=\operatorname{rref}(A)$. Each row operation corresponds to left multiplication by one of the elementary matrices. So, if we write Gauss-Jordan elimination in terms of the elementary matrices, what we have is
$$
E_{s(N)} E_{s(N-1)} \cdots E_{s(1)} A=B
$$
Here we have written $E_{s(i)}$ to denote the elementary matrix corresponding to the row operation performed at step $i$ of the Gauss-Jordan algorithm. Furthermore, from Gauss-Jordan elimination we know that
$$
\vec{v} \in \operatorname{Ker}(A) \text { if and only if } \vec{v} \in \operatorname{Ker}(B) .
$$
If this is unclear to you, it might be worth reflecting on Gauss-Jordan elimination.
We are now very close to being finished. Recall that if $M_{1}, M_{2}$ are $n \times n$ matrices then
$$
\operatorname{det}\left(M_{1} M_{2}\right)=\operatorname{det}\left(M_{1}\right) \cdot \operatorname{det}\left(M_{2}\right) .
$$
From this we will finish our proof. (Story time ends, again).
By applying the multiplication property of the determinant (C) iteratively, show that (A) together with part (d) implies
$$
\operatorname{det} A=0 \text { if and only if } \operatorname{det} B=0 .
$$","From (A) and (C) we have
$$
\begin{aligned}
\operatorname{det}(B) &=\operatorname{det}\left(E_{s(N)} E_{s(N-1)} \cdots E_{s(1)} A\right)=\operatorname{det}\left(E_{s(N)} E_{s(N-1)} \cdots E_{s(1)}\right) \operatorname{det}(A) \\
&=\operatorname{det}\left(E_{s(N)} E_{s(N-1)} \cdots E_{s(2)}\right) \operatorname{det}\left(E_{s(1)}\right) \operatorname{det}(A)=\cdots \\
&=\operatorname{det}\left(E_{s(N)}\right) \operatorname{det}\left(E_{s(N-1)}\right) \cdots \operatorname{det}\left(E_{s(1)}\right) \operatorname{det}(A) .
\end{aligned}
$$
Since $\operatorname{det}\left(E_{s(i)}\right)$ is not 0 for all $i$, we conclude that $\operatorname{det}(A)=0$ if and only if $\operatorname{det}(B)=0$."
115,Mathematics,18.01,Calculus I,None,None,Problem Set 3,Chain Rule,10,a,0.05279831045,Text,"Find the derivatives of the following functions:
$e^{5 x}$.",Expression,$\frac{d}{d x} e^{5 x}=e^{5 x}(5)=5 e^{5 x}$.,"Find the derivatives of the following functions:
$e^{x+1}$.",$\frac{d}{d x} e^{x+1}=e^{x+1}(1)=e^{x+1}$.,"Using the product rule, compute the derivative of each of the following functions.
$x e^{x}$.",$\frac{d}{d x} x e^{x}=e^{x}+x e^{x}$.,"Compute the derivatives of the following functions.
$e^{-x^{2}}$.",Here we use the chain rule. That gives us that $\left(e^{\left(-x^{2}\right)}\right)^{\prime}=\left(-x^{2}\right)^{\prime} e^{-x^{2}}=-2 x e^{-x^{2}}$.
610,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Final Exam,Convolutional Neural Networks,8,c,0.35,Text,"MIT grad student Rec Urrent would like to submit an entry to win this year's Grand ML Tetris Competition, which gives awards to the smallest neural networks which can identify tetris pieces with the highest accuracy. Rec seeks to make a convolutional neural network that can accurately classify single-channel $3 \times 3$ images of $2 \mathrm{D}$ tetris pieces as being either a line-shaped piece, or a corner-shaped piece, using just one $2 \times 2$ filter. Let's help Rec win this competition.
If Rec wants to allow for more than two classes, which activation function should they use for final_act and which loss function?",Open,Softmax $+$ Cross Entropy.,"MIT grad student Rec Urrent would like to submit an entry to win this year's Grand ML Tetris Competition, which gives awards to the smallest neural networks which can identify tetris pieces with the highest accuracy. Rec seeks to make a convolutional neural network that can accurately classify single-channel $3 \times 3$ images of $2 \mathrm{D}$ tetris pieces as being either a line-shaped piece, or a corner-shaped piece, using just one $2 \times 2$ filter. Let's help Rec win this competition.
What does each filter do? Which filter is best for distinguishing line-shaped tetris pieces vs. corner-shaped pieces? Why?","The first filter detects pixels on the diagonal and ignores vertical and horizontal lines. The second filter only detects vertical lines. The first filter is best for distinguishing corners and lines after applying ReLU to the output, it linearly separates corners and lines whereas the second filter does not.","MIT grad student Rec Urrent would like to submit an entry to win this year's Grand ML Tetris Competition, which gives awards to the smallest neural networks which can identify tetris pieces with the highest accuracy. Rec seeks to make a convolutional neural network that can accurately classify single-channel $3 \times 3$ images of $2 \mathrm{D}$ tetris pieces as being either a line-shaped piece, or a corner-shaped piece, using just one $2 \times 2$ filter. Let's help Rec win this competition.
If Rec instead labeled line-shaped pieces as ""1"" and corner-shaped pieces as ""0"" then what values of $\mathrm{w}$ and $\mathrm{b}$ of the output layer give perfect classification and outputs that are close to 0 for corners and close to 1 for lines?",The same as above with opposite sign.,"MIT grad student Rec Urrent would like to submit an entry to win this year's Grand ML Tetris Competition, which gives awards to the smallest neural networks which can identify tetris pieces with the highest accuracy. Rec seeks to make a convolutional neural network that can accurately classify single-channel $3 \times 3$ images of $2 \mathrm{D}$ tetris pieces as being either a line-shaped piece, or a corner-shaped piece, using just one $2 \times 2$ filter. Let's help Rec win this competition.
Write an expression for the derivative of the binary classification loss with respect to z2, the input of final_act. You may express your answer using $g$ for the output of $f$ inal_act and $y$ for the example label.",The derivative of the negative log likelihood loss with respect to the argument of the Sigmoid function is very elegant. It is $g-y$.
222,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 6,Particle Filter,5,dii,0.08333333333,Text,"Consider a domain in which the forward transition dynamics are ""hybrid"" in the sense that 
$$
P\left(X_{t}=x_{t} \mid X_{t-1}=x_{t-1}\right)=p * N\left(x_{t-1}+1,0.1\right)\left(x_{t}\right)+(1-p) * N\left(x_{t-1}-1,0.1\right)\left(x_{t}\right)
$$
that is, that the state will hop forward one unit in expectation with probability $p$, or backward one unit in expectation with probability $1-p$, with variance $0.1$ in each case.
Assume additionally that the observation model $P\left(Y_{t}=y_{t} \mid X_{t}=x_{t}\right)=\operatorname{Uniform}\left(x_{t}-1, x_{t}+1\right)\left(y_{t}\right)$.
Norm runs the filter for two steps with no observations several times and is trying to decide whether there could be bugs in the code. Assuming $p=0.5$, for each of the following sets of particles, indicate whether it is (a) fairly likely (b) quite unlikely (c) completely impossible: {-2.01, -1.9, -1.0, 0.1, 0, 2.1}.",Multiple Choice,b.,"Consider a domain in which the forward transition dynamics are ""hybrid"" in the sense that 
$$
P\left(X_{t}=x_{t} \mid X_{t-1}=x_{t-1}\right)=p * N\left(x_{t-1}+1,0.1\right)\left(x_{t}\right)+(1-p) * N\left(x_{t-1}-1,0.1\right)\left(x_{t}\right)
$$
that is, that the state will hop forward one unit in expectation with probability $p$, or backward one unit in expectation with probability $1-p$, with variance $0.1$ in each case.
Assume additionally that the observation model $P\left(Y_{t}=y_{t} \mid X_{t}=x_{t}\right)=\operatorname{Uniform}\left(x_{t}-1, x_{t}+1\right)\left(y_{t}\right)$.
Norm runs the filter for two steps with no observations several times and is trying to decide whether there could be bugs in the code. Assuming $p=0.5$, for each of the following sets of particles, indicate whether it is (a) fairly likely (b) quite unlikely (c) completely impossible: {-2.05, -1.95, -0.1, 0.1, 1.9, 2.1}.",a.,"Consider a domain in which the forward transition dynamics are ""hybrid"" in the sense that 
$$
P\left(X_{t}=x_{t} \mid X_{t-1}=x_{t-1}\right)=p * N\left(x_{t-1}+1,0.1\right)\left(x_{t}\right)+(1-p) * N\left(x_{t-1}-1,0.1\right)\left(x_{t}\right)
$$
that is, that the state will hop forward one unit in expectation with probability $p$, or backward one unit in expectation with probability $1-p$, with variance $0.1$ in each case.
Assume additionally that the observation model $P\left(Y_{t}=y_{t} \mid X_{t}=x_{t}\right)=\operatorname{Uniform}\left(x_{t}-1, x_{t}+1\right)\left(y_{t}\right)$.
Norm runs the filter for two steps with no observations several times and is trying to decide whether there could be bugs in the code. Assuming $p=0.5$, for each of the following sets of particles, indicate whether it is (a) fairly likely (b) quite unlikely (c) completely impossible: {-20, -2.01, -2.001, .01, .001, 1.99, 1.999}.",b.,"Consider a domain in which the forward transition dynamics are ""hybrid"" in the sense that 
$$
P\left(X_{t}=x_{t} \mid X_{t-1}=x_{t-1}\right)=p * N\left(x_{t-1}+1,0.1\right)\left(x_{t}\right)+(1-p) * N\left(x_{t-1}-1,0.1\right)\left(x_{t}\right)
$$
that is, that the state will hop forward one unit in expectation with probability $p$, or backward one unit in expectation with probability $1-p$, with variance $0.1$ in each case.
Assume additionally that the observation model $P\left(Y_{t}=y_{t} \mid X_{t}=x_{t}\right)=\operatorname{Uniform}\left(x_{t}-1, x_{t}+1\right)\left(y_{t}\right)$.
Norm initializes the filter with particles {-2.05, -1.95, -0.1, 0.1, 1.9, 2.1} and then gets an observation of -1.0. Which of the following is a plausible posterior, assuming resampling?
(a) {-1.95, -0.1, -1.95, -1.95, -0.1, -0.1, -0.1}
(b) {-1.95, -.01}
(c) {0.1, 0.1, 0.1, -0.1, -0.1, -0.1}
(d) {-1.96, -0.11, -1.94, -1.97, -0.11, -0.09, -0.12}v","(a) {-1.95, -0.1, -1.95, -1.95, -0.1, -0.1, -0.1}"
24,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Prelab Questions 2,RISC-V Calling Convention,1,a,0.025,Text,"Consider the following C function, `f`:
int f(int x, int y) {
    int w = y;
    int z = mul(x, 2) + y + w;
    return z;
}
Suppose that you wanted to implement the function, f, in RISC-V assembly.
Which register(s) should be used to pass the arguments to the function f? Select all correct answers.
(a) zero.
(b) ra.
(c) a0.
(d) a1.
(e) a2.
(f) t0.
(g) t1.
(h) s0.
(i) s1.",Multiple Choice,"(c) a0.
(d) a1.
According to the calling conventions, the arguments to the function are passed in through the a registers, starting from a0, a1, and so on. In this question, there are 2 arguments (x and y) needed to be passed in, so only a0 and a1 are used.","Consider the following C function, `f`:
int f(int x, int y) {
    int w = y;
    int z = mul(x, 2) + y + w;
    return z;
}
Suppose that you wanted to implement the function, f, in RISC-V assembly.
When the function returns, which register(s) should be set to the returned value? Select all correct answers.
(a) zero.
(b) ra.
(c) a0.
(d) a1.
(e) a2.
(f) t0.
(g) t1.
(h) s0.
(i) s1.","(c) a0.
According to the calling conventions, the return value from the functions should always be returned in the a0 register (or in a0 and a1 if 2 values need to be returned).","Consider the following incorrect RISC-V implementation of the function f.
Assume that its calling function believes that f is properly implemented and follows the RISC-V calling conventions. Also
assume that the function mul, being called by f, is implemented correctly and follows the RISC-V calling convention. The
function mul takes two unsigned integer arguments and returns the result of multiplying those inputs.
f:
// (1)
mv a2, a1
mv s0, a1
li a1, 2
// (2)
call mul
// (3)
add a0, a0, a2
add a0, a0, s0
// (4)
ret
// (5)
Given that mul follows the calling convention, which of the following register(s) are guaranteed to hold the same value at both points (2) and (3) in the code execution? Select all correct answers.
(a) zero.
(b) ra.
(c) a0.
(d) a1.
(e) a2.
(f) t0.
(g) t1.
(h) s0.
(i) s1.","(a) zero.
(h) s0.
(i) s1.
According to the calling convention, s registers are callee-saved registers. Callee-saved registers must be returned unaltered from any function call. In addition, the zero register is hardwired to 0 and its value can never be changed. The a registers are caller-saved, however, so there is no guarantee that their value will be the same both before and after the call to mul.","Consider the following incorrect RISC-V implementation of the function f.
Assume that its calling function believes that f is properly implemented and follows the RISC-V calling conventions. Also
assume that the function mul, being called by f, is implemented correctly and follows the RISC-V calling convention. The
function mul takes two unsigned integer arguments and returns the result of multiplying those inputs.
f:
// (1)
mv a2, a1
mv s0, a1
li a1, 2
// (2)
call mul
// (3)
add a0, a0, a2
add a0, a0, s0
// (4)
ret
// (5)
Given that mul follows the calling convention, but f does not, which register(s) are not handled properly by the code above? Select all correct answers.
(a) zero.
(b) ra.
(c) a0.
(d) a1.
(e) a2.
(f) t0.
(g) t1.
(h) s0.
(i) s1.","(b) ra.
(e) a2.
(h) s0.
According to the calling convention, ra and a2 are caller-saved registers. Caller-saved registers must be saved onto the stack prior to calling another procedure if their original value will be needed upon return from the called procedure. ra must be saved in order for the ret pseudoinstruction of function f to return to the correct location in the calling code. a2 must be saved onto the stack in order to make sure that when it is used, it holds its original value and was not modified by the mul function. In addition, callee-saved registers must be saved onto the stack before being modified. Thus, s0, must be saved onto the stack prior to pseudoinstruction mv s0, a1."
19,Mathematics,18.102,Introduction to Functional Analysis,"18.C06, 18.100B",None,Problem Set 3,Lp Spaces,5,nan,0.5,Text,"Suppose $f \in \mathcal{L}^{1}(\mathbb{R})$ is real-valued. Show that there is a sequence $f_{n} \in \mathcal{C}_{\mathrm{c}}(\mathbb{R})$ and another element $F \in \mathcal{L}^{1}(\mathbb{R})$ such that
$$
f_{n}(x) \rightarrow f(x) \text { a.e. on } \mathbb{R},\left|f_{n}(x)\right| \leq F(x) \text { a.e. }
$$
Hint: Take an approximating series $u_{n}$ as in the definition and think about $\left|u_{n}\right|$.
Remark: The converse of this, where the $f_{n}$ are allowed to be in $\mathcal{L}^{1}(\mathbb{R})$ is 'Lebesgue Dominated Convergence'.",Open,"Let $f_{n} \in C_{c}(\mathbb{R})$ be such that if $w_{1}=f_{1}$ and $w_{k}=f_{k}-f_{k-1}$, $\left(w_{n}\right)$ is absolutely summable and $f_{n}(x) \rightarrow f(x)$ almost everywhere (such a sequence $\left(f_{n}\right)$ exists by the definition of $\mathcal{L}^{1}(\mathbb{R})$ ). Then, define
$$
F(x)=\left\{\begin{array}{ll}
\sum_{n}\left|w_{n}(x)\right| & \text { if } \sum_{n}\left|w_{n}(x)\right|<\infty \\
0 & \text { otherwise }
\end{array} .\right.
$$
By the definition of measure zero, $F(x)=\sum_{n}\left|w_{n}(x)\right|$ almost everywhere, so by Proposition $2.5$ it follows that $F \in \mathcal{L}^{1}(\mathbb{R})$. Moreover, because whenever $F(x)=\sum_{n}\left|w_{n}(x)\right|$ we have that
$$
\left|f_{n}(x)\right|=\left|\sum_{k=1}^{n} w_{k}(x)\right| \leq \sum_{k=1}^{n}\left|w_{k}(x)\right| \leq F(x),
$$
it follows that $\left|f_{n}(x)\right| \leq F(x)$ almost everywhere. The desired conclusion follows.",Let $[f] \in L^{1}(\mathbb{R})$ be the image of $f \in \mathcal{L}^{1}(\mathbb{R})$. Suppose that $\left[f_{j}\right] \in L^{1}(\mathbb{R})$ is a Cauchy sequence. Show that $f_{j}$ has a subsequence which converges almost everywhere.,"Let $n_{k}$ be such that for $m, n \geq n_{k}$ we have
$$
\left\|f_{n}-f_{m}\right\|<2^{-k}.
$$
Then setting $g_{1}=f_{n_{1}}$ and $g_{k}:=f_{n_{k}}-f_{n_{k-1}}$ for $k \geq 2$, by the triangle inequality we have
$$
\left\|g_{k}\right\|<2^{-k+1}, k \geq 2
$$
So the series $\sum_{k} g_{k}$ is absolutely summable, and its partial sums are equal to $f_{n_{k}}$. This implies that $f_{n_{k}}$ converges almost everywhere (Proposition $2.5$ in the notes), as claimed. ","Suppose $u_{n} \in \mathcal{C}_{\mathrm{c}}(\mathbb{R})$ form an absolutely summable series with respect to the $L^{1}$ norm and set
$$
E=\left\{x \in \mathbb{R} ; \sum_{n}\left|u_{n}(x)\right|=\infty\right\}
$$
Deduce that if $\epsilon>0$ is given then there is an open set $O_{\epsilon} \supset E$ with $\sum_{n}\left|u_{n}(x)\right|>1 / \epsilon$ for each $x \in O_{\epsilon}$.","The subset $Z_{\epsilon}=\left\{x \in \mathbb{R} ; \sum_{n}\left|u_{n}(x)\right| \leq 1 / \epsilon\right\}$ is closed by 1 . Then $O_{\epsilon}=\mathbb{R} \backslash Z_{\epsilon}$ is open and, obviously, $E \subset O_{\epsilon}$.","Define $\mathcal{L}^{\infty}(\mathbb{R})$ as the set of functions $g: \mathbb{R} \longrightarrow \mathbb{C}$ such that there exists $C>0$ and a sequence $v_{n} \in \mathcal{C}(\mathbb{R})$ with $\left|v_{n}(x)\right| \leq C$ and $v_{n}(x) \rightarrow g(x)$ a.e.
Show that if $g \in \mathcal{L}^{\infty}(\mathbb{R})$ and $f \in \mathcal{L}^{1}(\mathbb{R})$ then $g f \in \mathcal{L}^{1}(\mathbb{R})$ and that this defines a map
$$
L^{\infty}(\mathbb{R}) \times L^{1}(\mathbb{R}) \longrightarrow L^{1}(\mathbb{R})
$$
which satisfies $\|g f\|_{L^{1}} \leq\|g\|_{L^{\infty}}\|f\|_{L^{1}}$.","Proof. For $g$ we keep the notations from the definition. For $f$ let $w_{n}$ be the absolutely summable series converging to $f$ a.e.
Note that the sequence $u_{n}=v_{k} w_{n}$ is absolutely summable as $\sum_{n} \int\left|v_{k} w_{n}(x)\right| \leq C \sum_{n} \int\left|w_{n}(x)\right|<\infty$ and converges to $v_{k} f$ a.e. which is thus in $\mathcal{L}^{1}(\mathbb{R})$. Now $t_{n}=v_{n} f$ is dominated by $C|f|$ and converges to $f g \in \mathcal{L}^{1}(\mathbb{R})$.
If either $f$ or $g$ is in $\mathcal{N}$ then $f g \in \mathcal{N}$, which ensure passing from $\mathcal{L}$ to $L$.
Finally, since $|g| \leq\|g\|_{L^{\infty}}$ a.e.
$$
\|g f\|_{L^{1}}=\int|g f| \leq \int\|g\|_{L^{\infty}}|f|=\|g\|_{L^{\infty}}\|f\|_{L^{1}}.
$$"
234,Mathematics,18.01,Calculus I,None,None,Problem Set 5,Differential Equations,19,b,0.07919746568,Text,"In this section, we give an oversimplified model of how blood sugar and insulin work, and we consider the problem of designing an artificial pancreas. The biology is over-simplified, but the issues we will explore are still relevant in more accurate and complex models.
Let $S(t)$ denote the blood sugar level at time $t$. Suppose $S=10$ is a good level of blood sugar, $S$ above 12 is too high, and $S$ below 8 is too low. The blood sugar reacts to insulin levels. Let $I(t)$ denote the insulin level in the blood at time $T$. Suppose that
$$
S^{\prime}(t)=5-I(t) .
$$
So if $I(t)>5$, then blood sugar does down, and if $I(t)<5$ then blood sugar goes up. In patients with severe diabetes, the pancreas doesn't make insulin. The artificial pancreas is a fairly recent medical technology where a medical device installed in the patient makes insulin and has to adjust insulin levels to regulate blood sugar. Figuring out when to increase/decrease the insulin level is a mathematical problem. One approach is the following: if the patient's blood sugar is too high, the artificial pancreas increases the insulin level. If the patient's blood sugar is too low, the artificial pancreas decreases the insulin level. This approach can be modelled by the following differential equation: 
$$
I^{\prime}(t)=S(t)-10 .
$$
At the moment we have two equations involving two functions:
$$
S^{\prime}(t)=5-I(t) \text { and } I^{\prime}(t)=S(t)-10 .
$$
To get an equation for just one function, we can differentiate the first equation $S^{\prime}(t)=5-I(t)$, which gives $S^{\prime \prime}(t)=-I^{\prime}(t)$ and then plug in the equation for $I^{\prime}(t)$. This leads to an equation for $S(t)$ which is similar to the ones in the last few problems.
Suppose that at time $0, S(0)=13$ (too high) and $I(0)=5$.
Is the artificial pancreas doing a good job or a bad job? Explain.",Open,"It's bad. Because the coefficient of $\sin$ in $S$ is 3 , the blood sugar swings between 7 and 13. Thus, it keeps swinging into the too-high zone $(>12)$ and the too-low zone $(<8)$. Another objection to this design is that the blood sugar never stops swinging. ","In this section, we give an oversimplified model of how blood sugar and insulin work, and we consider the problem of designing an artificial pancreas. The biology is over-simplified, but the issues we will explore are still relevant in more accurate and complex models.
Let $S(t)$ denote the blood sugar level at time $t$. Suppose $S=10$ is a good level of blood sugar, $S$ above 12 is too high, and $S$ below 8 is too low. The blood sugar reacts to insulin levels. Let $I(t)$ denote the insulin level in the blood at time $T$. Suppose that
$$
S^{\prime}(t)=5-I(t) .
$$
So if $I(t)>5$, then blood sugar does down, and if $I(t)<5$ then blood sugar goes up. In patients with severe diabetes, the pancreas doesn't make insulin. The artificial pancreas is a fairly recent medical technology where a medical device installed in the patient makes insulin and has to adjust insulin levels to regulate blood sugar. Figuring out when to increase/decrease the insulin level is a mathematical problem. One approach is the following: if the patient's blood sugar is too high, the artificial pancreas increases the insulin level. If the patient's blood sugar is too low, the artificial pancreas decreases the insulin level. This approach can be modelled by the following differential equation: 
$$
I^{\prime}(t)=S(t)-10 .
$$
At the moment we have two equations involving two functions:
$$
S^{\prime}(t)=5-I(t) \text { and } I^{\prime}(t)=S(t)-10 .
$$
To get an equation for just one function, we can differentiate the first equation $S^{\prime}(t)=5-I(t)$, which gives $S^{\prime \prime}(t)=-I^{\prime}(t)$ and then plug in the equation for $I^{\prime}(t)$. This leads to an equation for $S(t)$ which is similar to the ones in the last few problems.
Suppose that at time $0, S(0)=13$ (too high) and $I(0)=5$.
Find $S(t)$ and $I(t)$.","From $S^{\prime \prime}=-I^{\prime}$ (in the discussion just before Problem 19 officially begins) and $I^{\prime}=S-10$ (the second differential equation),
$$
S^{\prime \prime}=10-S \text {. }
$$
It has the same form as $x^{\prime \prime}=1-x$ (Problem 18), so its solution is, by analogy,
$$
S=10+A \sin t+B \cos t .
$$
To find $A$ and $B$, find $S(0)$ and $S^{\prime}(0) . S(0)$ is given as 13. And $S^{\prime}(0)=5-I(0)$. With $I(0)=5, S^{\prime}(0)=0$. Thus, $S$ has no sine term $(A=0)$, which would otherwise give $S$ a nonzero derivative at 0 . To make $S(0)=13$, set $B=3$.
$$
S=10+3 \cos t .
$$
To find $I$, use the first differential equation $S^{\prime}=5-I$, or $I=5-S^{\prime}$. Differentiating the solution (40) for $S$ gives $S^{\prime}=-3 \sin t$. Thus,
$$
I=5+3 \sin t .
$$
As a sanity check: $I$ is increasing at $t=0$, as it should (the blood sugar started out too high).","Let us remember where we left off trying to design a good feedback loop for an artificial pancreas. We let $S(t)$ denote the blood sugar at time $t$ and $I(t)$ the insulin level at time $t$. A blood sugar $S=10$ is normal, $S>12$ is too high, and $S<8$ is too low. Blood sugar is regulated by insulin according to the equation
$$
S^{\prime}(t)=5-I(t) .
$$
The artificial pancreas can measure the blood sugar and respond by increasing or decreasing the insulin level, and we have to design exactly how it does so. In our first model, the artificial pancreas increased insulin when the blood sugar was above 10, and decreased insulin when the blood sugar was below 10. This plan led us to the equation
$$
I^{\prime}(t)=S(t)-10 .
$$
Combining the equations, we found
$$
S^{\prime \prime}(t)=-I^{\prime}(t)=10-S(t) .
$$
On the last problem set, we supposed that $S(0)=13$ (blood sugar too high) and $I(0)=5$, and we solved for $S(t)$ and $I(t)$. This describes a situation where the patient's blood sugar starts off too high, and we want to see if the artificial pancreas can restore blood sugar to a normal level. When we solved the equations, we found
$$
S(t)=10+3 \cos t \text { and } I(t)=5+3 \sin t .
$$
These pictures below show the sugar level and insulin level over time.
The patient's blood sugar drops too low then goes up too high then drops too low again and repeats forever. Instead of this blood sugar roller coaster, we would like the patient's blood sugar to go down from 13 to the normal range and then stay in the normal range. How can we fix the artificial pancreas?
Diagnosis: We discussed in class what is going wrong. At time $t=\pi / 2$, we have $S(t)=10$ which looks normal, but $I(t)=8$. An insulin level of 8 is high and it's going to drive the blood sugar down. Having $S=10$ and $I=8$ is not a stable situation and not a particularly good situation. The goal is to get $S$ close to 10 and $I$ close to 5.
Here are four ways we could change the feedback loop of our artificial pancreas. Which one will best fix this problem? Explain your reasoning.
a. $I^{\prime}(t)=2(S(t)-10)$.
b. $I^{\prime}(t)=(1 / 2)(S(t)-10)$.
c. $I^{\prime}(t)=(S(t)-10)+(I(t)-5)$.
d. $I^{\prime}(t)=(S(t)-10)-(I(t)-5)$.","The best fix is option (d). Initially, using $S(0)=13$ and $I(0)=5, I^{\prime}(0)$ is positive for all the options. This means that $I(t)$ increases from 5 , which makes $S^{\prime}(t)=5-I(t)$ decrease from 13. As $S$ decreases from 13 to $10, S-10>0$ and $S^{\prime}<0$. Meanwhile, $I(t)$ is increasing until it reaches a maximum $I_{\max }$ when $I^{\prime}(t)=0$. Analyze each of the options to think about when this happens:
a. $I^{\prime}(t)=0 \quad \longrightarrow \quad S(t)=10$
b. $I^{\prime}(t)=0 \quad \longrightarrow \quad S(t)=10$
c. $I^{\prime}(t)=0 \quad \longrightarrow \quad S(t)-10=S^{\prime}(t)$
d. $I^{\prime}(t)=0 \quad \longrightarrow \quad S(t)-10=-S^{\prime}(t)$.
We should exclude (a) and (b) because they mean that $I(t)$ reaches $I_{\max }$ when $S(t)=10$, which means that the next thing that happens is a sugar crash $(S(t)$ decreases at a rapid rate). For (c), as $S(t)>10, S^{\prime}(t)$ should still be negative, so $I(t)$ is still increasing until $S(t) \leq 10$. This is also an unstable situation because $I(t)$ reaches $I_{\max }$ after $S(t) \leq 10$, causing another sugar crash. The last option is (d), which makes sense since $S(t)-10=-S^{\prime}(t)$ (a positive number) has a chance of happening before $S(t)$ reaches 10, so the insulin level can come down from $I_{\max }$ before $S(t)=10$.","Differential equations model feedback loops. Here is a description of a feedback loop from biology. Your job is to decide which differential equations are a reasonable model of this feedback loop. This probably won't be a very accurate model, but it's really good practice in understanding what differential equations mean, and that skill would help you find a more accurate model based on more data.
Hormone $\mathrm{X}$ tells the liver to make more of protein P. However, when the liver is exposed to hormone $X$, it slowly becomes less sensitive to hormone $X$, and the effect of a given amount of hormone $\mathrm{X}$ is smaller.
We let $P(t)$ be the amount of protein $P$ in the bloodstream at time $t, X(t)$ be the amount of hormone $X$, and $S(t)$ be a measure of the sensitivity of the liver to hormone $X$. The sensitivity $S$ lies in between 0 and 1 , with 1 being the most sensitive and 0 being the least sensitive. Which differential equations approximately match the description in the last paragraph? Explain your reasoning.
b. $P^{\prime}(t)=S(t)+X(t)$ and $S^{\prime}(t)=-\frac{1}{100} P(t)$.","Choice $\mathrm{c}$ is no good because its second equation, $S^{\prime}=X-S$, says that hormone $X$ increases the sensitivity $S$-contrary to the description that exposure to hormone $X$ decreases sensitivity. Choice $b$ is also no good because $S^{\prime}$ doesn't depend on $X$.
Fortunately, choice a does show a reasonable dependence for $S^{\prime}:$ more $X$ makes $S^{\prime}$ more negative, which indeed decreases $S$. This choice also has a reasonable behavior for $P$. More $X$ means more $P^{\prime}$ (increasing $P$ ), as it should. And more $S$ (more sensitivity) means that $P^{\prime}$ is bigger, consistent with the meaning of sensitivity. "
311,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Lab 12,Reinforcement Learning,3,aiii,0.06944444444,Text,"Recall that the hyperparameter epsilon $(\epsilon)$ characterizes a trade-off between exploration and exploitation in reinforcement learning. When we use an "" $\epsilon$-greedy"" strategy in Q learning, we take a completely random action with probability $\epsilon$; and with probability $1-\epsilon$, we take the action that'd lead to the highest $Q$ value, i.e. we take $\arg \max _{a} Q(s, a)$.
We'll explore how choosing the value of epsilon affects the performance of $Q$ learning in a very simple game.
The choice of epsilon can affect the overall behavior of Q-learning. Let's consider three possible values for epsilon: $0.0$, $0.5$, and $1.0$.
Which of these epsilon values is guaranteed to cause optimal behavior during learning?",Multiple Choice,"none: No algorithm can guarantee optimal behavior in training time. The algorithm is oblivious to the true transition and reward functions and it needs to explore to get reward signal and understand the world (eps $>0$ ), but then even if it eventually converged, it would take sub-optimal actions due to the eps $>0$ which was necessary in the first place.","Recall that the hyperparameter epsilon $(\epsilon)$ characterizes a trade-off between exploration and exploitation in reinforcement learning. When we use an "" $\epsilon$-greedy"" strategy in Q learning, we take a completely random action with probability $\epsilon$; and with probability $1-\epsilon$, we take the action that'd lead to the highest $Q$ value, i.e. we take $\arg \max _{a} Q(s, a)$.
We'll explore how choosing the value of epsilon affects the performance of $Q$ learning in a very simple game.
The choice of epsilon can affect the overall behavior of Q-learning. Let's consider three possible values for epsilon: $0.0$, $0.5$, and $1.0$.
Which of these epsilon values risks never finding the optimal policy?",eps=0: No exploration means there is a good chance you will miss the optimal.,"Recall that the hyperparameter epsilon $(\epsilon)$ characterizes a trade-off between exploration and exploitation in reinforcement learning. When we use an "" $\epsilon$-greedy"" strategy in Q learning, we take a completely random action with probability $\epsilon$; and with probability $1-\epsilon$, we take the action that'd lead to the highest $Q$ value, i.e. we take $\arg \max _{a} Q(s, a)$.
We'll explore how choosing the value of epsilon affects the performance of $Q$ learning in a very simple game.
The choice of epsilon can affect the overall behavior of Q-learning. Let's consider three possible values for epsilon: $0.0$, $0.5$, and $1.0$.
Which of these epsilon values has the highest risk of spending way too much time exploring parts of the space that are unlikely to be useful?",eps=1: Completely random exploration means that a lot of time might be spent exploring clearly suboptimal strategies.,"Recall that the hyperparameter epsilon $(\epsilon)$ characterizes a trade-off between exploration and exploitation in reinforcement learning. When we use an "" $\epsilon$-greedy"" strategy in Q learning, we take a completely random action with probability $\epsilon$; and with probability $1-\epsilon$, we take the action that'd lead to the highest $Q$ value, i.e. we take $\arg \max _{a} Q(s, a)$.
We'll explore how choosing the value of epsilon affects the performance of $Q$ learning in a very simple game.
For this part, you will use a Colab notebook we have prepared for you. You can find the Colab notebook here.
Once you run the code, wait patiently until you see a yellow and purple square on a teal background (you may need to scroll down from the ""score"" and ""reward"" text lines printed out). Ignore everything else for now. Click play in the button right below the square. This is a movie of a policy playing the game No Exit. It's kind of like Pong: the purple square is the ""ball"" and the yellow square is your ""paddle"". The actions are to move the paddle up, down, or keep it still.
The state is specified by the positions and velocities of the ball and paddle, with a special added ""game over"" state.
The transition model is a very approximate physics model of the ball reflecting off walls and the paddle, except if the ball gets past the paddle in the positive $x$ direction, the game is over.
The agent gets a reward of $+1$ on every step it manages to survive.
When watching the game play out, you'll sometimes see that the purple square gets near the right-hand border and then suddenly it changes to a state with the purple square in the bottom left and the yellow one in the upper right $--$ this means that the game terminated and then reset to the initial state.
Now we can go back and look at the other output in the notebook:
\begin{itemize}
\item First, we print what happens during learning in the format (number of iterations, average score): after every 10 iterations of batch Q learning, we take the current greedy policy and run it to see what its average score is. This score represents how long the episode ran before the ball ran off the map, or 100 if it lasted for that long.
\item Next is a plot of the score as a function of number of iterations.
\item Finally, we run the greedy policy with respect to the last Q-value function for 10 games and report the rewards achieved on each game. We also show a movie clip from a handful of these 10 games.
\end{itemize}
Run the code given on the notebook for values of $\epsilon$ in the set $0,0.5,1$. Does your observation match your answers from $3.1$?
Remember that this is a small instance, so sometimes the random noise of the environment might prevent you from seeing any useful information. Run the notebook two or three times if something doesn't line up with your expectation, and then ask for help.","For part (b), ask to see their plots, and whether that match up with their answers. Take time to explain anything that might make the plots not match.
It appears that the model with epsilon $=0$ case performs poorly, and the epsilon $=0.5$ and epsilon $=1$ models perform better. There is randomness here, so student results may vary. Have them try to explain why they got the results that they did."
13,Mathematics,18.2,Principles of Discrete Applied Mathematics,None,18.C06,Problem Set 3,Bijection,2,b,0.7638888889,Text,"In the notes on counting in canvas, Section $4.2$ describes a map $\Psi$ that takes a binary tree $B$ with $n$ nodes (remember these are those vertices with 2 children, as opposed to leaves who have no children) and maps it to a lattice path.
Furthermore prove that $\Psi$ is a bijection between $\mathcal{B}_{n}$ and $\mathcal{D}_{n}$.",Open,"To show that $\Psi$ is a bijection, we construct an inverse $\Phi$, so that given a Dyck path $D$, we construct a binary tree $B=\Phi(D)$ such that $\Psi(B)=D$. Since the first step of $D$ is an upwards step, we add a vertex to $B$ and place ourselves on that vertex. We now go step-by-step through $D$ to generate $B$. At each step, we will be growing a 2-tree in such a way that any vertex with a single child must be an ancestor of the vertex we are on. If we are at an upwards step, if the vertex we are on has less than two children, we add a child and move to the new vertex. If the vertex has two children, we move up the tree until we are at an ancestor vertex with less than two children, then add a child and move to the new vertex. (We show later that this is always possible.) This new vertex will become a node of $B$, and it will be a node of the generated tree after the next step. If we are at a downwards step and the current vertex has less than two children, we add a child but stay on the current vertex. This new vertex will become a leaf of $B$. If there are two children, then like before we move up until we are at a vertex $v$ with less than two children, and add a child while staying at $v$. Each of these procedures preserves the fact the generated tree is a 2-tree and that all vertices with a single child are ancestors of the current vertex.
We now show that when needed, we can always find an ancestor with only one child. Let $T$ be the tree we have generated so far, and suppose we need to check the ancestors for a place to add a vertex, and no ancestor has space. This implies that every node has zero or two children, and so $T$ is a binary tree. Then $n(T)=l(T)-1$ by the lemma. The previous step of the Dyck path must have produced a leaf, since otherwise there would have been space at the current vertex. This means that, by this point, every vertex produced with an upwards path has at least one child. Thus, every node of $T$ corresponds to an upwards path, and every leaf corresponds to a downwards path. If $k$ is the number of upwards paths so far and $m$ is the number of downwards paths so far, then $k=n(T)=l(T)-1=m-1$. Then $k<m$, which contradicts the fact that $D$ is a Dyck path. Thus, we can never reach this state and we can always find an ancestor with one child when necessary.
After the last step of the Dyck path, we will have just added a new leaf vertex, so if $G$ is the tree generated so far, then $l(G)=n$ and $n(G)=n$. Then from the lemma, $G$ is not yet a binary tree, and either the current node has space or one of its ancestors does. We add a leaf to this node, and call this tree $B$. We have $l(B)=l(G)+1$, so $l(B)-1=n(G)=n(B)$, which makes $B$ a binary tree.
The route that we added vertices is exactly the same route we would take when doing a depth-first search, so $\Psi(\Phi(D))=\Psi(B)=D$. Conversely, we have $\Phi(\Psi(B))=B$ for all binary trees $B$. Thus, $\Phi$ and $\Psi$ are inverses and we get that these maps are bijections.","In the notes on counting in canvas, Section $4.2$ describes a map $\Psi$ that takes a binary tree $B$ with $n$ nodes (remember these are those vertices with 2 children, as opposed to leaves who have no children) and maps it to a lattice path.
Prove that $\Psi(B)$ is a Dyck path with $2 n$ steps.","We define a 2-tree to be a plane tree where each vertex has at most 2 children. Similar to the definition of the binary tree, each vertex with at least one child is called a node, and each vertex with no children is called a leaf. In order to relate binary trees to Dyck paths, we first prove the following lemma to relate the number of leaves to the number of nodes.
Lemma 1. Let $T$ be a 2-tree, and let $l(T)$ be the number of leaves, $n(T)$ be the number of nodes. Then $n(T) \geq l(T)-1$, with equality if and only if $T$ is a binary tree.
Proof. We prove this by induction on the number of vertices. If $T$ is the trivial tree with only one vertex, then $l(T)=1$ and $n(T)=0$, so we get the statement. Now suppose we have proved the statement for all trees with at most $k$ vertices, and $T$ has $k+1$ vertices. Let $v \in T$ be a leaf of maximum depth. Then it has a parent node $w$ and at most one other sibling $v^{\prime}$. If we remove both $v$ and $v^{\prime}$ (if $v^{\prime}$ exists) to get a new tree $T^{\prime}$, then $w$ will become a leaf node. If $v^{\prime}$ exists, then $l\left(T^{\prime}\right)=l(T)-1$ and $n\left(T^{\prime}\right)=n(T)-1$, and if $v^{\prime}$ does not exist, then $l\left(T^{\prime}\right)=l(T)$ and $n\left(T^{\prime}\right)=n(T)-1$. Since $n\left(T^{\prime}\right) \geq l\left(T^{\prime}\right)-1$ by induction, we know that
$$
n(T)=n\left(T^{\prime}\right)+1 \geq l\left(T^{\prime}\right) \geq l(T)-1 .
$$
Equality only holds if $v^{\prime}$ exists and $n\left(T^{\prime}\right)=l\left(T^{\prime}\right)-1$, which only holds if $T^{\prime}$ is a binary tree. This implies that we have equality if and only if $T$ is a binary tree, as desired. Now suppose we are given a binary tree $G$. In order for $\Psi(G)$ to be a Dyck path, we need to show that as we traverse $G$ using a depth-first search, the number of leaves encountered does not exceed the number of nodes encountered until we reach the last vertex in the search. Let $T$ be a subtree of $G$ consisting of all nodes traversed at some point in the depth-first search. Note that $T$ is a 2 -tree and each node of $T$ must be a node of $G$. Then $n(T) \geq l(T)-1$ with equality only if $T$ is a binary tree. If $T$ is not a binary tree, then the number of nodes encountered at this point in the search must exceed $n(T)$ and the number of leaves encountered is at most $l(T)$, so the number of encountered leaves does not exceed the number of nodes. If $T$ is a binary tree and $T \neq G$, then one of the leaves of $T$ must be a node of $G$ (in particular, the parent of the next vertex encountered in the search). Then the number of leaves encountered is at most $l(T)-1$ and we are still fine. This shows that the number of leaves encountered does not exceed the number of nodes encountered until the last vertex, so $\Psi(G)$ is a Dyck path.","The set of $n \times n$ matrices can be identified with the space $\mathbb{R}^{n \times n}$. Let $G$ be a subgroup of $G L_n(\mathbb{R})$. With the notation of the previous problem, prove:
If $A, B, C, D$ are in $G$, and if there are paths in $G$ from $A$ to $B$ and from $C$ to $D$, then there is a path in $G$ from $A C$ to $B D$.","If $X(t)$ is a path from $A$ to $B$ in $G L_{n}$ and $Y(t)$ is a path from $C$ to $D$, then the matrix product $X(t) Y(t)$ defines a path from $A B$ to $C D$. It is continuous because matrix multiplication is continuous.",Prove that $D_{2 n}$ has exactly 4 one-dimensional complex representations if $n$ is even and exactly 2 one-dimensional representations if $n$ is odd.,"Let $G$ be the group formed by the set of commutators of $D_{2 n}$. We know that the number of distinct linear characters (and thus the number of non-isomorphic one-dimensional representations) is the order of the quotient group $D_{2 n} / G$, so it is enough to identify $G$. Write $D_{2 n}=\left\{a, b: a^{n}=1, b^{2}=1, b a^{i}=a^{-i} b\right\}$. Then the commutators
$$
\begin{aligned}
{\left[a^{i} b, a^{j} b\right] } & =\left(a^{i} b\right)^{-1}\left(a^{j} b\right)^{-1} a^{i} b a^{j} b=b a^{-i} b a^{-j} a^{i-j}=a^{2(i-j)}, \\
{\left[a^{i} b, a^{j}\right] } & =b a^{-i} a^{-j} a^{i} b a^{j}=b a^{-2 j} b=a^{2 j} \\
{\left[a^{i}, a^{j} b\right] } & =a^{-i} b a^{-j} a^{i} a^{j} b=a^{-2 i} \\
{\left[a^{i}, a^{j}\right] } & =1
\end{aligned}
$$
Therefore the derived subgroup of $D_{2 n}$ is the cyclic group $G=\left\langle a^{2}\right\rangle$. If $n$ is odd, $\left\langle a^{2}\right\rangle=\langle a\rangle$ and $D_{2 n} / G$ is isomorphic to $\langle b\rangle$ which has order 2. If $n$ is even, we have four cosets: $G, G a, G b$, and $G a b$. Thus $D_{2 n}$ has 4 1D representations for $n$ even and 2 1D representations for $n$ odd. $\diamond$."
50,Mathematics,18.100B,Real Analysis,18.02,None,Midterm Exam 1,Metric Spaces,3,nan,5,Text,"Let $K$ be a non-empty compact set in a metric space $X$ and suppose $p \in$ $X \backslash K$. Show that there exists a point $q \in K$ such that
$$
d(p, q)=\inf \{d(p, x) ; x \in K\}
$$",Open,"The set $\{d(p, x) ; x \in K\}$ is a non-empty subset of $(0, \infty)$ so the infimum exists and there is a sequence $x_{n} \in K$ such that $d\left(p, x_{n}\right) \rightarrow$ $D=\inf \{d(p, x) ; x \in K\}$. Now, as a sequence in a compact set, $\left\{x_{n}\right\}$ has a convergent subsequence. Since $d\left(p, x_{n_{k}}\right)$ also converges to $D$, we may just assume that $x_{n} \rightarrow q$ in $X$. Since compact sets are closed, $q \in K$ and we just need to check that $d(p, q)=D$. By the definition of infimum and the convergence of the distance, give $\epsilon>0$ there exists $n$ such that 
$$
\begin{array}{r}
\left|d\left(x, x_{n}\right)-D\right|<\epsilon / 2 \text { and } d\left(x_{n}, q\right)<\epsilon / 2 \text { but this implies that } \\
|d(p, q)-D|<\left|d(p, q)-d\left(p, x_{n}\right)\right|+\left|d\left(p, x_{n}\right)-D\right|<\epsilon
\end{array}
$$
for any $\epsilon>0$. Thus $d(p, q)=D$ as desired and the infimum of the distance is attained.
Here is a direct approach that a couple of people used. Set $D=$ $\inf \{d(p, x) ; x \in K\}$ and suppose that this is not attained on $K$, so for all $x \in K, d(p, x)>D$. Thus
$$
K \subset \bigcup_{x \in K} B\left(x, \frac{1}{2}(d(p, x)-D)\right)
$$
is an open cover, which therefore has a finite subcover since $K$ is compact. Let $x_{i}, i=1, \ldots, N$ be the centers of such a cover with $\epsilon_{i}=\frac{1}{2}\left(d\left(p, x_{i}\right)-D\right)$ and $\epsilon=\min _{i} \epsilon_{i}>0$. Then, each $x \in K$ is in one of these balls, so from the triangle inequality, for the appropriate $i$,
$$
d(p, x) \geq d\left(p, x_{i}\right)-\epsilon_{i} \geq D+\epsilon_{i} \geq D+\epsilon .
$$
This however shows that $D$ is not the infimum as it is defined to be, so there must be a point $q \in K$ with $d(p, q)=D$.
There is an even simpler direct approach used by several people. Suppose that $d(p, x)>r=\inf \{d(y, p) ; y \in K\}$ for all $x \in K$. Then the open sets
$$
G(n)=\{x \in K ; d(x, p)>r+1 / n\}
$$
form an open cover of $K$ which therefore must have a finite subcover by compactness. Since the $G(n)$ increase with $n, K \subset G(N)$ for some $N$ and hence $d(x, p)>r+1 / N$ for all $x \in K$, contradicting the definition of the infimum.
Another variant of this is to define $r=\inf \{d(x, p) ; x \in K\}$ and then to set
$$
K(n)=K \cap\{x \in X ; d(x, p) \leq r+1 / n\} .
$$
Since the second sets are closed, these are compact sets, being closed subsets of $K$, which are non-empty, by the definition of infimum, and decreasing as $n$ increases. Thus, by a theorem in Rudin, $T=\cap_{n} K(n) \neq \emptyset$. If $q \in T \subset K$ then $d(p, q)=r$ since $d(p, q) \leq r+1 / n$ for all $n$ and $d(p, q) \geq r$.","Suppose that $X$ is a metric in which $d(x, y)$ is always a (nonnegative) integer. Show that $X$ is complete.","Set $\epsilon=1$ in the Cauchy property. There is an $N$ such that $d\left(x_{n}, x_{m}\right)<1$ for $m, n \geq N$. By assumption, this means that $d\left(x_{n}, x_{m}\right)=0$, so $x_{n}=x_{m}$, meaning that the sequence is eventually constant, $x_{n}=x$ for $n \geq N$. It is clear from the definition that $x_{n}$ converges to $x$.","Suppose $E \subset \mathbb{R}$ has the property that for every non-empty $B \subset E$ which is bounded, $\sup B$ and $\inf B$ are in $E$. Show that $E$ is closed with respect to the standard metric.","By a theorem in Rudin, any limit point of a set in a metric space is the limit of a sequence, the sequence in the set, $E$, the limit in the metric space. Thus if $x \in E^{\prime}$ is a limit point of $E$ then there is a sequence $x_{n} \in E$ with $x_{n} \rightarrow x$ in $\mathbb{R}$. Consider all $n \in \mathbb{N}$ such that $x_{n} \leq x$. If this is infinite, then there is a subsequence $x_{n_{j}}$ with $x_{n_{j}} \leq x$. If not then there is a subsequence $x_{n_{j}}$ with $x_{n_{j}}>x$. In either case, $x_{n_{j}} \rightarrow x$ so we can change notation and just assume that either $x_{n} \leq x$ or $x_{n}>x$ for all $n$. Let $B \subset E$ be the range of this sequence, this set is bounded, since any convergent sequence is bounded. Moreover in the first case $\sup B=x$ and in the second $\inf B=x$, since other wise the sequence could not converge to $x$. Thus $x \in E$ and hence $E^{\prime} \subset E$ and $E$ is necessarily closed.
Of course there are many variants of this. One can certainly avoid using sequences. For instance, suppose $x \in E^{\prime}$ but $x \notin E$. Then the sets $B(x, 1 / n) \cap E$ are all infinite, for $n \in \mathbb{N}$. Consider $(x, 1 / n) \cap E$; either this is infinite for all $n$ or else it is empty for large $n$, in which case $(x-1 / n, x) \cap E$ must be infinite for all $n$. So, we can choose either $x_{n} \in(x, x+1 / n)$ for all $n$ or $x_{n} \in(x-1 / n, x)$ for all $n$. Let $B$ be the subset of $E$ consisting of these choices, then $x=\inf B$ in the first case and $x=\sup B$ in the second case, and in both cases $B$ is bounded. Thus in fact $x \in E$ by the assumption, contradicting the assumption that $x \notin E$. Thus $E$ is closed.
I rather like the following proof from Yunjian Xu which neatly avoids the division into two pieces: Let $p$ be a limit point of $E$. Then for every $n \in \mathbb{N}$, $D_{n}=B(p, 1 / n) \cap E$ is a bounded, infinite subset of $E$, so by assumption $q_{n}=\sup D_{n} \in E$. This sequence is bounded since it lies in $B(p, 1)$; let $B$ be its range. This is again a bounded nonempty subset of $E$ and we claim $p=\inf B$, so $p \in E$. Indeed $q_{n}$ is a non-increasing (the sets are getting smaller) sequence which is bounded below so it converges to the infimum of its range, but since $\left|q_{n}-p\right| \leq 1 / n$ the limit must be $p$.
Main shortcomings: Not making sure that $x$ was the sup or inf of a chosen subset. Minor problems included assuming that just because $(x-1, x) \cap E$ was infinite then $x$ has to be the supremum $-E \cap(x-1, x) \subset\left(x-1, x-\frac{1}{2}\right)$ is a possibility (but then of course $x=\inf (x, x+1) \cap E)$.","Let $X$ be a metric space which is totally bounded. Show that there is a countable subset $B \subset X$ such that, for every point $l \in X$, there is a sequence in $B$ which converges to $l$.","For each $n \geq 1$, set $\varepsilon=\frac{1}{n}$. Since $X$ is totally bounded, there exists a finite set $F_{n}$ such that for each $x \in X$, there is a $y \in F_{n}$ with $d(x, y)<\varepsilon$. Let $B=\bigcup_{n \geq 1} F_{n}$. Since $B$ is a countable union of finite sets, it is countable.
Let $l \in X$ be given. For each $n \in \mathbb{N}$, let $x_{n}$ be a point in $F_{n}$ such that $d\left(x_{n}, k\right)<\frac{1}{n}$. Then $\left(x_{n}\right)$ is a sequence in $B$ converging to $l$."
5,Mathematics,18.100B,Real Analysis,18.02,None,Problem Set 1,Axioms of Arithmetic,6,nan,1.071428571,Text,"Show that the axioms of arithmetic and the axioms of ordering imply the following: if $x>y$, then $x^{3}>y^{3}$. [Besides the axioms, you can use any theorem proved in the first two lectures. If you feel underwhelmed by this pset, you can try to also prove the converse implication to this problem; however, no credit will be awarded for it.]",Open,"We need to show that if $x-y \in P$, then $x^{3}-y^{3} \in P$. Write
$$
2\left(x^{3}-y^{3}\right)=(x-y)\left(2 x^{2}+2 x y+2 y^{2}\right)=(x-y)\left(x^{2}+y^{2}+(x+y)^{2}\right).
$$
The three squares $x^{2}, y^{2}$, and $(x+y)^{2}$ are either zero or in $P$ (theorem from the class: the square of any nonzero element lies in $P$ ). Moreover, since $x \neq y$ by assumption, at least one of the squares $x^{2}, y^{2}$ must be in $P$ (same theorem). It follows that $x^{2}+y^{2}+(x+y)^{2} \in P$. We now know, from the equation above and the assumption that $x-y \in P$, that $2\left(x^{3}-y^{3}\right) \in P$. If $x^{3}-y^{3}$ were not in $P$, it would either have to be zero, or $-\left(x^{3}-y^{3}\right)$ would have to be in $P$ (trichotomy), and then $2\left(x^{3}-y^{3}\right)$ would inherit the same properties, which is a contradiction. Hence, $x^{3}-y^{3}$ must be in $P$.
Now, the solution above definitely qualifies as sneaky (the much-hated ""pull a formula out of a hat"" trick). A more reasonable alternative (only sketched here) would be to first show the following Lemma: if $a$ is positive, and $b>c$, then $a b>a c$. (This follows directly from the axioms, all we're saying is that if $a \in P$ and $b-c \in P$, then $a b-a c=a(b-c) \in P$.). Using that, one can show the desired inequality if both $x$ and $y$ are positive:
$$
x^{3}=\left(x^{2}\right) x>\left(x^{2}\right) y=(x y) x>(x y) y=\left(y^{2}\right) x>\left(y^{2}\right) y=y^{3}.
$$
What about all the other situations? If both $x$ and $y$ are negative and satisfy $x>y$, then $(-x)$ and $(-y)$ are both positive, and $-x<-y$ (one can easily check that by reducing both properties to $x-y \in P$ ). The previous case tells us that $(-x)^{3}<(-y)^{3}$, but (using the fact that $(-a) \cdot(-b)=a b$ from the lecture) one sees easily that $-x^{3}=(-x)^{3}$ and $-y^{3}=(-y)^{3}$, so we now know that $-x^{3}<-y^{3}$, which (as before) yields $x^{3}>y^{3}$. There are still more cases, namely when one of the two numbers is zero, or when $x$ is positive and $y$ is negative; but those can be dealt with case-by-case quite easily.","Continuing the previous problem, suppose that our originally given numbers had a subset $P$ which satisfies the axioms of ordering (with respect to $+$ and $\cdot$ ). Is there a subset which does the same for our new $+$, . . operations? [Note that the axiom of completeness is not part of the axioms of ordering.]","We use $P=-P=\{-x \quad: \quad x \in P\}$ as subset of positive numbers for our new operations. Trichotomy for this $P$ says that for each $x$, either $x=0$, or $-x \in P$, or $-(-x) \in P$. But $-(-x)=x$, because both those numbers are the additive inverse of $-x$, and additive inverses are unique. So this statement is the same as trichotomy for $P$, which we know.
Suppose $x, y \in P$, so $-x \in P$ and $-y \in P$. Now $(-x)+(-y)$ is the additive inverse of $x+y$, because $(-x)+(-y)+x+y=((-x)+x)+((-y)+y)=0+0=0$. Therefore, it follows from the axioms of ordering for $P$ that $(-x)+(-y)=-(x+y) \in P$, which shows that $x+y \in P$.
Suppose $x, y \in P$, so $-x \in P$ and $-y \in P$. The statement that $x \cdot y \in P$ means that $-(-(x \cdot y)) \in P$, or equivalently (by what I've observed above) that $x \cdot y \in P$. But we know that to be true, because (as proved in lecture) $x \cdot y=(-x) \cdot(-y)$, where the right hand side lies in $P$ because of the axiom of ordering for $\cdot$.","Suppose that we have any notion of number, satisfying the axioms of arithmetic. Let's change the operations as follows: we keep addition, $x+y=x+y$, but change multiplication to $x \cdot y=-(x \cdot y)$, where $-(\cdots)$ is the additive inverse for the old operation $+$. Do our new operations satisfy the axioms of arithmetic? Explain your answer.","During these computations, we will use $-(a \cdot b)=(-a) \cdot b=a \cdot(-b)$ many times. (Axiomatically, this follows from the distributive axiom, which shows that $(-a) \cdot b$ is an additive inverse to $a \cdot b$.)
Addition did not change, so we don't have to check any of its properties.
When we spell out axioms for $\cdot \cdot$ in terms of the old operations, we get:
$$
\begin{array}{ll}
-(x \cdot y)=-(y \cdot x) & \text { commutativity } \\
-(x \cdot(-(y \cdot z)))=-((-(x \cdot y)) \cdot z) & \text { associativity } \\
-(x \cdot(y+z))=(-(x \cdot y))+(-(x \cdot z)) & \text { distributivity. }
\end{array}
$$
The first line, commutativity, is obviously true. For the second line, we see that (using the fact mentioned at the beginning $)-(x \cdot(-(y \cdot z)))=x \cdot y \cdot z$, and the same applies to $-((-(x \cdot y)) \cdot z)$. Distributivity uses the same strategy, $-(x \cdot(y+z))=(-x) \cdot(y+z)=(-x) \cdot y+(-x) \cdot z=$ $(-(x \cdot y))+(-(x \cdot z))$
The final step is multiplicative neutral element and inverses. One has $-((-1) \cdot x)=1 \cdot x=x$, so $(-1)$ is a multiplicative neutral element for $\cdot \cdot$. One also has $-\left(\left(-x^{-1}\right) \cdot x\right)=x^{-1} \cdot x=1$, so $-x^{-1}$ is a multiplicative inverse with respect to $\cdot$.","Prove that the commutativity and associativity axioms for addition, together with the axiom of the existence of a neutral element for addition, imply that each $x$ can have at most one additive inverse. [This is Lemma 1.2 from the class summaries; obviously, you can't use either that Lemma, or anything that came after that. Argue strictly axiomatically.]","Suppose that $y$ and $z$ are both additive inverses of $x$, so $x+y=0$ and $x+z=0$. Then,
$$
y=y+0=y+(x+z).
$$
Here, we have used the defining property of the neutral element 0 , as well as the fact that $z$ is an inverse of $x$. Now we use associativity and commutativity:
$$
y+(x+z)=(y+x)+z=(x+y)+z .
$$
Now we use that $y$ is an inverse, and the defining property of the neutral element 0:
$$
(x+y)+z=0+z=z .
$$
Taking all that together, we have shown that $y=z$: any two additive inverses of $x$ must be equal, so there is at most one."
12,Mathematics,18.6,Probability and Random Variables,18.02,None,Problem Set 1,Counting,7,d,0.1,Text,In how many ways can 8 people be seated in a row if there are 5 men and they must sit next to each other?,Numerical,"If there are 5 men and they must sit next to each other, then there are $5! \cdot 4! = 2,880$ possible seating arrangements because the 5 men can be bundled together and permuted with the remaining 3 people.",In how many ways can 8 people be seated in a row if there are 4 men and 4 women and no 2 men or 2 women can sit next to each other?,"If there are 4 men and 4 women and no 2 men or 2 women can sit next to each other, then there are $4! \cdot 4! \cdot 2! = 1,152$ possible seating arrangements because there are $4!$ possible permutations of the men, $4!$ possible permutations of the women, and $2!$ possible permutations of their positioning.",In how many ways can 8 people be seated in a row if there are 4 married couples and each couple must sit together?,"If there are 4 married couples and each couple must sit together, then there are $4! \cdot (2!)^4 = 384$ possible seating arrangements because there are $4!$ possible permutations of the couples and $2!$ possible permutations of the couples among themselves.",In how many ways can 8 people be seated in a row if there are no restrictions on the seating arrangement?,"If there are no restrictions, then there are $8! = 40, 320$ possible seating arrangements."
143,EECS,18.C06,Linear Algebra and Optimization,18.02,None,Midterm Exam 1,Projection Matrix,6,a,0.9375,Text,"Consider two $n \times n$ projection matrices
$$
P=I-v_{1} v_{1}^{\top} \quad \text { and } \quad Q=I-v_{2} v_{2}^{\top}
$$
where $v_{1}$ and $v_{2}$ have unit norm and are orthogonal to each other. Let $A=P Q$.
What is the dimension of $N(A)$? Find an orthonormal basis for $N(A)$.
Hint: You can find vectors in $N(A)$, but to show a vector is not in $N(A)$ you may want to use an orthogonal decomposition.",Expression,"The dimension of $N(A)$ is two and $\left\{v_{1}, v_{2}\right\}$ forms an orthonormal basis. It is easy to see that $A v_{i}=0$. Moreover for any vector $v$ we can form an orthogonal decomposition $v=u+w$ where $u$ is in the span of $v_{1}$ and $v_{2}$ and $w$ is in the orthogonal complement. Then $A v=u$ and so if $v$ is not in the span of $v_{1}$ and $v_{2}$ it is not in the nullspace. ","Consider two $n \times n$ projection matrices
$$
P=I-v_{1} v_{1}^{\top} \quad \text { and } \quad Q=I-v_{2} v_{2}^{\top}
$$
where $v_{1}$ and $v_{2}$ have unit norm and are orthogonal to each other. Let $A=P Q$.
What is the rank of $A$?","By the rank-nullity theorem, we have that
$$
\operatorname{rank}(A)+\operatorname{dim} N(A)=n .
$$
By the previous item, $\operatorname{dim} N(A)=2$, and thus the rank of $A$ is $n-2$.","Consider two $n \times n$ projection matrices
$$
P=I-v_{1} v_{1}^{\top} \quad \text { and } \quad Q=I-v_{2} v_{2}^{\top}
$$
where $v_{1}$ and $v_{2}$ have unit norm and are orthogonal to each other. Let $A=P Q$.
Is $A$ a projection matrix?","Yes. We can write out
$$
A=\left(I-v_{1} v_{1}^{\top}\right)\left(I-v_{2} v_{2}^{\top}\right)=I-v_{1} v_{1}^{\top}-v_{2} v_{2}^{\top},
$$
so this is the projection onto the orthogonal complement of $\operatorname{span}\left\{v_{1}, v_{2}\right\}$. We can also verify that $A^{2}=A$. ","Consider the following matrix.
$$
A=\left[\begin{array}{ccccc}
0 & 2 & 4 & 5 & 6 \\
0 & 1 & 2 & 5 & 8 \\
0 & 0 & 0 & -3 & -6
\end{array}\right].
$$
Give a basis for $N(A)$, and also state the dimension of $N(A)$.","The null-space has dimension 3, and is
$$
N(A)=\operatorname{span}\left\{\left[\begin{array}{l}
1 \\
0 \\
0 \\
0 \\
0
\end{array}\right],\left[\begin{array}{c}
0 \\
2 \\
0 \\
-2 \\
1
\end{array}\right],\left[\begin{array}{c}
0 \\
-2 \\
1 \\
0 \\
0
\end{array}\right]\right\}
$$
Notice that this is consistent with the rank-nullity theorem, since
$$
\operatorname{dim} C(A)+\operatorname{dim} N(A)=2+3=5=\operatorname{dim} \mathbb{R}^{5}.
$$"
38,Mathematics,18.701,Algebra I,18.100B,None,Problem Set 5,Orthogonal Matrices and Rotations,3,a,0.25,Text,"Let $A$ be a $3 \times 3$ orthogonal matrix with det $A=1$, whose angle of rotation is different from 0 or $\pi$, and let $M=A-A^t$.
Show that $M$ has rank 2, and that a nonzero vector $X$ in the nullspace of $M$ is an eigenvector of $A$ with eigenvalue 1.",Open,"Let $A$ be a rotation matrix, an element of $S O_{3}$. If a vector $X$ is fixed by $A$, it is also fixed by its inverse $A^{-1}=A^{t}$, and therefore $M X=\left(A-A^{t}\right) X=0$. The rank of $M$ is less than 3 . Conversely, if $M X=0$, then $A X=A^{-1} X$. When the angle of rotation isn't 0 or $\pi$, this happens only for vectors $X$ in the axis of rotation, so the $\operatorname{rank}$ of $M$ is 2.","Let $A$ be a $3 \times 3$ orthogonal matrix with det $A=1$, whose angle of rotation is different from 0 or $\pi$, and let $M=A-A^t$.
Find such an eigenvector explicitly in terms of the entries of the matrix $A$.","A fixed vector can be found by solving the equation $M X=0$, and this isn't difficult. The result is this: Let $u=a_{12}-a_{21}, v=a_{13}-a_{31}$, and $w=a_{23}-a_{32}$. Then
$$
M=\left(\begin{array}{ccc}
0 & u & v \\
-u & 0 & w \\
-v & -w & 0
\end{array}\right)
$$
and $(w,-v, u)^{t}$ is in the nullspace of $M$ and is a fixed vector of $A$.","One of the black boxes we used in class was the theorem that an $n \times n$ matrix $A$ has $A \vec{v}=0$ for some non-zero vector $\vec{v} \in \mathbb{R}^{n}\left(\right.$ or $\mathbb{C}^{n}$ ) if and only if $\operatorname{det}(A)=0$ (see, e.g., MITx 20.7). The goal of this problem is to work out $w h y$ this is true (at least in the case of $3 \times 3$ matrices). The only blackbox we will use is the properties of the determinant. Recall that $\operatorname{dim} \operatorname{Ker}(A)=0$ means that $\operatorname{Ker}(A)$ contains only the zero vector.
(Story time begins) The way we are going to go about showing that a $3 \times 3$ matrix has $\operatorname{det} A=0$ if and only if $\operatorname{dim} \operatorname{Ker}(A)>0$ is by using Gaussian elimination to reduce the statement to the case of upper triangular (or rather, RREF) matrices. So, as a first step, we're going to check that the theorem is true for this model case. (Story time ends)
Suppose $A$ is a $3 \times 3$ matrix which is upper triangular; that is
$$
A=\left(\begin{array}{ccc}
p_{1} & a & b \\
0 & p_{2} & c \\
0 & 0 & p_{3}
\end{array}\right) \text {. }
$$
Show that $\operatorname{det} A=p_{1} p_{2} p_{3}$. In particular, $\operatorname{det}(A)=0$ if and only if at least one of $p_{1}, p_{2}, p_{3}$ is 0.","Using the Laplace expansion, the only non-zero term is $p_{1} \cdot\left|\left(\begin{array}{cc}p_{2} & c \\ 0 & p_{3}\end{array}\right)\right|=$ $p_{1} p_{2} p_{3}$. Or you may use the fact that eigenvalues are $p_{1}, p_{2}, p_{3}$ and the determinant is the product of them. ",There is a $3 \times 3$ real matrix $A$ so that $A^{2}=-I$. Hint: Think about determinants.,False. Suppose there is such an $A$. Then $\operatorname{det}\left(A^{2}\right)=\operatorname{det}(A)^{2}>0$. But $\operatorname{det}(-I)=(-1)^{3}=-1$. Thus we reach a contradiction and there can be no such $A$.
68,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Prelab Questions 7,Ideal Cache Behavior,2,d,0.012,Text,"We will be using the following program to examine our cache behavior. Let N = 16 be the size of data region, in words. Let A be an array of N elements, located initially at 0x240. Note that these values are hardcoded into the program below but we will be changing them later.
// A = 0x240, starting address of array
// N = 16, size of data region
// this program adds 16 words from array A, then repeats.
. = 0x200
test:
li a0, 16 // initialize loop index i
li a1, 0 // sum = 0
loop: // add up elements in array
addi a0, a0, -1 // decrement index
slli a2, a0, 2 // convert to index byte offset
lw a3, 0x240(a2) // load value of A[i]
add a1, a1, a3 // add to sum
bnez a0, loop // loop until all words are summed
j test // perform test again!
// Array
. = 0x240
.word ... // A[0]
.word ... // A[1]
...
.word ... // A[15]
Our cache has a total of 64 words. The initial configuration is direct mapped, with 1 word per line, so the cache has 64 lines numbered 0-63 (0x00 - 0x3F).
To achieve 100% steady state hit ratio, it must be the case that the instructions and array data can reside in the cache at the same time. Let's check if this is currently the case.
Which cache line (index) does the last data element, A[15], map to? Provide your answer in hexadecimal.",Numerical,"0x1F.
The address of the last data element, A[15], is 0x27C = 0b_0010_0111_1100. Bits[7:2] are the index bits = 0b011111 = 0x1F (or line 31).","We will be using the following program to examine our cache behavior. Let N = 16 be the size of data region, in words. Let A be an array of N elements, located initially at 0x240. Note that these values are hardcoded into the program below but we will be changing them later.
// A = 0x240, starting address of array
// N = 16, size of data region
// this program adds 16 words from array A, then repeats.
. = 0x200
test:
li a0, 16 // initialize loop index i
li a1, 0 // sum = 0
loop: // add up elements in array
addi a0, a0, -1 // decrement index
slli a2, a0, 2 // convert to index byte offset
lw a3, 0x240(a2) // load value of A[i]
add a1, a1, a3 // add to sum
bnez a0, loop // loop until all words are summed
j test // perform test again!
// Array
. = 0x240
.word ... // A[0]
.word ... // A[1]
...
.word ... // A[15]
Our cache has a total of 64 words. The initial configuration is direct mapped, with 1 word per line, so the cache has 64 lines numbered 0-63 (0x00 - 0x3F).
To achieve 100% steady state hit ratio, it must be the case that the instructions and array data can reside in the cache at the same time. Let's check if this is currently the case.
Which cache line (index) does A[0] map to? Provide your answer in hexadecimal.","0x10.
The address of A[0] is 0x240 = 0b_0010_0100_0000. The bottom two bits are used for word alignment. Bits[7:2] are the index bits = 0b010000 = 0x10. So A[0] maps to index 0x10 (or line 16).","We will be using the following program to examine our cache behavior. Let N = 16 be the size of data region, in words. Let A be an array of N elements, located initially at 0x240. Note that these values are hardcoded into the program below but we will be changing them later.
// A = 0x240, starting address of array
// N = 16, size of data region
// this program adds 16 words from array A, then repeats.
. = 0x200
test:
li a0, 16 // initialize loop index i
li a1, 0 // sum = 0
loop: // add up elements in array
addi a0, a0, -1 // decrement index
slli a2, a0, 2 // convert to index byte offset
lw a3, 0x240(a2) // load value of A[i]
add a1, a1, a3 // add to sum
bnez a0, loop // loop until all words are summed
j test // perform test again!
// Array
. = 0x240
.word ... // A[0]
.word ... // A[1]
...
.word ... // A[15]
Our cache has a total of 64 words. The initial configuration is direct mapped, with 1 word per line, so the cache has 64 lines numbered 0-63 (0x00 - 0x3F).
To achieve 100% steady state hit ratio, it must be the case that the instructions and array data can reside in the cache at the same time. Let's check if this is currently the case.
Which cache line (index) does the last instruction j test map to? Provide your answer in hexadecimal.","0x7.
The address of the last instruction is 0x21C = 0b_0010_0001_1100. Bits[7:2] are the index bits = 0b000111 = 0x7.","We will be using the following program to examine our cache behavior. Let N = 16 be the size of data region, in words. Let A be an array of N elements, located initially at 0x240. Note that these values are hardcoded into the program below but we will be changing them later.
// A = 0x240, starting address of array
// N = 16, size of data region
// this program adds 16 words from array A, then repeats.
. = 0x200
test:
li a0, 16 // initialize loop index i
li a1, 0 // sum = 0
loop: // add up elements in array
addi a0, a0, -1 // decrement index
slli a2, a0, 2 // convert to index byte offset
lw a3, 0x240(a2) // load value of A[i]
add a1, a1, a3 // add to sum
bnez a0, loop // loop until all words are summed
j test // perform test again!
// Array
. = 0x240
.word ... // A[0]
.word ... // A[1]
...
.word ... // A[15]
Our cache has a total of 64 words. The initial configuration is direct mapped, with 1 word per line, so the cache has 64 lines numbered 0-63 (0x00 - 0x3F).
To achieve 100% steady state hit ratio, it must be the case that the instructions and array data can reside in the cache at the same time. Let's check if this is currently the case.
Since there are 64 lines in the cache, we need log2(64) = 6 index bits to select a cache line. Which cache line (index) does the first instruction li a0, 16 map to? Provide your answer in hexadecimal.","0x0.
The address of the first instruction is 0x200 = 0b_0010_0000_0000. The bottom two bits are used for word alignment. Since the cache has a block size of one, there are no block offset bits. Since there are 64 lines in the cache, there are 6 index bits (bits[7:2]). Since the index = 0x0 for the first instruction, this instruction will go in line 0x0 of the cache."
35,Mathematics,18.01,Calculus I,None,None,Problem Set 1,Exponentials and Logarithms,16,b,0.07919746568,Text,"If $2^{100}=10^{t}$, which of the following is the best approximation of $t: 10$ or 20 or 30 or 40 or $50 ?$ (If you want, you can use that $\log _{2} 10=3.32 \ldots$)",Multiple Choice,"In words, $\log _{2} 10 \approx 3.32$ means that there are approximately $3.32$ factors of 2 in a factor of 10 . Thus, 100 factors of 2 are, approximately, 100/3.32 $\approx 30$ factors of 10.
$$
2^{100} \approx 10^{30} .
$$","Given that $\log _{2} 10=3.32 \ldots$, give a reasonable approximation for $\log _{2} 100 ?$ What about $\log _{2} 10^{10} ?$","First,
$$
\log _{2} 100=\log _{2} 10^{2}=2 \times \underbrace{\log _{2} 10}_{\approx 3.32} \approx 6.64 .
$$
Similarly,
$$
\log _{2} 10^{10}=10 \log _{2} 10 \approx 33.2 \text {. }
$$","If $100^{10}=10^{t}$, what is $t$?","Since $100=10^{2}$,
$$
100^{10}=\left(10^{2}\right)^{10}=10^{20} .
$$
Thus, $t=20$.","Recall that $e$ is the number 2.71... It plays a special role in calculus because $\frac{d}{d x} e^{x}=e^{x}$.
Approximate $10^{.01}$. First write $10^{.01}=e^{t}$ and approximate $t$. You can use that $\log _{e} 10=2.30 \ldots$ Then use linear approximation to approximate $e^{t}$. Give an answer that is accurate to within .01.","Start with
$$
10 \equiv e^{\log _{e} 10} .
$$
Then,
$$
10^{0.01}=\left(e^{\log _{e} 10}\right)^{0.01}=e^{0.01 \times \log _{e} 10} \approx e^{0.023} .
$$
Using the linear approximation for $e^{x}$ gives
$$
10^{0.01} \approx 1.023 .
$$"
346,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Lab 13,Nearest Neighbors,4,nan,0.4166666667,Text,"Suppose we are interested in comparing decision trees and kNNs in a new application. We have 10 million data points for training. Suppose every leaf in our trained decision tree has a depth of 5. Now a test point comes along, and we are interested in making a prediction at the new point. At testing time, about how many operations would it take to make a prediction using our decision tree? At testing time, about how many operations would it take to make a prediction using kNNs?",Open,"For the decision tree: We need to check our test data set at every split in the decision tree. If every leaf is at a depth of 5 , we expect to check 5 splits.
For kNNs: it seems like we have to compare our test point to all 10 million points. There are more clever ways to handle this in practice, but kNNs can be expensive at test time if there's a lot of data.","For this section, we will be looking at a dataset with 10 points that has three classes, shown below. We're going to apply the BuildTree algorithm from the notes, but for classification instead of regression. 
When we use BuildTree for classification, there are two main differences relative to the BuildTree algorithm for regression:
\begin{itemize}
\item In classification, we decide where to split a node based on one of the classification-specific criteria, such as weighted average entropy. (In regression, we decide to split based on squared error loss.)
\item In classification, we predict the majority vote of training data points at a leaf. (In regression, we predict the empirical average of training data points at a leaf.)
\end{itemize}
We're now going to step through building a decision tree for classification. First, we'll need to choose how to split our tree at the root node. To decide how to split our tree at the root node, we'll need to compute the weighted average entropy for all possible splits.
What if our data set looked like the right plot below? How does this new data set relate to the old data set (repeated on the left below for easy comparison)? If you were to repeat the BuildTree $(I=\{1, \ldots, 10\}, k=4)$ computations from above but now on this new data set, how would the decision tree you find be different from on the old data set? How would the accuracies change? (Optional: what if we were to repeat the call to BuildTree $(I=\{1, \ldots, 10\}, k=1$ ) on the new data set? Would the resulting tree and accuracy change compared with when we ran $\operatorname{BuildTree}(I=\{1, \ldots, 10\}, k=1)$ on the old data set?))","We notice that the new dataset is the same as the old dataset except both $\mathrm{x} 1$ and $\mathrm{x} 2$ features have been both shifted and scaled. Thus, the decision tree boundaries will have the same shape and placement relative to the data points, but the values at the splits will just be different. The accuracies of the decision trees stay the same.","Consider the following training set used to train a kNN for classification. The feature space is two-dimensional and the dataset contains two classes: orange stars and blue dots. Points 1 and 2 are test data points. Assume we use Euclidean distance.
Draw the decision boundaries (a rough sketch is fine) for the following values of $k: 1,5,9$. Be prepared to show your sketches during check-off. What is going on when $k=9$ ?","These are the plots for $k=1,5,9$ respectively: 
When $\mathrm{k}=9$, everything is classified as orange star because there are only 9 training examples, 5 of which are orange stars.","For this section, we will be looking at a dataset with 10 points that has three classes, shown below. We're going to apply the BuildTree algorithm from the notes, but for classification instead of regression. 
When we use BuildTree for classification, there are two main differences relative to the BuildTree algorithm for regression:
\begin{itemize}
\item In classification, we decide where to split a node based on one of the classification-specific criteria, such as weighted average entropy. (In regression, we decide to split based on squared error loss.)
\item In classification, we predict the majority vote of training data points at a leaf. (In regression, we predict the empirical average of training data points at a leaf.)
\end{itemize}
We're now going to step through building a decision tree for classification. First, we'll need to choose how to split our tree at the root node. To decide how to split our tree at the root node, we'll need to compute the weighted average entropy for all possible splits.
Without actually doing all the BuildTree $(I=\{1, \ldots, 10\}, k=1$ ) computations, can you say what the accuracy of the resulting tree would be on the training data?",The accuracy would be 10/10 because every data point would get its own leaf.
3,EECS,18.C06,Linear Algebra and Optimization,18.02,None,Problem Set 1,Vector Spaces,2,a,0.1851851852,Text,True or False: The columns of the matrix $\left[\begin{array}{lll}0 & 1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 1\end{array}\right]$ span $\mathbb{R}^{3}$.,Multiple Choice,"True. We can write any vector as a linear combination of the columns, since these are the vectors of the standard basis (i.e., columns of the identity matrix) in a different order.",True or False: The columns of the matrix $\left[\begin{array}{lll}2 & 0 & 0 \\ 1 & 0 & 0 \\ 4 & 3 & 2\end{array}\right]$ span $\mathbb{R}^{3}$.,"False. The last two columns are multiples of each other, so the column space is a two-dimensional subspace, not $\mathbb{R}^{3}$.",True or False: The columns of the matrix $\left[\begin{array}{ccc}1 & -3 & -1 \\ 0 & 3 & -6 \\ 0 & 0 & 4\end{array}\right]$ span $\mathbb{R}^{3}$.,"True. If we try to express a vector as a linear combination of the columns, we can always solve the corresponding linear system since the given matrix is diagonal with nonzero diagonal entries.","Use Gaussian elimination to find all the solutions to the following system of linear equations
$$
\left[\begin{array}{ccc}
2 & -1 & 4 \\
-3 & 2 & 5 \\
-5 & 3 & 1
\end{array}\right]\left[\begin{array}{l}
x \\
y \\
z
\end{array}\right]=\left[\begin{array}{c}
-2 \\
0 \\
2
\end{array}\right]
$$
You should express your answer in the form where there are some free variables that can be set independently and the rest of the variables are then determined. What can you say about the span of the three columns of this matrix? Do they span $\mathbb{R}^{3}$ or can you express one column as a linear combination of the others?","Consider the extended matrix $[A \mid b]$ and its RREF form
$$
\left[\begin{array}{ccc|c}
2 & -1 & 4 & -2 \\
-3 & 2 & 5 & 0 \\
-5 & 3 & 1 & 2
\end{array}\right] \quad \stackrel{\text { RREF }}{\longrightarrow} \quad\left[\begin{array}{ccc|c}
1 & 0 & 13 & -4 \\
0 & 1 & 22 & -6 \\
0 & 0 & 0 & 0
\end{array}\right]
$$
Backsolving from this, we obtain the general solution
$$
x=-4-13 t, \quad y=-6-22 t, \quad z=t .
$$
The column space is two-dimensional, since the first two columns are linearly independent, and the last column is 13 times the first one plus 22 times the second one. Equivalently, the null-space of $A$ is spanned by the vector $[13,22,-1]$."
30,EECS,6.18,Computer Systems Engineering,"6.1010, 6.1910",None,Hands-on 5,Traceroute,5,nan,0.1666666667,Text,"At the command prompt, type:
traceroute 18.31.0.200
Describe what is strange about the observed output, and why traceroute gives you such an output. Refer to the traceroute man page for useful hints.  Copy/paste any of the relevant portions of output below.",Open,"After the 4th hop, the hops begin to oscillate between 18.69.3.2 and 18.4.7.65, until the maximum number of hops is reached. 
5  MITNET.CORE-1-EXT.CSAIL.MIT.EDU (18.4.7.65)  9.058 ms  9.099 ms  9.344 ms
...
25  MITNET.CORE-1-EXT.CSAIL.MIT.EDU (18.4.7.65)  9.040 ms  9.077 ms  9.035 ms
26  DMZ-RTR-2-CSAIL.MIT.EDU (18.4.7.1)  8.764 ms  8.878 ms  8.836 ms
27  MITNET.CORE-1-EXT.CSAIL.MIT.EDU (18.4.7.65)  8.813 ms  9.049 ms  9.021 ms
28  DMZ-RTR-2-CSAIL.MIT.EDU (18.4.7.1)  8.562 ms  8.726 ms  8.797 ms
29  MITNET.CORE-1-EXT.CSAIL.MIT.EDU (18.4.7.65)  9.335 ms  9.373 ms  9.381 ms
30  DMZ-RTR-2-CSAIL.MIT.EDU (18.4.7.1)  8.980 ms  9.224 ms  9.000 ms
One possible reason for this is the existence of a “routing loop” by which each of the two routers thinks the other has a route to the destination, i.e. that each has a path to the destination that contains the other. This can happen in link-state routing, in part because details of the path being advertised are not shared.","For this exercise, you need to use the traceroute server at http://www.slac.stanford.edu/cgi-bin/nph-traceroute.pl. You'll use this server to execute a traceroute to your own machine.
To figure out your machine's IP address, run /sbin/ifconfig. You'll get a lot of information, including its IP address.
Once you have your IP, use Stanford's server to execute a traceroute to it.
Then run your own traceroute to Stanford's server, via 
traceroute [IP ADDRESS FROM STANFORD]
You can get Stanford's IP address from the website.
Describe anything unusual about the output. Are the same routers traversed in both directions? If not, why might this happen?  Be sure to copy/paste any relevant portions of your traceroute output here.","I used the looking-glass at www.net.princeton.edu, both outputs are below:
traceroute to 18.9.64.24 (18.9.64.24), 30 hops max, 40 byte packets
 1  core-87-router (128.112.128.2)  0.743 ms  0.586 ms  0.438 ms
 2  border-87-router (128.112.12.142)  0.888 ms  0.701 ms  0.638 ms
 3  local1.princeton.magpi.net (216.27.98.113)  11.788 ms  1.824 ms  1.815 ms
 4  216.27.100.18 (216.27.100.18)  2.166 ms  2.009 ms  2.062 ms
 5  et-7-1-0.4079.rtsw.newy32aoa.net.internet2.edu (162.252.70.102)  4.070 ms  4.019 ms  4.051 ms
 6  nox300gw1-i2-re.nox.org (192.5.89.221)  9.263 ms  9.165 ms  9.262 ms
 7  192.5.89.22 (192.5.89.22)  9.220 ms  9.407 ms  9.199 ms
 8  external-rtr-3-nox.mit.edu (18.32.4.110)  8.428 ms  8.682 ms  8.334 ms
 9  dmz-rtr-1-external-rtr-3.mit.edu (18.69.7.1)  8.715 ms  8.603 ms  8.589 ms
10  backbone-rtr-1-dmz-rtr-1.mit.edu (18.69.1.2)  8.665 ms  8.759 ms  8.622 ms
11  oc11-rtr-1-backbone-rtr-1.mit.edu (18.123.69.2)  8.858 ms  8.459 ms  8.457 ms
12  buzzword-bingo.mit.edu (18.9.64.24)  16.011 ms  16.173 ms  15.738 ms
traceroute to www.net.princeton.edu (128.112.128.55), 30 hops max, 60 byte packets
 1  18.9.64.3 (18.9.64.3)  8.164 ms  8.192 ms  8.173 ms
 2  BACKBONE-RTR-1-OC11-RTR-1.MIT.EDU (18.123.69.1)  8.367 ms  8.493 ms  8.473 ms
 3  DMZ-RTR-1-BACKBONE-RTR-1.MIT.EDU (18.69.1.1)  8.488 ms  8.468 ms  8.442 ms
 4  EXTERNAL-RTR-3-DMZ-RTR-1.MIT.EDU (18.69.7.2)  8.498 ms  8.386 ms  8.380 ms
 5  NOX-CPS-EXTERNAL-RTR-3.MIT.EDU (18.32.132.109)  8.533 ms  8.633 ms  8.610 ms
 6  10ge5-7.core1.bos1.he.net (206.108.236.30)  22.500 ms  15.543 ms  8.487 ms
 7  100ge12-2.core1.nyc4.he.net (184.105.64.53)  13.449 ms  13.479 ms  13.526 ms
 8  princeton-university.10gigabitethernet1-1-6.switch1.nyc8.he.net (216.66.49.74)  15.948 ms  15.732 ms  15.834 ms
 9  core-87-router.Princeton.EDU (128.112.12.130)  16.998 ms  16.951 ms  17.037 ms
10  www.net.Princeton.EDU (128.112.128.55)  16.329 ms  23.503 ms  16.239 ms
The routers shown are definitely not the same for both direction, however the ends of the paths are very similar. This suggests that the AS tends to route the packets through the same routers in both directions, but that BGP chooses different paths for the two directions. This would arise from ties between two routers in path selection being decided arbitrarily, and the fact that BGP typically attempts to hand off packets to ASes at the first possible point, which can be different for the different directions.","In at most 50 words, explain how traceroute discovers a path to a remote host. The man page might be useful in answering this question.","Traceroute works by sending probe packets to to random, typically unused ports on a given destination with small but increasing TTL values, and then listening for “time exceeded” responses from each gateway along the path, which will come from each gateway in order from the original machine to the destination, which we can identify by the “port unreachable” response we get.",What are the IP addresses of maple and willow on this network? (Hint: Check the man page of tcpdump to discover how you can obtain the IP addresses),"If we redo the given command: tcpdump -r tcpdump.dat > /tmp/outfile.pcap ; mv /tmp/outfile.pcap outfile.txt but with the added modifier “-n” in front of the “-r” modifier, the new outfile has the numeric IP addresses instead of the domain names. These are 128.30.4.223 for maple, and 128.30.4.222 for willow."
461,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Problem Set 3,Gradient Descent,10,aii,0.02083333333,Text,"Last week, we defined the _ridge regression_objective function.
$$
J_{\text {ridge }}\left(\theta, \theta_{0}\right)=\frac{1}{n} \sum_{i=1}^{n}\left(\theta^{T} x^{(i)}+\theta_{0}-y^{(i)}\right)^{2}+\lambda\|\theta\|^{2}
$$
Recall that in last week's homework, we derived the closed-form solution for the $\theta$ value that minimizes the least squares loss function. However, it is computationally challenging to compute the closed-form solution on $\theta$ on high-dimensional data and large datasets.
This week, we wish to apply gradient descent and stochastic gradient descent to minimize the ridge regression function. In order to use the gradient descent and stochastic gradient descent functions implemented previously in the homework, we must add ones to the end of each datapoint in $X$, which we implemented in the add_ones_row function in homework 1.
In the next subsections, we assume that $X$ is a $d \times n$ matrix, $Y$ is a $1 \times n$ matrix, and $\theta$ is a $d \times 1$ matrix. Rewriting the ridge objective through matrix operations, we find that:
$$
J_{\text {ridge }}(\theta)=\frac{1}{n}\left(\theta^{T} X-Y\right)\left(\theta^{T} X-Y\right)^{T}+\lambda\|\theta\|^{2}
$$
For the rest of the problem, assume that $\mathrm{X}$ already has ones at the end of each datapoint. You do not need to call the add_one_rows function.
Implement objective_func. objective_func returns a function that computes $J_{\text {ridge }}(\theta)$.
inputs:
X: a (dxn) numpy array.
Y: a (1xn) numpy array
lam: regularization parameter
outputs:
f : a function that takes in a (dx1) numpy array ""theta"" and returns *as a float* the value of the ridge regression objective when theta(the variable)=""theta""(the numpy array)
def objective_func(X, Y, lam):
def f(theta):
# write your implementation here
pass
return f",Programming,"def objective_func(X, Y, lam):
def f(theta):
n = X.shape[1]
sq_loss = (1/n) *(theta.T @ X - Y) @ (theta.T @ X - Y).T
regularizer = lam* theta.T @ theta
return (sq_loss + regularizer).item()
return f","Last week, we defined the _ridge regression_objective function.
$$
J_{\text {ridge }}\left(\theta, \theta_{0}\right)=\frac{1}{n} \sum_{i=1}^{n}\left(\theta^{T} x^{(i)}+\theta_{0}-y^{(i)}\right)^{2}+\lambda\|\theta\|^{2}
$$
Recall that in last week's homework, we derived the closed-form solution for the $\theta$ value that minimizes the least squares loss function. However, it is computationally challenging to compute the closed-form solution on $\theta$ on high-dimensional data and large datasets.
This week, we wish to apply gradient descent and stochastic gradient descent to minimize the ridge regression function. In order to use the gradient descent and stochastic gradient descent functions implemented previously in the homework, we must add ones to the end of each datapoint in $X$, which we implemented in the add_ones_row function in homework 1.
In the next subsections, we assume that $X$ is a $d \times n$ matrix, $Y$ is a $1 \times n$ matrix, and $\theta$ is a $d \times 1$ matrix. Rewriting the ridge objective through matrix operations, we find that:
$$
J_{\text {ridge }}(\theta)=\frac{1}{n}\left(\theta^{T} X-Y\right)\left(\theta^{T} X-Y\right)^{T}+\lambda\|\theta\|^{2}
$$
For the rest of the problem, assume that $\mathrm{X}$ already has ones at the end of each datapoint. You do not need to call the add_one_rows function.
Implement objective_func_grad. objective_func_grad returns a function that computes $\nabla J_{\text {ridge }}(\theta)$.
inputs:
X: a (dxn) numpy array.
Y: a (1xn) numpy array
lam: regularization parameter
outputs:
df : a function that takes in a (dx1) numpy array ""theta"" and returns the gradient of the ridge regression objective when theta(the variable)=""theta""(the numpy array)
def objective_func_grad(X, Y, lam):
def df(theta):
# write your implementation here
pass
return df","def objective_func_grad(X, Y, lam):
def df(theta):
n = X.shape[1]
sq_loss = (2/n)*X@(theta.T@X - Y).T
regularizer = 2*lam*theta
return sq_loss + regularizer
return df","Last week, we defined the _ridge regression_objective function.
$$
J_{\text {ridge }}\left(\theta, \theta_{0}\right)=\frac{1}{n} \sum_{i=1}^{n}\left(\theta^{T} x^{(i)}+\theta_{0}-y^{(i)}\right)^{2}+\lambda\|\theta\|^{2}
$$
Recall that in last week's homework, we derived the closed-form solution for the $\theta$ value that minimizes the least squares loss function. However, it is computationally challenging to compute the closed-form solution on $\theta$ on high-dimensional data and large datasets.
This week, we wish to apply gradient descent and stochastic gradient descent to minimize the ridge regression function. In order to use the gradient descent and stochastic gradient descent functions implemented previously in the homework, we must add ones to the end of each datapoint in $X$, which we implemented in the add_ones_row function in homework 1.
In the next subsections, we assume that $X$ is a $d \times n$ matrix, $Y$ is a $1 \times n$ matrix, and $\theta$ is a $d \times 1$ matrix. Rewriting the ridge objective through matrix operations, we find that:
$$
J_{\text {ridge }}(\theta)=\frac{1}{n}\left(\theta^{T} X-Y\right)\left(\theta^{T} X-Y\right)^{T}+\lambda\|\theta\|^{2}
$$
For the rest of the problem, assume that $\mathrm{X}$ already has ones at the end of each datapoint. You do not need to call the add_one_rows function.
Write an expression for $\nabla J_{\text {ridge }}(\theta)$ with respect to $\theta$.
Enter your answers as mathematical expressions. You should use transpose $(m)$ for transpose of an array $m$, $f(q)$ for a function $f$ applied to scalar or vector $\mathrm{x}$, and $\mathrm{Qq}$ to indicate a matrix product of two arrays/matrices, $\mathrm{p}$ and q. Remember that $p^{*} q$ denotes component-wise multiplication. 
Enter a Python expression involving X, Y, lambda, n, and theta. You will also need to use transpose, @ and * appropriately.",(2 / n) * X @ transpose(transpose(theta)@X - Y) + 2*lambda*theta,"Last week, we defined the _ridge regression_objective function.
$$
J_{\text {ridge }}\left(\theta, \theta_{0}\right)=\frac{1}{n} \sum_{i=1}^{n}\left(\theta^{T} x^{(i)}+\theta_{0}-y^{(i)}\right)^{2}+\lambda\|\theta\|^{2}
$$
Recall that in last week's homework, we derived the closed-form solution for the $\theta$ value that minimizes the least squares loss function. However, it is computationally challenging to compute the closed-form solution on $\theta$ on high-dimensional data and large datasets.
This week, we wish to apply gradient descent and stochastic gradient descent to minimize the ridge regression function. In order to use the gradient descent and stochastic gradient descent functions implemented previously in the homework, we must add ones to the end of each datapoint in $X$, which we implemented in the add_ones_row function in homework 1.
So far in the course, you've learned about two different hyperparameters: the regularization rate $\lambda$ and the step size/learning rate $\eta$. You might be wondering, how do we pick the best hyperparameters for minimizing the loss function? One of the most basic ways to pick regularization rate and learning rate is to use grid search. The basic idea behind grid search is to select several possible $(\lambda, \eta)$ pairs, train models with every combination of these hyperparameters, and evaluate each trained model to select the best hyperparameters. 
We will be running grid search over the Boston Housing dataset. For more information about this dataset, please visit this link.
For the rest of this exercise, we will be predicting the median value of houses in the Boston area using linear regression and gradient descent. Please visit the colab notebook linked on the top of this page to collect metrics on how well gradient descent works on this regression problem.
Among the grid of values specified in the colab, what is the best value of $\lambda$ and $\eta$ when using gradient descent? Enter your answer as a tuple $(\lambda, \eta)$.","(0.1, 0.001)"
33,EECS,6.2,Electrical Circuits: Modeling and Design of Physical Systems,8.02,None,Problem Set 7,Thermal System,2,e,0.2380952381,Text,"As mentioned in our first lecture, electrical circuit is a good mathematical language for modelling other non-electrical systems such as mechanical, biological systems, etc. Here we are going to use circuit to analyze a thermal system.
Prior to $t=0$, the building considered in (D) reaches thermal equilibrium with the environment, i.e. $T_{i}=T_{e}$. Then at $t=0$, the owner of the building turns on the heater which has a constant power Q. What is the final temperature that the interior of the building will reach? Express the interior temperature as a function of time $T_{i}(t)$ for $t>$ 0. Note that the environment temperature remains constant at $T_{\mathrm{e}}$.",Expression,$T_{i}^{(t+\infty)} =T_{e}+\frac{Q}{\frac{1}{R_{1}}+\frac{1}{R_{2}}+\frac{1}{R_{3}}+\frac{1}{R_{4}}+\frac{1}{R_{5}}+\frac{1}{R_{6}}}$.,"As mentioned in our first lecture, electrical circuit is a good mathematical language for modelling other non-electrical systems such as mechanical, biological systems, etc. Here we are going to use circuit to analyze a thermal system.
Now consider a small building that is attached to a big building as shown in the figure below. The small building exchanges heat with the big building through one shared wall with the thermal resistance $R_{1}$. Meanwhile, the small building exchanges heat with the external environment through the rest three walls plus the roof and the floor $\left(\mathrm{R}_{2} \sim \mathrm{R}_{6}\right)$. Because the big building has a very large volume, its temperature $T_{0}$ remains almost unchanged for the considered time. In order to calculate the temperature change of the small building, what circuit element will you use to model the influence from the big building? Draw a circuit to model the thermal system associated with the small building shown in the figure below. Label node voltages, current, resistances, and values of all the other circuit elements you use. In this part, the heater in the small building has a constant power $\mathrm{Q}$ which turns on at $\mathrm{t}=0$. For $\mathrm{t}<0$, the small building temperature has reached a stable point by exchanging thermal energy with the big building and environment for a very long time. For $t>0$, express the interior temperature of the small building as a function of time $T_{i}(t)$.","Since $T_o$ of the big building is constant, we con use a voltage source with $V=T_o - T_e$ to model it.
The circuit is below.","As mentioned in our first lecture, electrical circuit is a good mathematical language for modelling other non-electrical systems such as mechanical, biological systems, etc. Here we are going to use circuit to analyze a thermal system.
When the heater turns on, the room's temperature does not jump to a high value immediately. Instead, the air, furniture and everything else inside the room absorb thermal energy and slowly raise their temperature. The temperature change rate is proportional to the net heat flow into the room via $q=C_{t h} \frac{d T_{i}}{d t}$, where $C_{t h}$ is the 'thermal capacity', in unit of Joule/Kelvin, $\mathrm{q}$ is the net heat flow (the heater power minus the heat flow to the environment). Here for simplicity we assume that the whole interior of the building has the same temperature $T_{i}$. What circuit element will you use to model the thermal capacity of the building? Draw a circuit to model the heat generation, thermal capacity and heat flow process of this building. Label node voltages, current, resistances and the other circuit element you use.","We use electrical capacitor to model the thermal capacity.
The circuit is below.","As mentioned in our first lecture, electrical circuit is a good mathematical language for modelling other non-electrical systems such as mechanical, biological systems, etc. Here we are going to use circuit to analyze a thermal system.
The building in (B) is equipped with a heating device which generates heat with a constant power of $Q$ (in units of Watt, the same as the unit of heat flow q). What circuit element will you use to model this heat generation device? Draw a circuit to model the heat generation and heat transfer process of this building. Label node voltages, current and resistances in the circuit below.","A currext source with $I=Q$ con be used to model the heater.
The circuit is below."
194,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 5,Localization with Viterbi,4,d,0.2604166667,Text,"In this section, we will implement an HMM for a robot that is moving around randomly in a 2D grid with obstacles. The robot has sensors that allow it to detect obstacles in its immediate vicinity. It knows the grid map, with the locations of all obstacles, but it is uncertain about its own location in the grid. We will use Viterbi to determine the most likely locations for the robot given a sequence of local and potentially noisy observations. 
Concretely, we will represent the 2D grid with obstacles as a list of lists, where 1s represent obstacles and 0s represent free space. Example:
obstacle_map = [
[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
[1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1],
[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0],
[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
]
The state of the robot is its location in the grid, represented as a tuple of ints, (row, col). Transitions are uniformly distributed amongst the robot's current location and the neighboring free (not obstacle) locations, where neighboring = 4 cardinal directions (up, down, left, right).
Observations are a 4-tuple that list which directions have obstacles, in order [N E S W], with a 1 for an obstacle and 0 for no obstacle. Observations that are ""off the map"" are 1, as though they are obstacles. For instance, in the map above, if there were no observation noise, then the observation for the top left corner (state=(0, 0)) would be (1, 0, 1, 1). Observations can also be corrupted with noise; see the create_observation_potential docstring for more details.
Our ultimate task will be to take in a sequence of observations and return the corresponding sequence of most likely states.
Write a function that creates a random variable for an observation at a given time step in an obstacle HMM. See docstring for description.
For reference, our solution is 3 line(s) of code.
def create_observation_variable(name):
'''Creates a RV for the HMM observation with the given name.
Observations are a 4-tuple that list which directions have obstacles,
in order [N E S W], with a 1 for an obstacle and 0 for no obstacle.
Observations that are ""off the map"" are 1, as though they are obstacles.
For instance, in the following map:
obstacle_map = [
[0, 1],
[0, 0],
]
if there were no observation noise, then the observation for the top left
location would be (1, 1, 0, 1).
The domain of the observation variable should be a list of 4-tuples.
Hint: you may find it useful to use `itertools.product`. For example,
see what happens with `list(itertools.product([""foo"", ""bar""], repeat=2))`.
Args:
name: A str name for the variable.
Returns:
zt: A RV as described above.
'''
raise NotImplementedError(""Implement me!"")",Programming,"def create_observation_variable(name):
'''Creates a RV for the HMM observation with the given name.
Observations are a 4-tuple that list which directions have obstacles,
in order [N E S W], with a 1 for an obstacle and 0 for no obstacle.
Observations that are ""off the map"" are 1, as though they are obstacles.
For instance, in the following map:
obstacle_map = [
[0, 1],
[0, 0],
]
if there were no observation noise, then the observation for the top left
location would be (1, 1, 0, 1).
The domain of the observation variable should be a list of 4-tuples.
Hint: you may find it useful to use `itertools.product`. For example,
see what happens with `list(itertools.product([""foo"", ""bar""], repeat=2))`.
Args:
name: A str name for the variable.
Returns:
zt: A RV as described above.
'''
domain = list(itertools.product([0, 1], repeat=4))
return RV(name, domain)","In this section, we will implement an HMM for a robot that is moving around randomly in a 2D grid with obstacles. The robot has sensors that allow it to detect obstacles in its immediate vicinity. It knows the grid map, with the locations of all obstacles, but it is uncertain about its own location in the grid. We will use Viterbi to determine the most likely locations for the robot given a sequence of local and potentially noisy observations. 
Concretely, we will represent the 2D grid with obstacles as a list of lists, where 1s represent obstacles and 0s represent free space. Example:
obstacle_map = [
[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
[1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1],
[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0],
[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
]
The state of the robot is its location in the grid, represented as a tuple of ints, (row, col). Transitions are uniformly distributed amongst the robot's current location and the neighboring free (not obstacle) locations, where neighboring = 4 cardinal directions (up, down, left, right).
Observations are a 4-tuple that list which directions have obstacles, in order [N E S W], with a 1 for an obstacle and 0 for no obstacle. Observations that are ""off the map"" are 1, as though they are obstacles. For instance, in the map above, if there were no observation noise, then the observation for the top left corner (state=(0, 0)) would be (1, 0, 1, 1). Observations can also be corrupted with noise; see the create_observation_potential docstring for more details.
Our ultimate task will be to take in a sequence of observations and return the corresponding sequence of most likely states.
Write a function that creates a random variable for a state at a given time step in an obstacle HMM. The domain of the state variable should be a list of(row, col) indices into the map. Only free positions (not obstacles) should be included in the domain of the state variable. See docstring for more description.
For reference, our solution is 4 line(s) of code.
def create_state_variable(obstacle_map, name):
'''Creates a RV for the HMM state.
The state can be any position in the map.
Example map:
obstacle_map = [
[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
[1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1],
[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0],
[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
]
Ones are obstacles and zeros are free positions.
The domain of the state variable should be a list of (row, col)
indices into the map. Only free positions (not obstacles) should
be included in the domain of the state variable.
The domain should be in row-major order. For example, an empty
2x2 obstacle map should lead to the domain:
[(0, 0), (0, 1), (1, 0), (1, 1)].
Args:
obstacle_map: A list of lists of ints, see example above.
name: A str name for the state variable.
Returns:
state_var: A RV as described above.
'''
raise NotImplementedError(""Implement me!"")","def create_state_variable(obstacle_map, name):
'''Creates a RV for the HMM state.
The state can be any position in the map.
Example map:
obstacle_map = [
[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
[1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1],
[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0],
[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
]
Ones are obstacles and zeros are free positions.
The domain of the state variable should be a list of (row, col)
indices into the map. Only free positions (not obstacles) should
be included in the domain of the state variable.
The domain should be in row-major order. For example, an empty
2x2 obstacle map should lead to the domain:
[(0, 0), (0, 1), (1, 0), (1, 1)].
Args:
obstacle_map: A list of lists of ints, see example above.
name: A str name for the state variable.
Returns:
state_var: A RV as described above.
'''
domain = [(r, c) for r in range(len(obstacle_map))
for c in range(len(obstacle_map[0])) if obstacle_map[r][c] == 0]
return RV(name, domain)","In this section, we will implement an HMM for a robot that is moving around randomly in a 2D grid with obstacles. The robot has sensors that allow it to detect obstacles in its immediate vicinity. It knows the grid map, with the locations of all obstacles, but it is uncertain about its own location in the grid. We will use Viterbi to determine the most likely locations for the robot given a sequence of local and potentially noisy observations. 
Concretely, we will represent the 2D grid with obstacles as a list of lists, where 1s represent obstacles and 0s represent free space. Example:
obstacle_map = [
[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
[1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1],
[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0],
[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
]
The state of the robot is its location in the grid, represented as a tuple of ints, (row, col). Transitions are uniformly distributed amongst the robot's current location and the neighboring free (not obstacle) locations, where neighboring = 4 cardinal directions (up, down, left, right).
Observations are a 4-tuple that list which directions have obstacles, in order [N E S W], with a 1 for an obstacle and 0 for no obstacle. Observations that are ""off the map"" are 1, as though they are obstacles. For instance, in the map above, if there were no observation noise, then the observation for the top left corner (state=(0, 0)) would be (1, 0, 1, 1). Observations can also be corrupted with noise; see the create_observation_potential docstring for more details.
Our ultimate task will be to take in a sequence of observations and return the corresponding sequence of most likely states.
Write a function that creates a potential for the observation distribution between $s_{t}$ and $z_{t}$.
For reference, our solution is 29 line(s) of code. 
def create_observation_potential(obstacle_map, state_rv, observation_rv,

noise_prob=0.):

'''Write a function to create a potential between state_rv
and observation_rv in an HMM that corresponds to the map.
You can assume that state_rv was created by `create_state_variable`
and observation_rv was created by `create_observation_variable`.
See `create_observation_variable` for a description of the
observation model. Recall the order is [N E S W].
If noise_prob = 0., then the observations are noise-free. That is,
you observe 0 if there is a free space and 1 otherwise.
In general, for each of the four observation entries, with
probability 1 - noise_prob, the entry will be ""correct""; with
probability noise_prob, the entry will be incorrect, that is,
the opposite of the true occupancy.
So if the noise-free observation would be (1, 0, 0, 1), then
the probability of observation (1, 1, 0, 1) would be
noise_prob*(1 - noise_prob)^3.
Args:
obstacle_map: A list of lists of ints;
see example and description in `create_state_variable`.
state_rv: An RV representing the state at time t.
observation_rv: An RV representing the observation at time t.
noise_prob: A float between 0 and 1 indicating the probability
that an observation flips.
Returns:
potential: A Potential for the distribution between st and zt.
'''
raise NotImplementedError(""Implement me!"")","def create_observation_potential(obstacle_map, state_rv, observation_rv,

noise_prob=0.):

'''Write a function to create a potential between state_rv
and observation_rv in an HMM that corresponds to the map.
You can assume that state_rv was created by `create_state_variable`
and observation_rv was created by `create_observation_variable`.
See `create_observation_variable` for a description of the
observation model. Recall the order is [N E S W].
If noise_prob = 0., then the observations are noise-free. That is,
you observe 0 if there is a free space and 1 otherwise.
In general, for each of the four observation entries, with
probability 1 - noise_prob, the entry will be ""correct""; with
probability noise_prob, the entry will be incorrect, that is,
the opposite of the true occupancy.
So if the noise-free observation would be (1, 0, 0, 1), then
the probability of observation (1, 1, 0, 1) would be
noise_prob*(1 - noise_prob)^3.
Args:
obstacle_map: A list of lists of ints;
see example and description in `create_state_variable`.
state_rv: An RV representing the state at time t.
observation_rv: An RV representing the observation at time t.
noise_prob: A float between 0 and 1 indicating the probability
that an observation flips.
Returns:
potential: A Potential for the distribution between st and zt.
'''
def get_obs_for_loc(r, c):
# Out of bounds
if not (0 <= r < len(obstacle_map) and 0 <= c < len(obstacle_map[0])):
return 1
return obstacle_map[r][c]
def get_obs_prob(obs, true_obs):
p = 1.
for i, j in zip(obs, true_obs):
if i == j:
p *= (1 - noise_prob)
else:
p *= noise_prob
return p
table = np.zeros((state_rv.dim, observation_rv.dim))
for i, (r, c) in enumerate(state_rv.domain):
true_obs = (
get_obs_for_loc(r - 1, c), # North
get_obs_for_loc(r, c + 1), # East
get_obs_for_loc(r + 1, c), # South
get_obs_for_loc(r, c - 1), # West
)
for j, obs in enumerate(observation_rv.domain):
table[i, j] = get_obs_prob(obs, true_obs)
return Potential([state_rv, observation_rv], table)","In this section, we will implement an HMM for a robot that is moving around randomly in a 2D grid with obstacles. The robot has sensors that allow it to detect obstacles in its immediate vicinity. It knows the grid map, with the locations of all obstacles, but it is uncertain about its own location in the grid. We will use Viterbi to determine the most likely locations for the robot given a sequence of local and potentially noisy observations. 
Concretely, we will represent the 2D grid with obstacles as a list of lists, where 1s represent obstacles and 0s represent free space. Example:
obstacle_map = [
[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
[1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1],
[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0],
[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
]
The state of the robot is its location in the grid, represented as a tuple of ints, (row, col). Transitions are uniformly distributed amongst the robot's current location and the neighboring free (not obstacle) locations, where neighboring = 4 cardinal directions (up, down, left, right).
Observations are a 4-tuple that list which directions have obstacles, in order [N E S W], with a 1 for an obstacle and 0 for no obstacle. Observations that are ""off the map"" are 1, as though they are obstacles. For instance, in the map above, if there were no observation noise, then the observation for the top left corner (state=(0, 0)) would be (1, 0, 1, 1). Observations can also be corrupted with noise; see the create_observation_potential docstring for more details.
Our ultimate task will be to take in a sequence of observations and return the corresponding sequence of most likely states.
Write a function that creates a potential for the transition distribution between states $s_{t}$ and $s_{t+1}$. Refer to the previous question for more information about the state variables and their domains.
For reference, our solution is 13 line(s) of code. 
def create_transition_potential(obstacle_map, st, st1):
'''Write a function to create a potential for the transition from state s_t
to s_{t+1}, in an HMM that corresponds to the map.
Transitions are uniformly distributed amongst the robot's current
location and the neighboring free (not obstacle) locations, where
neighboring = 4 cardinal directions (up, down, left, right).
Hint: remember that if we have a potential with two variables A and B,
with dimension N and M, then the potential table will be a numpy array
of shape (N, M). Furthermore, the potential value for the i^{th} domain
value of A and the j^{th} domain value of B will be table[i, j]. With
this in mind, you may find it useful to use the following pattern in
your code somewhere:
```
for i, (prev_r, prev_c) in enumerate(st.domain):
...
for j, (next_r, next_c) in enumerate(st1.domain):
...
table[i, j] = ...
```
Args:
st: An RV representing the state at time t.
st1: An RV representing the state at time t+1.
obstacle_map: A list of lists of ints;
see example and description in `create_state_variable`.
Returns:
potential: A Potential for the transition between st and st1.
'''
raise NotImplementedError(""Implement me!"")","def create_transition_potential(obstacle_map, st, st1):
'''Write a function to create a potential for the transition from state s_t
to s_{t+1}, in an HMM that corresponds to the map.
Transitions are uniformly distributed amongst the robot's current
location and the neighboring free (not obstacle) locations, where
neighboring = 4 cardinal directions (up, down, left, right).
Hint: remember that if we have a potential with two variables A and B,
with dimension N and M, then the potential table will be a numpy array
of shape (N, M). Furthermore, the potential value for the i^{th} domain
value of A and the j^{th} domain value of B will be table[i, j]. With
this in mind, you may find it useful to use the following pattern in
your code somewhere:
```
for i, (prev_r, prev_c) in enumerate(st.domain):
...
for j, (next_r, next_c) in enumerate(st1.domain):
...
table[i, j] = ...
```
Args:
st: An RV representing the state at time t.
st1: An RV representing the state at time t+1.
obstacle_map: A list of lists of ints;
see example and description in `create_state_variable`.
Returns:
potential: A Potential for the transition between st and st1.
'''
table = np.zeros((st.dim, st1.dim))
for i, (prev_r, prev_c) in enumerate(st.domain):
possible_next_loc_idxs = set()
for j, (next_r, next_c) in enumerate(st1.domain):
# Check if neighbors or self
if abs(prev_r - next_r) + abs(prev_c - next_c) <= 1:
possible_next_loc_idxs.add(j)
# Next locs have uniform probability
p = 1. / len(possible_next_loc_idxs)
for j in possible_next_loc_idxs:
table[i, j] = p
return Potential([st, st1], table)"
116,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Problem Set 7,Caches,2,nan,2.7,Text,"Implement a direct-mapped cache by completing the DirectMappedCache module in DirectMappedCache.ms. Note that you should also keep track of hit and miss counts.

import CacheTypes;
import CacheHelpers;
import MainMemory;

// ReqStatus (defined in CacheTypes.ms) is used to keep track of the state of the current request
//typedef enum {
//    Ready,         // The cache is ready for a new request
//    Lookup,        // Issued a lookup to tag/data arrays
//    Writeback,     // In main memory access for dirty writeback
//    Fill           // In main memory access for requested data
//} ReqStatus;
//
// Possible flows:
//   HIT: Ready -> Lookup -> Ready
//   MISS, line is clean: Ready -> Lookup -> Fill
//   MISS, line is dirty: Ready -> Lookup -> Writeback -> Fill

// Cache SRAM Synonyms (defined in CacheTypes.ms)
// You may find the following type synonyms helpful to access the tag/data/status arrays
// typedef SRAMReq#(logCacheSets, CacheTag) TagReq;
// typedef SRAMReq#(logCacheSets, Line) DataReq;
// typedef SRAMReq#(logCacheSets, CacheStatus) StatusReq;

// TODO: Complete the implementation of DirectMappedCache
// NOTE: Implementing this module requires about 50 lines of additional code
// (~40 lines in rule tick, ~5-10 lines in method data, 1 line in method reqEnabled, 1 line in function isHit)
module DirectMappedCache(MainMemory mainMem);
    // SRAM arrays. Note that, for a direct-mapped cache,
    // number of cache sets == number of cache lines
    SRAM#(logCacheSets, Line) dataArray;
    SRAM#(logCacheSets, CacheTag) tagArray;
    SRAM#(logCacheSets, CacheStatus) statusArray;
    
    // Registers for holding the current state of the cache and how far along
    // it is in processing a request.
    RegU#(MemReq) curReq;
    Reg#(ReqStatus) state(Ready);
    
    // Hit/miss counters
    Reg#(Word) hits(0);
    Reg#(Word) misses(0);

    input Maybe#(MemReq) req default = Invalid;
    
    // TODO return True if the cache can accept a new request
    method Bool reqEnabled = False;

    // TODO return True if the cache is in lookup and it is a hit
    function Bool isHit;
        return False;
    endfunction

    rule tick;
        if (state == Ready && isValid(req)) begin
            // TODO Your code here 
        end else if (state == Lookup) begin
            // TODO Your code here
        end else if (state == Writeback && mainMem.reqEnabled) begin
            // TODO Your code here
        end else if (state == Fill && isValid(mainMem.data)) begin
            // TODO Your code here
        end
    endrule

    method Maybe#(Word) data;
        // This method should return a Valid output in only two cases:
        // 1. On a load hit (it is a hit, and curReq.op == Ld).
        // 2. On a fill for a load request (we're in the Fill state,
        //    mainMem.data is valid, and curReq.op == Ld).
        // In all other cases, the output should be Invalid
        //
        // NOTE: You should be checking the above conditions explicitly in
        //    THIS method so you can return data as soon as possible.
        //    DO NOT place your output into a register in the rule and then
        //    simply return that register here.
        // This function should take about 4-8 lines of code to implement.
        // TODO Your code here.
        return Valid(0);
    endmethod
    method Bit#(32) getHits = hits;
    method Bit#(32) getMisses = misses;
endmodule",Programming,"import CacheTypes;
import CacheHelpers;
import MainMemory;

// ReqStatus (defined in CacheTypes.ms) is used to keep track of the state of the current request
//typedef enum {
//    Ready,         // The cache is ready for a new request
//    Lookup,        // Issued a lookup to tag/data arrays
//    Writeback,     // In main memory access for dirty writeback
//    Fill           // In main memory access for requested data
//} ReqStatus;
//
// Possible flows:
//   HIT: Ready -> Lookup -> Ready
//   MISS, line is clean: Ready -> Lookup -> Fill
//   MISS, line is dirty: Ready -> Lookup -> Writeback -> Fill

// Cache SRAM Synonyms (defined in CacheTypes.ms)
// You may find the following type synonyms helpful to access the tag/data/status arrays
// typedef SRAMReq#(logCacheSets, CacheTag) TagReq;
// typedef SRAMReq#(logCacheSets, Line) DataReq;
// typedef SRAMReq#(logCacheSets, CacheStatus) StatusReq;

// TODO: Complete the implementation of DirectMappedCache
// NOTE: Implementing this module requires about 50 lines of additional code
// (~40 lines in rule tick, ~5-10 lines in method data, 1 line in method reqEnabled, 1 line in function isHit)
module DirectMappedCache(MainMemory mainMem);
    // SRAM arrays. Note that, for a direct-mapped cache,
    // number of cache sets == number of cache lines
    SRAM#(logCacheSets, Line) dataArray;
    SRAM#(logCacheSets, CacheTag) tagArray;
    SRAM#(logCacheSets, CacheStatus) statusArray;
 
    // Registers for holding the current state of the cache and how far along
    // it is in processing a request.
    RegU#(MemReq) curReq;
    Reg#(ReqStatus) state(Ready);
    
    // Hit/miss counters
    Reg#(Word) hits(0);
    Reg#(Word) misses(0);

    input Maybe#(MemReq) req default = Invalid;
    
    // TODO return True if the cache can accept a new request
    method Bool reqEnabled = state == Ready;

    // TODO return True if the cache is in lookup and it is a hit
    function Bool isHit(CacheTag tag);
        return state == Lookup && getTag(curReq.addr) == tag;
    endfunction

    rule tick;
        if (state == Ready && isValid(req)) begin
            // TODO Your code here 
            curReq <= fromMaybe(?, req);
            MemReq newReq = fromMaybe(?, req);
            CacheIndex index = getIndex(newReq.addr);
            tagArray.req = Valid(TagReq{addr: index, write: False, data: ?});
            statusArray.req = Valid(StatusReq{addr: index, write: False, data: ?});
            dataArray.req = Valid(DataReq{addr: index, write: False, data: ?});
            state <= Lookup;
        end else if (state == Lookup) begin
            // TODO Your code here
            CacheIndex index = getIndex(curReq.addr);
            let tag = fromMaybe(?, tagArray.data);
            let status = fromMaybe(?, statusArray.data);
            let data = fromMaybe(?, dataArray.data);
            if (isHit(tag) && status != NotValid) begin
                hits <= hits + 1;
                if (curReq.op == St) begin
                    Line newLine = data;
                    newLine[getWordOffset(curReq.addr)] = curReq.data;
                    dataArray.req = Valid(DataReq{addr: index, write: True, data: newLine});
                    statusArray.req = Valid(StatusReq{addr: index, write: True, data: Dirty});
                end
                state <= Ready;
            end else begin
                misses <= misses + 1;
                if (status == NotValid || status == Clean) begin
                    mainMem.req = Valid(LineReq{op: Ld, lineAddr: getLineAddr(curReq.addr), data: ?});
                    state <= Fill;
                end else if (status == Dirty) begin
                    mainMem.req = Valid(LineReq{op: St, lineAddr: {tag, index}, data: data});
                    state <= Writeback;
                end
            end
        end else if (state == Writeback) begin
            // TODO Your code here
            if (mainMem.reqEnabled == True) begin
                mainMem.req = Valid(LineReq{op: Ld, lineAddr: getLineAddr(curReq.addr), data: ?});
                state <= Fill;
            end
        end else if (state == Fill) begin
            // TODO Your code here
            if (isValid(mainMem.data)) begin
                CacheIndex index = getIndex(curReq.addr);
                CacheTag newTag = getTag(curReq.addr);
                Line newLine = fromMaybe(?, mainMem.data);
                if (curReq.op == Ld) begin
                    statusArray.req = Valid(StatusReq{addr: index, write: True, data: Clean});
                end else 
                if (curReq.op == St) begin
                    statusArray.req = Valid(StatusReq{addr: index, write: True, data: Dirty});
                    newLine[getWordOffset(curReq.addr)] = curReq.data;
                end
                tagArray.req = Valid(TagReq{addr: index, write: True, data: newTag});
                dataArray.req = Valid(DataReq{addr: index, write: True, data: newLine});
                state <= Ready;
            end
        end
    endrule

    method Maybe#(Word) data;
        // This method should return a Valid output in only two cases:
        // 1. On a load hit (it is a hit, and curReq.op == Ld).
        // 2. On a fill for a load request (we're in the Fill state,
        //    mainMem.data is valid, and curReq.op == Ld).
        // In all other cases, the output should be Invalid
        //
        // NOTE: You should be checking the above conditions explicitly in
        //    THIS method so you can return data as soon as possible.
        //    DO NOT place your output into a register in the rule and then
        //    simply return that register here.
        // This function should take about 4-8 lines of code to implement.
        // TODO Your code here.
        let tag = fromMaybe(?, tagArray.data);
        if (isHit(tag) && curReq.op == Ld) begin
            Line newLine = fromMaybe(?, dataArray.data);
            return Valid(newLine[getWordOffset(curReq.addr)]);
        end else if (state == Fill && isValid(mainMem.data) && curReq.op == Ld) begin
            Line newLine = fromMaybe(?, mainMem.data);
            return Valid(newLine[getWordOffset(curReq.addr)]);
        end else return Invalid;
    endmethod
    method Bit#(32) getHits = hits;
    method Bit#(32) getMisses = misses;
endmodule","The Processor module in Processor.ms should implement the single-cycle processor. We have provided skeleton code for Processor, which instantiates all state elements and has a single rule that should execute an instruction. Before you can test your processor, you need to complete the skeleton code for this rule. Fortunately, because we have structured the code to have most of the logic in the decode and execute functions (Section 1), the Processor code you need to write is quite short, less than 20 lines of code.
As you fill in your processor and decode and execute functions, you can build your processor by running make Processor, and you can run the microtests or fullasmtests on the processor by running ./test.py. After filling in your processor and at least parts of your decode and execute functions, you should be able to pass some early microtests (./test.py 1, ./test.py 2, etc.). To get credit for nishing your processor, you should pass the microtests (./test.py a) and the fullasmtests (./test.py f).
Complete the Processor module in Processor.ms.
Note: The processor code will not be ready for testing yet: you will be testing it once you finish each instruction class in both Decode.ms and Execute.ms.
Overall, your processor needs to do these things every cycle:
1. Fetch the instruction your processor should decode and execute from memory, i.e., load it. The program counter pc will hold the address of this instruction. For example, at the start of every microtest
when pc is 0, your processor should load the word at address 0.
NOTE: The two memory modules, iMem and dMem, have combinational reads: memory reads return data in the same cycle. This is unrealistic, and hence these memories are MagicMemory modules. In future lectures and in the design project, you will learn how to implement a processor with memories where reads return data one or several cycles later.
For this part of the processor, you should use the instruction memory, iMem. To load from a memory, call its read() method, which accepts a Word as the address you want to access. For example, iMem.read(32'd4) reads the word at address 4. Addresses must be multiples of 4.
2. Decode the instruction to gure out its instruction type, ALU operation, and operands. For example, in microtest 1, the rst instruction in raw hexadecimal is 0x000010b7. To decode it, you must find that it is an LUI instruction and then determine its destination register and immediate.
In Processor.ms, the decode function is already imported from Decode.ms. It takes in a single argument, the instruction as a Word, and returns a struct of type DecodedInst. For now, just call decode with the instruction you loaded, and put the result in a variable; you will fill in decode in Section 4.
3. Read from the registers any values that the instruction might need. We have provided you with a register le rf, of type RegisterFile, which contains 32 registers, where register 0 is hardwired to 0. In every cycle, you can read from two of its registers and write to one of its registers. The code to read from rf is rf.rd1(x) or rf.rd2(x) (there are two methods because you should only call each of these methods once per cycle), where x is a Bit#(5), the x-number of the register.
You can get the x-numbers of the registers to read from your DecodedInst, which has src1 and src2 fields. Note that it is safe and actually simpler than the alternative to always read from two registers every cycle, even for instructions that only need values from zero or one registers, since reading unnecessary values doesn't have side effects and can just be ignored by the next step.
4. Execute the instruction to figure out what you need to do. Eects of the instruction include that you might need to write to a register, load data from memory, store data to memory, and update the program counter pc to the next value.
In Processor.ms, the execute function is already imported from Execute.ms. It takes in four argu-
ments:
(a) the decoded instruction as a DecodedInst;
(b) the value in the rst register to be read (rs1), as a Word, if any;
(c) the value in the second register to be read (rs2), as a Word, if any;
(d) the current program counter (pc), as a Word.
It returns a struct of type ExecInst. You should call execute with the instruction you decoded and the other information required, and put the result in a variable; you will fill in execute in Section 5.
5. Load from or store to memory, if the instruction requires you to, using dMem. Like iMem, you can load from dMem with the read() method. To write to the data memory, use the write input to dMem, which accepts a Maybe#(MemWriteReq). The MemWriteReq struct has the following format:
typedef struct { Word addr; Word data; } MemWriteReq;
For example, to write 0x1234 to address 0x100:
dMem.write = Valid(MemWriteReq{addr: 32'h100, data: 32'h1234});
If you are executing a LW instruction, the data you load from memory needs to get written to a register. You can put the loaded data in the data eld of your ExecInst so that the logic for writing a register (in the next step) can handle it like all other register writes.
6. Write to a register, if the instruction requires you to. Writing rf, allowed only once each cycle, is done by setting the register le's wr input:
rf.wr = Valid(RegWriteArgs{index: x, data: data});
where x is the x-number of the register and data is a Word, the data you are writing into the register.
You can get the register you might need to write from your ExecInst, which has a dst field.
Note that unlike the reading from registers step, if an instruction isn't supposed to write to a register, then you need to make sure no register is written to. To do this, set rf.wr to Invalid (or don't set it).
7. Update the program counter pc. You can again get this from your ExecInst, which has a nextPc field.

import ProcTypes;
import RegisterFile;
import Decode;
import Execute;
import MagicMemory;

module Processor;
    Reg#(Word) pc(0);
    RegisterFile rf;
    MagicMemory iMem; // Memory for loading instructions
    MagicMemory dMem; // Memory for loading and storing data

    rule doSingleCycle;
        // Load the instruction from instruction memory (iMem)
        Word inst = 0; // TODO Replace 0 with the correct value

        // Decode the instruction
        DecodedInst dInst = unpack(0); // TODO Replace unpack(0) with the correct value

        // Read the register values used by the instruction
        Word rVal1 = 0; // TODO Replace 0 with the correct value
        Word rVal2 = 0; // TODO Replace 0 with the correct value

        // Compute all outputs of the instruction
        ExecInst eInst = unpack(0); // TODO Replace unpack(0) with the correct value

        if (eInst.iType == LOAD) begin
            // TODO: Load from data memory (dMem) if the instruction requires it
        end else if (eInst.iType == STORE) begin
            // TODO: Store to data memory (dMem) if the instruction requires it
        end

        if (isValid(eInst.dst)) begin
            // TODO: Write to a register if the instruction requires it
        end

        // TODO: Update pc to the next pc

        // If unsupported instruction, stops simulation and print the state of the processor
        // IMPORTANT: Do not modify this code! The microtests check for it.
        if (eInst.iType == Unsupported) begin
            $display(""Reached unsupported instruction (0x%x)"", inst);
            $display(""Dumping the state of the processor"");
            $display(""pc = 0x%x"", pc);
            $display(rf.fshow);
            $display(""Quitting simulation."");
            $finish;
        end
    endrule

    // This method exists to make the processor synthesizable: synth removes
    // circuits without outputs, so we need some non-trivial output to avoid
    // removing the processor :)
    method Word getPc = pc;
endmodule","import ProcTypes;
import RegisterFile;
import Decode;
import Execute;
import MagicMemory;

module Processor;
    Reg#(Word) pc(0);
    RegisterFile rf;
    MagicMemory iMem; // Memory for loading instructions
    MagicMemory dMem; // Memory for loading and storing data

    rule doSingleCycle;
        // Load the instruction from instruction memory (iMem)
        Word inst = iMem.read(pc); // TODO Replace 0 with the correct value

        // Decode the instruction
        DecodedInst dInst = decode(inst); // TODO Replace unpack(0) with the correct value

        // Read the register values used by the instruction
        Word rVal1 = rf.rd1(dInst.src1); // TODO Replace 0 with the correct value
        Word rVal2 = rf.rd2(dInst.src2); // TODO Replace 0 with the correct value

        // Compute all outputs of the instruction
        ExecInst eInst = execute(dInst, rVal1, rVal2, pc); // TODO Replace unpack(0) with the correct value

        if (eInst.iType == LOAD) begin
            // TODO: Load from data memory (dMem) if the instruction requires it
            eInst.data = dMem.read(eInst.addr);
        end else if (eInst.iType == STORE) begin
            // TODO: Store to data memory (dMem) if the instruction requires it
            dMem.write = Valid(MemWriteReq{addr: eInst.addr, data: eInst.data});
        end

        if (isValid(eInst.dst)) begin
            // TODO: Write to a register if the instruction requires it
            rf.wr = Valid(RegWriteArgs{index: fromMaybe(?, eInst.dst), data: eInst.data});
        end

        // TODO: Update pc to the next pc
        pc <= eInst.nextPc;

        // If unsupported instruction, stops simulation and print the state of the processor
        // IMPORTANT: Do not modify this code! The microtests check for it.
        if (eInst.iType == Unsupported) begin
            $display(""Reached unsupported instruction (0x%x)"", inst);
            $display(""Dumping the state of the processor"");
            $display(""pc = 0x%x"", pc);
            $display(rf.fshow);
            $display(""Quitting simulation."");
            $finish;
        end
    endrule

    // This method exists to make the processor synthesizable: synth removes
    // circuits without outputs, so we need some non-trivial output to avoid
    // removing the processor :)
    method Word getPc = pc;
endmodule","We will be using the following program to examine our cache behavior. Let N = 16 be the size of data region, in words. Let A be an array of N elements, located initially at 0x240. Note that these values are hardcoded into the program below but we will be changing them later.
// A = 0x240, starting address of array
// N = 16, size of data region
// this program adds 16 words from array A, then repeats.
. = 0x200
test:
li a0, 16 // initialize loop index i
li a1, 0 // sum = 0
loop: // add up elements in array
addi a0, a0, -1 // decrement index
slli a2, a0, 2 // convert to index byte offset
lw a3, 0x240(a2) // load value of A[i]
add a1, a1, a3 // add to sum
bnez a0, loop // loop until all words are summed
j test // perform test again!
// Array
. = 0x240
.word ... // A[0]
.word ... // A[1]
...
.word ... // A[15]
Our cache has a total of 64 words. The initial configuration is direct mapped, with 1 word per line, so the cache has 64 lines numbered 0-63 (0x00 - 0x3F).
To achieve 100% steady state hit ratio, it must be the case that the instructions and array data can reside in the cache at the same time. Let's check if this is currently the case.
All of the instructions and all of the data elements happen to have the same tag, what is the value of this tag? Provide your answer in hexadecimal.","0x2.
The address of the first instruction is 0x200 = 0b_0010_0000_0000.
The address of the last instruction is 0x21C = 0b_0010_0001_1100.
The address of the first data element, A[0] is 0x240 = 0b_0010_0100_0000.
The address of the last data element, A[15], is 0x27C = 0b_0010_0111_1100.
The bottom 8 bits of the address are used for the 6 bit index and 2 bit word alignment. The remaining bits make up the tag which is 0x2 for all of the instructions and data elements.","We will be using the following program to examine our cache behavior. Let N = 16 be the size of data region, in words. Let A be an array of N elements, located initially at 0x240. Note that these values are hardcoded into the program below but we will be changing them later.
// A = 0x240, starting address of array
// N = 16, size of data region
// this program adds 16 words from array A, then repeats.
. = 0x200
test:
li a0, 16 // initialize loop index i
li a1, 0 // sum = 0
loop: // add up elements in array
addi a0, a0, -1 // decrement index
slli a2, a0, 2 // convert to index byte offset
lw a3, 0x240(a2) // load value of A[i]
add a1, a1, a3 // add to sum
bnez a0, loop // loop until all words are summed
j test // perform test again!
// Array
. = 0x240
.word ... // A[0]
.word ... // A[1]
...
.word ... // A[15]
Our cache has a total of 64 words. The initial configuration is direct mapped, with 1 word per line, so the cache has 64 lines numbered 0-63 (0x00 - 0x3F).
To achieve 100% steady state hit ratio, it must be the case that the instructions and array data can reside in the cache at the same time. Let's check if this is currently the case.
Which cache line (index) does A[0] map to? Provide your answer in hexadecimal.","0x10.
The address of A[0] is 0x240 = 0b_0010_0100_0000. The bottom two bits are used for word alignment. Bits[7:2] are the index bits = 0b010000 = 0x10. So A[0] maps to index 0x10 (or line 16)."
205,Mathematics,18.01,Calculus I,None,None,Problem Set 5,Second Derivatives,9,c,0.04751847941,Text,"A graphing problem using second derivatives. Let $f(x)=x e^{-x}$. We will graph $f(x)$ on the range $0 \leq x$. But first we compute some information about $f(x)$.
For which $x$ is $f^{\prime \prime}(x)=0$ ? For which $x$ is $f^{\prime \prime}(x)>0$ and for which $x$ is $f^{\prime \prime}(x)<0$ ?",Expression,$f^{\prime \prime}(x)=0$ (inflection point) when $x=2 . f^{\prime \prime}(x)>0$ (concave up) when $x>2$. $f^{\prime \prime}(x)<0$ (concave down) when $x<2$.,"A graphing problem using second derivatives. Let $f(x)=x e^{-x}$. We will graph $f(x)$ on the range $0 \leq x$. But first we compute some information about $f(x)$.
For which $x$ is $f^{\prime}(x)=0$ ? For which $x$ is $f^{\prime}(x)>0$ and for which $x$ is $f^{\prime}(x)<0$?",$f^{\prime}(x)=0$ (maximum) when $x=1 . f^{\prime}(x)>0$ (increasing) when $x<1 . f^{\prime}(x)<0$ (decreasing) when $x>1$.,"A graphing problem using second derivatives. Let $f(x)=x e^{-x}$. We will graph $f(x)$ on the range $0 \leq x$. But first we compute some information about $f(x)$.
Compute $f^{\prime}(x)$ and $f^{\prime \prime}(x)$.",$f^{\prime}(x)=(1-x) e^{-x}$ (product rule) and $f^{\prime \prime}(x)=(x-2) e^{-x}$ (product rule again).,"A graphing problem using second derivatives. Let $f(x)=x e^{-x}$. We will graph $f(x)$ on the range $0 \leq x$. But first we compute some information about $f(x)$.
For which value of $x$ is $f^{\prime}(x)$ the most negative?","When $f^{\prime}(x)$ is the most negative, $f^{\prime}(x)$ is at a minimum. Thus, $f^{\prime \prime}(x)$ must be zero, which happens only when $x=2$."
181,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Midterm Exam 3,Operating Systems,2,b,0.45,Text,"Consider the following two processes running RISC-V programs labeled with virtual addresses. Note that all pseudoinstructions in this code translate into a single RISC-V instruction.
Program for Process A
.=0x200
li t0, 5000
li t1, 0
loop:
li a0, 0x300
li a7, 0x13 // print system call
ecall
addi t1, t1, 1
ble t1, t0, loop
j exit // exit process
.=0x300
.ascii “Hello from process A\n”
Program for Process B
.=0x450
li t0, 50
li t1, 10
div t2, t0, t1
sw t2, 0x900(x0)
li a0, 0x600
li a7, 0x13 // print system call
ecall
j exit // exit process
.=0x600
.ascii “Hello from Process B\n”
Assume the OS schedules Process B first. For the following questions, if you can’t tell a value based on the information given, write CAN’T TELL.
What are the values in the following registers just after the first ecall in Process A completes?
t0:
t1:
pc:",Numerical,"t0: ______5000_________
t1: _______0___________
pc: _____0x214_________","Consider the following two processes running RISC-V programs labeled with virtual addresses. Note that all pseudoinstructions in this code translate into a single RISC-V instruction.
Program for Process A
.=0x200
li t0, 5000
li t1, 0
loop:
li a0, 0x300
li a7, 0x13 // print system call
ecall
addi t1, t1, 1
ble t1, t0, loop
j exit // exit process
.=0x300
.ascii “Hello from process A\n”
Program for Process B
.=0x450
li t0, 50
li t1, 10
div t2, t0, t1
sw t2, 0x900(x0)
li a0, 0x600
li a7, 0x13 // print system call
ecall
j exit // exit process
.=0x600
.ascii “Hello from Process B\n”
Assume the OS schedules Process B first. For the following questions, if you can’t tell a value based on the information given, write CAN’T TELL.
A timer interrupt occurs just prior to the execution of li t1, 10 in Process B. Process A runs for some time, then another timer interrupt occurs and control is returned to Process B. What are the values in the following registers immediately after returning to Process B?
t0:
t1:
pc:","t0: _______50__________
t1: __CAN’T TELL or 0_
pc: _____0x454_________","Consider the following two processes running RISC-V programs labeled with virtual addresses. Note that all pseudoinstructions in this code translate into a single RISC-V instruction.
Program for Process A
.=0x200
li t0, 5000
li t1, 0
loop:
li a0, 0x300
li a7, 0x13 // print system call
ecall
addi t1, t1, 1
ble t1, t0, loop
j exit // exit process
.=0x300
.ascii “Hello from process A\n”
Program for Process B
.=0x450
li t0, 50
li t1, 10
div t2, t0, t1
sw t2, 0x900(x0)
li a0, 0x600
li a7, 0x13 // print system call
ecall
j exit // exit process
.=0x600
.ascii “Hello from Process B\n”
Assume the OS schedules Process B first. For the following questions, if you can’t tell a value based on the information given, write CAN’T TELL.
The RISC-V processor does not have hardware to support a div (integer division) instruction, so the OS must emulate it. What are the values in the following registers after div is emulated?
t0:
t1:
t2:
pc:","t0: _______50_________
t1: _______10_________
t2: ________5_________
pc: ____0x45C________","Please assume that all registers are initialized to 0, and the instructions in the section below are executed one after another.
addi a1, a2, 9
lui a2, 3
li a3, 3 
sub a3, a3, a1
slt a4, a3, zero
sltu a5, a3, zero
li a4, 1
beq a5, zero, L1
slli a4, a4, 2
L1:
slli a4, a4, 5
What final value (answer in 32-bit hexadecimal format like 0x0CDEF1AF) will be inside the register a4 after all entire code snippet above is executed?","0x00000020.
The instruction li a4, 1 first sets the value inside a4 to be 1.
Then, the instruction beq a5, zero, L1 checks whether the value inside a5 is equal to the value in zero or not. In this case, the value inside a5 from the previous section is 0, so the beq jumps to the specified label, L1, and continues its execution there.
Finally, the instruction slli a4, a4, 5. It shifts the value inside a4 the left by 5 bits and writes the shifted result back into a4. a4 was just set to 1 or 0b0000 0000 0000 0000 0000 0000 0000 0001. Shifting this value by 5 bits to the left results in a value of 0b0000 0000 0000 0000 0000 0000 0010 0000 which is 0x00000020 in hexadecimal. This result is written to the destination register which also happens to be a4 in this instruction."
160,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Midterm Exam 2,Sequential Circuits in Minispec,4,c,1.2,Text,"You are frustrated with the 77 Mass. Ave crosswalk and decide to design a better traffic signal in Minispec. To start, you want to make sure the traffic light will function well in the daytime when there’s lots of traffic. After carefully analyzing traffic patterns, you define the following specification:
• The traffic light should be red for 4 cycles, then green for 10 cycles, then yellow for 1 cycle, and repeat this pattern indefinitely.
• The light starts red (and should stay red for 4 cycles before turning green).
• Pedestrians can only cross when the light is red.
Now you want to add a new feature to your traffic light. During the daytime, you want it to work as in part (A). But during the nighttime, the traffic light should work differently:
• By default, the light should be green.
• When a pedestrian requests to cross the street and the light is green, it should remain green for 3 more cycles, turn yellow for 1 cycle, then red for 4 cycles. Then it should go back to being green indefinitely.
• If a pedestrian requests to cross the street when the light is yellow or red, this request should be ignored and have no effect.
• If a pedestrian requests to cross the street while the light is green, and a pedestrian requests to cross the street in a following cycle when the light is still green, this request should also have no effect.
You also want to add a feature for emergency pedestrian requests. In an emergency, if a pedestrian requests to cross, the light should immediately turn yellow on the next cycle. The pedestrian request is provided as a Maybe#(PedestrianRequest) type – on each cycle it will either be:
• Invalid (no pedestrian request)
• Standard (a standard pedestrian request was made)
• Emergency (an emergency pedestrian request was made)
Note that your implementation should still work when the input transitions from daytime to nighttime, even though in daytime the Green light is 10 cycles and in nighttime it is only 3 cycles following a pedestrian request. Thus, if it is nighttime and our counter variable is too large (because we were counting down from a larger value during the daytime), we should “clamp” it to be no larger than it can be in nighttime. We have provided a currentCounter variable to use for this purpose – i.e. it will be clamped to the maximum value the counter can be during nighttime.
Fill in the Minispec module below to add this functionality. We have provided two inputs – one for whether it is currently nighttime or daytime, and one for whether a pedestrian has requested to cross the street in this cycle.
typedef enum { Green, Yellow, Red } LightState;
typedef enum { Daytime, Nighttime } TimeOfDay;
typedef enum { Standard, Emergency } PedestrianRequest;
module TrafficLight;
Reg#(LightState) light(_<answer from Part A>_);
Reg#(Bit#(_<answer from Part A>_)) counter(_<answer from part A>_);
input TimeOfDay timeOfDay default = Nighttime;
input Maybe#(PedestrianRequest) pedestrianRequest default = Invalid;
method Bool pedestriansCanCross = <answer from part A>;
method LightState currentLight = <answer from part A>;
rule tick;
if (timeOfDay == Daytime) begin
<Your answer from Part A>
end else begin
if (light == Green) begin
Bit#(<answer from part A>) currentCounter;
// Clamp currentCounter to the maximum value counter
// can be for a Green light at night
 currentCounter = counter > ____ ? ____ : counter;
if (currentCounter == 0) begin
light <= __________;
// Check if received pedestrian request this cycle
end else if (___________________________________)
begin
// Handle emergency request
if (__________________________________) begin
light <= ___________________________;
end else begin
counter <= _________________________;
end
end else if (currentCounter < _______________) begin
counter <= ___________________________;
end else begin
 counter <= ___________________________;
end
end else if (light == Yellow) begin
<Your answer from Part A>
end else if (light == Red) begin
<Your answer from Part A>
end
end
endrule
endmodule",Programming,"typedef enum { Green, Yellow, Red } LightState;
typedef enum { Daytime, Nighttime } TimeOfDay;
typedef enum { Standard, Emergency } PedestrianRequest;
module TrafficLight;
Reg#(LightState) light(_<answer from Part A>_);
Reg#(Bit#(_<answer from Part A>_)) counter(_<answer from part A>_);
input TimeOfDay timeOfDay default = Nighttime;
input Maybe#(PedestrianRequest) pedestrianRequest default = Invalid;
method Bool pedestriansCanCross = <answer from part A>;
method LightState currentLight = <answer from part A>;
rule tick;
if (timeOfDay == Daytime) begin
<Your answer from Part A>
end else begin
if (light == Green) begin
Bit#(<answer from part A>) currentCounter;
// Clamp currentCounter to the maximum value counter
// can be for a Green light at night
currentCounter = counter > ___3_ ? ___3_ : counter;
if (currentCounter == 0) begin
light <= ___Yellow___;
// Check if received pedestrian request this cycle
end else if (_____isValid(pedestrianRequest)_____)
begin
// Handle emergency request
if (fromMaybe(?, pedestrianRequest) ==
Emergency) begin
light <= ____Yellow_________________;
end else begin
counter <= ___currentCounter - 1____;
end
end else if (currentCounter < ______3________) begin
counter <= ___currentCounter - 1______;
end else begin
counter <= ___currentCounter_(or 3)____;
end
end else if (light == Yellow) begin
<Your answer from Part A>
end else if (light == Red) begin
<Your answer from Part A>
end
end
endrule
endmodule","You are frustrated with the 77 Mass. Ave crosswalk and decide to design a better traffic signal in Minispec. To start, you want to make sure the traffic light will function well in the daytime when there’s lots of traffic. After carefully analyzing traffic patterns, you define the following specification:
• The traffic light should be red for 4 cycles, then green for 10 cycles, then yellow for 1 cycle, and repeat this pattern indefinitely.
• The light starts red (and should stay red for 4 cycles before turning green).
• Pedestrians can only cross when the light is red.
Fill in the Minispec module on the next page to track the traffic light state as a sequential circuit.
• The pedestriansCanCross method should return True if and only if the light is in a state where pedestrians are allowed to cross.
• The currentLight method should return the current state of the traffic light.
• We have provided a counter register – use this to count down to the next state transition.
typedef enum { Green, Yellow, Red } LightState;
module TrafficLight;
Reg#(LightState) light(_________);
Reg#(Bit#(_________)) counter(___________);
method Bool pedestriansCanCross = _______________;
method LightState currentLight = _______________;
rule tick;
if (light == Green) begin
if (counter == 0) begin
light <= _____________;
end else begin
counter <= ____________;
end
end else if (light == Yellow) begin
light <= ______________;
counter <= ____________;
end else if (light == Red) begin
if (counter == 0) begin
light <= ____________;
counter <= ___________;
end else begin
counter <= ___________;
end
end
endrule
endmodule","typedef enum { Green, Yellow, Red } LightState;
module TrafficLight;
Reg#(LightState) light(___Red___);
Reg#(Bit#(____4_____)) counter(_____3______);
method Bool pedestriansCanCross = _light == Red__;
method LightState currentLight = __light_________;
rule tick;
if (light == Green) begin
if (counter == 0) begin
light <= __Yellow_____;
end else begin
counter <= __counter - 1__;
end
end else if (light == Yellow) begin
light <= ___Red________;
counter <= ______3______;
end else if (light == Red) begin
if (counter == 0) begin
light <= ___Green____;
counter <= ____9_______;
end else begin
counter <= __counter - 1__;
end
end
endrule
endmodule","You are frustrated with the 77 Mass. Ave crosswalk and decide to design a better traffic signal in Minispec. To start, you want to make sure the traffic light will function well in the daytime when there’s lots of traffic. After carefully analyzing traffic patterns, you define the following specification:
• The traffic light should be red for 4 cycles, then green for 10 cycles, then yellow for 1 cycle, and repeat this pattern indefinitely.
• The light starts red (and should stay red for 4 cycles before turning green).
• Pedestrians can only cross when the light is red.
To ensure that your module behaves as expected, fill in the timing chart below with the register values and outputs for the first 6 cycles.
\begin{tabular}{|l|l|l|l|l|l|l|}
\hline Cycle & $\mathbf{0}$ & $\mathbf{1}$ & $\mathbf{2}$ & $\mathbf{3}$ & $\mathbf{4}$ & $\mathbf{5}$ \\
\hline counter &  &  &  &  &  &  \\
\hline light & & & & & & \\
\hline currentLight & & & & & & \\
\hline pedestriansCanCross & & & & & & \\
\hline
\end{tabular}","\begin{tabular}{|l|l|l|l|l|l|l|}
\hline Cycle & $\mathbf{0}$ & $\mathbf{1}$ & $\mathbf{2}$ & $\mathbf{3}$ & $\mathbf{4}$ & $\mathbf{5}$ \\
\hline counter & 3 & 2 & 1 & 0 & 9 & 8 \\
\hline light & Red & Red & Red & Red & Green & Green \\
\hline currentLight & Red & Red & Red & Red & Green & Green \\
\hline pedestriansCanCross & True & True & True & True & False & False \\
\hline
\end{tabular}","For each of the following questions you are asked to specify the result that the provided minispec code will produce.
Consider the following sequential module:
module Test;
    Reg#(Word) x(3);
    Reg#(Word) y(7);
    Reg#(Bit#(6)) cycle(0);
    rule runCycle;
        Word temp = x;
        x <= y;
        y <= temp;
        cycle <= cycle + 1;
        $display(""cycle = %d, x = %d, y = %d"", cycle, x, y);
        if (cycle >= 2) $finish;
    endrule
endmodule
Suppose that the runCycle code was modified so that it no longer used the temp variable and instead it just specified: x <= y; y <= x. Would this code behave differently from the way it was originally written?
(a) Yes.
(b) No.","(b) No.
Since all registers are updated at the same time, at the end of each cycle, there is no need to use the temp variable to specify that x and y should be swapped. The sequence of instructions x <= y; y <= x; will put the old value of x into y and will put the old value of y into x. In fact the order of those two statements will not change the behavior of the code."
54,Mathematics,18.2,Principles of Discrete Applied Mathematics,None,18.C06,Problem Set 10,Discrete Fourier Transform,3,a,0.6790123457,Text,"What is the Discrete Fourier Transform over $\mathbb{C}$ of $y=(1,1,0, i)$?",Expression,"We use the formula
$$
c_{k}=\sum_{j=0}^{n-1} y_{j} e^{-2 \pi i j k / n} .
$$
Since $n=4$, we have the roots
$$
r=\left(e^{-2 \pi i 0 / n}, e^{-2 \pi i 1 / n}, e^{-2 \pi i 2 / n}, e^{-2 \pi i 3 / n}\right)=(1,-i,-1, i).
$$
We need the different powers of these roots: $r_{k}=\left(1^{k},(-i)^{k},(-1)^{k}, i^{k}\right)$ for $k=0,1,2,3$. The dot product with $y$ gives us the transform, i.e.
$$
c_{k}=y \cdot r_{k}
$$
We then obtain $c=(2+i,-i,-i, 2+i)$.","Using the result in (a) above, what is the Discrete Fourier Transform of $z$?","Let $\hat{z}$ be the Fourier transform of $z$, then $\hat{z}=y \hat{*} y=\hat{y} \times \hat{y}=c \times c$, where $\times$ denotes pointwise multiplication. From this, we obtain
$$
\hat{z}=(3+4 i,-1,-1,3+4 i).
$$","Let $x[n]$ represent a discrete time signal whose DTFT is given by
$$
X(\Omega)= \begin{cases}1 & \text { if }|\Omega|<\frac{\pi}{5} \\ 0 & \text { if } \frac{\pi}{5}<|\Omega|<\pi\end{cases}
$$
and is periodic in $\Omega$ with period $2 \pi$ as shown below.
Determine an expression for $Y_{1}(\Omega)$ (the Fourier transform of $y_{1}[n]$ ) in terms of $Y_{0}(\Omega)$.
Make a plot of $Y_{1}(\Omega)$.
Briefly describe the relation between $Y_{0}(\Omega)$ and $Y_{1}(\Omega)$.","$$
\begin{aligned}
Y_{1}(\Omega) & =\sum_{n=-\infty}^{\infty} y_{1}[n] e^{-j \Omega n}=\sum_{n=-\infty}^{\infty}\left(\frac{1}{2} y_{0}[n-1]+y_{0}[n]+\frac{1}{2} y_{0}[n+1]\right) e^{-j \Omega n} \\
& =\frac{1}{2} e^{-j \Omega} Y_{0}(\Omega)+Y_{0}(\Omega)+\frac{1}{2} e^{j \Omega} Y_{0}(\Omega)=(1+\cos (\Omega)) Y_{0}(\Omega)
\end{aligned}
$$
The plot of $Y_{1}(\Omega)$ is below.
The overall amplitude of $Y_{1}(\Omega)$ is twice that of $Y_{0}(\Omega)$. This results because the values of $y_{0}[n]$ are zero for odd values of $n$, while those for $y_{1}[n]$ are not. Components of $Y_{1}(\Omega)$ near $\Omega=\pi$ are greatly reduced in magnitude relative to those in $Y_{0}(\Omega)$.
The net effect of these changes is to generate a new signal $Y_{1}(\Omega)$ with half the bandwidth of $X(\Omega)$. ","Let $y[n]$ represent the discrete-time signal that results from sampling $x(t)$ once every $\Delta=\frac{1}{2}$ second. Determine $Y(\Omega)$, which represents the discrete-time Fourier transform (DTFT) of $y$ [n]. Plot the magnitude and angle of $Y(\Omega)$ on the axes below.
Determine an expression for $y[n]$.","$$
\begin{aligned}
& y[n]=\frac{\sin \frac{\pi(n+2)}{2}}{\frac{\pi(n+2)}{2}} \\
& y[n]=x(n \Delta)=\left.\frac{\sin (\pi(t+1))}{\pi(t+1)}\right|_{t=n \Delta}=\frac{\sin \left(\pi\left(\frac{n}{2}+1\right)\right)}{\pi\left(\frac{n}{2}+1\right)}=2 \frac{\sin \left(\frac{\pi}{2}(n+2)\right)}{\pi(n+2)}
\end{aligned}
$$
Since $y[n]$ is a sinc function of $n, Y(\Omega)$ is a lowpass filter with cutoff frequency $\frac{\pi}{2}$ and DC value 2. There is a also a time shift of 2 since $n$ has been replaced by $n+2$. This time shift introduces a phase lead of $2 \Omega$. The final answer is
$$
Y(\Omega)= \begin{cases}2 e^{j 2 \Omega} & \text { if }-\pi<(\Omega+2 \pi m)<\pi \text { for some integer } m \\ 0 & \text { otherwise }\end{cases}
$$
The plot is below."
246,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Lab 9,Convolutional Neural Networks,4,a,0.1041666667,Text,"Many of us have seen applications of facial recognition in real life (ex. Unlocking a phone) and movies (ex. Jarvis, built by fictional MIT alum, Tony Stark, has facial recognition capabilities). In this lab, we are going to introduce some of the ethical and social considerations that arise in the development, deployment, and very existence of facial recognition systems.
Convolutional Neural Networks require a LOT of data to train well. What are some ethical and social implications in deciding whether and how to collect such data for facial recognition systems (e.g., labeled images of faces)?
Tip: Having trouble getting started? Think about this question from a security perspective, privacy perspective, consent perspective, etc. See this interesting Nature article on The ethical questions that haunt facial recognition research .",Open,"We want students to think about data privacy, security, consent, and monetization of softwares that use the image of unknowing, unconsenting individuals.
The nature article is really worth a read. To summarize, most research groups scrape the Internet/public sources to collect facial images (And do not ask for permission). Examples: In 2015, Stanford published a set of 12000 images from a webcam in a cafe in SF that had been live-streamed online. Researches at Duke released more than 2 million video frame footage of students walking around campus. MegaFace and MSCeleb are large datasets that have been posted online and were collected from the internet. Many of these larger datasets have been used to evaluate and improve commercial surveillance products. And quite a few of these datasets were published online in one place without a password in place.
There's also the issues to consider around data privacy. When you use a facial recognition model, your personal data is being sent to a model and there are both privacy and security risks associated with that.","Many of us have seen applications of facial recognition in real life (ex. Unlocking a phone) and movies (ex. Jarvis, built by fictional MIT alum, Tony Stark, has facial recognition capabilities). In this lab, we are going to introduce some of the ethical and social considerations that arise in the development, deployment, and very existence of facial recognition systems.
Even if we can make a perfect or ""fair"" facial recognition system, the first question we should ask (and one that is often skipped) is whether we should develop such technology at all. What are some of the potential ethical and social impacts facial recognition surveillance could have on society (Assuming it can be applied to any images or video feed in the world)? Think about this question from a security perspective, privacy perspective, consent perspective, and what such technologies could do in the hands of bad actors (and even well-intentioned actors).","Facial Recognition is dangerous. The ACLU is actually trying to get the government to regulate surveillance technology. To quote this ACLU article, ""Face recognition surveillance presents an unprecedented threat to our privacy and civil liberties. It gives governments, companies, and individuals the power to spy on us wherever we go - tracking our faces at protests, political rallies, places of worship, and more."" There is already an issue of governments using this to target particular minorities.","Many of us have seen applications of facial recognition in real life (ex. Unlocking a phone) and movies (ex. Jarvis, built by fictional MIT alum, Tony Stark, has facial recognition capabilities). In this lab, we are going to introduce some of the ethical and social considerations that arise in the development, deployment, and very existence of facial recognition systems.
Suppose you tested the facial recognition systems from Microsoft and IBM on a dataset of 1,270 faces, and you found these systems achieved accuracy rates of $93.7 \%$ and $87.9 \%$ respectively. Are these accuracy rates sufficiently high? Would you feel comfortable deploying either of these systems? What other tests might you want to conduct?",The data set is relatively small and the accuracy isn't that high either. So perhaps not a good idea to deploy as is. Would probably be a good idea to test and validate against more diverse data sets before full deployment.,"Many of us have seen applications of facial recognition in real life (ex. Unlocking a phone) and movies (ex. Jarvis, built by fictional MIT alum, Tony Stark, has facial recognition capabilities). In this lab, we are going to introduce some of the ethical and social considerations that arise in the development, deployment, and very existence of facial recognition systems.
Error analysis reveals that $93.6 \%$ of Microsoft's mislabeled faces were those of people with darker skin, and that the IBM system's error rate is $34.4 \%$ higher for women with darker skin than men with lighter skin (for more info, see Dr. Joy Buolamwini's research on gendershades.org. As we've learned, these discrepancies could be a consequence of a confluence of factors: imbalanced representation in the dataset, a bias introduced or amplified through architectural choices in modeling or training the neural network, etc. How might we fix this performance imbalance?","Supposed to be an open-ended question. Some ideas are: Diversify the data set. Adding regularization to the architecture to prevent overfitting. Connecting back to last lab, maybe robust network training could also help here."
180,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Midterm Exam 3,Operating Systems,2,a,0.45,Text,"Consider the following two processes running RISC-V programs labeled with virtual addresses. Note that all pseudoinstructions in this code translate into a single RISC-V instruction.
Program for Process A
.=0x200
li t0, 5000
li t1, 0
loop:
li a0, 0x300
li a7, 0x13 // print system call
ecall
addi t1, t1, 1
ble t1, t0, loop
j exit // exit process
.=0x300
.ascii “Hello from process A\n”
Program for Process B
.=0x450
li t0, 50
li t1, 10
div t2, t0, t1
sw t2, 0x900(x0)
li a0, 0x600
li a7, 0x13 // print system call
ecall
j exit // exit process
.=0x600
.ascii “Hello from Process B\n”
Assume the OS schedules Process B first. For the following questions, if you can’t tell a value based on the information given, write CAN’T TELL.
A timer interrupt occurs just prior to the execution of li t1, 10 in Process B. Process A runs for some time, then another timer interrupt occurs and control is returned to Process B. What are the values in the following registers immediately after returning to Process B?
t0:
t1:
pc:",Numerical,"t0: _______50__________
t1: __CAN’T TELL or 0_
pc: _____0x454_________","Consider the following two processes running RISC-V programs labeled with virtual addresses. Note that all pseudoinstructions in this code translate into a single RISC-V instruction.
Program for Process A
.=0x200
li t0, 5000
li t1, 0
loop:
li a0, 0x300
li a7, 0x13 // print system call
ecall
addi t1, t1, 1
ble t1, t0, loop
j exit // exit process
.=0x300
.ascii “Hello from process A\n”
Program for Process B
.=0x450
li t0, 50
li t1, 10
div t2, t0, t1
sw t2, 0x900(x0)
li a0, 0x600
li a7, 0x13 // print system call
ecall
j exit // exit process
.=0x600
.ascii “Hello from Process B\n”
Assume the OS schedules Process B first. For the following questions, if you can’t tell a value based on the information given, write CAN’T TELL.
What are the values in the following registers just after the first ecall in Process A completes?
t0:
t1:
pc:","t0: ______5000_________
t1: _______0___________
pc: _____0x214_________","Consider the following two processes running RISC-V programs labeled with virtual addresses. Note that all pseudoinstructions in this code translate into a single RISC-V instruction.
Program for Process A
.=0x200
li t0, 5000
li t1, 0
loop:
li a0, 0x300
li a7, 0x13 // print system call
ecall
addi t1, t1, 1
ble t1, t0, loop
j exit // exit process
.=0x300
.ascii “Hello from process A\n”
Program for Process B
.=0x450
li t0, 50
li t1, 10
div t2, t0, t1
sw t2, 0x900(x0)
li a0, 0x600
li a7, 0x13 // print system call
ecall
j exit // exit process
.=0x600
.ascii “Hello from Process B\n”
Assume the OS schedules Process B first. For the following questions, if you can’t tell a value based on the information given, write CAN’T TELL.
The RISC-V processor does not have hardware to support a div (integer division) instruction, so the OS must emulate it. What are the values in the following registers after div is emulated?
t0:
t1:
t2:
pc:","t0: _______50_________
t1: _______10_________
t2: ________5_________
pc: ____0x45C________","Now let's look back at the main code.
li a0, 0x2000
li a7, 0
lw a1, 0(a0)
// start of the code piece
L1 :
andi a2, a1, 1
beq a2, zero, L2
addi a7, a7, 1
L2 :
srli a1, a1, 1
// end of the code piece
bnez a1, L1
unimp
. = 0x2000
.word 0x12345678
Execution begins with the first instruction li a0, 0x2000 which initializes register a0 to 0x00002000. The next instruction sets register a7 to 0.
What does the lw a1, 0(a0) instruction write into register a1 (answer in 32-bit hexadecimal format like 0x0CDEF1AF)?","0x12345678.
This instruction loads the contents of the memory location whose address is computed by adding 0 to a0. Thus, a1 is initialized to the value in memory location 0x2000 which is 0x12345678."
35,EECS,6.18,Computer Systems Engineering,"6.1010, 6.1910",None,Midterm Exam 1,Unix,2,b,0.375,Text,"As a result of a fork, there are two processes running on a machine: the parent and the child $\mathrm{A}$. Immediately after returning from the fork() call, the parent forks again, creating child B. Neither child process has been scheduled yet (i.e., they have not yet had an opportunity to execute anything after the return from fork()). We are asking about an instant when the two children are fully created and completely ready to run, but before either has had a chance to run.
Select True or False for the following statement:
Processes $\mathrm{A}$ and $\mathrm{B}$ have identical file descriptors.",Multiple Choice,True.,"As a result of a fork, there are two processes running on a machine: the parent and the child $\mathrm{A}$. Immediately after returning from the fork() call, the parent forks again, creating child B. Neither child process has been scheduled yet (i.e., they have not yet had an opportunity to execute anything after the return from fork()). We are asking about an instant when the two children are fully created and completely ready to run, but before either has had a chance to run.
Select True or False for the following statement:
Child A knows the pid of Child B.",False.,"As a result of a fork, there are two processes running on a machine: the parent and the child $\mathrm{A}$. Immediately after returning from the fork() call, the parent forks again, creating child B. Neither child process has been scheduled yet (i.e., they have not yet had an opportunity to execute anything after the return from fork()). We are asking about an instant when the two children are fully created and completely ready to run, but before either has had a chance to run.
Select True or False for the following statement:
Child B knows the pid of Child A. Parent knows pid of $A$ when forking $B$, so $B$ knows to 0.",True.,"As a result of a fork, there are two processes running on a machine: the parent and the child $\mathrm{A}$. Immediately after returning from the fork() call, the parent forks again, creating child B. Neither child process has been scheduled yet (i.e., they have not yet had an opportunity to execute anything after the return from fork()). We are asking about an instant when the two children are fully created and completely ready to run, but before either has had a chance to run.
Select True or False for the following statement:
If virtual address $a$ maps to physical address $p$ in process $A$, then virtual address $a$ maps to physical address $p$ in process $B$.",False.
155,Mathematics,18.03,Differential Equations,None,18.02,Final Exam,Boundary Value Problems,9,nan,3.614457831,Text,"Consider the function
$$
f(x)=x(\pi-x)
$$
Find the function $u(x, t)$ solving the partial differential equation
$$
\frac{\partial u}{\partial t}=\frac{\partial^{2} u}{\partial x^{2}} \quad u(0, t)=u(\pi, t)=0
$$
for $x \in[0, \pi]$ and $t \geq 0$ subject to the initial condition
$$
u(x, 0)=f(x) .
$$",Expression,"We recall that a solution to the heat equation with Dirichlet boundary condition is
$$
c e^{-n^{2} t} \sin (n x)
$$
Now we find a sine series for the initial condition by finding the Fourier series of the odd extension of $f(x)$. Since it is an odd function, we have $\tilde{a}_{0}=0$ and $a_{n}=0$ for all $n \geq 1$. For $n \geq 1$
$$
\begin{aligned}
b_{n} &=\frac{2}{\pi} \int_{0}^{\pi} x(\pi-x) \sin (n x) d x \\
&=\frac{2}{\pi}\left[\frac{-x(\pi-x)}{n} \cos (n x)\right]_{0}^{\pi}+\frac{2}{\pi} \int_{0}^{\pi} \frac{\pi-2 x}{n} \cos (n x) d x \\
&=0+\frac{2}{\pi}\left[\frac{\pi-2 x}{n^{2}} \sin (n x)\right]_{0}^{\pi}+\frac{4}{n^{2} \pi} \int_{0}^{\pi} \sin (n x) d x \\
&=0-\frac{4}{n^{3} \pi}[\cos (n x)]_{0}^{\pi}=\frac{4}{n^{3} \pi}\left(1-(-1)^{n}\right)
\end{aligned}
$$
where in the second and the third line we have used integration by parts. In the last equality, we have also used $\cos (n \pi)=(-1)^{n}$. Thus, a sine series for $f$ on $[0, \pi]$ is given by
$$
f(x)=\sum_{n \geq 1, n \text { odd }} \frac{8}{n^{3} \pi} \sin (n x) .
$$
We use this series to find the solution
$$
u(x, t)=\sum_{n \geq 1, n \text { odd }} \frac{8}{n^{3} \pi} e^{-n^{2} t} \sin (n x).
$$","Consider the function $f(x)=x(\pi-x)$ on $[0, \pi]$.
Find the solution of the equation
$$
\begin{aligned}
&\frac{\partial}{\partial t} u(x, t)=\frac{\partial^{2}}{\partial x^{2}} u(x, t) \quad x \in(0, \pi), t>0 \\
&u(0, t)=u(\pi, t)=0 \\
&u(x, t)=f(x)
\end{aligned}
$$
Your solution may be left in complex form. (Hint: You may want to recall what you computed on Problem Set 8).","From Problem Set 8, we have a sine series for $f(x)$.
$$
f(x)=\sum_{n \geq 1, n \text { odd }} \frac{8}{n^{3} \pi} \sin (n x) .
$$
Thus, for Dirichlet boundary conditions, the general solution is,
$$
u(x, t)=\sum_{n \geq 1, n \text { odd }} \frac{8}{n^{3} \pi} e^{-n^{2} t} \sin (n x) .
$$","Find the solution of the equation
$$
\begin{gathered}
\frac{\partial}{\partial t} u(x, t)=\frac{\partial^{2}}{\partial x^{2}} u(x, t) \quad x \in(0, \pi), t>0 \\
\frac{\partial u}{\partial x}(0, t)=\frac{\partial u}{\partial x}(\pi, t)=0 \\
u(x, t)=f(x)
\end{gathered}
$$
Your solution may be left in complex form.","We want a cosine series for $f(x)$. We have,
$$
a_{0}=\frac{2}{\pi} \int_{0}^{\pi} x(\pi-x) d x=\frac{\pi^{2}}{3} .
$$
For $k \geq 1$, we have,
$$
a_{k}=\frac{2}{\pi} \int_{0}^{\pi} x(\pi-x) \cos (k x) d x .
$$
Thus, we have,
$$
a_{k}= \begin{cases}-\frac{4}{k^{2}} & \text { for } k \text { even } \\ 0 & \text { otherwise. }\end{cases}
$$
Thus,
$$
f(x)=\frac{\pi^{2}}{6}-\sum_{k \geq 2, k \text { even }} \frac{4}{k^{2}} \cos (k x)
$$
Thus, for Neumann boundary conditions, the general solution is,
$$
u(x, t)=\frac{\pi^{2}}{6}-\sum_{k \geq 1, k \text { even }} \frac{4}{k^{2}} e^{-k^{2} t} \cos (k x).
$$","Let $u=u(x, t)$ be a solution of the heat
$$
u_{t}=u_{x x} .
$$
What equation does $\phi=-\frac{1}{u} u_{x}$ satisfy?
Hint. Calculate $\phi_{t}$ and use the equation for $u$. Calculate $\phi_{x}$ and write it in terms of $u, u_{x x}$, and $\phi^{2}$. Then compute $\phi_{x x}$. You should now be able to write $\phi_{t}$ in terms of $\phi, \phi_{x}$, and $\phi_{x x}$.","We have
$$
\begin{aligned}
& \phi_{t}=-\frac{1}{u} u_{x t}+\frac{1}{u^{2}} u_{x} u_{t}=-\frac{1}{u} u_{x x x}+\frac{1}{u^{2}} u_{x} u_{x x} \text {, where we have used (12.1). } \\
& \phi_{x}=-\frac{1}{u} u_{x x}+\phi^{2} . \\
& \phi_{x x}=-\frac{1}{u} u_{x x x}+\frac{1}{u^{2}} u_{x} u_{x x}+\left(\phi^{2}\right)_{x} . \\
& \phi_{t}+\left(\phi^{2}\right)_{x}=\phi_{x x} .
\end{aligned}
$$
Thus $\phi$ satisfies $\phi_{t} + (\phi^{2})_{x} = \phi_{xx}$."
101,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Exercise 13,Decision Trees,1,bv,0.02083333333,Text,"We won't go through the algorithm of building a tree in full, but we will look at the first step of the algorithm, which is deciding where to first split the data, based on minimizing the weighted average entropy.
Recall the following notation from the notes. We consider a data set $\mathcal{D}$, and let $I$ be an indicator set of all the elements within $\mathcal{D}$, so that $I=\{1, \ldots, n\}$ for our whole data set.
We consider the features $x^{(i)}$ for examples $i \in I$, and split on the $j$ th dimension at location $s$, i.e., based on $x_{j}^{(i)} \geq s$. We let $I_{j, s}^{+}$represent the set of points on the ""right"" side of the split:
$$
I_{j, s}^{+}=\left\{i \in I \mid x_{j}^{(i)} \geq s\right\} .
$$
Similarly the points on the left side of the same split are
$$
I_{j, s}^{-}=\left\{i \in I \mid x_{j}^{(i)}<s\right\} .
$$
We can define $I_{m}$ as the subset of data samples that are in region $R_{m}$. We then define $\hat{P}_{m, k}$ as the empirical probability of class $k$ in $I_{m}$, where $\hat{P}_{m, k}$ is the fraction of data points in $I_{m}$ that are labeled with class $k$.
The entropy of data points in $I_{m}$ is given by
$$
H\left(I_{m}\right)=-\sum_{k} \hat{P}_{m, k} \log _{2} \hat{P}_{m, k}
$$
where we stipulate that $0 \log _{2} 0=0$.
Finally, the weighted average entropy $\hat{H}$ of a split on the $j$ th dimension at location $s$ is:
$$
\begin{aligned}
\hat{H} & =(\text { fraction of points in left data set }) \cdot H\left(I_{j, s}^{-}\right)+(\text {fraction of points in right data set }) \cdot H\left(I_{j, s}^{+}\right) \\
& =\frac{\left|I_{j, s}^{-}\right|}{N_{m}} \cdot H\left(I_{j, s}^{-}\right)+\frac{\left|I_{j, s}^{+}\right|}{N_{m}} \cdot H\left(I_{j, s}^{+}\right),
\end{aligned}
$$
where $N_{m}=\left|I_{m}\right|$.
For the dataset above, we will compute the weighted average entropies for the following potential splits of the data:
\begin{itemize}
\item Feature $x_{1} \geq 1.5$
\item Feature $x_{1} \geq-1.5$
\item Feature $x_{1} \geq 0.0$
\item Feature $x_{2} \geq 0.0$
\end{itemize}
We will compute the weighted average entropy of the first split $x_{1} \geq 1.5$ as an example:
There are two points in the right split, and both have the same class. So $H\left(I_{1,1.5}^{+}\right)=0-1 \cdot \log _{2} 1=0$.
In the left split there are four points, where $\frac{3}{4}$ of the points are positively labeled and $\frac{1}{4}$ are negatively labeled, so $H\left(I_{1,1.5}^{-}\right)=$ $-\left(\frac{3}{4} \log _{2}\left(\frac{3}{4}\right)+\frac{1}{4} \log _{2}\left(\frac{1}{4}\right)\right) \approx 0.8113$
Thus, the weighted average entropy is
$$
\frac{4}{6} H\left(I_{1,1.5}^{-}\right)+\frac{2}{6} H\left(I_{1,1.5}^{+}\right) \approx 0.541
$$
Make sure that you use log base 2 in computing entropies. You may use $\log 2$ when entering Python expressions or values in the boxes below.
What is the accuracy of the tree using only the split $x_{1} \geq 1.5$?:",Numerical,"0.8333333333.
We are able to classify all the points correctly in the right split and 3 out of 4 points correctly in the left split, for a total of classifying 5 out of 6 points correctly.","We won't go through the algorithm of building a tree in full, but we will look at the first step of the algorithm, which is deciding where to first split the data, based on minimizing the weighted average entropy.
Recall the following notation from the notes. We consider a data set $\mathcal{D}$, and let $I$ be an indicator set of all the elements within $\mathcal{D}$, so that $I=\{1, \ldots, n\}$ for our whole data set.
We consider the features $x^{(i)}$ for examples $i \in I$, and split on the $j$ th dimension at location $s$, i.e., based on $x_{j}^{(i)} \geq s$. We let $I_{j, s}^{+}$represent the set of points on the ""right"" side of the split:
$$
I_{j, s}^{+}=\left\{i \in I \mid x_{j}^{(i)} \geq s\right\} .
$$
Similarly the points on the left side of the same split are
$$
I_{j, s}^{-}=\left\{i \in I \mid x_{j}^{(i)}<s\right\} .
$$
We can define $I_{m}$ as the subset of data samples that are in region $R_{m}$. We then define $\hat{P}_{m, k}$ as the empirical probability of class $k$ in $I_{m}$, where $\hat{P}_{m, k}$ is the fraction of data points in $I_{m}$ that are labeled with class $k$.
The entropy of data points in $I_{m}$ is given by
$$
H\left(I_{m}\right)=-\sum_{k} \hat{P}_{m, k} \log _{2} \hat{P}_{m, k}
$$
where we stipulate that $0 \log _{2} 0=0$.
Finally, the weighted average entropy $\hat{H}$ of a split on the $j$ th dimension at location $s$ is:
$$
\begin{aligned}
\hat{H} & =(\text { fraction of points in left data set }) \cdot H\left(I_{j, s}^{-}\right)+(\text {fraction of points in right data set }) \cdot H\left(I_{j, s}^{+}\right) \\
& =\frac{\left|I_{j, s}^{-}\right|}{N_{m}} \cdot H\left(I_{j, s}^{-}\right)+\frac{\left|I_{j, s}^{+}\right|}{N_{m}} \cdot H\left(I_{j, s}^{+}\right),
\end{aligned}
$$
where $N_{m}=\left|I_{m}\right|$.
For the dataset above, we will compute the weighted average entropies for the following potential splits of the data:
\begin{itemize}
\item Feature $x_{1} \geq 1.5$
\item Feature $x_{1} \geq-1.5$
\item Feature $x_{1} \geq 0.0$
\item Feature $x_{2} \geq 0.0$
\end{itemize}
We will compute the weighted average entropy of the first split $x_{1} \geq 1.5$ as an example:
There are two points in the right split, and both have the same class. So $H\left(I_{1,1.5}^{+}\right)=0-1 \cdot \log _{2} 1=0$.
In the left split there are four points, where $\frac{3}{4}$ of the points are positively labeled and $\frac{1}{4}$ are negatively labeled, so $H\left(I_{1,1.5}^{-}\right)=$ $-\left(\frac{3}{4} \log _{2}\left(\frac{3}{4}\right)+\frac{1}{4} \log _{2}\left(\frac{1}{4}\right)\right) \approx 0.8113$
Thus, the weighted average entropy is
$$
\frac{4}{6} H\left(I_{1,1.5}^{-}\right)+\frac{2}{6} H\left(I_{1,1.5}^{+}\right) \approx 0.541
$$
Make sure that you use log base 2 in computing entropies. You may use $\log 2$ when entering Python expressions or values in the boxes below.
Compute the weighted average entropy for the split $x_{1} \geq-1.5$, with at least two decimal places:","0.809.
Feature $x_{1} \geq-1.5$ : the weighted average entropy is $\hat{H}=\frac{1}{6} * 0+\frac{5}{6} *-\left(\frac{2}{5} * \log _{2}\left(\frac{2}{5}\right)+\frac{3}{5} *\right.$ $\left.\log _{2}\left(\frac{3}{5}\right)\right) \approx 0.809$.
In this case the left side contains items that all have the same label, so the entropy on the left side of this split is 0.","We won't go through the algorithm of building a tree in full, but we will look at the first step of the algorithm, which is deciding where to first split the data, based on minimizing the weighted average entropy.
Recall the following notation from the notes. We consider a data set $\mathcal{D}$, and let $I$ be an indicator set of all the elements within $\mathcal{D}$, so that $I=\{1, \ldots, n\}$ for our whole data set.
We consider the features $x^{(i)}$ for examples $i \in I$, and split on the $j$ th dimension at location $s$, i.e., based on $x_{j}^{(i)} \geq s$. We let $I_{j, s}^{+}$represent the set of points on the ""right"" side of the split:
$$
I_{j, s}^{+}=\left\{i \in I \mid x_{j}^{(i)} \geq s\right\} .
$$
Similarly the points on the left side of the same split are
$$
I_{j, s}^{-}=\left\{i \in I \mid x_{j}^{(i)}<s\right\} .
$$
We can define $I_{m}$ as the subset of data samples that are in region $R_{m}$. We then define $\hat{P}_{m, k}$ as the empirical probability of class $k$ in $I_{m}$, where $\hat{P}_{m, k}$ is the fraction of data points in $I_{m}$ that are labeled with class $k$.
The entropy of data points in $I_{m}$ is given by
$$
H\left(I_{m}\right)=-\sum_{k} \hat{P}_{m, k} \log _{2} \hat{P}_{m, k}
$$
where we stipulate that $0 \log _{2} 0=0$.
Finally, the weighted average entropy $\hat{H}$ of a split on the $j$ th dimension at location $s$ is:
$$
\begin{aligned}
\hat{H} & =(\text { fraction of points in left data set }) \cdot H\left(I_{j, s}^{-}\right)+(\text {fraction of points in right data set }) \cdot H\left(I_{j, s}^{+}\right) \\
& =\frac{\left|I_{j, s}^{-}\right|}{N_{m}} \cdot H\left(I_{j, s}^{-}\right)+\frac{\left|I_{j, s}^{+}\right|}{N_{m}} \cdot H\left(I_{j, s}^{+}\right),
\end{aligned}
$$
where $N_{m}=\left|I_{m}\right|$.
For the dataset above, we will compute the weighted average entropies for the following potential splits of the data:
\begin{itemize}
\item Feature $x_{1} \geq 1.5$
\item Feature $x_{1} \geq-1.5$
\item Feature $x_{1} \geq 0.0$
\item Feature $x_{2} \geq 0.0$
\end{itemize}
We will compute the weighted average entropy of the first split $x_{1} \geq 1.5$ as an example:
There are two points in the right split, and both have the same class. So $H\left(I_{1,1.5}^{+}\right)=0-1 \cdot \log _{2} 1=0$.
In the left split there are four points, where $\frac{3}{4}$ of the points are positively labeled and $\frac{1}{4}$ are negatively labeled, so $H\left(I_{1,1.5}^{-}\right)=$ $-\left(\frac{3}{4} \log _{2}\left(\frac{3}{4}\right)+\frac{1}{4} \log _{2}\left(\frac{1}{4}\right)\right) \approx 0.8113$
Thus, the weighted average entropy is
$$
\frac{4}{6} H\left(I_{1,1.5}^{-}\right)+\frac{2}{6} H\left(I_{1,1.5}^{+}\right) \approx 0.541
$$
Make sure that you use log base 2 in computing entropies. You may use $\log 2$ when entering Python expressions or values in the boxes below.
Compute the weighted average entropy for the split $x_{1} \geq 0$, with at least two decimal places:","0.918.
Feature $x_{1} \geq 0.0: \hat{H}=\frac{3}{6} *-\left(\frac{1}{3} * \log _{2}\left(\frac{1}{3}\right)+\frac{2}{3} * \log _{2}\left(\frac{2}{3}\right)\right)+\frac{3}{6} *-\left(\frac{1}{3} * \log _{2}\left(\frac{1}{3}\right)+\frac{2}{3} *\right.$ $\left.\log _{2}\left(\frac{2}{3}\right)\right)=0.918$.","We won't go through the algorithm of building a tree in full, but we will look at the first step of the algorithm, which is deciding where to first split the data, based on minimizing the weighted average entropy.
Recall the following notation from the notes. We consider a data set $\mathcal{D}$, and let $I$ be an indicator set of all the elements within $\mathcal{D}$, so that $I=\{1, \ldots, n\}$ for our whole data set.
We consider the features $x^{(i)}$ for examples $i \in I$, and split on the $j$ th dimension at location $s$, i.e., based on $x_{j}^{(i)} \geq s$. We let $I_{j, s}^{+}$represent the set of points on the ""right"" side of the split:
$$
I_{j, s}^{+}=\left\{i \in I \mid x_{j}^{(i)} \geq s\right\} .
$$
Similarly the points on the left side of the same split are
$$
I_{j, s}^{-}=\left\{i \in I \mid x_{j}^{(i)}<s\right\} .
$$
We can define $I_{m}$ as the subset of data samples that are in region $R_{m}$. We then define $\hat{P}_{m, k}$ as the empirical probability of class $k$ in $I_{m}$, where $\hat{P}_{m, k}$ is the fraction of data points in $I_{m}$ that are labeled with class $k$.
The entropy of data points in $I_{m}$ is given by
$$
H\left(I_{m}\right)=-\sum_{k} \hat{P}_{m, k} \log _{2} \hat{P}_{m, k}
$$
where we stipulate that $0 \log _{2} 0=0$.
Finally, the weighted average entropy $\hat{H}$ of a split on the $j$ th dimension at location $s$ is:
$$
\begin{aligned}
\hat{H} & =(\text { fraction of points in left data set }) \cdot H\left(I_{j, s}^{-}\right)+(\text {fraction of points in right data set }) \cdot H\left(I_{j, s}^{+}\right) \\
& =\frac{\left|I_{j, s}^{-}\right|}{N_{m}} \cdot H\left(I_{j, s}^{-}\right)+\frac{\left|I_{j, s}^{+}\right|}{N_{m}} \cdot H\left(I_{j, s}^{+}\right),
\end{aligned}
$$
where $N_{m}=\left|I_{m}\right|$.
For the dataset above, we will compute the weighted average entropies for the following potential splits of the data:
\begin{itemize}
\item Feature $x_{1} \geq 1.5$
\item Feature $x_{1} \geq-1.5$
\item Feature $x_{1} \geq 0.0$
\item Feature $x_{2} \geq 0.0$
\end{itemize}
We will compute the weighted average entropy of the first split $x_{1} \geq 1.5$ as an example:
There are two points in the right split, and both have the same class. So $H\left(I_{1,1.5}^{+}\right)=0-1 \cdot \log _{2} 1=0$.
In the left split there are four points, where $\frac{3}{4}$ of the points are positively labeled and $\frac{1}{4}$ are negatively labeled, so $H\left(I_{1,1.5}^{-}\right)=$ $-\left(\frac{3}{4} \log _{2}\left(\frac{3}{4}\right)+\frac{1}{4} \log _{2}\left(\frac{1}{4}\right)\right) \approx 0.8113$
Thus, the weighted average entropy is
$$
\frac{4}{6} H\left(I_{1,1.5}^{-}\right)+\frac{2}{6} H\left(I_{1,1.5}^{+}\right) \approx 0.541
$$
Make sure that you use log base 2 in computing entropies. You may use $\log 2$ when entering Python expressions or values in the boxes below.
Compute the weighted average entropy for the split $x_{2} \geq 0$, with at least two decimal places:","0.918.
Feature $x_{2} \geq 0.0: \hat{H}=\frac{3}{6} *-\left(\frac{1}{3} * \log _{2}\left(\frac{1}{3}\right)+\frac{2}{3} * \log _{2}\left(\frac{2}{3}\right)\right)+\frac{3}{6} *-\left(\frac{1}{3} * \log _{2}\left(\frac{1}{3}\right)+\frac{2}{3} *\right.$ $\left.\log _{2}\left(\frac{2}{3}\right)\right)=0.918$."
51,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Exercise 7,Neural Networks,3,d,0.01736111111,Text,"When Alex was first studying machine learning, he sometimes wondered about the relationship between linear regression, logistic regression, and neural networks. Is there actually any? For each of the neural-network architectures described below, help him identify whether it is equivalent to some previous model we have studied.
In each case, we will specify the number of layers, the activation function for each layer, and the loss function. In all cases, please assume the last layer outputs a scalar. Let $f$ be the activation function in a single-layer network, and let $f^{1}$ and $f^{2}$ be the activations in the first and second layers of a two-layer network, respectively.
Two layers, $f^{1}$ is identity, $f^{2}$ is sigmoid, loss is NLL.
Which of the following is this equivalent to:
(a) linear regression.
(b) logistic regression.
(c) a different kind of sensible neural network.
(d) an ill-formed neural network.",Multiple Choice,"(b) logistic regression.
Since the output of the network is a scalar, the weight matrix in the second layer must be a vector of the same shape as the output of the first layer. We have that the whole network takes the form
$$
\begin{aligned}
f^{2}\left(w_{2}^{T} f^{1}\left(W_{1}^{T} x+b_{1}\right)+b_{2}\right) & =\sigma\left(w_{2}^{T}\left(W_{1}^{T} x+b_{1}\right)+b_{2}\right) \\
& =\sigma\left(\left(w_{2}^{T} W_{1}\right) x+\left(w_{2}^{T} b_{1}+b_{2}\right)\right)
\end{aligned}
$$
Letting $\theta=W_{1}^{T} w_{2}$ (note $\theta$ is a vector) and $\theta_{0}=w_{2}^{T} b_{1}+b_{2}$ (note $\theta_{0}$ is a scalar), we can rewrite the network as $\sigma\left(\theta^{T} x+\theta_{0}\right)$, which together with the NLL loss we recognize as a logistic regression.
Then in the reverse direction, starting with a logistic regression model $\sigma\left(\theta^{T} x+\theta_{0}\right)$, we can take $w_{2}=\theta_{1} b_{2}=\theta_{0}, W_{1}=I$, and $b_{1}=0$ to get an output of the form
$$
\begin{aligned}
\sigma\left(w_{2}^{T}\left(W_{1}^{T} x+b_{1}\right)+b_{2}\right) & =\sigma\left(\theta^{T}\left(I^{T} x+0\right)+\theta_{0}\right) \\
& =\sigma\left(\theta^{T} x+\theta_{0}\right),
\end{aligned}
$$
meaning this two-layer net can express any logistic regression model.
Since we can express any instance of logistic regression as an instance of this two-layer net and any instance of this two-layer net as an instance of logistic regression, we say that the two models are equivalent.","When Alex was first studying machine learning, he sometimes wondered about the relationship between linear regression, logistic regression, and neural networks. Is there actually any? For each of the neural-network architectures described below, help him identify whether it is equivalent to some previous model we have studied.
In each case, we will specify the number of layers, the activation function for each layer, and the loss function. In all cases, please assume the last layer outputs a scalar. Let $f$ be the activation function in a single-layer network, and let $f^{1}$ and $f^{2}$ be the activations in the first and second layers of a two-layer network, respectively.
Two layers, $f^{1}$ is sigmoid, $f^{2}$ is identity, loss is NLL.
Which of the following is this equivalent to:
(a) linear regression.
(b) logistic regression.
(c) a different kind of sensible neural network.
(d) an ill-formed neural network.","(d) an ill-formed neural network.
The weights in layer 2 can push the output outside $(0,1)$, so NLL loss would be ill-suited and undefined for some outputs.","When Alex was first studying machine learning, he sometimes wondered about the relationship between linear regression, logistic regression, and neural networks. Is there actually any? For each of the neural-network architectures described below, help him identify whether it is equivalent to some previous model we have studied.
In each case, we will specify the number of layers, the activation function for each layer, and the loss function. In all cases, please assume the last layer outputs a scalar. Let $f$ be the activation function in a single-layer network, and let $f^{1}$ and $f^{2}$ be the activations in the first and second layers of a two-layer network, respectively.
Two layers, $f^{1}$ is sigmoid, $f^{2}$ is sigmoid, loss is NLL.
Which of the following is this equivalent to:
(a) linear regression.
(b) logistic regression.
(c) a different kind of sensible neural network.
(d) an ill-formed neural network.","(c) a different kind of sensible neural network.
Note that since the output of this network is a scalar, it takes the form
$$
\sigma\left(w_{2}^{T} \sigma\left(W_{1}^{T} x+b_{1}\right)+b_{2}\right) .
$$
This network is sensible because its output is a scalar in the interval $(0,1)$ (the range of sigmoid), and the NLL loss is well-defined for any input in $(0,1)$. Then taking $W_{1}=I, b_{1}=0, b_{2}=0$, and $w_{2}=$ $[1,0, \cdots, 0]^{T}$, we get an output of
$$
\sigma\left([1,0, \cdots, 0] \sigma\left(I^{T} x+0\right)+0\right)=\sigma\left(\sigma\left(x_{0}\right)\right),
$$
a function which cannot be expressed via either a linear or logistic regression.","When Alex was first studying machine learning, he sometimes wondered about the relationship between linear regression, logistic regression, and neural networks. Is there actually any? For each of the neural-network architectures described below, help him identify whether it is equivalent to some previous model we have studied.
In each case, we will specify the number of layers, the activation function for each layer, and the loss function. In all cases, please assume the last layer outputs a scalar. Let $f$ be the activation function in a single-layer network, and let $f^{1}$ and $f^{2}$ be the activations in the first and second layers of a two-layer network, respectively.
One layer, $f$ is sigmoid, loss is NLL.
Which of the following is this equivalent to:
(a) linear regression.
(b) logistic regression.
(c) a different kind of sensible neural network.
(d) an ill-formed neural network.","(b) logistic regression.
As in previous questions, since the output of the neural net is a scalar, the net takes the form
$$
f\left(w^{T} x+b\right)=\sigma\left(w^{T} x+b\right)
$$
which together with the NLL loss we recognize as a logistic regression with $\theta=w$ and $\theta_{0}=b$ in our usual notation."
67,Mathematics,18.404,Theory of Computation,6.1210/18.200,None,Midterm Exam,Finite Automata,9,nan,2.222222222,Text,"A 2-way counter automaton (2WAY-CA) is a deterministic counter automaton where the head on the input tape can move left or right at each step, as specified by its transition function. The input tape is still read-only. For example, a 2WAY-CA can recognize the language $B=\left\{x \# x \mid x \in\{\mathrm{a}, \mathrm{b}\}^{*}\right\}$ as follows. First it scans the entire input to check that it is of the form $y \# z$ where $y, z \in\{\mathrm{a}, \mathrm{b}\}^{*}$ and it uses the counter to check that $y$ and $z$ agree in length. Then it makes multiple scans over the input to check that corresponding symbols in $y$ and $z$ agree, using the counter to identify corresponding locations. If all checks succeed, then it accepts.
Let $E_{2 \text { WAY-CA }}=\{\langle C\rangle \mid C$ is a 2WAY-CA and $L(C)=\emptyset\}$. Show $E_{2 W A Y-C A}$ is undecidable. (Give enough detail to show how the counter and the 2-way head are needed, such as in the example above.)",Open,"To prove that $E_{2 \mathrm{WAY}-\mathrm{CA}}$ is undecidable, reduce $A_{\mathrm{TM}}$ to $E_{2 \mathrm{WAY}}$-CA by using the computation history method. Assume TM $R$ decides $E_{\text {2WAY-CA }}$ and construct TM $S$ deciding $A_{\mathrm{TM}}$. This proof is similar to the proof that $E_{\mathrm{LBA}}$ is undecidable.
$S =$ ""On input $\langle M, W \rangle$
1. Construct 2WAY-CA $C_{M, w}$ as follows. $\left(C_{M, w}\right.$ is designed to accept all strings $u$ that are an accepting computation history of $M$ on $w$. We refer to the parts of $u$ separated by \# symbols as blocks, so $u=b_{1} \# b_{2} \# \cdots \# b_{k}$.) $C_{M, w}={ }^{\text {""On input } u}$
1. Check (by using a built-in string) that $b_{1}$ is the start configuration of $M$ on $w$. If not then reject.
2. For each pair of blocks $b_{i}$ and $b_{i+1}$, check that $b_{i}$ yields $b_{i+1}$ as configurations according to $M$ 's rules. Do so by using the counter to identify corresponding locations in the blocks (as in the example) and going back and forth to check the entire configuration. Reject if any of these pairs fail.
3. Check that the last block $b_{k}$ contains the accept state. Reject if not.
4. Accept if all checks pass.""
2. Run $R$ on input $\left\langle C_{M, w}\right\rangle$ to determine whether its language is empty.
3. Accept if $R$ rejects. Reject if $R$ accepts.""
If $M$ accepts $w$ then some string $u$ is an accepting computation history of $M$ on $w$, so $C_{M, w}$ accepts $u$ and its language is nonempty. Hence $R$ rejects $\left\langle C_{M, w}\right\rangle$. If $M$ rejects $w$ then no string $u$ is an accepting computation of $M$ on $w$, so $C_{M, w}$ rejects all strings, its language is empty, and so $R$ accepts $\left\langle C_{M, w}\right\rangle$. Therefore $M$ accepts $w$ iff $R$ rejects $\left\langle C_{M, w}\right\rangle$. Hence $S$ decides $A_{\mathrm{TM}}$, a contradiction. Therefore $E_{2 \text { WAY-CA }}$ is undecidable.","A counter automaton has a single, read-only finite input tape that is just large enough to contain its input, and it also has a counter which contains a non-negative integer value. The counter initially starts at 0 . Under control of the transition function, at each step the counter automaton can add 1, subtract 1, or leave the counter value unchanged, and it can test whether the counter value is 0 . At each step it can also read the symbol under its tape head, and it can test whether the head is at the beginning or end of the input tape. It accepts its input by entering an accept state. Here we consider only deterministic counter automata. A 1-way counter automaton (1WAY-CA) is a counter automaton where the head on the input tape moves one symbol right at each step. In other words, a 1WAY-CA is a DFA with a counter. For example, a 1WAY-CA can recognize the language $A=\left\{\mathrm{a}^{k} \mathrm{~b}^{k} \mid k \geq 0\right\}$ as follows. It scans its input until it reaches the end, adding 1 to the counter for each a and subtracting 1 for each $\mathrm{b}$. When it reaches the end of the input, it accepts if the counter is 0 , and no a's come after b's.
Let $E_{1 \text { WAY-CA }}=\{\langle C\rangle \mid C$ is a 1WAY-CA and $L(C)=\emptyset\}$. Show that $E_{1 \text { WAY-CA }}$ is decidable. (Hint: A theorem we've seen before is useful here.)",We can convert a 1WAY-CA to an equivalent PDA which simulates the counter by using the stack. Hence we can decide $E_{\text {1WAY-CA }}$ by using the $E_{\mathrm{PDA}}$ (or $E_{\mathrm{CFG}}$ ) decider.,"In a \defin{two-dimensional finite automaton} (\twodimdfa)
the input is an $m \times n$ rectangle, for any $m,n\ge 2$. 
The squares along the boundary of the rectangle contain
the symbol \texttt{\#} and the internal squares contain symbols
over the input alphabet $\Sigma$.  The transition function
$\fcn{\delta}
    {Q \times (\Sigma\union\{\st\#\})} {Q \times \{\mathrm{L,R,U,D}\}}$
indicates the next state and the new head position (Left, Right, Up, Down).
The machine accepts when it enters one of the designated accept states. 
It rejects if it tries to move off the input rectangle or if it never halts.
Two such machines are equivalent if they accept the same rectangles.  
Let $A_\twodimdfa = \setb{B,r}B$ is a \twodimdfa\ and $B$ accepts
rectangle $r$\setend.\\ Show that $A_\twodimdfa$ is decidable. ","The following TM decides $A_{2 \text { DIM-DFA. }}$
""On input $\langle B, r\rangle$ :
1. Run $B$ for $|Q| m n$ steps.
2. If $B$ has accepted, then accept. Otherwise reject.""
If $B$ runs for $|Q| m n$ steps without halting, then it must have repeated some state in the same location, so it will loop forever.","Consider the problem of determining whether a single-tape Turing machine
ever writes a blank symbol over a nonblank symbol during the course of
its computation on any input string.
Formulate this problem as a language and show that it is undecidable.","Let $E=\{\langle M\rangle \mid M$ is a single-tape TM which writes a blank symbol over a nonblank symbol for some input $\}$. Reduce $A_{\text {TM }}$ to $E$ as follows. Assume for the sake of contradiction that TM $R$ decides E. Construct TM $S$ that uses $R$ to decide $A_{\text {TM }}$.
$S=$ ""On input $\langle M, w\rangle$ :
1. Use $M$ and $w$ to construct the following TM $T_{M, w}$.
$T_{M, w}=$ ""On any input:
1. Simulate $M$ on $w$. Use new symbol $\sqcup$ ' instead of a true blank $\sqcup$ when writing, and treat it like a true blank when reading it.
2. If $M$ accepts, write a true blank over some nonblank.""
2. Run $R$ on $\left\langle T_{M, w}\right\rangle$ to determine whether $T_{M, w}$ ever writes a blank.
3. If $R$ accepts, $M$ accepts $w$, therefore accept. Otherwise reject."""
3,EECS,6.122,Design and Analysis of Algorithms,6.121,None,Problem Set 1,Probability,2,c,0.1818181818,Text,"Asami and Bolin are playing a dice game in which a pair of dice is rolled repeatedly. Asami wins if a sum of 6 is rolled before any sum greater than or equal to 9, and Bolin wins if any sum greater than or equal to 9 is rolled first. We will find the probability that Asami wins the game.
Let $E_n$ denote the event that a 6 occurs on the $n^{\text {th }}$ roll and neither 6 nor any number greater than or equal to 9 occurs on any of the first $(n-1)$ rolls.
Compute $\sum_{n=1}^{\infty} P\left(E_n\right)$ and argue rigorously that it is the desired probability. HINT: $\sum_{n=0}^{\infty} r^n=\frac{1}{1-r}$ for $|r|<1$.",Open,"Since the events $E_n$ are mutually disjoint and their union is precisely the event whose probability we want, we can add their probabilities to obtain the desired result:
$$
P(6 \text { before } \geq 9)=\sum_{n=1}^{\infty} P\left(E_n\right)=\sum_{n=1}^{\infty}\left(\frac{21}{36}\right)^{n-1} \cdot \frac{5}{36} .
$$
This can be evaluated using the hint in the problem to be
$$
\frac{1}{1-21 / 36} \cdot \frac{5}{36}=\frac{1}{3} \text {. }
$$","Asami and Bolin are playing a dice game in which a pair of dice is rolled repeatedly. Asami wins if a sum of 6 is rolled before any sum greater than or equal to 9, and Bolin wins if any sum greater than or equal to 9 is rolled first. We will find the probability that Asami wins the game.
Let $E_n$ denote the event that a 6 occurs on the $n^{\text {th }}$ roll and neither 6 nor any number greater than or equal to 9 occurs on any of the first $(n-1)$ rolls.
Compute $P\left(E_n\right)$.","As we found in the previous part, 6 occurs with probability $\frac{5}{36}$ and any number greater than or equal to 9 with probability $\frac{10}{36}$. Therefore, neither occurs on a given roll with probability
$$
1-\frac{5}{36}-\frac{10}{36}=\frac{21}{36} .
$$
Each of the n rolls required for $E_n$ to occur are independent, so to find the probability $P\left(E_n\right)$, we can multiply the probabilities that the first $(n-1)$ rolls result in neither 6 nor any number greater than or equal to 9 and the probability that the $n^{\text {th }}$ roll results in a 6, yielding
$$
P\left(E_n\right)=\left(\frac{21}{36}\right)^{n-1} \cdot \frac{5}{36} .
$$","Asami and Bolin are playing a dice game in which a pair of dice is rolled repeatedly. Asami wins if a sum of 6 is rolled before any sum greater than or equal to 9, and Bolin wins if any sum greater than or equal to 9 is rolled first. We will find the probability that Asami wins the game.
Let $E_n$ denote the event that a 6 occurs on the $n^{\text {th }}$ roll and neither 6 nor any number greater than or equal to 9 occurs on any of the first $(n-1)$ rolls.
What is the probability that a sum of 6 is rolled on any given roll of the pair of dice? What is the probability that any number greater than or equal to 9 is rolled on any given roll of the pair of dice?","Of the 36 equally likely possible rolls, 5 result in a total roll of 6-(1, 5), $(2,4),(3,3),(4,2)$, and $(5,1)$. Thus, the probability that $a 6$ is rolled on any given roll of the pair of dice is $\frac{5}{36}$.
We can analyze the other probability similarly. Of the 36 equally likely possible rolls, 10 result in a total roll greater than or equal to 9 , with four corresponding to a total of 9 , three corresponding to a total of 10, two corresponding to a total of 11, and one corresponding to a total of 12 . Thus, the probability that any number greater than or equal to 9 is rolled on any given roll of the pair of dice is $\frac{10}{36}=\frac{5}{18}$.","Asami and Bolin are playing a dice game in which a pair of dice is rolled repeatedly. Asami wins if a sum of 6 is rolled before any sum greater than or equal to 9, and Bolin wins if any sum greater than or equal to 9 is rolled first. We will find the probability that Asami wins the game.
Let $E_n$ denote the event that a 6 occurs on the $n^{\text {th }}$ roll and neither 6 nor any number greater than or equal to 9 occurs on any of the first $(n-1)$ rolls.
Now, suppose that in a run of this game, the dice are rolled ten times with neither a 6 nor any number greater than or equal to 9 appearing. Given this, let X be the sum of these ten rolls. We would now like to find an upper bound for the following probability $P[|X − \mathbb{E}[X]| \geq 10]$.
Given that each of these ten rolls results in neither a 6 nor any number greater than or equal to 9, enumerate the possible totals for each roll and their respective probabilities.","Because we know that we roll neither a 6 nor any number greater than or equal to 9 , the only possible rolls are $2,3,4,5,7,8$. There are $36-5-10=21$ rolls that result in these totals, with counts $1,2,3,4$, 6, and 5, respectively. "
58,EECS,6.3,Signal Processing,"6.100A, 18.03",None,Problem Set 5,Fourier Transforms,2,c,0.1171875,Text,"Find the Discrete-Time Fourier Transform of $f_{3}[n]$ :
$$
f_{3}[n]=\left(\frac{1}{2}\right)^{|n|}
$$",Expression,"$$
\begin{aligned}
F_{3}(\Omega) & =\sum_{n=-\infty}^{\infty}\left(\frac{1}{2}\right)^{|n|} e^{-j \Omega n}=2\left(\sum_{n=0}^{\infty}\left(\frac{1}{2}\right)^{n} e^{-j \Omega n}\right)-1=2\left(\sum_{n=0}^{\infty}\left(\frac{1}{2} e^{-j \Omega}\right)^{n}\right)-1 \\
= & \frac{2}{1-\frac{1}{2} e^{-j \Omega}}-1=\frac{1+\frac{1}{2} e^{-j \Omega}}{1-\frac{1}{2} e^{-j \Omega}}
\end{aligned}
$$","Find the Discrete-Time Fourier Transform of $f_{4}[n]$ :
$$
f_{4}[n]= \begin{cases}n\left(\frac{1}{2}\right)^{n} & \text { if } n \geq 0 \\ 0 & \text { otherwise }\end{cases}
$$","$$
\sum_{n=0}^{\infty} a^{n}=\frac{1}{1-a}
$$
Differentiate both sides by $a$:
$$
\begin{aligned}
& \sum_{n=0}^{\infty} n a^{n-1}=\frac{1}{(1-a)^{2}} \\
& F_{4}(\Omega)=\sum_{n=0}^{\infty} n\left(\frac{1}{2}\right)^{n} e^{-j \Omega n}=\sum_{n=0}^{\infty} n\left(\frac{1}{2} e^{-j \Omega}\right)^{n}=\frac{1}{\left(1-\frac{1}{2} e^{-j \Omega}\right)^{2}}
\end{aligned}
$$","Each part of this problem describes a different discrete-time signal $f_{i}[n]$ and then asks you to determine the $k=3$ component of the DFT of that signal, where the DFT is computed with analysis window $N=16$:
$$
F_{i}[3]=\frac{1}{16} \sum_{n=0}^{15} f_{i}[n] e^{-j 2 \pi 3 n / 16}
$$
Let $f_{3}[n]=\cos (3 \pi n / 8-9 \pi / 8)$. Enter a closed form expression for $F_{3}[3]$ below.","$$
\mathrm{F}_{3}[3]=\overline{\frac{1}{2} e^{-j 2 \pi 9 / 16}}
$$
Since
$$
f_{3}[n]=f_{2}[n-3]
$$
it follows that
$$
\mathrm{F}_{3}[\mathrm{k}]=\mathrm{e}^{-\mathrm{j} 2 \pi \mathrm{k} 3 / 16} \mathrm{~F}_{2}[\mathrm{k}]
$$
Therefore $F_{3}[3]=\frac{1}{2} e^{-j 2 \pi 9 / 16}$.","Each part of this problem describes a different discrete-time signal $f_{i}[n]$ and then asks you to determine the $k=3$ component of the DFT of that signal, where the DFT is computed with analysis window $N=16$:
$$
F_{i}[3]=\frac{1}{16} \sum_{n=0}^{15} f_{i}[n] e^{-j 2 \pi 3 n / 16}
$$
Determine a closed form expression for $F_{5}[3]$ where
$$
\begin{aligned}
& f_{5}[n]=\left(\frac{1}{2}\right)^{n} u[n] \\
\end{aligned}
$$","$$
F_{5}[3]=\frac{1}{16}\left(\frac{1-\left(\frac{1}{2}\right)^{16}}{1-\frac{1}{2} e^{-j 2 \pi 3 / 16}}\right)
$$
$$
\begin{aligned}
& F_{5}[k]=\frac{1}{N} \sum_{n=0}^{N-1}\left(\frac{1}{2}\right)^{n} e^{-j 2 \pi k n / N}=\frac{1}{N}\left(\frac{1-\left(\frac{1}{2}\right)^{N} e^{-j 2 \pi k N / N}}{1-\frac{1}{2} e^{-j 2 \pi k / N}}\right)=\frac{1}{N}\left(\frac{1-\left(\frac{1}{2}\right)^{N}}{1-\frac{1}{2} e^{-j 2 \pi k / N}}\right)
\end{aligned}
$$
Substituting $k=3$ and $\mathrm{N}=16$ yields
$$
F_{5}[3]=\frac{1}{16}\left(\frac{1-\left(\frac{1}{2}\right)^{16}}{1-\frac{1}{2} e^{-j 2 \pi 3 / 16}}\right)
$$"
18,Mathematics,18.3,Principles of Continuum Applied Mathematics,"18.02, 18.03",None,Problem Set 1,Differentiation Within Integrals,8,b,0.2430555556,Text,"In each case compute $u_{x}=\frac{\partial u}{\partial x}$ and $u_{p}=\frac{\partial u}{\partial p}$ (as functions of $u, x$, and $p$ ), given that $u=u(x, p)$ satisfies: $u=\int_{0}^{x} \sin \left(p u\left(s^{2}, s\right)+x s\right) d s$.",Expression,"Clearly $u_p=\int_0^x u\left(s^2, s\right) \cos \left(p u\left(s^2, s\right)+x s\right) d s$ and $u_x=\sin \left(p u\left(x^2, x\right)+x^2\right)+\int_0^x s \cos \left(p u\left(s^2, s\right)+x s\right) d s$.","In each case compute $u_{x}=\frac{\partial u}{\partial x}$ and $u_{p}=\frac{\partial u}{\partial p}$ (as functions of $u, x$, and $p$ ), given that $u=u(x, p)$ satisfies: $p=\int_{x}^{u} \cos \left(p \sin (s)+x s^{2}\right) d s$.","$1=\cos \left(p \sin (u)+x u^{2}\right) u_{p}-\int_{x}^{u} \sin (s) \sin \left(p \sin (s)+x s^{2}\right) d s$,
so that
$$
u_{p}=\frac{\int_{x}^{u} \sin (s) \sin \left(p \sin (s)+x s^{2}\right) d s}{\cos \left(p \sin (u)+x u^{2}\right)}
$$
$0=\cos \left(p \sin (u)+x u^{2}\right) u_{x}-\cos \left(p \sin (x)+x^{3}\right)-\int_{x}^{u} \sin \left(p \sin (s)+x s^{2}\right) s^{2} d s$,
so that
$$
u_{x}=\frac{\cos \left(p \sin (x)+x^{3}\right)+\int_{x}^{u} \sin \left(p \sin (s)+x s^{2}\right) s^{2} d s}{\cos \left(p \sin (u)+x u^{2}\right)} .
$$","In each case compute $u_{x}=\frac{\partial u}{\partial x}$ and $u_{p}=\frac{\partial u}{\partial p}$ (as functions of $u, x$, and $p$ ), given that $u=u(x, p)$ satisfies: $p=\int_{0}^{u} \exp \left(p \sin (s)+x s^{2}\right) d s$.","$1=\exp \left(p \sin (u)+x u^{2}\right) u_{p}+\int_{0}^{u} \exp \left(p \sin (s)+x s^{2}\right) \sin (s) d s$
so that $\ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots \ldots+u_{p}=\frac{1-\int_{0}^{u} \exp \left(p \sin (s)+x s^{2}\right) \sin (s) d s}{\exp \left(p \sin (u)+x u^{2}\right)}$
$0=\exp \left(p \sin (u)+x u^{2}\right) u_{x}+\int_{0}^{u} \exp \left(p \sin (s)+x s^{2}\right) s^{2} d s$
so that
$$
u_{x}=-\frac{\int_{0}^{u} \exp \left(p \sin (s)+x s^{2}\right) s^{2} d s}{\exp \left(p \sin (u)+x u^{2}\right)} .
$$","In each case compute $u_{x}=\frac{\partial u}{\partial x}$ and $u_{p}=\frac{\partial u}{\partial p}$ (as functions of $u, x$, and $p$ ), given that $u=u(x, p)$ satisfies: $p=\cos (x+u)$.","Upon taking partial derivatives with respect to $x$ and $p, p=\cos (x+u)$ yields:
$0=\left(1+u_{x}\right) \sin (x+u) \quad$ and $\quad 1=-u_{p} \sin (x+u)$.
Thus: $u_{x}=-1 \quad$ and $\quad u_{p}=-\frac{1}{\sin (x+u)}$."
331,Mathematics,18.01,Calculus I,None,None,Problem Set 7,Probability,13,b,0.03167898627,Text,"Suppose we flip a coin three times. There are eight possible sequences of heads and tails that we could get.
As we discussed in class each of these sequences is equally likely. Each sequence occurs with probability 1/8. For instance, the chance of flipping $\mathrm{H}$ then $\mathrm{T}$ then $\mathrm{H}$ is $1 / 8$.
If we flip a coin three times, what is the probability of getting at least one $\mathrm{H}$.",Numerical,$\operatorname{Prob}($ at least one $\mathrm{H})=1-\operatorname{Prob}($ only $\mathrm{T})=1-\operatorname{Prob}(\mathrm{TTT})=1-\frac{1}{8}=\frac{7}{8}$.,"Suppose we flip a coin three times. There are eight possible sequences of heads and tails that we could get.
If we flip a coin three times, what is the probability that all three flips are the same?",$\operatorname{Prob}($ All flips are the same $)=\operatorname{Prob}(\mathrm{TTT})+\operatorname{Prob}(\mathrm{HHH})=\frac{1}{8}+\frac{1}{8}=\frac{1}{4}$.,"Now suppose we flip a coin four times.
What is the probability of getting $\mathrm{H}$ then $\mathrm{H}$ then $\mathrm{T}$ then $\mathrm{H}$?",$\operatorname{Prob}(\mathrm{HHTH})=2^{-4}=\frac{1}{16}$.,"Suppose we flip a coin three times. There are eight possible sequences of heads and tails that we could get.
Write down all eight sequences of heads and tails in an organized way.","In the following picture, left is for tails and right for heads."
98,Mathematics,18.02,Calculus II,18.01,None,Midterm Exam 3,Directional Derivative,1,c,1.125,Text,"What is the directional derivative of the function $g(x, y, z)$ in the direction $\hat{i}+\hat{j}+\hat{k}$ at the point $(1,0,-1)$?",Expression,"The unit vector in the direction $\hat{i}+\hat{j}+\hat{k}$ is $\vec{u}=1 / \sqrt{3}\langle 1,1,1\rangle$ hence $D_{\vec{u}} g(1,0,-1)=\nabla g(1,0,-1) \cdot \vec{u}=\langle-2,-2,2\rangle \cdot 1 / \sqrt{3}\langle 1,1,1\rangle=-2 / \sqrt{3}$.","Consider again $g(x, y, z)=x y+3 y z+2 x z$. In which direction is $g$ decreasing most rapidly at the point $(1,0,-1)$ ? Express your answer in the form $a \hat{i}+b \hat{j}+c \hat{k}$. (You do not need to normalize this vector.)","It should be in the opposite direction of the gradient. Since
$$
\left.\nabla g\right|_{(1,0,-1)}=\left.\langle y+2 z, x+3 z, 3 y+2 x\rangle\right|_{(1,0,-1)}=\langle-2,-2,2\rangle
$$
the direction is $2 \hat{i}+2 \hat{j}-2 \hat{k}$.","$\mathbf{F}(x, y, z)=\left(y+y^2 z\right) \mathbf{i}+(x-z+2 x y z) \mathbf{j}+\left(-y+x y^2\right) \mathbf{k}$. Show that $\mathbf{F}(x, y, z)$ is a gradient field using the derivative conditions.","We have $\mathbf{F}=\langle P, Q, R\rangle$, where $P=y+y^2 z, \quad Q=x-z+2 x y z, \quad R=-y+x y^2$.
$$
\frac{\partial P}{\partial z}=y^2=\frac{\partial R}{\partial x} ; \quad \frac{\partial Q}{\partial z}=-1+2 x y=\frac{\partial R}{\partial y} ; \quad \frac{\partial P}{\partial y}=1+2 y z=\frac{\partial Q}{\partial x} .
$$","Consider the function $g(x, y, z)=x y+3 y z+2 x z$ and consider its level surface $\{(x, y, z) \mid x y+3 y z+2 x z=9\}$. Find the equation of the tangent plane to this surface at the point $(0,1,3)$ in the form $a x+b y+c z=d$.","$$
7 x+9 y+3 z=18 \text {. }
$$"
70,Mathematics,18.01,Calculus I,None,None,Problem Set 2,Integration,10,b,0.03959873284,Text,"Suppose that a train is moving. It starts at time $t=0$ and ends at time $t=5$. At time $t$, its velocity is equal to $5-t$.
Approximately how far did the train go from time $t$ to time $t+\Delta t$?",Expression,From time $t$ to $\Delta t$ the velocity is approximately $5-\Delta t$. This goes on for an amount of time $\Delta t$. The distance traversed in this time is approximately $(5-t) \Delta t$.,"Suppose that a train is moving. It starts at time $t=0$ and ends at time $t=5$. At time $t$, its velocity is equal to $5-t$.
Approximately how far did the train go from time $t=2$ to time $t=2.1-5$ or 3 or $.5$ or $.3$ or $.1 ?$",From time 2 to $2.1$ the velocity is approximately $5-2=3$. This goes on for an amount of time $\Delta t=.1$. The distance traversed in this time is approximately $3 \Delta t=.3$.,"Suppose that a train is moving. It starts at time $t=0$ and ends at time $t=5$. At time $t$, its velocity is equal to $5-t$.
Write down an integral for the total change in the position of the train.","As the times $0=t_{0}, t_{1}, \ldots, t_{n}=5$ get closer together $\left(\Delta t_{i}=t_{i+1}-t_{i} \rightarrow 0\right)$, the sum $\sum_{i=0}^{n-1}(5-t) \Delta t_{i}$ approximating the total distance converges to the integral:
$$
\int_{0}^{5}(5-t) d t .
$$","Suppose that a train is moving. It starts at time $t=0$ and ends at time $t=5$. At time $t$, its velocity is equal to $5-t$.
Compute the integral.","$$
\int_{0}^{5}(5-t) d t=\left.\left(5 t-\frac{t^{2}}{2}\right)\right|_{0} ^{5}=\frac{25}{2} .
$$"
391,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Problem Set 2,Regression,1,fi,0.01736111111,Text,"You are given the following data, where $d=1, n=4$.
$$
D=\{[[1], 2],[[2], 7],[[3],-3],[[4], 1]\}
$$
You want to use analytic linear regression to solve the problem.
Using the same data as in the previous question (with two added noise dimensions) but using ridge regression with $\lambda=1 \times$ $10^{-10}$
We get the following parameters:
$$
\theta=\left[\begin{array}{l}
-1.377711 \times 10^{0} \\
-2.574581 \times 10^{5} \\
-5.070563 \times 10^{4}
\end{array}\right], \theta_{0}=7.260269 \times 10^{0}
$$
Does this hypothesis have higher or lower training set error than the result without ridge regression?",Multiple Choice,Higher.,"You are given the following data, where $d=1, n=4$.
$$
D=\{[[1], 2],[[2], 7],[[3],-3],[[4], 1]\}
$$
You want to use analytic linear regression to solve the problem.
Using the same data as in the previous question (with two added noise dimensions) but using ridge regression with $\lambda=1 \times$ $10^{-10}$
We get the following parameters:
$$
\theta=\left[\begin{array}{l}
-1.377711 \times 10^{0} \\
-2.574581 \times 10^{5} \\
-5.070563 \times 10^{4}
\end{array}\right], \theta_{0}=7.260269 \times 10^{0}
$$
Does this hypothesis have higher or lower testing set error than the result without ridge regression?",Lower.,"You are given the following data, where $d=1, n=4$.
$$
D=\{[[1], 2],[[2], 7],[[3],-3],[[4], 1]\}
$$
You want to use analytic linear regression to solve the problem.
Now, if we change the data to have a small amount of noise so that
$$
D=\{[[1, \epsilon, \epsilon], 2],[[2, \epsilon, \epsilon], 7],[[3, \epsilon, \epsilon],-3],[[4, \epsilon, \epsilon], 1]\}
$$
where the $\epsilon$ values are all different, randomly chosen independently in the range $\left(-1 \times 10^{-5},+1 \times 10^{-5}\right)$, we get the following parameters:
$$
\theta=\left[\begin{array}{c}
4.70697 \times 10^{0} \\
-1.28107 \times 10^{6} \\
1.10581 \times 10^{7}
\end{array}\right], \theta_{0}=-1.03437 \times 10^{2}
$$
This hypothesis has the following MSE on the training data: $1.6970 \times 10^{-24}$.
Consider a ""testing"" set, which is very similar to the training set:
$$
D=\{[[1,0,0], 2],[[2,0,0], 7],[[3,0,0],-3],[[4,0,0], 1]\} .
$$
What's the MSE of th, th0 on the testing set?",8782.9,"You are given the following data, where $d=1, n=4$.
$$
D=\{[[1], 2],[[2], 7],[[3],-3],[[4], 1]\}
$$
You want to use analytic linear regression to solve the problem.
What is the MSE of the hypothesis you found on the data (any answer within the right order of magnitude will be fine)?",10.575
423,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Problem Set 2,Regression,6,b,0.05208333333,Text,"We will now try to synthesize what we've learned in order to perform ridge regression on the DataCommons public health dataset that we explored in Lab 2. Unlike in Lab 2, where we did some simple linear regressions, here we now employ and explore regularization, with the goal of building a model which generalizes better (than without regularization) to unseen data.
The overall objective function for ridge regression is
$$
J_{\text {ridge }}\left(\theta, \theta_{0}\right)=\frac{1}{n} \sum_{i=1}^{n}\left(\theta^{T} x^{(i)}+\theta_{0}-y^{(i)}\right)^{2}+\lambda\|\theta\|^{2}
$$
Remarkably, there is an analytical function giving $\Theta=\left(\theta, \theta_{0}\right)$ which minimizes this objective, given $X, Y$, and $\lambda$. But how should we choose $\lambda$?
To choose an optimum $\lambda$, we can use the following approach. Each particular value of $\lambda$ gives us a different linear regression model. And we want the best model: one which balances providing good predictions (fitting well to given training data) with generalizing well (avoiding overfitting training data). And as we saw in the notes on Regression, we can employ cross-validation to evaluate and compare different models.
Let us begin by implementing this algorithm for cross-validation:
CROSS-VALIDATE $(\mathcal{D}, k)$
1 divide $\mathcal{D}$ into $k$ chunks $\mathcal{D}_{1}, \mathcal{D}_{2}, \ldots \mathcal{D}_{k}$ (of roughly equal size)
2 for $i=1$ to $k$
3 train $h_{i}$ on $\mathcal{D} \backslash \mathcal{D}_{i}$ (withholding chunk $\mathcal{D}_{i}$ )
4 compute ""test"" error $\mathcal{E}_{\mathfrak{i}}\left(h_{i}\right)$ on withheld data $\mathcal{D}_{i}$
5 return $\frac{1}{k} \sum_{i=1}^{k} \varepsilon_{i}\left(h_{i}\right)$
Below, X and Y are sample data, and lams is a list of possible values of lambda. Write code to set errors as a list of corresponding cross-validation errors. Use the cross_validate function above to run cross-validation with three splits. Use the following functions (which we implement for you, per the specifications below) as the learning algorithm and loss function:
def ridge_analytic(X_train, Y_train, lam):
'''Applies analytic ridge regression on the given training data.
Returns th, th0.
X : d x n numpy array (d = # features, n = # data points)
Y : 1 x n numpy array
lam : (float) regularization strength parameter
th : d x 1 numpy array
th0 : 1 x 1 numpy array'''
def mse(x, y, th, th0):
'''Calculates the mean-squared loss of a linear regression.
Returns a scalar.
x : d x n numpy array
y : 1 x n numpy array
th : d x 1 numpy array
th0 : 1 x 1 numpy array'''
X = np.array([[4, 6, 8, 2, 9, 10, 11, 17],
[1, 1, 6, 0, 5, 8, 7, 9],
[2, 2, 2, 6, 7, 4, 9, 8],
[1, 2, 3, 4, 5, 6, 7, 8]])
Y = np.array([[1, 3, 3, 4, 7, 6, 7, 7]])
lams = [0, 0.01, 0.02, 0.1]
errors = [] # your code here",Programming,"X = np.array([[4, 6, 8, 2, 9, 10, 11, 17],
[1, 1, 6, 0, 5, 8, 7, 9],
[2, 2, 2, 6, 7, 4, 9, 8],
[1, 2, 3, 4, 5, 6, 7, 8]])
Y = np.array([[1, 3, 3, 4, 7, 6, 7, 7]])
lams = [0, 0.01, 0.02, 0.1]
errors = [cross_validate(X, Y, 3, lam, ridge_analytic, mse) for lam in lams]","We will now try to synthesize what we've learned in order to perform ridge regression on the DataCommons public health dataset that we explored in Lab 2. Unlike in Lab 2, where we did some simple linear regressions, here we now employ and explore regularization, with the goal of building a model which generalizes better (than without regularization) to unseen data.
The overall objective function for ridge regression is
$$
J_{\text {ridge }}\left(\theta, \theta_{0}\right)=\frac{1}{n} \sum_{i=1}^{n}\left(\theta^{T} x^{(i)}+\theta_{0}-y^{(i)}\right)^{2}+\lambda\|\theta\|^{2}
$$
Remarkably, there is an analytical function giving $\Theta=\left(\theta, \theta_{0}\right)$ which minimizes this objective, given $X, Y$, and $\lambda$. But how should we choose $\lambda$?
To choose an optimum $\lambda$, we can use the following approach. Each particular value of $\lambda$ gives us a different linear regression model. And we want the best model: one which balances providing good predictions (fitting well to given training data) with generalizing well (avoiding overfitting training data). And as we saw in the notes on Regression, we can employ cross-validation to evaluate and compare different models.
Let us begin by implementing this algorithm for cross-validation:
CROSS-VALIDATE $(\mathcal{D}, k)$
1 divide $\mathcal{D}$ into $k$ chunks $\mathcal{D}_{1}, \mathcal{D}_{2}, \ldots \mathcal{D}_{k}$ (of roughly equal size)
2 for $i=1$ to $k$
3 train $h_{i}$ on $\mathcal{D} \backslash \mathcal{D}_{i}$ (withholding chunk $\mathcal{D}_{i}$ )
4 compute ""test"" error $\mathcal{E}_{\mathfrak{i}}\left(h_{i}\right)$ on withheld data $\mathcal{D}_{i}$
5 return $\frac{1}{k} \sum_{i=1}^{k} \varepsilon_{i}\left(h_{i}\right)$
Let's implement the cross-validation algorithm as the procedure cross_validate, which takes the following input arguments:
\begin{itemize}
\item $\mathrm{x}$ : the list of data points $(d \times n)$
\item $\mathrm{Y}$ : the true values of the responders $(1 \times n)$
\item n_splits: the number of chunks to divide the dataset into
\item lam: the regularization parameter
\item learning_algorithm: a function that takes $X, Y$, and 1 lam, and returns th, th $\theta$
\item loss_function: a function that takes $X, Y$, th, and th $\theta$, and returns a $1 \times 1$ array
\end{itemize}
cross_validate should return a scalar, the cross-validation error of applying the learning algorithm on the list of data points.
Note that this is a generic version of cross-validation, that can be applied to any learning algorithm and any loss function. Later in this problem, we will use cross-validation specifically for ridge regression and mean square loss.
You have the following function available to you:
def make_splits(X, Y, n_splits):
'''
Splits the dataset into n_split chunks, creating n_split sets of
cross-validation data.
Returns a list of n_split tuples (X_train, Y_train, X_test, Y_test).
For the ith returned tuple:
*X_train and Y_train include all data except the ith chunk, and
* X_test and Y_test are the ith chunk.
X : d x n numpy array (d = #features, n = #data points)
Y : 1 x n numpy array
n_splits : integer
'''
def cross_validate(X, Y, n_splits, lam,
learning_algorithm, loss_function):
pass","def cross_validate(X, Y, n_splits, lam,
learning_algorithm, loss_function):
test_errors = []
for (X_train, Y_train, X_test, Y_test) in make_splits(X, Y, n_splits):
th, th0 = learning_algorithm(X_train, Y_train, lam)
test_errors.append(loss_function(X_test, Y_test, th, th0))
return np.array(test_errors).mean()","We are interested in performing ordinary least squares regression given data $X, Y$ to find parameters $\theta, \theta_{0}$ that minimize the mean squared error objective: 
$$
J\left(\theta, \theta_{0}\right)=\frac{1}{n} \sum_{i=1}^{n} L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)
$$
where the squared loss is
$$
L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)=\left(\hat{y}^{(i)}-y^{(i)}\right)^{2}=\left(\theta^{T} x^{(i)}+\theta_{0}-y^{(i)}\right)^{2}
$$
Note that the $L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)$ notation here is used to emphasize that the loss depends on both the data sample $\left(x^{(i)}, y^{(i)}\right)$, and the parameters, $\theta$ and $\theta_{0}$. Compared to the $\mathcal{L}_{s}$ notation as used in some part of the notes and the lab, we see that $L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)=\mathcal{L}_{s}\left(h\left(x^{(i)} ; \theta, \theta_{0}\right), y^{(i)}\right)$, where $h\left(x^{(i)} ; \theta, \theta_{0}\right)=\theta^{T} x^{(i)}+\theta_{0}$.
Now implement $\theta^{*}$ as found in the previous problem, using symbols $\mathrm{X}$ and $\mathrm{Y}$ for the data matrix and outputs, and np.dot(or @ shorthand), np.transpose (or .T shorthand), np.linalg.inv.
# Enter an expression to compute and set th to the optimal theta
th = None","th = np.dot(np.linalg.inv(np.dot(X, X.T)), np.dot(X, Y.T))","We are beginning our study of machine learning with linear regression which is a fundamental problem in supervised learning. Please study Sections $2.1$ through $2.4$ of the Chapter 2 - Regression lecture notes before starting in on these problems.
A hypothesis in linear regression has the form
$$
y=\theta^{T} x+\theta_{0}
$$
where $x$ is a $d \times 1$ input vector, $y$ is a scalar output prediction, $\theta$ is a $d \times 1$ parameter vector and $\theta_{0}$ is a scalar offset parameter.
This week, just to get warmed up, we will consider a simple algorithm for trying to find a hypothesis that fits the data well: we will generate a lot of random hypotheses and see which one has the smallest error on this data, and return that one as our answer. (We don't recommend this method in actual practice, but it gets us started and makes some useful points.)
Use the mse and lin_reg_predict procedures to implement a procedure that takes
\begin{itemize}
\item $\mathrm{X}: d \times n$ input array representing $n$ points in $d$ dimensions
\item Y: $1 \times n$ output vector representing output values for $n$ points
\item th: parameter vector $d \times 1$
\item th $\emptyset$ : offset $1 \times 1$ (or scalar)
\end{itemize}
and returns
\begin{itemize}
\item  $1 \times 1$ (or scalar) value representing the MSE of hypothesis th, th 0 on the data set $X, Y$.
\item Read about the axis argument to $n p$. mean 
\end{itemize}
import numpy as np
def lin_reg_err(X, Y, th, th0):
pass","import numpy as np
def lin_reg_err(X, Y, th, th0):
return mse(Y, lin_reg_predict(X, th, th0))"
498,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Problem Set 4,Logistic Regression,4,ci,0.01275510204,Text,"Our eventual goal is to do gradient descent on the logistic regression objective $J_{\text {nll }}$. In this problem, we'll take the first step toward deriving that gradient update. We'll focus on the gradient of the loss at a single point with respect to parameters $\theta$ and $\theta_{0}$.
What is the maximum value of $\frac{\partial \sigma(z)}{\partial z}$?",Numerical,0.25.,"Our eventual goal is to do gradient descent on the logistic regression objective $J_{\text {nll }}$. In this problem, we'll take the first step toward deriving that gradient update. We'll focus on the gradient of the loss at a single point with respect to parameters $\theta$ and $\theta_{0}$.
What is the largest number that is always less than any actual value of $\frac{\partial \sigma(z)}{\partial z}$?",0,"Our eventual goal is to do gradient descent on the logistic regression objective $J_{\text {nll }}$. In this problem, we'll take the first step toward deriving that gradient update. We'll focus on the gradient of the loss at a single point with respect to parameters $\theta$ and $\theta_{0}$.
What is an expression for the derivative of the sigmoid function $\sigma(z)=\frac{1}{1+e^{-z}}$ with respect to $z$, expressed as a function of $z$, its input? Enter a Python expression (use ** for exponentiation) involving e and $z$.","Solution 1: e**(-z)/(1 + e**(-z))**2
Solution 2: (1/(1+e**(-z)))*(1-(1/(1+e**(-z))))","Our eventual goal is to do gradient descent on the logistic regression objective $J_{\text {nll }}$. In this problem, we'll take the first step toward deriving that gradient update. We'll focus on the gradient of the loss at a single point with respect to parameters $\theta$ and $\theta_{0}$.
What is an expression for the derivative of the sigmoid with respect to $z$, but this time expressed as a function of $o=\sigma(z)=\frac{1}{1+e^{-z}}$ ? (It's beautifully simple!)
Hint: Think about the expression $1-\frac{1}{1+e^{-z}}$. (Here is a review of computing derivatives.)
Enter a Python expression (use ** for exponentiation) involving only $o$. e and $z$ are not allowed, and remember $o=\sigma(z)$. ",o*(1-o)
317,Mathematics,18.01,Calculus I,None,None,Problem Set 7,Second Order Differential Equations,9,a,0.04751847941,Text,Check that the equation $x^{\prime}(t)=-x(t)$ is linear.,Open,"Suppose functions $x(t)$ and $z(t)$ are solutions to $x^{\prime}(t)=-x(t)$, and let $s(t)=x(t)+z(t)$ be their sum. Since $x$ and $z$ are solutions we have
$$
\begin{aligned}
& x^{\prime}(t)=-x(t), \\
& z^{\prime}(t)=-z(t)
\end{aligned}
$$
Adding the two equations we have
$$
s^{\prime}(t)=x^{\prime}(t)+z^{\prime}(t)=-x(t)-z(t)=-s(t)
$$
So $s(t)$ also solves the differential equation. And for any constant $A, A x(t)$ also solves the differential equation since
$$
x^{\prime}(t)=-x(t) \quad \Rightarrow \quad A x^{\prime}(t)=A \cdot(-x(t))=-(A x(t))
$$","If $C$ is a constant, then check that the equation $x^{\prime \prime}(t)=-C x(t)$ is linear.","Suppose functions $x(t)$ and $z(t)$ are solutions to $x^{\prime \prime}(t)=-C x(t)$, and let $s(t)=x(t)+z(t)$ be their sum. The fact that $x$ and $z$ are solutions says that
$$
\begin{aligned}
& x^{\prime \prime}(t)=-C x(t), \\
& z^{\prime \prime}(t)=-C z(t) .
\end{aligned}
$$
Adding the two equations yields
$$
s^{\prime \prime}(t)=x^{\prime \prime}(t)+z^{\prime \prime}(t)=-C x(t)-C z(t)=-C s(t),
$$
So function $s$ solves the differential equation. Furthermore,
$$
x^{\prime \prime}(t)=-C x(t) \Rightarrow A x^{\prime \prime}(t)=A \cdot\left(-C x^{\prime \prime}(t)\right)=-C \cdot(A x(t)),
$$
so $A x$ solves the differential equation.","Consider the equation $x^{\prime \prime}(t)=-x(t)$.
Check that $\sin t$ and $\cos t$ obey this equation.","For $x(t)=\sin t, x^{\prime \prime}=-\sin t$, which indeed is $-x$. Similarly, for $x(t)=\cos t$, $x^{\prime \prime}=-\cos t$, which again is $-x$.",Is the equation $x^{\prime \prime}(t)=x(t)-2$ linear? Explain your reasoning.,"For the zero function, the left-hand side (LHS) $z_{0}^{\prime \prime}(t)=0$ does not equal the RHS $z_{0}(t)-2=-2$. So the differential equation is not linear."
220,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 6,Particle Filter,5,c,0.25,Text,"Consider a domain in which the forward transition dynamics are ""hybrid"" in the sense that 
$$
P\left(X_{t}=x_{t} \mid X_{t-1}=x_{t-1}\right)=p * N\left(x_{t-1}+1,0.1\right)\left(x_{t}\right)+(1-p) * N\left(x_{t-1}-1,0.1\right)\left(x_{t}\right)
$$
that is, that the state will hop forward one unit in expectation with probability $p$, or backward one unit in expectation with probability $1-p$, with variance $0.1$ in each case.
Assume additionally that the observation model $P\left(Y_{t}=y_{t} \mid X_{t}=x_{t}\right)=\operatorname{Uniform}\left(x_{t}-1, x_{t}+1\right)\left(y_{t}\right)$.
You know the initial state of the system $X_{0}=0$. Your friend Norm thinks it's fine to initialize a particle filter with a single particle at 0. What do you think?
(a) This is fine and we can continue with a single particle.
(b) We should initialize our pf with $N$ copies of this particle.",Multiple Choice,(b) We should initialize our pf with $N$ copies of this particle.,"Consider a domain in which the forward transition dynamics are ""hybrid"" in the sense that 
$$
P\left(X_{t}=x_{t} \mid X_{t-1}=x_{t-1}\right)=p * N\left(x_{t-1}+1,0.1\right)\left(x_{t}\right)+(1-p) * N\left(x_{t-1}-1,0.1\right)\left(x_{t}\right)
$$
that is, that the state will hop forward one unit in expectation with probability $p$, or backward one unit in expectation with probability $1-p$, with variance $0.1$ in each case.
Assume additionally that the observation model $P\left(Y_{t}=y_{t} \mid X_{t}=x_{t}\right)=\operatorname{Uniform}\left(x_{t}-1, x_{t}+1\right)\left(y_{t}\right)$.
Norm runs the filter for two steps with no observations several times and is trying to decide whether there could be bugs in the code. Assuming $p=0.5$, for each of the following sets of particles, indicate whether it is (a) fairly likely (b) quite unlikely (c) completely impossible: {-2.01, -1.9, -1.0, 0.1, 0, 2.1}.",b.,"Consider a domain in which the forward transition dynamics are ""hybrid"" in the sense that 
$$
P\left(X_{t}=x_{t} \mid X_{t-1}=x_{t-1}\right)=p * N\left(x_{t-1}+1,0.1\right)\left(x_{t}\right)+(1-p) * N\left(x_{t-1}-1,0.1\right)\left(x_{t}\right)
$$
that is, that the state will hop forward one unit in expectation with probability $p$, or backward one unit in expectation with probability $1-p$, with variance $0.1$ in each case.
Assume additionally that the observation model $P\left(Y_{t}=y_{t} \mid X_{t}=x_{t}\right)=\operatorname{Uniform}\left(x_{t}-1, x_{t}+1\right)\left(y_{t}\right)$.
Norm runs the filter for two steps with no observations several times and is trying to decide whether there could be bugs in the code. Assuming $p=0.5$, for each of the following sets of particles, indicate whether it is (a) fairly likely (b) quite unlikely (c) completely impossible: {-2.05, -1.95, -0.1, 0.1, 1.9, 2.1}.",a.,"Consider a domain in which the forward transition dynamics are ""hybrid"" in the sense that 
$$
P\left(X_{t}=x_{t} \mid X_{t-1}=x_{t-1}\right)=p * N\left(x_{t-1}+1,0.1\right)\left(x_{t}\right)+(1-p) * N\left(x_{t-1}-1,0.1\right)\left(x_{t}\right)
$$
that is, that the state will hop forward one unit in expectation with probability $p$, or backward one unit in expectation with probability $1-p$, with variance $0.1$ in each case.
Assume additionally that the observation model $P\left(Y_{t}=y_{t} \mid X_{t}=x_{t}\right)=\operatorname{Uniform}\left(x_{t}-1, x_{t}+1\right)\left(y_{t}\right)$.
Norm runs the filter for two steps with no observations several times and is trying to decide whether there could be bugs in the code. Assuming $p=0.5$, for each of the following sets of particles, indicate whether it is (a) fairly likely (b) quite unlikely (c) completely impossible: {-20, -2.01, -2.001, .01, .001, 1.99, 1.999}.",b.
103,EECS,6.18,Computer Systems Engineering,"6.1010, 6.1910",None,Midterm Exam 2,Meltdown,13,a,0.3,Text,"A colleague is proposing mitigation strategies for Meltdown in an architecture they are designing. For each proposal, choose the BEST response.
""We could eliminate speculative execution.""
(a) No Meltdown attacks would be affected by that change.
(b) That could help against Meltdown, but cost too much performance.
(c) That is a mitigating technique recommended in the published paper.
(d) That would fix the problem, and eliminate stack smashing too.",Multiple Choice,(b).,"A colleague is proposing mitigation strategies for Meltdown in an architecture they are designing. For each proposal, choose the BEST response.
""We could eliminate caching.""
(a) No Meltdown attacks would be affected by that change.
(b) That could help against Meltdown, but cost too much performance.
(c) That is a mitigating technique recommended in the published paper.
(d) That would fix the problem, and eliminate stack smashing too.",(b).,"A colleague is proposing mitigation strategies for Meltdown in an architecture they are designing. For each proposal, choose the BEST response.
""We could change the operating system to map in less of the kernel's address space.""
(a) No Meltdown attacks would be affected by that change.
(b) That could help against Meltdown, but cost too much performance.
(c) That is a mitigating technique recommended in the published paper.
(d) That would fix the problem, and eliminate stack smashing too.",(c).,"A colleague is proposing mitigation strategies for Meltdown in an architecture they are designing. For each proposal, choose the BEST response.
""We could add a mode that splits the address space.""
(a) No Meltdown attacks would be affected by that change.
(b) That could help against Meltdown, but cost too much performance.
(c) That is a mitigating technique recommended in the published paper.
(d) That would fix the problem, and eliminate stack smashing too.",(c).
14,Mathematics,18.701,Algebra I,18.100B,None,Problem Set 2,Cyclic Groups,5,nan,0.5,Text,"Prove that the two matrices
$$
E=\left[\begin{array}{ll}
1 & 1 \\
0 & 1
\end{array}\right], E^{\prime}=\left[\begin{array}{ll}
1 & 0 \\
1 & 1
\end{array}\right]
$$
generate the group $S L_2(\mathbb{Z})$ of all integer matrices with determinant 1. Remember that the subgroup they generate consists of all elements that can be expressed as products using the four elements $E, E^{\prime}, E^{-1}, E^{\prime-1}$.
Hint: Do not try to write a matrix directly as a product of the generators. Use row reduction.",Open,"It is hard to use the fact that $S L_{2}(\mathbb{R})$ is generated by elementary matrices of the first type here. One has to start over.
As always, the method is to reduce a matrix $A$ in $S L_{2}(\mathbb{Z})$ to the identity using the given elementary matrices $E$ and $E^{\prime}$ and their inverses. What multiplication by a power of $E$ or $E^{\prime}$ does to a matrix $A$ is add a (positive or negative) integer multiple of one row to the other.
Let's work on the first column of
$$
A=\left(\begin{array}{ll}
a & b \\
c & d
\end{array}\right)
$$
using division with remainder. Also, let's denote the entries of any one of the matrices that we get along the way by $a, b, c, d$. We don't need to change notation at each step.
Note first that because $\operatorname{det} A=1$, the entries $a$ and $c$ of the first column can't both be zero.
Step 1: We make one of the entries $a$ or $c$ of the first column positive. If $c \neq 0$, we add a large positive or negative integer multiple of the second row to the first to make $a>0$. If $c=0$, then $a \neq 0$. In this case we do the analogous thing to make $c>0$.
Step 2: If $a>0$, we divide $c$ by $a$, writing $c=a q+r$ where $q$ and $r$ are integers and $0 \leq r<a$. Then we add $-q($ row 1$)$ to row2. This replaces $c$ by $r$. We change notation, writing $c$ for $r$ in the new matrix, and $d$ for the other entry of row2. Now $0 \leq c<a$. If $c=0$, we stop.
Step 3: If $c>0$, we divide $a$ by $c: a=c q^{\prime}+r^{\prime}$, where $0 \leq r^{\prime}<c$. We add $q^{\prime}$ (row2) to row1, which changes $a$ to $r^{\prime}$. We adjust notation, writing $a$ for $r^{\prime}$. If $a=0$ we stop. If $a>0$, we go back to Step 2.
Since the entries of the first column decrease at each step, the process must stop at some point, with either $c=0$ or $a=0$. Then since $\operatorname{det} A=a d-b c=1$, the nonzero entry of the first column must be 1.
Step 4: If the entry 1 of the first column is the ""c"" entry, we add (row2) to (row1) to get $a=c=1$. Then we subtract (row1) from $($ row 2$)$ to get $a=1, c=0$.
Step 5: The matrix is now $A=\left(\begin{array}{ll}1 & b \\ 0 & d\end{array}\right)$. Since $\operatorname{det} A=1, d=1$. We subtract $b($ row 2$)$ from (row1) to get the identity matrix.",Prove that the elementary matrices of the first type generate $S L_n(\mathbb{R})$. Do the $2 \times 2$ case first.,"Let's do the $2 \times 2$ case. Let $A$ be a matrix $\left(\begin{array}{ll}a & b \\ c & d\end{array}\right)$ with determinant equal to 1. We must show that $A$ can be reduced to the identity using the first type of elementary row operations. In describing this process, we'll use the symbols $a, b, c, d$ to denote the matrix entries in all of the matrices we get as we go along. Our end result should be $a=d=1$, $b=c=0$.
If $c=0$, then $a$ can't be zero. In that case, we add row 1 to row 2 to eliminate this possibility. Next, since $c \neq 0$ in our new matrix, we can add a multiple of row 2 to row 1 to change $a$ to 1 . Then we add a multiple of row 1 to row 2 to change $c$ to 0 . The new matrix has $a=1$ and $c=0$. Elementary operations of the first type don't change the determinant. So the determinant of the new matrix with $a=1$ and $c=0$ is still equal to 1. Therefore $d=1$ in this matrix, an one further row operation reduces the matrix to the identity.",The group $S L_n(\mathbb{R})$ is generated by elementary matrices of the first type (see Exercise 4.8). Use this fact to prove that $S L_n(\mathbb{R})$ is path-connected.,"We know from a previous assginment that $S L_{n}$ is generated by elementary matrices of the first type: $E=$ $I+a e_{i j}$. Such a matrix connected to the identity by a path $E_{t}=I+a t e_{i j}$ in $S L_{n}$. Then $A$ connects to $E A$ by the path $E_{t} A$. The relation $A \sim B$ defined in Problem M.6 is an equivalence relation, so any two elements of $S L_{n}$ can be connected by a path.","One of the black boxes we used in class was the theorem that an $n \times n$ matrix $A$ has $A \vec{v}=0$ for some non-zero vector $\vec{v} \in \mathbb{R}^{n}\left(\right.$ or $\mathbb{C}^{n}$ ) if and only if $\operatorname{det}(A)=0$ (see, e.g., MITx 20.7). The goal of this problem is to work out $w h y$ this is true (at least in the case of $3 \times 3$ matrices). The only blackbox we will use is the properties of the determinant. Recall that $\operatorname{dim} \operatorname{Ker}(A)=0$ means that $\operatorname{Ker}(A)$ contains only the zero vector.
(Story time begins) The way we are going to go about showing that a $3 \times 3$ matrix has $\operatorname{det} A=0$ if and only if $\operatorname{dim} \operatorname{Ker}(A)>0$ is by using Gaussian elimination to reduce the statement to the case of upper triangular (or rather, RREF) matrices. So, as a first step, we're going to check that the theorem is true for this model case. (Story time ends)
(Story time begins, again) At this point we can make the following conclusion: If $A$ is a $3 \times 3$ matrix in reduced row echelon form, then $\operatorname{dim} \operatorname{Ker}(A)>0$ if and only if $\operatorname{det} A=0$. The next step is to turn this into a statement about general $3 \times 3$ matrices using Gauss-Jordan elimination. (Story time ends, again)
Recall that the elementary row operations consist of swapping rows, multiplying a row by a non-zero constant, and adding rows. Find matrices $E_{i}$ such that each row operation corresponds to multiplication on the left by one of the $E_{i}$. For example, multiplying the top row of $A$ by a non-zero constant $c$ corresponds to
$$
\left(\begin{array}{lll}
c & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{array}\right) A
$$
We call the matrices $E_{i}$ elementary matrices. (Hint: including the one given to you above, there should be 12 such matrices. Once you recognize the pattern you should be able to write them all down fairly quickly.)","You can do the same elementary row operation to the identity matrix to find the corresponding elementary matrix.
The twelve elementary matrices $E_i$ are 
\begin{enumerate}[label=(\roman*)]
\item Swapping the first row of $A$ with the second row of $A$ corresponds to
\begin{center}
\boxed{E_1 = \begin{pmatrix}
0 & 1 & 0 \\
1 & 0 & 0 \\
0 & 0 & 1
\end{pmatrix}}
\end{center}
\item Swapping the first row of $A$ with the third row of $A$ corresponds to
\begin{center}
\boxed{E_2 = \begin{pmatrix}
0 & 0 & 1 \\
0 & 1 & 0 \\
1 & 0 & 0
\end{pmatrix}}
\end{center}
\item Swapping the second row of $A$ with the third row of $A$ corresponds to
\begin{center}
\boxed{E_3 = \begin{pmatrix}
1 & 0 & 0 \\
0 & 0 & 1 \\
0 & 1 & 0
\end{pmatrix}}
\end{center}
\item Multiplying the top row of $A$ by a non-zero constant $c$ corresponds to
\begin{center}
\boxed{E_4 = \begin{pmatrix}
c & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{pmatrix}}
\end{center}
\item Multiplying the middle row of $A$ by a non-zero constant $c$ corresponds to
\begin{center}
\boxed{E_5 = \begin{pmatrix}
1 & 0 & 0 \\
0 & c & 0 \\
0 & 0 & 1
\end{pmatrix}}
\end{center}
\item Multiplying the bottom row of $A$ by a non-zero constant $c$ corresponds to
\begin{center}
\boxed{E_6 = \begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & c
\end{pmatrix}}
\end{center}
\item Adding the second row of $A$ to the first row of $A$ corresponds to
\begin{center}
\boxed{E_7 = \begin{pmatrix}
1 & 1 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{pmatrix}}
\end{center}
\item Adding the third row of $A$ to the first row of $A$ corresponds to
\begin{center}
\boxed{E_8 = \begin{pmatrix}
1 & 0 & 1 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{pmatrix}}
\end{center}
\item Adding the first row of $A$ to the second row of $A$ corresponds to
\begin{center}
\boxed{E_9 = \begin{pmatrix}
1 & 0 & 0 \\
1 & 1 & 0 \\
0 & 0 & 1
\end{pmatrix}}
\end{center}
\item Adding the third row of $A$ to the second row of $A$ corresponds to
\begin{center}
\boxed{E_{10} = \begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 1 \\
0 & 0 & 1
\end{pmatrix}}
\end{center}
\item Adding the first row of $A$ to the third row of $A$ corresponds to
\begin{center}
\boxed{E_{11} = \begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
1 & 0 & 1
\end{pmatrix}}
\end{center}
\item Adding the second row of $A$ to the third row of $A$ corresponds to
 \begin{center}
\boxed{E_{12} = \begin{pmatrix}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 1 & 1
\end{pmatrix}}
\end{center}
\end{enumerate}"
134,EECS,6.121,Introduction to Algorithms,"6.100A, 6.1200",6.101,Midterm Exam 2,Weighted Directed Graph,2,b,2,Text,"We are given a directed weighted graph $G$ with both positive and negative weights. Provide an algorithm that returns a directed cycle of positive weight in $G$, or report that none exists. Correct algorithms with better running times will receive more credit. You can invoke any algorithm discussed in lecture, recitations or p-sets.",Open,"Create a graph $G^{\prime}$ with the same vertices and edges, but with the edge weights negated. Add a super node $s$ with directed edges with weight 0 to all original nodes. Run Bellman-Ford on $G^{\prime}$ starting from $s$ to either find a negative-weight cycle (by following parent pointers from a witness), or report that none exists. A negative-weight cycle in $G^{\prime}$ is a positive-weight cycle in $G$. This takes $O(|V| \cdot|E|)$ time. ","Your friend Mash Coney was shopping online and noticed that someone was selling 3 TVs in exchange for 5 laptops. She saw another deal, selling 10 shirts for $1 \mathrm{TV}$, and another one selling 5 laptops for 3 shirts.
Mash worked out the math and realized that if she invests 5 laptops, she can exchange it for 3 TVs, exchange those for 30 shirts, to finally get 50 laptops. She just $10 \times$ 'ed her laptops! Notice that this sort of opportunity would not exist if the second deal was 1 shirt for 1 TV.
Sadly, Mash can only handle the business side, and reaches out to you, a $6.006$ student, to code the algorithm to find these money-making opportunities from online stores. We're going to use graphs to solve this problem!
Given a graph, $(V, E) \in G$, recall that the Bellman-Ford algorithm is able to tell us if a given graph contains a negative-weight cycle or not in $O(|V \| E|)$ time. However, it does not tell us where the cycle is.
Modify the Bellman-Ford algorithm such that it can also return an array of all nodes that are on a negative-weight cycle, if one exists. Justify why your algorithm is $O(|V \| E|)$ time. If the graph has multiple negative-weight cycles, you are free to return any one of them. Note that in your output array, it does not matter what the first element is, as long as it is in cyclical order. You can assume that each node is labeled with a unique integer from 0 to $|V|-1$, inclusive.","Bellman-Ford relaxes every edge, $|V|$ times. If we can relax an edge during the last round, then we know that there is a negative-weight cycle on this graph. The vertices incident to the edges that could be relaxed on the last round are surely reachable from a negative-weight cycle. Note that they are not necessarily on the cycle themselves. We call such vertices ""witnesses"". Using the parent pointer chain, we back-track from any such witness, using a DAA to keep track of seen nodes in $O(1)$ time per lookup/insert. If we encounter a vertex that we have already seen, that vertex has to be on the negative-weight cycle. We then repeat the parent pointer back-track starting at that vertex, until we see it again, inserting it into a linked list, which we return.
Since the length of this cycle is at most $|V|$, our tracing algorithm is within the $O(|V \| E|)$ budget.","Consider the weighted directed graph below.
Modify the weights so that they are all non-negative and yet all shortest paths are preserved. No justification needed, though you might want to show your work in case you make a small mistake.","Run Johnson's first step. We add a super-node $s$ connected to all other vertices with edges of weight 0 . The shortest distances from $s$ to all other vertices are $\delta(z)=0, \delta(x)=-7, \delta(y)=-4, \delta(w)=-1$. Using $w^{\prime}(u, v)=w(u, v)+\delta(u)-\delta(v)$, we get the following.
There are alternative solutions. For example, given that the graph consists of a single strongly connected component, one does not need to add a super-node to do BF on the first step. One can start BF form any node in the graph. Different choices will end up in a different set of weights, all of them correct. ","You are given a weighted directed graph $G=(V, E, w)$ where each node $v$ has a color v.color (which is part of the input). Assume that there are $k$ possible colors and that the weights can be both positive and negative. Describe an algorithm that computes the length of the shortest path from a designated source $s$ to a given destination $t$, where every time the path repeats colors, you incur a cost of $\ell$. Here, we say that a path repeats colors if two consecutive nodes in the path have the same color. So, for example, going RED, BLUE, RED does not repeat colors but going RED, BLUE, BLUE does. You can assume that there is at least one path from $s$ to $t$.
For full credit, provide a short description of the algorithm and an analysis of its run time. The runtime should be expressed in terms of $|V|,|E|$ and/or $k$. Faster algorithms will receive more credit. You can invoke any algorithm discussed in lecture, recitation or p-sets.",Change the weights to add $l$ to the weight of any edge between nodes of the same color. Run BF. The cost is $O(|V| \cdot|E|)$.
0,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Prelab Questions 1,Binary Representation,1,a,0.03333333333,Text,Write 5 as a 4-bit binary number:,Numerical,"0b0101.
As $5=0 \times 2^{3}+1 \times 2^{2}+0 \times 2^{1}+1 \times 2^{0}$, this is equivalent to 0b0101. The 0b prefix indicates that it is a binary number.",Write -11 as a 5-bit binary number using 2's complement representation:,"0b10101.
As $11=0 \times 2^{4}+1 \times 2^{3}+0 \times 2^{2}+1 \times 2^{1}+1 \times 2^{0}$, this is equivalent to 0b01011. The $2^{\prime}$ s complement representation of $-11$ can be found by inverting all the bits and adding 1.
$$
0b01011 \stackrel{\text { invert bits }}{\longrightarrow} 0b10100 \stackrel{+1}{\longrightarrow} 0b10101
$$","Write 7 and 4 in 4-bit 2's complement notation, then add them together using fixed width 2's complement arithmetic. Show your work. Provide your result in binary, and decimal. For each computation also specify whether or not overflow occurred.","Sum in binary: $0b1011$
Sum in decimal: $-5$
Did overflow occur? (Yes/No): Yes","Write -3 and -4 in 4-bit 2's complement notation, then add them together using fixed width 2's complement arithmetic. Show your work. Provide your result in binary, and decimal. For each computation also specify whether or not overflow occurred.","Sum in binary: $0b1001$
Sum in decimal: -7
Did overflow occur? (Yes/No): No"
33,EECS,6.121,Introduction to Algorithms,"6.100A, 6.1200",6.101,Problem Set 3,Critter Sort,1,e,0.125,Text,"Professor Oak is trying to organize his $n$ Critters so he can study them more efficiently. For each of the following scenarios, provide the most efficient algorithm for sorting the Critters, and state whether the asymptotic complexity is $\Theta(n), \Theta(n \log n)$, or $\Theta\left(n^{2}\right)$. Briefly justify your answers (a sentence or two suffices). Choose only one of the following sorting algorithms from lecture and recitation: insertion sort, selection sort, merge sort, counting sort, and radix sort.
Professor Oak's Critters like to battle each other. Each Critter has participated in at least one battle, and each pair of Critters has battled each other at most once. Professor Oak wants to sort his Critters by the number of times that they have battled.",Open,"The sorting key is an integer in the range $[1, n]$, and so radix sort takes $\Theta(n)$ time.","Professor Oak is trying to organize his $n$ Critters so he can study them more efficiently. For each of the following scenarios, provide the most efficient algorithm for sorting the Critters, and state whether the asymptotic complexity is $\Theta(n), \Theta(n \log n)$, or $\Theta\left(n^{2}\right)$. Briefly justify your answers (a sentence or two suffices). Choose only one of the following sorting algorithms from lecture and recitation: insertion sort, selection sort, merge sort, counting sort, and radix sort.
Professor Oak wants to sort his Critters alphabetically by the names he has given them, which are strings of length at $\operatorname{most} \log _{2} n+1$, containing lowercase letters of the English alphabet. Each string is stored as contiguous bits in memory.","There are 26 choices for each letter. Therefore, the names can be interpreted as positive integers bounded by $26^{\log _{2} n+1}=O\left(n^{6}\right)$, so we can use radix sort in $\Theta(n)$ time.","Professor Oak is trying to organize his $n$ Critters so he can study them more efficiently. For each of the following scenarios, provide the most efficient algorithm for sorting the Critters, and state whether the asymptotic complexity is $\Theta(n), \Theta(n \log n)$, or $\Theta\left(n^{2}\right)$. Briefly justify your answers (a sentence or two suffices). Choose only one of the following sorting algorithms from lecture and recitation: insertion sort, selection sort, merge sort, counting sort, and radix sort.
Professor Oak wants to sort his Critters by their species' ID number, which is a positive integer less than 894.","The sorting key comes from a constant-size set, and so counting sort runs in $\Theta(n)$ time.","Professor Oak is trying to organize his $n$ Critters so he can study them more efficiently. For each of the following scenarios, provide the most efficient algorithm for sorting the Critters, and state whether the asymptotic complexity is $\Theta(n), \Theta(n \log n)$, or $\Theta\left(n^{2}\right)$. Briefly justify your answers (a sentence or two suffices). Choose only one of the following sorting algorithms from lecture and recitation: insertion sort, selection sort, merge sort, counting sort, and radix sort.
After Professor Oak sorts his Critters by their weight, one of the Critters got heavier. Professor Oak wants to resort his Critters by weight.","Only one Critter has a different weight from before, and so insertion sort will only need to do $\Theta(n)$ work to put this Critter into its new correct position."
434,Mathematics,18.01,Calculus I,None,None,Midterm Exam 2,Integrals,1,nan,1.166666667,Text,Find $\int_{0}^{10} \frac{1}{10+x} d x$.,Numerical,"We use the $u$-substitution $u=10+x$, so $d u=d x$. This gives the integral $\int_{10}^{20} \frac{d u}{u}=\left.\ln (u)\right|_{10} ^{20}=\ln \left(\frac{20}{10}\right)=\ln (2)$.",Find $\int_{0}^{\infty} x e^{-x / 100} d x$.,"Do integration by parts with $u(x)=x$ and
$$
v(x)=-100 e^{-\frac{x}{100}}, \quad v^{\prime}(x)=e^{-\frac{x}{100}} .
$$
Then,
$$
\begin{aligned}
\int_{0}^{B} x e^{-x / 100} d x= & -\left.100 x e^{-x / 100}\right|_{0} ^{B}-\int_{0}^{B}-100 e^{-x / 100} d x \\
& =-100 B e^{-B / 100}-10,\left.000 e^{-x / 100}\right|_{0} ^{B} \\
& =-100 B e^{-B / 100}-10,000\left(e^{-B / 100}-1\right)
\end{aligned}
$$
Taking the limit $B \rightarrow \infty$,
$$
\int_{0}^{\infty} x e^{-x / 100} d x=\lim _{B \rightarrow \infty}\left[-100 B e^{-B / 100}+10,000\left(1-e^{-B / 100}\right)\right]=10,000
$$","Compute the following definite integrals, and simplify your answer as much as you can.
$\int_{10}^{20} \frac{1}{x} d x$.",$\int_{10}^{20} \frac{1}{x} d x=\ln (20)-\ln (10)=\ln \frac{20}{10}=\ln 2$.,"Compute the following definite integrals.
$\int_{7}^{10} 1 d x$.",$\int_{7}^{10} 1 d x=\left.x\right|_{7} ^{10}=3$.
73,EECS,6.121,Introduction to Algorithms,"6.100A, 6.1200",6.101,Mini Quiz 1,Runtime Analysis,2,b,0.2222222222,Text,"Consider the problem of finding whether a given string S of length s is a sub-string of a string N of length n. Assume s ≤ n.
def is_substring(S, N):
       for i in range(len(N)-len(S)):
             found = True
             for j in range(len(S)):
                   if N[i+j] != S[j]:
                      found = False
                      break
             if found:
                 return True
             return False
What is a lower bound on the worst-case running time of IS SUBSTRING (mark all correct answers)?
1. $\Omega(n^{2})$.
2. $\Omega(sn)$.
3. $\Omega(s^{2})$.",Multiple Choice,"1. $\Omega(n^{2})$. Incorrect, the maximum runtime of the algorithm is $\Omega(sn)$ in the case where S is not a substring of N which is less than $O(n^{2})$.
2. $\Omega(sn)$. Correct, the algorithm will take $\Omega(sn)$ steps in the case where S is not a substring of N.
3. $\Omega(s^{2})$. Correct, the correct lower bound is $\Omega(sn)$, but $\Omega(s^{2})$ is also a lower bound, though not tight.","Consider the problem of finding whether a given string S of length s is a sub-string of a string N of length n. Assume s ≤ n.
def is_substring(S, N):
       for i in range(len(N)-len(S)):
             found = True
             for j in range(len(S)):
                   if N[i+j] != S[j]:
                      found = False
                      break
             if found:
                 return True
             return False
What is an upper bound on the worst-case running time of IS SUBSTRING (mark all correct answers)?
1. $O(n^{2})$.
2. $O(sn)$.
3. $O(s^{2})$.  ","1. $O(n^{2})$. Correct, the runtime is $O(sn)$ which is less than $O(n^{2})$.
2. $O(sn)$. Correct, the runtime is $O(sn)$.
3. $O(s^{2})$. Incorrect, the runtime is $O(sn) which maybe much larger than $O(s^{2})$ (for example if s = O(1)).","Alice is given a book $\mathcal{B}$, which we can think of as a long string of length $b$. The book consists solely of ASCII characters, that is to say, there are 128 possible characters in $\mathcal{B}$. Alice is running a search engine, where users give her input substrings $\mathcal{S}$ of arbitrary length $s$, and ask if $\mathcal{S}$ exists in their book or not. If it exists, they would like the index in $\mathcal{B}$ that marks the start of an instance of $\mathcal{S}$ in the book (if there are multiple instances of $\mathcal{S}$, the index of any of these instances will do). Assume $s \leq b$. Alice must pre-process her book $\mathcal{B}$ and build a data structure, such that she can efficiently answer search queries from her users.
Alice is unsatisfied with her basic solution. Instead, she would like a solution that allows her to construct a data structure in only $O\left(b^{2}\right)$ time, and she would like to be able to search for any given substring $\mathcal{S}$ in only $O(s \log b)$ time. Explain a way to construct such a data structure, and explain how searching for $\mathcal{S}$ would work with your new data structure. Your solution does not have to satisfy the new request from Part (3) (although your solution may end up satisfying this request anyways).
Note: There is actually a way to construct a data structure in $O(b \log b)$ time (using only the sorts taught in class so far), with the same time allowed for the substring search. This is somewhat tricky to do and is not required for this problem, but it is fun to think about!","The main idea is to sort all suffixes of $\mathcal{B}$ using radix sort, and then modify the binary search for our substring $\mathcal{S}$ to check if it is a prefix of one of the suffixes of $\mathcal{B}$. More precisely, we first append a character $\circ$ to the end of $\mathcal{B}$ that we consider to be lexicographically after every character in ASCII. Then, we consider the set of every cyclic rotation of $\mathcal{B}$; by cyclic rotations, we mean for each $i=0, \ldots, b-1$, we consider $\mathcal{C}_{i}=\mathcal{B}[i, b]+\mathcal{B}[0, i]$ (where $+$ denotes string concatenation). We use radix sort to sort the set of all $\mathcal{C}_{i}$. This completes the construction of our data structure, and takes $O\left(b^{2}\right)$ time because we are performing radix sort on a set of $b$ strings each of length $b$.
Note that there are some valid ways that capture the same idea as adding a character $\circ$ and taking the cyclic rotations of $\mathcal{B}$. For instance, one could take the suffixes of $\mathcal{B}$, but append with o so that all of the suffixes are of the same length $b$, to allow for the radix sort to properly proceed.
When performing a binary search to find $\mathcal{S}$, we stop at the first substring greater than or equal to $\mathcal{S}$ in our sorted list of $\mathcal{C}_{i}$. It takes $O(s \log b)$ time to perform this binary search, where the factor of $s$ is to check for equality to $\mathcal{S}$. Then, we can check in $O(s)$ time if $\mathcal{S}$ is a prefix of the substring $\mathcal{C}_{i}$ that we find in our sorted list; if so, we return $i$, and if not, we report that $\mathcal{S}$ does not exist in $\mathcal{B}$.
Note that using a trie (which takes $O\left(b^{2}\right)$ time to construct, and $O(s)$ time to search for a substring) is also acceptable. Using a suffix tree, which takes $O(b)$ time to construct and $O(s)$ time to search for a substring is acceptable as well, but the construction should be fully described.
To meet the $O(b \log b)$ time bound without using a suffix tree, we will still attempt to sort all of the suffixes of $\mathcal{B}$, but in a more clever way. Note that we take $\mathcal{B}$ to be the same input book $\mathcal{B}$, but augmented with a character $\circ$ at the end that is lexicographically after every character in ASCII. First, for simplicity in our notation, we define substrings of $\mathcal{B}[i, j]$ where $j<i$ to be $\mathcal{B}[i, b]+\mathcal{B}[0, j]$. We will proceed in rounds, for $i=0, \ldots,\lceil\log b\rceil$. In the $i^{\text {th }}$ round, we will consider a set of substrings of $\mathcal{B}$, namely $\mathcal{T}_{i}=\left\{\mathcal{B}\left[j, j+2^{i} \bmod b\right] \mid j \in[0,|\mathcal{B}|]\right\}$. That is to say, $\mathcal{T}_{i}$ consists of all substrings of length $2^{i}$ in $\mathcal{B}$, allowing for wrapping back to the first character of $\mathcal{B}$. Note that alongside each substring in $\mathcal{T}_{i}$, we also store its index. In the first round, where $i=0$, $\mathcal{T}_{0}$ consists of each character of $\mathcal{B}$. Since there are only 129 possible characters, we can use a counting sort to sort each character, in $O(b)$ time.
In every subsequent round $i$, we would like to sort the substrings in $\mathcal{T}_{i}$. We will now sort each $\mathcal{T}_{i}$, assuming that for $j<i$, we have sorted $\mathcal{T}_{j}$. Let $\pi_{j}$ be a function denoting the sorted index of each substring in $\mathcal{T}_{j}$. We note that every substring in $\mathcal{T}_{i}$ can be split in half, where the first half and the second half are each substrings in $\mathcal{T}_{i-1}$. Our main idea is to first sort the substrings in $\mathcal{T}_{i}$ based on the second half of each substring, and then sort based on the first half of each substring. After this process, $\mathcal{T}_{i}$ will be in sorted order. Thus, we can convert each substring in $\mathcal{T}_{i}$ into a pair of numbers, where the first number is given by $\pi_{i-1}$ of the first half of the substring, and the second number is given by $\pi_{i-1}$ of the second half of the substring. We use counting sort to sort first by the second numbers in the pairs, and then by the first numbers in the pairs. Each use of counting sort takes $O(b)$ time, since $\pi_{x} \leq b$ by definition.
At the end of this process, our final $\mathcal{T}$ gives precisely the desired sorted suffixes, and we can search for each substring $\mathcal{S}$ using a binary search.
Now, we note that we have taken $O(\log b)$ rounds, and in each round, we have used $O(b)$ time. Thus, the construction of our data structure is complete in $O(b \log b)$ time. ","Alice is given a book $\mathcal{B}$, which we can think of as a long string of length $b$. The book consists solely of ASCII characters, that is to say, there are 128 possible characters in $\mathcal{B}$. Alice is running a search engine, where users give her input substrings $\mathcal{S}$ of arbitrary length $s$, and ask if $\mathcal{S}$ exists in their book or not. If it exists, they would like the index in $\mathcal{B}$ that marks the start of an instance of $\mathcal{S}$ in the book (if there are multiple instances of $\mathcal{S}$, the index of any of these instances will do). Assume $s \leq b$. Alice must pre-process her book $\mathcal{B}$ and build a data structure, such that she can efficiently answer search queries from her users.
Alice comes up with a basic data structure to solve her problem. First, she constructs a data structure that computes every substring of $\mathcal{B}$ (along with the index of each substring in $\mathcal{B}$ ), and then she uses radix sort to store the substrings in lexicographic order (based on the standard ASCII sort order). Then, for any given substring $\mathcal{S}$, she performs a binary search on her sorted list. What is the time complexity of the construction of the data structure, and what is the time complexity of searching for $\mathcal{S}$, in terms of $s$ and $b$?","There are $O\left(b^{2}\right)$ substrings of $\mathcal{B}$ of any length. This can be shown in a number of ways. One way is to note that there are $b$ substrings of length $1, b-1$ substrings of length 2, and so on, up to 1 substring of length $b$. Summing over the different lengths, there are $O\left(b^{2}\right)$ substrings. Another way is to note that there are $\left(\begin{array}{l}b \\ 2\end{array}\right)$ possible locations for the start index and end index of any substring, so there are $O\left(b^{2}\right)$ substrings.
Since each substring is of length at most $b$, the radix sort takes $O\left(b^{3}\right)$ time (this can also be computed more exactly, by taking the number of substrings of each length into account). Thus, the construction of the data structure takes $O\left(b^{3}\right)$ time.
Since there are $O\left(b^{2}\right)$ substrings, the binary search takes $O(s \log b)$ time, where the factor of $s$ is the check for equality with $\mathcal{S}$."
192,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Midterm Exam 3,Processor Pipeline Performance,5,b,0.45,Text,"You are designing a 5- stage pipelined (IF, DEC, EXE, MEM, WB) RISC-V processor with the same functionality in each stage that we have seen in lecture:
• IF: Initiate instruction fetch
• DEC: Decode instruction and gather source operands (stall if not available)
• EXE: Perform ALU operations and resolve branches
• MEM: Initiate data memory accesses
• WB: Write results back to register file
The processor has the following features:
• The instruction memory responds to every request in one cycle.
• The data memory responds to cache hits in one cycle. The cache miss penalty of the data memory is 1 additional cycle.
• You have a cache with 4-word cache lines for the data memory.
• The processor predicts that all branches are TAKEN and can start fetching the instruction at the target address on the cycle immediately following the branch.
This processor will spend most of its time executing the following loop: 
loop:
0x100 lw x1, 0(x2)
0x104 lw x3, 0(x1) # address depends on value loaded above
0x108 add x4, x3, x1
0x10c sw x4, 0(x2)
0x110 addi x2, x2, 4
0x114 addi x6, x6, -1 # assume x6 initially is 128
0x118 bne x6, x0, loop
Assume that:
• x2 has an initial value of 0x1000, so on the first iteration, the lw x1, 0(x2) instruction accesses a memory address with cache block offset 0.
• The memory location accessed by the lw x3, 0(x1) instruction does not overlap with the locations accessed by lw x1, 0(x2) and sw x4, 0(x2), and each access maps to a different cache line.
How many cycles does the 6th iteration of the loop take? The processor again predicts the branch to be taken.",Numerical,Number of cycles for 6th iteration of the loop: ______12_________,"You are designing a 5- stage pipelined (IF, DEC, EXE, MEM, WB) RISC-V processor with the same functionality in each stage that we have seen in lecture:
• IF: Initiate instruction fetch
• DEC: Decode instruction and gather source operands (stall if not available)
• EXE: Perform ALU operations and resolve branches
• MEM: Initiate data memory accesses
• WB: Write results back to register file
The processor has the following features:
• The instruction memory responds to every request in one cycle.
• The data memory responds to cache hits in one cycle. The cache miss penalty of the data memory is 1 additional cycle.
• You have a cache with 4-word cache lines for the data memory.
• The processor predicts that all branches are TAKEN and can start fetching the instruction at the target address on the cycle immediately following the branch.
This processor will spend most of its time executing the following loop: 
loop:
0x100 lw x1, 0(x2)
0x104 lw x3, 0(x1) # address depends on value loaded above
0x108 add x4, x3, x1
0x10c sw x4, 0(x2)
0x110 addi x2, x2, 4
0x114 addi x6, x6, -1 # assume x6 initially is 128
0x118 bne x6, x0, loop
Assume that:
• x2 has an initial value of 0x1000, so on the first iteration, the lw x1, 0(x2) instruction accesses a memory address with cache block offset 0.
• The memory location accessed by the lw x3, 0(x1) instruction does not overlap with the locations accessed by lw x1, 0(x2) and sw x4, 0(x2), and each access maps to a different cache line.
On average, how many cycles does a loop iteration take?","Cycles per iteration: ______12.25_________
(3*12 + 13)/4 = 49/4 = 12.25.","You are designing a 5- stage pipelined (IF, DEC, EXE, MEM, WB) RISC-V processor with the same functionality in each stage that we have seen in lecture:
• IF: Initiate instruction fetch
• DEC: Decode instruction and gather source operands (stall if not available)
• EXE: Perform ALU operations and resolve branches
• MEM: Initiate data memory accesses
• WB: Write results back to register file
The processor has the following features:
• The instruction memory responds to every request in one cycle.
• The data memory responds to cache hits in one cycle. The cache miss penalty of the data memory is 1 additional cycle.
• You have a cache with 4-word cache lines for the data memory.
• The processor predicts that all branches are TAKEN and can start fetching the instruction at the target address on the cycle immediately following the branch.
This processor will spend most of its time executing the following loop: 
loop:
0x100 lw x1, 0(x2)
0x104 lw x3, 0(x1) # address depends on value loaded above
0x108 add x4, x3, x1
0x10c sw x4, 0(x2)
0x110 addi x2, x2, 4
0x114 addi x6, x6, -1 # assume x6 initially is 128
0x118 bne x6, x0, loop
Assume that:
• x2 has an initial value of 0x1000, so on the first iteration, the lw x1, 0(x2) instruction accesses a memory address with cache block offset 0.
• The memory location accessed by the lw x3, 0(x1) instruction does not overlap with the locations accessed by lw x1, 0(x2) and sw x4, 0(x2), and each access maps to a different cache line.
We are concerned with average performance and the loop runs for many iterations. Fill out the pipeline diagram below for the 5th iteration of the loop. Note that the processor predicts the branch to be taken. You may leave boxes blank to indicate NOP operations. Draw arrows to indicate where a bypass path was used. Then specify the number of cycles for the 5th iteration of the loop.","The pipeline diagram is below.
Number of cycles for 5th iteration of the loop: ______13_________","You are designing a 5- stage pipelined (IF, DEC, EXE, MEM, WB) RISC-V processor with the same functionality in each stage that we have seen in lecture:
• IF: Initiate instruction fetch
• DEC: Decode instruction and gather source operands (stall if not available)
• EXE: Perform ALU operations and resolve branches
• MEM: Initiate data memory accesses
• WB: Write results back to register file
The processor has the following features:
• The instruction memory responds to every request in one cycle.
• The data memory responds to cache hits in one cycle. The cache miss penalty of the data memory is 1 additional cycle.
• You have a cache with 4-word cache lines for the data memory.
• The processor predicts that all branches are TAKEN and can start fetching the instruction at the target address on the cycle immediately following the branch.
This processor will spend most of its time executing the following loop: 
loop:
0x100 lw x1, 0(x2)
0x104 lw x3, 0(x1) # address depends on value loaded above
0x108 add x4, x3, x1
0x10c sw x4, 0(x2)
0x110 addi x2, x2, 4
0x114 addi x6, x6, -1 # assume x6 initially is 128
0x118 bne x6, x0, loop
Assume that:
• x2 has an initial value of 0x1000, so on the first iteration, the lw x1, 0(x2) instruction accesses a memory address with cache block offset 0.
• The memory location accessed by the lw x3, 0(x1) instruction does not overlap with the locations accessed by lw x1, 0(x2) and sw x4, 0(x2), and each access maps to a different cache line.
We now slightly modify the loop to use a multiply instruction. All other instructions are the same as before. The execute stage of the multiplication takes 4 cycles.
loop:
0x100 lw x1, 0(x2)
0x104 lw x3, 0(x1) # address depends on value loaded above
0x108 mul x4, x3, x1
0x10c sw x4, 0(x2)
0x110 addi x2, x2, 4
0x114 addi x6, x6, -1 # assume x6 initially is 128
0x118 bne x6, x0, loop
On average, how many additional cycles does an iteration of this new loop take versus your answer in part C?",Additional cycles per iteration: ______3_________
161,EECS,18.C06,Linear Algebra and Optimization,18.02,None,Midterm Exam 2,Characteristic Polynomial,5,c,0.5625,Text,"Let $A$ be a $4 \times 6$ matrix with singular values
$$
\sigma_{1}=3, \quad \sigma_{2}=3, \quad \sigma_{3}=1
$$
and the rest are zero. For each of the following, either determine its value or argue that it cannot be determined from the singular values alone.
The characteristic polynomial of $A$.",Open,"Since $A \in \mathbb{R}^{4 \times 6}$ is not square, the characteristic polynomial is not defined.
Also, even if the matrix were square, the characteristic polynomial cannot be determined from the singular values alone because there can be two matrices with different eigenvalues but the same singular values.","Let $A$ be a $4 \times 6$ matrix with singular values
$$
\sigma_{1}=3, \quad \sigma_{2}=3, \quad \sigma_{3}=1
$$
and the rest are zero. For each of the following, either determine its value or argue that it cannot be determined from the singular values alone.
The dimension of the nullspace of $A$.",The rank is the number of nonzero singular values. Hence the rank of $A$ is 3. By the rank-nullity theorem we have that the null space has dimension $6-3=3$.,"Let $A$ be a $4 \times 6$ matrix with singular values
$$
\sigma_{1}=3, \quad \sigma_{2}=3, \quad \sigma_{3}=1
$$
and the rest are zero. For each of the following, either determine its value or argue that it cannot be determined from the singular values alone.
The operator norm of $A^{T}$.","The operator norm is the largest singular value, and hence is $\sigma_{1}=3$. ","Let $A$ be a $4 \times 6$ matrix with singular values
$$
\sigma_{1}=3, \quad \sigma_{2}=3, \quad \sigma_{3}=1
$$
and the rest are zero. For each of the following, either determine its value or argue that it cannot be determined from the singular values alone.
The operator norm of $A-B$ where $B$ is the best rank two approximation to $A$.",We can obtain the best rank two approximation by truncating the SVD of $A$ at two terms. Thus operator norm of $A-B$ would then be $\sigma_{3}=1$.
60,Mathematics,18.701,Algebra I,18.100B,None,Problem Set 9,Euclidean Spaces and Hermitian Spaces,5,a,0.25,Text,"Let $T$ be a linear operator on $V=\mathbb{R}^n$ whose matrix $A$ is a real symmetric matrix.
Prove that $V$ is the orthogonal sum $V=(\operatorname{ker} T) \oplus(\operatorname{im} T)$.",Open,"Let's work with column vectors. Let $K=\operatorname{ker} T$ and $W=\operatorname{im} T$, and let $k \in \operatorname{ker} T$ and $w \in \operatorname{im} T$. So $A k=0$ and $w=A v$ for some $v \in V$. Since $A$ is symmetric, $k^{*} w=k^{*}(A v)=(A k)^{*} v=0$. Therefore $k \perp w$. This shows that $K$ is orthogonal to $W$, i.e., $K$ is a subspace of $W^{\perp}$. The dimension formula for a linear operator shows that $\operatorname{dim} W+\operatorname{dim} K=n$ and we also know that $\operatorname{dim} W+\operatorname{dim} W^{\perp}=n$. Therefore $K=W^{\perp}$.","Let $T$ be a linear operator on $V=\mathbb{R}^n$ whose matrix $A$ is a real symmetric matrix.
Prove that $T$ is an orthogonal projection onto i $\mathrm{m} T$ if and only if, in addition to being symmetric, $A^2=A$.","The orthogonal projection to $W$ is defined by writing $v=w+u$ where $w$ is in $W$ and $u$ is in $W^{\perp}=K$. Then $\pi(v)=w$. Suppose that $A=A^{2}$, and let $w=A v$. Then $A(v-w)=A v-A w=A v-A^{2} v=A v-A v=0$, so $v-w=u$ is in $W^{\perp}$. It follows that $\pi(v)=A v$.
Conversely, if $A^{2} \neq A$ then there is a vector $z$ such that $A^{2} z \neq A z$. The vector $x=A z$ is in $W$, so the orthogonqal projection $\pi$ sends $x$ to $A z$. But $A x=A^{2} z \neq \pi(x)$.","Let $V, W$ be vector spaces, and suppose that $T: V \rightarrow W$ is a linear map.
Show that $\operatorname{Im}(T):=\{w \in W: T(v)=w$ for some $v \in V\}$ is a vector space.","Since $\operatorname{Im}(T) \subset W$, we only need to show it is a subspace of $W$.
1. $T(0)=0$, so $0 \in \operatorname{Im}(T)$.
2. 2. If $v, w \in \operatorname{Im}(T)$, then there are $v_{0}, w_{0} \in V$ such that $T\left(v_{0}\right)=v$ and $T\left(w_{0}\right)=w$. Thus $T\left(v_{0}+w_{0}\right)=v+w$ and $v+w \in \operatorname{Im}(T)$.
3. If $v \in \operatorname{Im}(T)$, then there is $v_{0} \in V$ such that $T\left(v_{0}\right)=v$. Thus $T\left(c v_{0}\right)=c v$ and $c v \in \operatorname{Im}(T)$
By 1, 2, and $3, \operatorname{Im}(T)$ is a subspace of $W$. Hence $\operatorname{Im}(T)$ is a vector space.","Let $T: H \rightarrow H$ be a bounded operator and $H=V \oplus W$ be an orthogonal decomposition. Write $T$ as a block matrix with respect to this decomposition: $T=\left(\begin{array}{ll}A & B \\ C & D\end{array}\right)$ where $A: V \rightarrow V, B: W \rightarrow V, C: V \rightarrow W, D: W \rightarrow W$. Show that if $A$ and $D-C A^{-1} B$ are invertible then $T$ is invertible.","If $A$ is invertible, we have
$$
\left(\begin{array}{cc}
A & B \\
C & D
\end{array}\right)=\left(\begin{array}{cc}
1 & 0 \\
C A^{-1} & 1
\end{array}\right)\left(\begin{array}{cc}
A & 0 \\
0 & D-C A^{-1} B
\end{array}\right)\left(\begin{array}{cc}
1 & A^{-1} B \\
0 & 1
\end{array}\right)
$$
This implies the statement."
262,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Midterm Exam,Symbolic Representations,4,biii,0.4,Text,"Let's continue the theme of keys and rooms, but this time writing operator descriptions. Use the following predicate definitions, with the obvious interpretations when $\mathrm{k}$ is a key and $\mathrm{r}$ is a room.
(opens ?k ?r)
(connected ?r1 ?r2)
(unlocked ?r)
(robot-in ?r)
(robot-holding ?k)
(in ?k ?r)
Assume there is one more operator
(:action pick-up
:parameters (?r ?k)
:precondition (and (robot-in ?r)
(in ?k ?r))
:effect (and (robot-holding ?k) (not (in ?k ?r))))
Here is an initial state:
(connected R0 R1) (connected R1 R2) (connected R2 R3)
(connected R1 R0) (connected R2 R1) (connected R3 R2)
(unlocked R1) (unlocked R2) (unlocked R3)
(robot-in R1) (opens K0 R0) (in K0 R3)
And goal: (and (robot-in R0) (unlocked R0) (robot-holding K0))
We want to base a heuristic on a relaxed plan graph for this problem.
At what level in the RPG is the fluent (unlocked R0)?",Numerical,4,"Let's continue the theme of keys and rooms, but this time writing operator descriptions. Use the following predicate definitions, with the obvious interpretations when $\mathrm{k}$ is a key and $\mathrm{r}$ is a room.
(opens ?k ?r)
(connected ?r1 ?r2)
(unlocked ?r)
(robot-in ?r)
(robot-holding ?k)
(in ?k ?r)
Assume there is one more operator
(:action pick-up
:parameters (?r ?k)
:precondition (and (robot-in ?r)
(in ?k ?r))
:effect (and (robot-holding ?k) (not (in ?k ?r))))
Here is an initial state:
(connected R0 R1) (connected R1 R2) (connected R2 R3)
(connected R1 R0) (connected R2 R1) (connected R3 R2)
(unlocked R1) (unlocked R2) (unlocked R3)
(robot-in R1) (opens K0 R0) (in K0 R3)
And goal: (and (robot-in R0) (unlocked R0) (robot-holding K0))
We want to base a heuristic on a relaxed plan graph for this problem.
At what level in the RPG is the fluent (robot-holding K0)?",3,"Let's continue the theme of keys and rooms, but this time writing operator descriptions. Use the following predicate definitions, with the obvious interpretations when $\mathrm{k}$ is a key and $\mathrm{r}$ is a room.
(opens ?k ?r)
(connected ?r1 ?r2)
(unlocked ?r)
(robot-in ?r)
(robot-holding ?k)
(in ?k ?r)
Assume there is one more operator
(:action pick-up
:parameters (?r ?k)
:precondition (and (robot-in ?r)
(in ?k ?r))
:effect (and (robot-holding ?k) (not (in ?k ?r))))
Here is an initial state:
(connected R0 R1) (connected R1 R2) (connected R2 R3)
(connected R1 R0) (connected R2 R1) (connected R3 R2)
(unlocked R1) (unlocked R2) (unlocked R3)
(robot-in R1) (opens K0 R0) (in K0 R3)
And goal: (and (robot-in R0) (unlocked R0) (robot-holding K0))
We want to base a heuristic on a relaxed plan graph for this problem.
First, what is the shortest solution for this problem? Please list the actions.","(move R1 R2) (move R2 R3)
(pick-up K0) (move R3 R2) (move R2 R1)
(unlock R1 R0 K0) (move R1 R0)","Let's continue the theme of keys and rooms, but this time writing operator descriptions. Use the following predicate definitions, with the obvious interpretations when $\mathrm{k}$ is a key and $\mathrm{r}$ is a room.
(opens ?k ?r)
(connected ?r1 ?r2)
(unlocked ?r)
(robot-in ?r)
(robot-holding ?k)
(in ?k ?r)
Assume there is one more operator
(:action pick-up
:parameters (?r ?k)
:precondition (and (robot-in ?r)
(in ?k ?r))
:effect (and (robot-holding ?k) (not (in ?k ?r))))
Here is an initial state:
(connected R0 R1) (connected R1 R2) (connected R2 R3)
(connected R1 R0) (connected R2 R1) (connected R3 R2)
(unlocked R1) (unlocked R2) (unlocked R3)
(robot-in R1) (opens K0 R0) (in K0 R3)
And goal: (and (robot-in R0) (unlocked R0) (robot-holding K0))
We want to base a heuristic on a relaxed plan graph for this problem.
What is the value of $H_{\text{max}}$ for this goal?",5
122,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 3,First-Order Logic Proof,5,bvii,0.0637755102,Text,"Now, we will use the sentence you chose in part 5.1.3 as an assumption, also assume that Dr. Evil does not own a dog, and then prove from these assumptions that Dr. Evil is not an animal lover. The first step in doing a resolution proof is to convert the premises to clausal form. You already did part of that! Below, you will select each of the premises that we will need for a proof.
Clause 7 We then resolve clauses 3 and 5.
Enter a clause as a list of lists of literal strings.",Expression,"[['~O(DrE,sk(DrE))']]","Now, we will use the sentence you chose in part 5.1.3 as an assumption, also assume that Dr. Evil does not own a dog, and then prove from these assumptions that Dr. Evil is not an animal lover. The first step in doing a resolution proof is to convert the premises to clausal form. You already did part of that! Below, you will select each of the premises that we will need for a proof.
Clause 6 We get the next clause by resolving clauses 2 and 4.
Enter a clause as a list of lists of literal strings.","[['O(DrE,sk(DrE))']]","Now, we will use the sentence you chose in part 5.1.3 as an assumption, also assume that Dr. Evil does not own a dog, and then prove from these assumptions that Dr. Evil is not an animal lover. The first step in doing a resolution proof is to convert the premises to clausal form. You already did part of that! Below, you will select each of the premises that we will need for a proof.
Clause 5 Now, we can actually do the proof, using FOL resoluton, starting with the four clauses above. We get another clause by resolving clauses 1 and 4.
Enter a clause as a list of lists of literal strings.",[['D(sk(DrE))']],"Now, we will use the sentence you chose in part 5.1.3 as an assumption, also assume that Dr. Evil does not own a dog, and then prove from these assumptions that Dr. Evil is not an animal lover. The first step in doing a resolution proof is to convert the premises to clausal form. You already did part of that! Below, you will select each of the premises that we will need for a proof.
Clause 2 One clause from the previous problem that involves an owner, that is, predicate $O$.
Choose one:
(a) ~O(x2,x3)
(b) O(x2,sk(x2))
(c) ~L(x2) v O(x2,x3)
(d) ~L(x2) v O(x2,sk(x2))
(e) ~D(x3) v ~O(x2, x3) v L(x3)","(d) ~L(x2) v O(x2,sk(x2))"
267,Mathematics,18.01,Calculus I,None,None,Problem Set 6,Taylor Series,13,a,0.05279831045,Text,"Consider the differential equation $x^{\prime}(t)=1+t x(t)-x(t)^{2}$ with initial condition $x(0)=1$. This is a differential equation that cannot be solved by separation of variables.
Find $x^{\prime}(0)$.",Numerical,$x^{\prime}(0)=1+(0) x(0)-x(0)^{2}=1-1=0$.,"Consider the differential equation $x^{\prime}(t)=1+t x(t)-x(t)^{2}$ with initial condition $x(0)=1$. This is a differential equation that cannot be solved by separation of variables.
Find $x^{\prime \prime \prime}(0)$.","Differentiate our formula for $x^{\prime \prime}(t)$ from part (b): $x^{\prime \prime \prime}(t)=x^{\prime}(t)+\left(1-t x^{\prime}(t)\right) x^{\prime}(t)+$ $(t-2 x(t)) x^{\prime \prime}(t)$. Plug in $t=0$ :
$$
x^{\prime \prime \prime}(0)=x^{\prime}(0)+(1-0) x^{\prime}(0)+(-2 x(0)) x^{\prime \prime}(0)=-2 .
$$","Consider the differential equation $x^{\prime}(t)=1+t x(t)-x(t)^{2}$ with initial condition $x(0)=1$. This is a differential equation that cannot be solved by separation of variables.
Find a formula for $x^{\prime \prime}(t)$ and use it to find $x^{\prime \prime}(0)$.",$x^{\prime \prime}(t)=x(t)+t x^{\prime}(t)-2 x(t) x^{\prime}(t)=x(t)+(t-2 x(t)) x^{\prime}(t)$. Plugging in $t=0$ gives $x^{\prime \prime}(0)=x(0)+(0-2 x(0))\left(x^{\prime}(0)\right)=1$.,"Consider the differential equation $x^{\prime}(t)=1+t x(t)-x(t)^{2}$ with initial condition $x(0)=1$. This is a differential equation that cannot be solved by separation of variables.
Find the degree 3 Taylor series of $x(t)$ around $t=0$.","$$
T(t)=1+0 \cdot t+\frac{(1)}{2} t^{2}+\frac{(-2)}{6} t^{3} .
$$"
11,Mathematics,18.701,Algebra I,18.100B,None,Problem Set 2,Cosets,3,b,0.25,Text,"Let $S$ be a set with a law of composition. A partition $\Pi_1 \cup \Pi_2 \cup \cdots$ of $S$ is compatible with the law of composition if for all $i$ and $j$, the product set
$$
\Pi_i \Pi_j=\left\{x y \mid x \in \Pi_i, y \in \Pi_j\right\}
$$
is contained in a single subset $\Pi_k$ of the partition.
Describe all partitions of the integers that are compatible with the operation $+$.",Open,"Say that we are given a partition of $\mathbb{Z}$ such that if $\Pi_{i}$ and $\Pi_{j}$ are elements of the partition, $\Pi_{i}+\Pi_{j} \subset \Pi_{k}$ for some $\Pi_{k}$.
One of the subsets will contain the integer 0. Let's call that subset $\Pi_{0}$. By hypothesis, $\Pi_{0}+\Pi_{0}$ is contained in a single subset of the partition, say in $\Pi_{1}$. Therefore $0=0+0 \in \Pi_{1}$. Since $0+0=0 \in \Pi_{0}, \Pi_{1}=\Pi_{0}$. Then if $a$ and $b$ are in $\Pi_{0}, a+b \in \Pi_{0}$.
Say that $(-a) \in \Pi_{2}$. Since $a+(-a)=0 \in \Pi_{0}, \Pi_{0}+\Pi_{2} \subset \Pi_{0}$. Then since $0 \in \Pi_{0}$, $0+\Pi_{2} \subset \Pi_{0}$, and therefore $\Pi_{2}=\Pi_{0}$. This shows that $\Pi_{0}$ is a subgroup of $\mathbb{Z}^{+}$.
So, such a partition is the set of cosets of a subgroup. ","Continuing the previous problem, suppose that our originally given numbers had a subset $P$ which satisfies the axioms of ordering (with respect to $+$ and $\cdot$ ). Is there a subset which does the same for our new $+$, . . operations? [Note that the axiom of completeness is not part of the axioms of ordering.]","We use $P=-P=\{-x \quad: \quad x \in P\}$ as subset of positive numbers for our new operations. Trichotomy for this $P$ says that for each $x$, either $x=0$, or $-x \in P$, or $-(-x) \in P$. But $-(-x)=x$, because both those numbers are the additive inverse of $-x$, and additive inverses are unique. So this statement is the same as trichotomy for $P$, which we know.
Suppose $x, y \in P$, so $-x \in P$ and $-y \in P$. Now $(-x)+(-y)$ is the additive inverse of $x+y$, because $(-x)+(-y)+x+y=((-x)+x)+((-y)+y)=0+0=0$. Therefore, it follows from the axioms of ordering for $P$ that $(-x)+(-y)=-(x+y) \in P$, which shows that $x+y \in P$.
Suppose $x, y \in P$, so $-x \in P$ and $-y \in P$. The statement that $x \cdot y \in P$ means that $-(-(x \cdot y)) \in P$, or equivalently (by what I've observed above) that $x \cdot y \in P$. But we know that to be true, because (as proved in lecture) $x \cdot y=(-x) \cdot(-y)$, where the right hand side lies in $P$ because of the axiom of ordering for $\cdot$.","For each of the sets $S_{1}, S_{2}, S_{3}, S_{4}$, say whether they are convex or not, and justify your answer.
For $X, Y \subseteq \mathbb{R}^{n}$, let $X+Y=\{x+y: x \in X, y \in Y\}$. Let
$$
S_{4}=S_{1}+S_{2}.
$$","$S_{4}$ is convex. First we show that if $X$ and $Y$ are convex, then $X+Y$ is also convex. For any $z_{1}, z_{2} \in X+Y$, they can be written as $z_{1}=x_{1}+y_{1}, z_{2}=x_{2}+y_{2}$ for some $x_{1}, x_{2} \in X$ and $y_{1}, y_{2} \in Y$. Then for $0 \leq \lambda \leq 1, \lambda z_{1}+(1-\lambda) z_{2}=\lambda x_{1}+$ $(1-\lambda) x_{2}+\lambda y_{1}+(1-\lambda) y_{2}$. Since $X$ and $Y$ are convex, $\lambda x_{1}+(1-\lambda) x_{2} \in X$ and $\lambda y_{1}+(1-\lambda) y_{2} \in Y$. Therefore $\lambda z_{1}+(1-\lambda) z_{2} \in X+Y$, showing that it is convex. Since $S_{1}$ and $S_{2}$ are convex, so is $S_{4}=S_{1}+S_{2}$.",Describe all ways in which $S_3$ can operate on a set of four elements.,"$S_{3}=\left\{1, x, x^{2}, y, x y, x^{2} y\right\}$, where $x=(123)$ and $y=(12)$. The relations are $x^{3}=1, y^{2}=1$ and $y=x^{2} y$. Let's denote $S_{3}$ by $G$.
One way to do this is to consider the ways that the set of four elements decomposes into orbits. There are five possibilities.
1. $4=4$ : one orbit of order 4. Since the order of an orbit divides the order of $G$, this isn't possible.
2. $4=1+1+1+1$ : four orbits of order one. This is the trivial operation.
3. $4=1+1+2$ : The group $G$ operates trivially on the orbits of order 1 . We must decide whether it can operate nontrivially on a set $\{a, b\}$ of two elements, and if so, in how many ways. Since $x$ has order 3 , we can't have $x a=b$ and $x b=a$, because this would imply $a=x^{3} a=x^{2}(x a)=x^{2} b=x(x b)=x a=b$. So $x$ must fix both $a$ and $b$. Then if the operation is nontrivial, $y$ must operate as the transposition $(a b)$. One checks that this is possible by checking that the relations are satisfied. So, up to relabeling the elements of $S$, there is one operation with this orbit decomposition.
4. $4=2+2$ : The operation on each orbit will be as described in case 3 . There is one such operation.
5. $1+3$ : Here, if $x$ operates trivially, then there cannot be an orbit of size 3 . So $x$ must operate as a 3 -cycle on the orbit of three, say as the permutation $(a b c)$. Since $y x=x^{2} y, y$ cannot operate trivially. So $y$ is a transposition. Relabeling if necessary, we may suppose that $y=(a b)$. This works, so there is one such operation."
22,EECS,6.122,Design and Analysis of Algorithms,6.121,None,Problem Set 3,Amortized Analysis,1,a,0.09090909091,Text,"Cam Petitive and Opal T. Mull have to do readings for a class, but they dread going to the library!
In typical MIT style, the library owns $m$ book titles which students refer to by number, from 1 to $m$. Their professor gives the name of a title, $b$, each time she assigns a reading. If a student has a copy the book checked out, they complete the reading swiftly and happily (cost 0). Otherwise, they have to walk across campus to check a copy out from the library (cost 1). The library has numerous copies of each book, so students don't have to worry about reserving books or book shortages. The problem is that each student is only allowed to have $k$ books checked out at any time, and they can only check out one book on each trip to the library. Therefore students who have $k$ books checked out must return one of their previously checked-out books when checking out a new one.
Opal has somehow managed to figure out not only the $n$ readings, but also the optimal sequence of books to return, to minimize trips to the library. Cam hasn't done the same, but he thinks he can compete with Opal without knowing the readings or doing such complicated calculations.
The library doesn't set due dates, so Cam thinks he can exploit this by holding on to his books for as long as possible. He works out the following strategy for each reading $b$ :
• If $b$ is already checked out, he does not go to the library, and completes the reading swiftly and happily.
• Otherwise, he checks out $b$ from the library as follows:
         - If Cam hasn't reached his limit of $k$ books checked out yet, he doesn't return any books.
         - Otherwise, he returns the book with the most recent check out date.
Note that the professor seems to enjoy repetition as a teaching tool, and doesn't hesitate to assign old readings. At the beginning of the semester, both Cam and Opal have zero books checked out.
Imagine that the library only has $m=4$ book titles and that this week's readings are in the following order: $[b, c, a, a, c]$. If $k=2$, how many times does Cam go to the library? How many times does Opal go to the library?",Numerical,"Cam goes to the library on readings 1, 2, 3, and 5. Opal only goes to the library on readings $a, b$, and $c$, because she returns book $b$ instead of book $c$ when picking up the third reading. Therefore, Cam goes to the library four times and Opal goes to the library three times.","Cam Petitive and Opal T. Mull have to do readings for a class, but they dread going to the library!
In typical MIT style, the library owns $m$ book titles which students refer to by number, from 1 to $m$. Their professor gives the name of a title, $b$, each time she assigns a reading. If a student has a copy the book checked out, they complete the reading swiftly and happily (cost 0). Otherwise, they have to walk across campus to check a copy out from the library (cost 1). The library has numerous copies of each book, so students don't have to worry about reserving books or book shortages. The problem is that each student is only allowed to have $k$ books checked out at any time, and they can only check out one book on each trip to the library. Therefore students who have $k$ books checked out must return one of their previously checked-out books when checking out a new one.
Opal has somehow managed to figure out not only the $n$ readings, but also the optimal sequence of books to return, to minimize trips to the library. Cam hasn't done the same, but he thinks he can compete with Opal without knowing the readings or doing such complicated calculations.
The library doesn't set due dates, so Cam thinks he can exploit this by holding on to his books for as long as possible. He works out the following strategy for each reading $b$ :
• If $b$ is already checked out, he does not go to the library, and completes the reading swiftly and happily.
• Otherwise, he checks out $b$ from the library as follows:
         - If Cam hasn't reached his limit of $k$ books checked out yet, he doesn't return any books.
         - Otherwise, he returns the book with the most recent check out date.
Note that the professor seems to enjoy repetition as a teaching tool, and doesn't hesitate to assign old readings. At the beginning of the semester, both Cam and Opal have zero books checked out.
Prove that Cam's strategy is not competitive with Opal's if $k \geq 2$. That is, prove that there are input sequences of length $n$ such that the ratio of Cam's to Opal's library trips tends to $\infty$ as $n$ tends to $\infty$.","In order for Cam's strategy to be $\alpha$-competitive, for any sequence $B$ of books, we need
$$
C_{C A M}(B) \leq \alpha \cdot C_{O P T}(B)+c
$$
for some constants $\alpha$ and $c$. Following the instructions, we'll construct an adversarial example of length $n$ such that the ratio of Cam's to Opal's library trips tends to $\infty$ as $n$ tends to $\infty$. As a result, there are no $\alpha$ and $c$ for which Cam's strategy is $\alpha$-competitive.
For any $n>k$ consider reading assignments of length $n$ of the following form:
• The first $k$ readings are books $1,2, \ldots, k$.
• After this, the readings alternate between $k+1$ and $k$.
After the first $k$ readings, Cam would always replace the books $k$ and $k+1$ alternatively at each reading assignment, and his cost on the sequence would be $n$.
Opal, on the other hand, after the first $k$ requests, would return one of the books other than $k$ or $k+1$, and would never have to visit the library again on the sequence. So her cost would be $k+1$.
The competitive ratio is hence $\frac{n}{k+1}$, which tends to $\infty$ as $n$ does. Cam's strategy here corresponds to the Last-In-First-Out (LIFO) paging algorithm.","Cam Petitive and Opal T. Mull have to do readings for a class, but they dread going to the library!
In typical MIT style, the library owns $m$ book titles which students refer to by number, from 1 to $m$. Their professor gives the name of a title, $b$, each time she assigns a reading. If a student has a copy the book checked out, they complete the reading swiftly and happily (cost 0). Otherwise, they have to walk across campus to check a copy out from the library (cost 1). The library has numerous copies of each book, so students don't have to worry about reserving books or book shortages. The problem is that each student is only allowed to have $k$ books checked out at any time, and they can only check out one book on each trip to the library. Therefore students who have $k$ books checked out must return one of their previously checked-out books when checking out a new one.
Opal has somehow managed to figure out not only the $n$ readings, but also the optimal sequence of books to return, to minimize trips to the library. Cam hasn't done the same, but he thinks he can compete with Opal without knowing the readings or doing such complicated calculations.
The library doesn't set due dates, so Cam thinks he can exploit this by holding on to his books for as long as possible. He works out the following strategy for each reading $b$ :
• If $b$ is already checked out, he does not go to the library, and completes the reading swiftly and happily.
• Otherwise, he checks out $b$ from the library as follows:
         - If Cam hasn't reached his limit of $k$ books checked out yet, he doesn't return any books.
         - Otherwise, he returns the book with the most recent check out date.
Note that the professor seems to enjoy repetition as a teaching tool, and doesn't hesitate to assign old readings. At the beginning of the semester, both Cam and Opal have zero books checked out.
The semester has progressed (both Opal and Cam have the same $k$ books checked out), and now Cam thinks he has a better idea, so he decides to change his strategy. Cam keeps his $k$ library books stacked up on his desk, to remember the last time each was used for a reading. Whenever a reading is assigned, if Cam has the book already, he slides it out, does the reading, and places it on the top of the stack. If Cam has to go to the library, he slides out the bottom book from the stack, returns that one, and puts his newly checked-out book on the top of the stack when he gets back.
Use the potential method to prove that Cam's strategy is $k$-competitive with Opal's. That is, for any sequence of reading assignments of length $n$, the ratio of Cam's to Opal's library trips is no more than $k$.
Hint: At any time let $S_{C A M}$ be the set of books that Cam has checked out, and let $S_{O P T}$ be the set of books that Opal has checked out. Use the potential
function
$$
\Phi=\sum_{b \in S} w(b)
$$
where $S=S_{C A M} \backslash S_{O P T}$ is the set of books that Cam has which Opal doesn't, and $w(b)$ is how high up book $b$ is on Cam's shelf, with the bottom book's height $w\left(b_{\text {bottom }}\right)=1$ and the top book's height $w\left(b_{\text {top }}\right)=k$.","To prove Cam's strategy is $k$-competitive, we need to show that for any sequence of books $B$,
$$
C_{C A M}(B) \leq k \cdot C_{O P T}+c .
$$
Let $C(i)$ represent the cost of an algorithm at step $i$. Our strategy will be to show Cam's amortized cost at each step is $k$-competitive:
$$
C_{C A M}(i)+\Phi(i)-\Phi(i-1) \leq k \cdot C_{O P T}(i),
$$
Then we can add up the amortized cost over all steps to show the overall cost is $k$-competitive.
As in the hint, let $\Phi=\sum_{b \in S} w(b)$.
Now consider an arbitrary reading $b$. To prove (1), we'll look at the different cases on whether Opal or Cam has the book checked out already.
• Suppose that Cam has $b$ checked out and Opal does not. Opal's cost is 1 . We will show that the potential increases by at most $k$. First, note that, whereas prior to the request, the book $b$ contributed to $\Phi$ (as Cam had it checked out but not Opal), after the request $b$ does not contribute to the sum. In addition, after reading $b$, Cam places it on top of his stack. Because of this, any books in $S_{C A M} \backslash S_{O P T}$ which were previously above $b$ will drop places by one, decreasing the summation. However, Opal must return at least one book. So the set $S_{C A M} \backslash S_{O P T}$ can increase by one. Therefore, we may need to add a term to the sum defining $\Phi$. This term can be at most $k$.
• Suppose that Opal has $b$ checked out and Cam does not. In this case, Opal's cost is 0 while Cam's cost is 1 . We will show that $\Delta \Phi \leq-1$. The set $S_{C A M} \backslash S_{O P T}$ has at least 1 book (this is because Opal has $b$ checked out, so there must be at least one book checked out by Cam and not by Opal). When Cam returns the book at the bottom of the stack, every book's place drops by 1 . So the summation decreases by at least 1 !
• Suppose that both Opal and Cam have $b$ checked out already. Then $C_{C A M}(i)=$ $C_{O P T}(i)=0$. Still, Opal may decide to go to the library. But if so, Opal will incur a cost of 1 and, as in the first case, the potential increases by at $\operatorname{most} k$.
• Suppose that neither Opal nor Cam have $b$ checked out yet. Then $C_{C A M}(i)=$ $C_{O P T}(i)=1$. When $C a m$ returns the bottom book, the potential can only decrease. If Opal returns a book that Cam has, then we need to add a term to $\Phi$ but, as before, this term can be at most $k$. We get that $\Delta \Phi \leq k$.
In all cases $C_{C A M}(i)+\Phi(i)-\Phi(i-1) \leq k * C_{O P T}(i)$. Therefore, when the costs and potentials are summed across the whole sequence, all the $\Phi(i)$ are cancelled out except for the first and last terms, leaving
$$
\sum_{i=1}^n C_{C A M}(i)+\Phi(n)-\Phi(0) \leq k \cdot \sum_{i=1}^n C_{O P T}(i) .
$$
Since the potential starts at 0 (Cam and Opal start with the same set of books, so $S_{C A M} \backslash S_{O P T}$ is empty), and the potential function is always positive,
$$
\sum_{i=1}^n C_{C A M}(i) \leq k \cdot \sum_{i=1}^n C_{O P T}(i)
$$
and hence Cam's strategy is $k$-competitive with Opal's.","Several cities around the world have been affected by climate change. Luckily, the city of Boston made preparations in advance to mitigate the effects, so we are safe at MIT.
In order to help the cities that have been affected, you decide to start a non-profit, distributed shipping system which sends supplies to these cities. Your research finds that there are a total of $n$ cities $C=\left\{c_1, c_2, \ldots, c_n\right\}$ that are affected and in need of supplies. Your goal is to send supplies to the cities and save the world.
You buy a total of $m<n$ ships $s_1, s_2, \ldots, s_m$ located in different places around the world. Each ship $s_j$ can transport supplies from its origin to a small subset of the cities $Y_j \subseteq C$ where $\left|Y_j\right| \leq 5$. Together, all the ships cover every city, possibly with overlaps. Each city $c_i$, needs a total of $f_i$ supplies. You decide to send the supplies over the course of a week (7 days $D=\left\{d_1, \ldots, d_7\right\}$ ). Because of financial reasons, on each day $d_i$, you can only send a total of $v_i$ supplies. Finally, since you don't want the ship captains to get exhausted from working continuously every day of the week, each ship $s_j$, will only be working on $X_j \subseteq D$ days.
Note: You may assume that both $v_i$ and $f_i$ are integers.
An example instance of this problem for $m=3$ and $n=5$ would look something like this:
• You have ships $s_1, s_2$ and $s_3$.
• There are affected cities $c_1, c_2, c_3, c_4$ and $c_5$ where $f_i=10$ for all $i \in[1 \ldots 5]$.
• Ship $s_1$ travels to cities $Y_1=\left\{c_1, c_2, c_3\right\}$ and operates on days $X_1=\left\{d_1, d_2, d_3\right\}$.
• Ship $s_2$ travels to cities $Y_2=\left\{c_2, c_3, c_5\right\}$ and operates on days $X_2=\left\{d_3, d_4\right\}$.
• Ship $s_3$ travels to cities $Y_3=\left\{c_4, c_5\right\}$ and operates on days $X_3=\left\{d_5, d_6, d_7\right\}$.
• On each day $d_i$, you can supply a total amount of $v_i=\{10$ if $i$ even, else 5$\}$ supplies.
Define a shipping plan to be a valid assignment for each day, $d_i$, consisting of the following specifications.
• How many supplies does each ship transport?
• How does each ship distribute its supplies among the cities that it visits?
You figure out a great shipping plan for part (a). Unfortunately, you hear that one of your ships failed an international quality assurance test and cannot be operational. In your original plan, this ship was scheduled to transport a total of $k$ supplies. Now you must re-evaluate your plan and check if it is still possible to supply the needs of all the cities without this ship. Give an $O(k n)$ time algorithm to decide whether it is still possible to find such a shipping plan and analyze its runtime as a function of $k$. Hint: If you decide to take a max-flow approach, it may be helpful to analyze your solution using the Ford-Fulkerson algorithm taught in class.","Let $s_j$ be the non-functional ship. We take the Flow Network $H$ from part (a), and modify it to $H^{\prime}$ where $s_j$ is removed. We now compute the Max Flow in $H^{\prime}$ by starting with the Max Flow we already computed for $H$ and pushing back the $k$ units of flow that went through $s_j$. If the Max Flow in $H^{\prime}$ is still $=\sum_{i=1}^n f_i$, then it is still possible to find a satisfying shipping plan. Otherwise, it is impossible. We do this as follows.
Let $G$ be the residual network for $H$. Run BFS in $G$ from $t$ to find a path to $s_j$, and run BFS from $s_j$ to find a path to $s$. The union of these two paths form a path from $t$ to $s$ that goes through $s_j$. Push one unit of flow in this path. Repeat this process $k$ times until the flow through $s_j$ is zero $\left(\sum_i f\left(s_j, c_i\right)=0\right)$. Notice that now, the overall flow has decreased by $k$. After this, simply remove $s_j$ from the network and run Edmonds-Karp to find the Max Flow in $H^{\prime}$. Since each augmenting path will increase the flow by at least 1 , and the Max-Flow of $H^{\prime}$ cannot exceed the Max-Flow of $H$, this will be at most $k$ iterations. Hence the runtime of this algorithm is $O(k(V+E))=O(k n)$."
10,Mathematics,18.704,Seminar in Algebra,18.701,None,Problem Set 2,Linear Representation,3,nan,1.5,Text,Find a representation $\rho$ of $G=\mathbb{Z}$ for which Maschke's thoerem fails. (Hint: see Exercise 5 in Chapter 8 of James-Liebeck.),Open,"Consider the representation $\rho: \mathbb{Z} \rightarrow \mathrm{GL}(2, \mathbb{C})$ defined by
$$
\rho: n \rightarrow\left(\begin{array}{ll}
1 & 0 \\
n & 1
\end{array}\right).
$$
This is a representation because
$$
(m \rho)(n \rho)=\left(\begin{array}{cc}
1 & 0 \\
m & 1
\end{array}\right)\left(\begin{array}{ll}
1 & 0 \\
n & 1
\end{array}\right)=\left(\begin{array}{cc}
1 & 0 \\
m+n & 1
\end{array}\right)=(m+n) \rho
$$
so it's a homomorphism, and $(n \rho)$ is invertible since the above calculation just shows that its inverse is $((-n) \rho)$ so it is a map from $\mathbb{Z}$ to $\mathrm{GL}(2, \mathbb{C})$.
Let's consider the action of $n \rho$ on $(a, b)$, an arbitrary row vector. $(a, b) n \rho=(a+b n, b)$. This is a multiple of $(a, b)$ if and only if $b=0$, that is, for multiples of $(1,0)$, ie for elements in $V:=\operatorname{sp}((1,0))$. In this case, $(1,0)(n \rho)=(1,0)$. When we use the corresponding $\mathbb{C Z}$-module $\mathbb{C}^{2}$ in Theorem 4.4(1) of James-Liebeck, we thus see that $\mathbb{C}^{2}$ has a submodule, $V$. Therefore, we can conclude that $\rho$ is reducible.
However, we just showed there is only one 1-dimensional $\mathbb{C} \mathbb{Z}$-submodule of $\mathbb{C}^{2}$. Therefore, $\mathbb{C}^{2}$ can't be the sum of two $\mathbb{C Z} \mathbb{Z}$-submodules, so there is no submodule $U$ such that $\mathbb{C}^{2}=U \oplus V$. Maschke's theorem thus fails. ",Let $G$ be a finite group. Let $\rho$ be an irreducible complex representation of $G$ of degree $n$ and let $\chi$ be the character of $\rho$. Let $Z$ be the center of $G$ (i.e. the set of $z \in G$ such that $z g=g z$ for all $g \in G)$. Show that $|\chi(z)|=n$ for all $z \in Z$.,"From Proposition $9.14$ from the text, we know that any irreducible representation takes elements in the center to a scalar multiple of the identity, i.e. $\lambda I$ for $\lambda \in \mathbb{C}$. But since $G$ is finite every element, including every element in the center, has some finite order $k$, i.e. we have $\lambda^{k}=1$ for some $k$. Then if $z \in Z$, we have $\chi(z)=n \lambda$, so
$$
|\chi(z)|=|n \lambda|=n|\lambda|=n,
$$
as desired. ",Let $\rho$ be an irreducible complex representation of a finite group $G$. Let $A$ be an abelian subgroup of $G$. Note that the representation $\rho: G \rightarrow \operatorname{GL}(V)$ naturally restricts to a representation $\rho: A \rightarrow \operatorname{GL}(V)$. Show that the degree of $\rho$ is at most $[G: A]$.,"We use our result from part 1. Considering the restriction of $\rho$ to $A$, and letting $\chi$ be the character of $\rho$, we know that $|A| \chi(1) \leq \sum_{a \in A}|\chi(a)|^{2}$. Since this is a sum of nonnegative integers, we know that the sum of the norm of characters over more elements of $G$ is larger than the sum over just $A$ :
$$
|A| \chi(1) \leq \sum_{a \in A}|\chi(a)|^{2} \leq \sum_{g \in G}|\chi(g)|^{2}
$$
Since $\rho$ is irreducible, $\chi$ is irreducible, so by definition $\sum_{g \in G}|\chi(g)|^{2}=|G|$:
$$
|A| \chi(1) \leq|G| \Longrightarrow \chi(1) \leq \frac{|G|}{|A|}=[G: A]
$$
Since $\chi(1)$ is the degree of $\rho$, we are done! ","A finite group $G$ operates on itself by conjugation. This operation produces a permutation representation $\rho$ of $G$.
Determine the character $\chi$ of $\rho$.","$\chi_{c}(g)$ is the number of group elements such that $h g h^{-1}=g$, i.e., such that $h g=g h$. It is the order of the centralizer of $g: \chi_{c}(g)=|Z(g)|$."
144,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Midterm Exam 1,CMOS Logic,7,c,0.6,Text,"Ben invented a light-speed spaceship last night, using a CMOS gate as the critical component. He wrote down the truth table for the Boolean expression implemented by this gate. Unfortunately, his nemesis replaced one of the entries in his truth table and Ben can't remember which one it was! Fortunately, you have taken $6.191$ and can help Ben reconstruct the truth table.
Below is the truth table for Ben's Boolean expression, $F(a, b, c)$. One entry of the truth table has been modified. Ben surmises that his nemesis has flipped one of the outputs from a $\mathbf{1}$ to a $\mathbf{0}$.
\begin{tabular}{|c|c|c|c|}
\hline $\mathbf{a}$ & $\mathbf{b}$ & $\mathbf{c}$ & $\mathbf{F}$ \\
\hline 0 & 0 & 0 & 1 \\
\hline 0 & 0 & 1 & 1 \\
\hline 0 & 1 & 0 & 0 \\
\hline 0 & 1 & 1 & 0 \\
\hline 1 & 0 & 0 & 1 \\
\hline 1 & 0 & 1 & 0 \\
\hline 1 & 1 & 0 & 1 \\
\hline 1 & 1 & 1 & 0 \\
\hline
\end{tabular}
Ben wants to add an input d to his CMOS gate to implement a new function, $G$. Ben sets $\mathrm{G}(\mathrm{a}, \mathrm{b}, \mathrm{c}, 0)=\mathrm{F}(\mathrm{a}, \mathrm{b}, \mathrm{c})$. Given that $\mathrm{G}$ can be implemented as a single CMOS gate, what are the following values?",Open,"$$
\begin{aligned}
&G(0,0,1,1)=\text {can't say}. \\
&G(1,0,1,1)=0.
\end{aligned}
$$","Ben invented a light-speed spaceship last night, using a CMOS gate as the critical component. He wrote down the truth table for the Boolean expression implemented by this gate. Unfortunately, his nemesis replaced one of the entries in his truth table and Ben can't remember which one it was! Fortunately, you have taken $6.191$ and can help Ben reconstruct the truth table.
Below is the truth table for Ben's Boolean expression, $F(a, b, c)$. One entry of the truth table has been modified. Ben surmises that his nemesis has flipped one of the outputs from a $\mathbf{1}$ to a $\mathbf{0}$.
\begin{tabular}{|c|c|c|c|}
\hline $\mathbf{a}$ & $\mathbf{b}$ & $\mathbf{c}$ & $\mathbf{F}$ \\
\hline 0 & 0 & 0 & 1 \\
\hline 0 & 0 & 1 & 1 \\
\hline 0 & 1 & 0 & 0 \\
\hline 0 & 1 & 1 & 0 \\
\hline 1 & 0 & 0 & 1 \\
\hline 1 & 0 & 1 & 0 \\
\hline 1 & 1 & 0 & 1 \\
\hline 1 & 1 & 1 & 0 \\
\hline
\end{tabular}
Alice thinks Ben should use a different design. She proposes using the Boolean expression $\bar{B}(\bar{A}+\bar{C})$. Draw the CMOS gate for Alice's Boolean expression.",The CMOS gate is below.,"Ben invented a light-speed spaceship last night, using a CMOS gate as the critical component. He wrote down the truth table for the Boolean expression implemented by this gate. Unfortunately, his nemesis replaced one of the entries in his truth table and Ben can't remember which one it was! Fortunately, you have taken $6.191$ and can help Ben reconstruct the truth table.
Below is the truth table for Ben's Boolean expression, $F(a, b, c)$. One entry of the truth table has been modified. Ben surmises that his nemesis has flipped one of the outputs from a $\mathbf{1}$ to a $\mathbf{0}$.
\begin{tabular}{|c|c|c|c|}
\hline $\mathbf{a}$ & $\mathbf{b}$ & $\mathbf{c}$ & $\mathbf{F}$ \\
\hline 0 & 0 & 0 & 1 \\
\hline 0 & 0 & 1 & 1 \\
\hline 0 & 1 & 0 & 0 \\
\hline 0 & 1 & 1 & 0 \\
\hline 1 & 0 & 0 & 1 \\
\hline 1 & 0 & 1 & 0 \\
\hline 1 & 1 & 0 & 1 \\
\hline 1 & 1 & 1 & 0 \\
\hline
\end{tabular}
Ben thinks he can make the spaceship even faster if he sets $\mathrm{F}(1,1,1)=1$. Can Ben still implement this with a single CMOS gate?",No.,"Ben invented a light-speed spaceship last night, using a CMOS gate as the critical component. He wrote down the truth table for the Boolean expression implemented by this gate. Unfortunately, his nemesis replaced one of the entries in his truth table and Ben can't remember which one it was! Fortunately, you have taken $6.191$ and can help Ben reconstruct the truth table.
Below is the truth table for Ben's Boolean expression, $F(a, b, c)$. One entry of the truth table has been modified. Ben surmises that his nemesis has flipped one of the outputs from a $\mathbf{1}$ to a $\mathbf{0}$.
\begin{tabular}{|c|c|c|c|}
\hline $\mathbf{a}$ & $\mathbf{b}$ & $\mathbf{c}$ & $\mathbf{F}$ \\
\hline 0 & 0 & 0 & 1 \\
\hline 0 & 0 & 1 & 1 \\
\hline 0 & 1 & 0 & 0 \\
\hline 0 & 1 & 1 & 0 \\
\hline 1 & 0 & 0 & 1 \\
\hline 1 & 0 & 1 & 0 \\
\hline 1 & 1 & 0 & 1 \\
\hline 1 & 1 & 1 & 0 \\
\hline
\end{tabular}
Select the entry in the truth table which has been modified and explain why it must have been incorrect.","$\mathrm{F}(0,1,0)->\mathrm{F}(1,1,0)$ should follow the ""rising inputs lead to falling outputs"" rule. However, the truth table has $\mathrm{F}(0,1,0)=0$ and $\mathrm{F}(1,1,0)=1$, which is not possible under this rule.
Since we know Ben's nemesis flipped an output from a 1 to a 0 , it must be that $\mathrm{F}(0,1,0)$ is the incorrect line - its output should really be a 1."
426,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Problem Set 3,Gradient Descent,1,ai,0.01041666667,Text,"Let's consider gradient descent when the dimension of the input is 2.
$$
\theta=\left[\begin{array}{l}
\theta_{1} \\
\theta_{2}
\end{array}\right]
$$
So, we have $f(\theta)$ and we are trying to find the values of $\theta_{1}$ and $\theta_{2}$ that minimize it. Suppose
$$
f(\theta)=-3 \theta_{1}-\theta_{1} \theta_{2}+2 \theta_{2}+\theta_{1}^{2}+\theta_{2}^{2}
$$
What is the first component of $\nabla_{\theta} f(\theta)$? 
Enter an expression involving theta_1 and theta_2.",Expression,2*theta_1 - theta_2 - 3,"Let's consider gradient descent when the dimension of the input is 2.
$$
\theta=\left[\begin{array}{l}
\theta_{1} \\
\theta_{2}
\end{array}\right]
$$
So, we have $f(\theta)$ and we are trying to find the values of $\theta_{1}$ and $\theta_{2}$ that minimize it. Suppose
$$
f(\theta)=-3 \theta_{1}-\theta_{1} \theta_{2}+2 \theta_{2}+\theta_{1}^{2}+\theta_{2}^{2}
$$
What is the second component of $\nabla_{\theta} f(\theta)$?
Enter an expression involving theta_1 and theta_2.",2*theta_2 - theta_1 + 2,"Let's consider gradient descent when the dimension of the input is 2.
$$
\theta=\left[\begin{array}{l}
\theta_{1} \\
\theta_{2}
\end{array}\right]
$$
So, we have $f(\theta)$ and we are trying to find the values of $\theta_{1}$ and $\theta_{2}$ that minimize it. Suppose
$$
f(\theta)=-3 \theta_{1}-\theta_{1} \theta_{2}+2 \theta_{2}+\theta_{1}^{2}+\theta_{2}^{2}
$$
What is $f([3,-2])$? 
Enter a numerical value.",6,"Let's consider gradient descent when the dimension of the input is 2.
$$
\theta=\left[\begin{array}{l}
\theta_{1} \\
\theta_{2}
\end{array}\right]
$$
So, we have $f(\theta)$ and we are trying to find the values of $\theta_{1}$ and $\theta_{2}$ that minimize it. Suppose
$$
f(\theta)=-3 \theta_{1}-\theta_{1} \theta_{2}+2 \theta_{2}+\theta_{1}^{2}+\theta_{2}^{2}
$$
What is $f([1,1])$? 
Enter a numerical value.",0
176,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Lab 5,Feature Representation,4,a,0.1388888889,Text,"According to Glassdoor, corporate job openings receive 250 resumes on average, and some receive many, many more. Screening resumes is an arduous and repetitive process. This seems like a great task to apply all of our classification algorithms! But what data should we give to a model to find the best resumes?
A typical resume includes a person's name, contact details, education, work history, extracurriculars, skills, awards, and languages, all of which can be used as features for an $\mathrm{ML}$ model.
In the United States, it's illegal to discriminate based on a job applicant's race, religion, sex, or on a number of other protected characteristics. A typical resume does not include these attributes; hence, any model you train will be unaware of these features. However, it is still possible for a machine learning model to discriminate based on a protected characteristic when screening resumes. Why is this possible?",Open,"Features can either embed this data directly (e.g., names often communicate sex), or features can be correlated such that they are subject to ""leakage."" For example, between a person's name and zip code, you can likely predict their race.","According to Glassdoor, corporate job openings receive 250 resumes on average, and some receive many, many more. Screening resumes is an arduous and repetitive process. This seems like a great task to apply all of our classification algorithms! But what data should we give to a model to find the best resumes?
According to a Reuters report, Amazon started using ML to screen resumes, and found that their model showed bias against women. In particular, they observed that their resume screening tool penalized resumes that included the word ""women's"" (as in ""Women's Chess Club Captain"") or resumes from women's colleges. How could you obfuscate the features from a resume to prevent this? Describe 3 rules you might write for obfuscation.","Students should come up with some example rules like ""remove the word women's or men's""; ""change the college name""; etc.","According to Glassdoor, corporate job openings receive 250 resumes on average, and some receive many, many more. Screening resumes is an arduous and repetitive process. This seems like a great task to apply all of our classification algorithms! But what data should we give to a model to find the best resumes?
After you obfuscate resume features, will the model be ""fair"" and why? What does ""fairness"" mean in this context?
There are many different definitions of fairness, and we will discuss these definitions in the coming weeks. One definition of fairness is ""fairness through unawareness,"" wherein you make sure protected features are not input to a model. Does a model trained on raw resume data meet this definition of ""fairness through unawareness""? How about a model trained on obfuscated resume data? ","This question is underspecified, so students will come up with a variety of different answers. One thing we can push them toward is realizing how hard/impossible it is to guarantee that a model does not infer protected characteristics.
It's possible to argue that even the first model meets this definition of ""fairness through unawareness"" since the data in question is not passed into the model directly. It's equally possible to argue that neither model meets this definition, since we can't guarantee that the models do not infer the protected characteristic from the data (depending on their answers to 5.2). ","In the features lab, we started to introduce the concept of fairness of outcomes. We discussed one definition of fairness: fairness through unawareness, wherein you make sure protected features are not input to a model. We saw that this definition is of limited usefulness, since features can often be correlated.
This week we will introduce several alternative definitions of fairness.
What is ""fairness"" and how do we evaluate the fairness of a model?
To ground this discussion, let's take a look at some synthetic data representing loan applications. Loans and especially mortgages have been used to discriminate against Black people and immigrants.
In these plots, credit scores range from 0 to 100, and higher credit scores represent higher likelihood of the person paying back the loan. Each circle represents a person: opaque circles represent people who pay off their loan and transparent circles represent those who default on their loan.
In this synthetic data, two different demographics of people are represented as ""blue"" and ""orange"". Our goal is to be fair to both the blue and orange people. But what does ""fair"" even mean?
(The visualizations can be further explored here.)
Definition 1: Fairness through Unawareness: As a first potential definition of fairness, we consider the following proposal: that a fair process, and, therefore, a fair model, does not account for the protected characteristic. This is the definition we discussed in the features lab. 
Applying this model to our synthetic case, we see above that both groups have the same ""loan threshold"", but the orange group has a lower positivity rate $(30 \%$ vs. blue's $52 \%)$.
Definition 2: Max Profit: It is proposed that a model and process that purely maximizes the profit with all available data, is considered fair. 
To achieve max profit, we would select the ""loan threshold"" differently for each group. The rates of both correctness and incorrectness vary for the different groups.
Definition 3: Demographic parity: The model is proposed to be fair if the distribution of outcomes for each demographic, gender, or other subgroup is the same among those that applied and those that were accepted. For example, if $30 \%$ of the applicants for loan applications come from the blue group, then $30 \%$ of the approved loan applications should also come from the blue group. 
To achieve demographic parity, we would select the ""loan threshold"" differently for each group such that the positive rate is the same across the different demographics.
Definition 4: Equal Opportunity: A model is proposed to be fair if the distribution of loans that are paid back is the same for each subgroup. This means that among people who would pay back a loan, the subgroups do almost equally as well. 
To achieve equal opportunity (sometimes called ""Equal Odds""), we would select the ""loan threshold"" differently for each group such that the true positive rate is the same across the different demographics.
Note: This list of definitions of fairness above is not exhaustive (see the 'Food for Thought' below). Also, questions about a model's ""fairness"" are not strictly questions about statistical distribution of the model's outputs. Questions of fairness may also concern assumptions about the model's data. This also brings up the question of whether the application of machine learning can itself be discriminatory or socially unjust.
Like with employment, in the United States it is illegal to discriminate based on a loan applicant's race, religion, sex, or on a number of other protected characteristics. Which of these definitions of fairness do you think best aligns with this law, and why?","\begin{itemize}
\item Unawareness: all this law wants is for us to not discriminate based on the precise protected class, so even if we can infer the protected class with relatively high accuracy, we still don't know for sure and therefore are not discriminating based on the class itself. Meanwhile, unawareness is sometimes considered the ""best"" definition of fairness since it's the only option which doesn't take the protected class into account.
\item Max profit. In the max profit model, we don't care about the protected class; we only care about maximizing the amount of money we make off of these loans. This clearly makes the most business sense! But one could ask - $-$ is it fair?
\end{itemize}"
155,EECS,6.121,Introduction to Algorithms,"6.100A, 6.1200",6.101,Final Exam,Strongly Connected Components,1,i,1.041666667,Text,"If a graph $G=(V, E)$ is a DAG, running Full-DFS and ordering the vertices in reverse order of their finish times results in a topological order. Assuming you run the same procedure on a general directed graph $G=(V, E)$, and that $u, v \in V$ are vertices in different Strongly Connected Components, which of the following statements are true? (We write $u \rightarrow v$ if there is a path from $u$ to $v$ in $G$ and $u \prec v$ if $u$ appears before $v$ in the resulting ordering). Select all correct statements.
(a) $u \rightarrow v$ implies $u \prec v$.
(b) $u \rightarrow v$ implies $v \prec u$.
(c) $u \prec v$ implies $u \rightarrow v$.
(d) $u \prec v$ implies $v \rightarrow u$.
(e) None of the above.",Multiple Choice,"(a) Correct: We show that $v$ finishes first. Two cases: (1) If $u$ is visited first, then as $u \rightarrow v, v$ is going to be visited (and finish) before $u$ finishes; (2) if $v$ is visited first, as $u$ and $v$ are in different SCC and $u \rightarrow v$, then we don't have a path from $v$ to $u$. Therefore, $v$ finishes first.
(b) Incorrect: For example if $G$ is a DAG.
(c) Incorrect: For example if $G$ consists of 2 disconnected SCC with $u$ in one and $v$ in the other.
(d) Incorrect: For example if $G$ is a DAG.
(e) Incorrect. ","Assume $G$ is a Directed Acyclic Graph. Which of the following sentences are correct?
$\mathrm{a}$ $G$ has at most one node with in-degree 0.
$\mathrm{b}$ $G$ has at least one node with in-degree 0 .
$\mathrm{c}$ The nodes of $G$ can be ordered so that if there is an edge from $u$ to $v$, then $v$ precedes $u$ in the ordering.
$\mathrm{d}$ A Full Depth First Search on $G$ takes $O(|E|)$ time.","$\mathrm{a}$ Incorrect. A DAG can have multiple ""sources"" (vertices with in-degree 0).
$\mathrm{b}$ Correct. in fact, starting from any node, and following edges backwards, will eventually take us to one such vertex.
$\mathrm{c}$ Correct. This ordering is the reverse Topological Ordering.
$\mathrm{d}$ Incorrect. A Full Depth First Search on $G$ takes $O(|V|+|E|)$ time. In this regard, DAGs are no different than regular graphs.","Given two vertices $u$ and $v$ is a directed graph $G$, if $u$ and $v$ are in the same Weakly Connected Component then either there is a path from $u$ to $v$ or a path from $v$ to $u$.
$\mathrm{a}$ True.
$\mathrm{b}$ False.","False.
As an example, consider a graph $G$ with vertices [1,2,3] and edges (1,2) and (3,2). Then all vertices are in the same weakly connected component but there is no path from 1 to 3 or from 3 to 1.","Consider the example graph $G$ below and imagine running the Kosaraju algorithm on $G$, but without pass (1). Which vertex orderings, if used for the second pass, would give an incorrect set of Strongly Connected Components?
$\mathrm{a} [a, b, c, d, e, f]$.
$\mathrm{b} [f, d, c, a, b, e]$.
$\mathrm{c} [f, d, c, b, a, e]$.
$\mathrm{d} [d, c, f, a, b, e]$.
$\mathrm{e}$ None of the above.","$\mathrm{a}$: Starting from $a$, vertex $d$ is reachable and so it will be marked as being in the same strongly connected component as $a$, which is wrong. Similarly,
$\mathrm{b}, \mathrm{c}, \mathrm{d}$: When we start a DFS from $c$, before visiting $a, b, e$, we will mark $e$ as being in the same component as $c$, which is wrong. "
3,Mathematics,18.102,Introduction to Functional Analysis,"18.C06, 18.100B",None,Problem Set 1,Banach Spaces,4,a,0.1666666667,Text,"Consider the 'unit sphere' in $l^{p}$. This is the set of vectors of length 1:
$$
S=\left\{a \in l^{p} ;\|a\|_{p}=1\right\}.
$$
Show that $S$ is closed.",Open,"The sphere is the inverse image of 1 under the norm, shown to be continuous in Q1 above, so is closed.","Consider the 'unit sphere' in $l^{p}$. This is the set of vectors of length 1:
$$
S=\left\{a \in l^{p} ;\|a\|_{p}=1\right\}.
$$
Recall the sequential (so not the open covering definition) characterization of compactness of a set in a metric space (e.g. by checking in Rudin).",A subset of a metric space is compact iff every sequence in it has a convergent subsequence with limit in the set.,"Consider the 'unit sphere' in $l^{p}$. This is the set of vectors of length 1:
$$
S=\left\{a \in l^{p} ;\|a\|_{p}=1\right\}.
$$
Show that $S$ is not compact by considering the sequence in $l^{p}$ with $k$ th element the sequence which is all zeros except for a 1 in the $k$ th slot. Note that the main problem is not to get yourself confused about sequences of sequences!",Let $e_{n}$ be the sequence in $l^{p}$ with all entries zero except the $n$ th. It is in $S$ but if $n \neq m$ then $\left\|e_{n}-e_{m}\right\|=2^{1 / p}$. The same is true on any subsequence which cannot therefore be Cauchy and hence cannot be convergent. Thus $S$ is not compact.,"Let $M=\left(M_{i}\right)$ be a positive sequence that goes to infinity. Consider the space consisting of the complex valued sequences $c_{i}$ such that
$$
\left\|c_{i}\right\|_{M}^{2}:=\sum_{i} M_{i}\left|c_{i}\right|^{2}<\infty .
$$
Show that the unit ball in this space, considered as a subset of $l^{2}$, has compact closure.","Proof. Let us use $l_{M}^{2}$ to denote the space defined in the problem. There is a natural norm-preserving linear bijection between $l_{M}^{2}$ and $l^{2}$ that maps $\left(c_{i}\right)$ to $\left(c_{i} \sqrt{M_{i}}\right)$. Therefore, we deduce $l_{M}^{2}$ is a Hilbert space. We consider the natural inclusion
$$
l_{M}^{2} \stackrel{T}{\rightarrow} l^{2}, T\left(c_{1}, \ldots, c_{i}, \ldots\right)=\left(c_{1}, \ldots, c_{i}, \ldots\right)
$$
and for each $n$ its truncation
$$
l_{M}^{2} \stackrel{T_{n}}{\longrightarrow} l^{2}, T_{n}\left(c_{1}, \ldots, c_{i}, \ldots\right)=\left(c_{1}, \ldots, c_{n}, 0,0, \ldots\right) .
$$
We find for any $x=\left(c_{1}, \ldots, c_{i}, \ldots\right)$
$$
\left\|T_{n}(x)-T(x)\right\|^{2}=\sum_{i=n+1}^{\infty}\left|c_{i}\right|^{2} \leq \operatorname{Min}_{i \geq n+1}^{-1}\left\{M_{i}\right\}^{-1} \sum_{i=n+1}^{\infty} M_{i}\left|c_{i}\right|^{2} \leq \operatorname{Min}_{i \geq n+1}\left\{M_{i}\right\}^{-1}\|x\|^{2}
$$
As $\left(M_{i}\right)$ tends to infinity, we conclude $\left\|T_{n}-T\right\| \rightarrow 0$ as $n \rightarrow \infty$. So $T$ is a limit of finite rank operators and therefore is compact."
162,EECS,18.C06,Linear Algebra and Optimization,18.02,None,Midterm Exam 2,Operator Norm,5,d,0.5625,Text,"Let $A$ be a $4 \times 6$ matrix with singular values
$$
\sigma_{1}=3, \quad \sigma_{2}=3, \quad \sigma_{3}=1
$$
and the rest are zero. For each of the following, either determine its value or argue that it cannot be determined from the singular values alone.
The operator norm of $A-B$ where $B$ is the best rank two approximation to $A$.",Open,We can obtain the best rank two approximation by truncating the SVD of $A$ at two terms. Thus operator norm of $A-B$ would then be $\sigma_{3}=1$.,"Let $A$ be a $4 \times 6$ matrix with singular values
$$
\sigma_{1}=3, \quad \sigma_{2}=3, \quad \sigma_{3}=1
$$
and the rest are zero. For each of the following, either determine its value or argue that it cannot be determined from the singular values alone.
The operator norm of $A^{T}$.","The operator norm is the largest singular value, and hence is $\sigma_{1}=3$. ","Let $A$ be a $4 \times 6$ matrix with singular values
$$
\sigma_{1}=3, \quad \sigma_{2}=3, \quad \sigma_{3}=1
$$
and the rest are zero. For each of the following, either determine its value or argue that it cannot be determined from the singular values alone.
The dimension of the nullspace of $A$.",The rank is the number of nonzero singular values. Hence the rank of $A$ is 3. By the rank-nullity theorem we have that the null space has dimension $6-3=3$.,"Let $A$ be a $4 \times 6$ matrix with singular values
$$
\sigma_{1}=3, \quad \sigma_{2}=3, \quad \sigma_{3}=1
$$
and the rest are zero. For each of the following, either determine its value or argue that it cannot be determined from the singular values alone.
The characteristic polynomial of $A$.","Since $A \in \mathbb{R}^{4 \times 6}$ is not square, the characteristic polynomial is not defined.
Also, even if the matrix were square, the characteristic polynomial cannot be determined from the singular values alone because there can be two matrices with different eigenvalues but the same singular values."
231,Mathematics,18.01,Calculus I,None,None,Problem Set 5,Differential Equations,18,a,0.04751847941,Text,"Consider the equation $x^{\prime \prime}(t)=1-x(t)$. This equation looks a bit like the one in problem 7. Here is a trick for solving the equation, which also helps in some other equations.
Define $f(t)=x(t)-1$. Check that $f^{\prime \prime}(t)=-f(t)$.",Open,"From the $f=x-1$ definition, $f^{\prime \prime}=x^{\prime \prime}$ (the $-1$ gets differentiated to zero). And $x^{\prime \prime}=1-x$ (the original equation). Thus, $f^{\prime \prime}=x^{\prime \prime}=-f$.","Consider the equation $x^{\prime \prime}(t)=1-x(t)$. This equation looks a bit like the one in problem 7. Here is a trick for solving the equation, which also helps in some other equations.
Suppose that $x(0)=1$ and $x^{\prime}(0)=1$. Find $x(t)$. Hint: First find $f(0)$ and $f^{\prime}(0)$, then find $f(t)$, and finally find $x(t)$.","$f=A \sin t+B \cos t$ (from Problem 16). To find $A$ and $B$, first find $f(0)$ and $f^{\prime}(0)$. $f(0)=x(0)-1=0$. Thus, $B=0$. And $f^{\prime}(0)=x^{\prime}(0)=1$. Thus, $A=1$, and
$$
f=\sin t .
$$
Changing back to $x$ :
$$
x=1+\sin t .
$$","Suppose that $x^{\prime}(t)=\frac{1}{x(t)}$ and $x(0)=1$.
Take your formula for $x(t)$, differentiate it, and check that $x^{\prime}(t)=\frac{1}{x(t)}$. Also check that $x(0)=1$.","$$
x^{\prime}(t)=\frac{d}{d t}(2 t+1)^{1 / 2}=\frac{1}{2}(2 t+1)^{-1 / 2}(2)=\frac{1}{x(t)} .
$$
Also check that $x(0)=(2(0)+1)^{1 / 2}=1$.","Consider the differential equation $x^{\prime \prime}(t)=-x^{\prime}(t)-x(t)$.
Suppose that $x_{1}(t)$ is a solution to the equation with $x_{1}(0)=0$ and $x_{1}^{\prime}(0)=1$. Here is a picture of $x_{1}(t)$ below.
Suppose that $x_{2}(t)$ is a solution to the equation with $x_{2}(0)=0$ and $x_{2}^{\prime}(0)=2$. Which picture on the following page shows $x_{2}(t)$ ? Briefly explain your reasoning.","The first picture since we have $x_{2}(t)=2 x_{1}(t)$ for all $t$. The first graph corresponds to stretching the graph of $x_{1}$ vertically by a factor of 2 . In fact, from 3 a, $2 x_{1}$ is a solution to the differential equation. Moreover, $2 x_{1}$ and $x_{2}$ have the same initial conditions. Hence, they are equal for all $t$. "
97,Mathematics,18.102,Introduction to Functional Analysis,"18.C06, 18.100B",None,Final Exam,Fourier Series,5,c,2.25,Text,"Consider the subspace $H \subset \mathcal{C}[0,2 \pi]$ consisting of those continuous functions on $[0,2 \pi]$ which satisfy
$$
u(x)=\int_{0}^{x} U, \forall x \in[0,2 \pi]
$$
for some $U \in L^{2}(0,2 \pi)$ (depending on $u$ of course).
If $\int_{0}^{2 \pi} U=0$, determine the Fourier series of $u$ in terms of that of $U$.",Open,"By (i) the Fourier coefficients of $u$ are $C_{n}=\frac{c_{n}}{i n}$ for $n \neq 0$ and $C_{0}=$ $-\sum_{n \neq 0} \frac{c_{n}}{i n}$. Note that this series is absolutely convergent, as
$$
\sum_{n \neq 0} \frac{\left|c_{n}\right|}{|n|} \leq \sqrt{\sum_{n \neq 0}\left|c_{n}\right|^{2} \cdot \sum_{n \neq 0} \frac{1}{n^{2}}}.
$$","Consider the subspace $H \subset \mathcal{C}[0,2 \pi]$ consisting of those continuous functions on $[0,2 \pi]$ which satisfy
$$
u(x)=\int_{0}^{x} U, \forall x \in[0,2 \pi]
$$
for some $U \in L^{2}(0,2 \pi)$ (depending on $u$ of course).
Show that the function $U$ is determined by $u$ (given that it exists).","Consider the Fourier expansion of $U$:
$$
U(x)=\sum_{n \in \mathbb{Z}} c_{n} e^{i n x}.
$$
This series converges in $L^{2}$, hence in $L^{1}$. Thus we have
$$
u(x)=\sum_{n \in \mathbb{Z}} c_{n} \int_{0}^{x} e^{i n t} d t=c_{0} x+\sum_{n \neq 0} c_{n} \frac{e^{i n x}-1}{i n},
$$
which converges uniformly in $x$. So $c_{0}=\frac{u(2 \pi)-u(0)}{2 \pi}$ and $c_{n}$ is the $n$-th Fourier coefficient of $u$ multiplied by in for $n \neq 0$.","Consider the subspace $H \subset \mathcal{C}[0,2 \pi]$ consisting of those continuous functions on $[0,2 \pi]$ which satisfy
$$
u(x)=\int_{0}^{x} U, \forall x \in[0,2 \pi]
$$
for some $U \in L^{2}(0,2 \pi)$ (depending on $u$ of course).
Show that
$$
\|u\|_{H}^{2}=\int_{(0,2 \pi)}|U|^{2}
$$
turns $H$ into a Hilbert space.","By (i), the map $u \mapsto\left(c_{n}, n \in \mathbb{Z}\right)$ is a linear isomorphism $H \rightarrow l_{2}(\mathbb{Z})$, and $\int|U|^{2}=2 \pi \sum_{n}\left|c_{n}\right|^{2}$. This implies the statement.","Show that if $u \in H_{0}^{2}([0, \pi])$ and $u_{N}$ is the sum of the first $N$ terms in the Fourier-Bessel series for $u$ (which is in $\left.L^{2}(0, \pi)\right)$ then
$$
u_{N} \rightarrow u, \frac{d u_{N}}{d x} \rightarrow F_{1}, \frac{d^{2} u_{N}}{d x^{2}} \rightarrow F_{2}
$$
where in the first two cases we have convergence in supremum norm and in the third, convergence in $L^{2}(0, \pi)$. Deduce that $u \in \mathcal{C}^{0}[0, \pi], u(0)=u(\pi)=0$ and $F_{1} \in \mathcal{C}^{0}[0, \pi]$ whereas $F_{2} \in L^{2}(0, \pi)$.","After normalisation, the set $\left\{\sqrt{\frac{2}{\pi}} \sin k x,(k=1,2, \ldots)\right\}$ forms an orthonormal basis of $L^{2}(0, \pi)$. Let $u \in H_{0}^{2}([0, \pi])$ and $c_{k}=\int_{0}^{\pi} \sin k x u(x) d x$. We have $\sum\left|k^{2} c_{k}\right|^{2}<\infty$. Therefore there exists functions $F_{1}$ and $F_{2}$ in $L^{2}(0, \pi)$ such that the following equations holds in $L^{2}(0, \pi)$:
$$
u=\frac{2}{\pi} \sum_{k=1}^{\infty} c_{k} \sin k x, \quad F_{1}=\frac{2}{\pi} \sum_{k=1}^{\infty} k c_{k} \cos k x, \quad F_{2}=-\frac{2}{\pi} \sum_{k=1}^{\infty} k^{2} c_{k} \sin k x .
$$
This shows the convergence in (2) holds at least in $L^{2}$ sense. Our goal is to show the first two summations actually converge in supremum norm (uniform convergence of continuous functions). This will imply $u$ and $F_{1}$ are uniform limit of continuous functions and therefore are continuous and $u(0)=u(\pi)=0$.
We first show the summation defining $F_{1}$ converges at $x=0$. Namely, $\sum k c_{k}$ converges. This follows from the Cauchy-Schwartz inequality $\sum\left|k c_{k}\right| \leq\left(\sum\left|k^{2} c_{k}\right|^{2}\right)\left(\sum \frac{1}{k^{2}}\right)$. Now, we show the summation defining $F_{1}$ converges in the supremum norm. For any $x \in[0, \pi]$, we compute the summation from $N_{1}$ to $N_{2}$ terms
$$
\sum_{k=N_{1}}^{N_{2}} k c_{k} \cos k x=\sum_{k=N_{1}}^{N_{2}} k c_{k}(\cos k x-1)+\sum_{k=N_{1}}^{N_{2}} k c_{k}=-\sum_{k=N_{1}}^{N_{2}} k^{2} c_{k} \int_{0}^{x} \sin k x+\sum_{k=N_{1}}^{N_{2}} k c_{k}
$$
Now, taking absolute value and using $\sum\left|k^{2} c_{k}\right|^{2}<\infty$, we find this tends to 0 as long as $N_{1}, N_{2}$ is large (independent of $x$ ). This finishes the uniform convergence of $F_{1}$. Similarly, the summation defining $u$ converges at $x=0$ since every term equals 0 . For any $x \in[0, \pi]$, we compute
$$
\sum_{k=N_{1}}^{N_{2}} c_{k} \sin k x=\sum_{k=N_{1}}^{N_{2}} k c_{k} \int_{0}^{x} \cos k x
$$
This tends to 0 as long as $N_{1}, N_{2}$ is large (independent of $x$ ). This proves the uniform convergence of $u$."
30,EECS,6.3,Signal Processing,"6.100A, 18.03",None,Problem Set 3,Sampling Sinuoids,2,b,0.15625,Text,"Let $f(t)$ represent the following continuous-time signal:
$$
f(t)=4 \cos (300 \pi t)+2 \sin (400 \pi t)+\cos (600 \pi t).
$$
Let $f_{b}[n]$ represent a discrete-time signal that is obtained by sampling $f(t)$ with sampling frequency $f_{s b}=200 \mathrm{~Hz}$, so that
$$
f_{b}[n]=f\left(n / f_{s b}\right).
$$
Determine the fundamental (shortest) period of $f_{b}[n]$ (if one exists). Briefly explain.",Open,"$$
f_{b}[n]=f(n / 200)=4 \cos (3 \pi n / 2)+2 \sin (2 \pi n)+\cos (3 \pi n)=4 \cos (3 \pi n / 2)+0+(-1)^{n}
$$
The fundamental period of this function is $N=4$.","Let $f(t)$ represent the following continuous-time signal:
$$
f(t)=4 \cos (300 \pi t)+2 \sin (400 \pi t)+\cos (600 \pi t).
$$
Let $f_{c}[n]$ represent a discrete-time signal that is obtained by sampling $f(t)$ with sampling frequency $f_{s c}=300 \mathrm{~Hz}$, so that
$$
f_{c}[n]=f\left(n / f_{s c}\right).
$$
Determine the fundamental (shortest) period of $f_{c}[n]$ (if one exists). Briefly explain.","$$
f_{c}[n]=f(n / 300)=4 \cos (\pi n)+2 \sin (4 \pi n / 3)+\cos (2 \pi n)=4(-1)^{n}+2 \sin (4 \pi n / 3)+1
$$
The fundamental period of this function is $N=6$.","Let $f(t)$ represent the following continuous-time signal:
$$
f(t)=4 \cos (300 \pi t)+2 \sin (400 \pi t)+\cos (600 \pi t).
$$
Let $f_{a}[n]$ represent a discrete-time signal that is obtained by sampling $f(t)$ with sampling frequency $f_{s a}=100 \mathrm{~Hz}$, so that
$$
f_{a}[n]=f\left(n / f_{s a}\right).
$$
Determine the fundamental (shortest) period of $f_{a}[n]$ (if one exists). Briefly explain.","$$
f_{a}[n]=f(n / 100)=4 \cos (3 \pi n)+2 \sin (4 \pi n)+\cos (6 \pi n)=4(-1)^{n}+0+1
$$
This function is periodic in $n$ with periods $N=2,4,6, \ldots$
Therefore the fundamental period is $N=2$.","Let $f(t)$ represent the following continuous-time signal:
$$
f(t)=4 \cos (300 \pi t)+2 \sin (400 \pi t)+\cos (600 \pi t).
$$
Determine a sampling frequency $f_{s d}$ for which
$$
f_{d}[n]=f\left(n / f_{s d}\right)
$$
is not periodic (if such a frequency exists). Briefly explain.","If $f_{s}$ is an irrational number, then $300 \pi / f_{s}, 400 \pi / f_{s}$, and $600 \pi / f_{s}$ will not be integer multiples of $2 \pi$. Therefore $f_{s}$ can be any irrational number, e.g., $f_{s}=\pi$. "
21,EECS,6.122,Design and Analysis of Algorithms,6.121,None,Problem Set 2,Amortized Analysis,2,c,0.5454545455,Text,"Zark Muckerburg, having just purchased the photo-sharing app Delaypound (DP), realizes that with so many users creating and deleting content, he'll need a more adaptable storage array. Zark wants to support two operations: appending image data at the end of the array and deleting the image data from the end of the array when a photo is removed.
In particular, he begins with an array of length one and inserts the first element into the one free space in this array. In general, if at any point Zark has a full array of length $n$ and wants to append an element, he creates a new empty array of length $n+1$, copies the $n$ elements from the length- $n$ array to the first $n$ entries of this new array, and then inserts the new element into the last space. If Zark wants to delete the last element from an array of length $n$, he creates a new empty array of length $n-1$ and copies the first $n-1$ elements from the length- $n$ array to the $n-1$ entries of this new array.
Suppose that copying each element when resizing the array has a cost of 1, as does adding a single element, or deleting a single element when the array is not being resized.
Zark sees some potential to the solution that his top engineers propose, but is still unsatisfied, so he recruits you to see if an amortized $\mathcal{O}(1)$ cost per operation can truly be achieved. You, being a hardworking algorithms student, realize that although the doubling scheme for appending elements is spot-on, the halving scheme is a bit ineffective. Instead, you propose that Zark
should only halve the size of the array if the number of elements reduces to one-quarter of the length of the array. In particular, if the array has length $n$ but is only populated by elements in the first $\frac{n}{4}+1$ slots and one element is to be deleted, then he can create a new empty array of length $\frac{n}{2}$ and copy the first $\frac{n}{4}$ elements from the length- $n$ array to the first $\frac{n}{4}$ entries of this new array. Use the potential method to demonstrate that this implementation provides an amortized cost of $\mathcal{O}(1)$ per operation, as desired. Hint: Use the potential function $\Phi(m, n)=\max \left\{2 m-n, \frac{n}{2}-m\right\}$, where $m$ is the current number of stored elements and $n$ is the current capacity (length) of the array.",Open,"First, we check that the potential function is non-negative. We can split this into two cases. Note that $0 \leq m \leq n$.
• When $m \geq \frac{n}{2}$, we have $2 m-n \geq 0$, so $\Phi(m, n) \geq 0$.
• When $m \leq \frac{n}{2}$, we have $\frac{n}{2}-m \geq 0$, so $\Phi(m, n) \geq 0$.
Thus, in either case, $\Phi(m, n)=\max \left\{2 m-n, \frac{n}{2}-m\right\} \geq 0$, as desired. We also assume that, at the beginning, both $m=n=0$ so that $\Phi(0,0)=0$.
Next, we would like to demonstrate that this potential function guarantees an amortized cost of $\mathcal{O}(1)$ per operation.
For all insertions and deletions that don't require any changes to the array, the cost is 1 . For insertions, $m$ increases by 1 so $\Delta \Phi \leq 2$. For deletions, $m$ decreases by 1 so $\Delta \Phi \leq 1$. So the amortized cost is at most 3 .
Suppose that the array is at max capacity, i.e. $m=n$, and Zark wants to append a new image. The cost of this operation is $n+1$, to copy over all $n$ elements as well as insert the newest one. Before the operation, the potential is
$$
\Phi=\Phi(n, n)=\max \left\{2 n-n, \frac{n}{2}-n\right\}=n .
$$
After the operation, the array has length $2 n$ and stores $n+1$ elements, so the potential is
$$
\Phi^{\prime}=\Phi(n+1,2 n)=\max \left\{2(n+1)-2 n, \frac{2 n}{2}-(n+1)\right\}=2 .
$$
Thus, we get that the amortized cost of doubling is
$$
\begin{aligned}
\text { amortized cost } &=\text { actual cost }+\Delta \Phi \\
&=(n+1)+2-n \\
&=3 .
\end{aligned}
$$
Suppose instead that the array is only populated by the first $\frac{n}{4}+1$ slots, i.e. $m=\frac{n}{4}+1$, and Zark wants to delete an image. The cost of this operation is
$\frac{n}{4}+1$ to copy the $\frac{n}{4}$ elements to be kept into a new array. Before the operation, the potential is
$$
\Phi=\Phi\left(\frac{n}{4}+1, n\right)=\max \left\{2\left(\frac{n}{4}+1\right)-n, \frac{n}{2}-\left(\frac{n}{4}+1\right)\right\}=\frac{n}{4}-1 .
$$
After the operation, the array has length $\frac{n}{2}$ and stores $\frac{n}{4}$ elements, so the potential is
$$
\Phi^{\prime}=\Phi\left(\frac{n}{4}, \frac{n}{2}\right)=\max \left\{2\left(\frac{n}{4}\right)-\frac{n}{2}, \frac{n}{4}-\frac{n}{4}\right\}=0 .
$$
Thus, we get that the amortized cost of halving is
$$
\begin{aligned}
\text { amortized cost } &=\text { actual cost }+\Delta \Phi \\
&=\frac{n}{4}+0-\left(\frac{n}{4}-1\right) \\
&=1 .
\end{aligned}
$$
If we start with no images and an empty array, then $\Phi=0$ initially. We have shown that $\Phi$ is always non-negative, and the cost of $k$ operations is bounded by $3 k$. Thus, this procedure achieves constant amortized cost per operation, as desired.","Zark Muckerburg, having just purchased the photo-sharing app Delaypound (DP), realizes that with so many users creating and deleting content, he'll need a more adaptable storage array. Zark wants to support two operations: appending image data at the end of the array and deleting the image data from the end of the array when a photo is removed.
In particular, he begins with an array of length one and inserts the first element into the one free space in this array. In general, if at any point Zark has a full array of length $n$ and wants to append an element, he creates a new empty array of length $n+1$, copies the $n$ elements from the length- $n$ array to the first $n$ entries of this new array, and then inserts the new element into the last space. If Zark wants to delete the last element from an array of length $n$, he creates a new empty array of length $n-1$ and copies the first $n-1$ elements from the length- $n$ array to the $n-1$ entries of this new array.
Suppose that copying each element when resizing the array has a cost of 1, as does adding a single element, or deleting a single element when the array is not being resized.
Zark is unsatisfied by this naïve storage method, so he puts his top engineers on the problem, and they propose an alternative solution. They suggest that, whenever the array reaches capacity, rather than being copied to a new array that is one unit longer, it can be copied to one that is twice as long. In particular, to append an element to a full length- $n$ array, Zark can create a new empty array of length $2 n$, copy the $n$ elements from the length- $n$ array to the first $n$ entries of this new array, and then insert the new element into the $(n+1)$ th space.
To handle deletions, the engineers suggest that an array can be shrunk if the number of elements reduces to one-half the length of the array. In particular, if the array has length $n$ but is only populated by elements in the first $\frac{n}{2}+1$ slots and Zark wants to delete an element, then he can create a new empty array of length $\frac{n}{2}$ and copy the first $\frac{n}{2}$ elements from the length- $n$ array to the $\frac{n}{2}$ entries of this new array.
The engineers purport that their algorithm achieves the desired amortized $\mathcal{O}(1)$ cost per operation. Propose an adversarial sequence of operations in which the amortized cost per operation is $\Omega(n)$.","Suppose that we take $n$ to be a power of 2 . Then one such sequence is performing $\frac{n}{2}$ inserts and then alternating between inserts and deletes. The total cost of the first $\frac{n}{2}$ appends is
$$
\sum_{i=0}^{\lg (n / 2)} 2^i=n-1 .
$$
Then the cost of the next append is $\frac{n}{2}+1$ (because all $\frac{n}{2}$ elements need to be copied and another element added when the length of the array doubles), and the cost of the next delete is $\frac{n}{2}$ (because the first $\frac{n}{2}$ elements need to be copied when the length of the array halves). This proceeds for all of the remaining $\frac{n}{2}$ operations, for a total cost of $\frac{n}{4} \cdot(n+1)$.
Finally, summing the total cost yields
$$
(n-1)+\frac{n}{4} \cdot(n+1)=\frac{1}{4} n^2+\frac{5}{4} n-1
$$
and the amortized cost per operation is $\Omega(n)$, as desired.","Zark Muckerburg, having just purchased the photo-sharing app Delaypound (DP), realizes that with so many users creating and deleting content, he'll need a more adaptable storage array. Zark wants to support two operations: appending image data at the end of the array and deleting the image data from the end of the array when a photo is removed.
In particular, he begins with an array of length one and inserts the first element into the one free space in this array. In general, if at any point Zark has a full array of length $n$ and wants to append an element, he creates a new empty array of length $n+1$, copies the $n$ elements from the length- $n$ array to the first $n$ entries of this new array, and then inserts the new element into the last space. If Zark wants to delete the last element from an array of length $n$, he creates a new empty array of length $n-1$ and copies the first $n-1$ elements from the length- $n$ array to the $n-1$ entries of this new array.
Suppose that copying each element when resizing the array has a cost of 1, as does adding a single element, or deleting a single element when the array is not being resized.
Calculate the cost of performing $n$ insertions followed by $n$ deletions. Given this cost, find the amortized cost per operation.","The first insertion has a cost of 1 because we add one element without changing the array size. The second insertion has a cost of 2 because we copy one element and add another element. In general, the $i^{\text {th }}$ insertion has a cost of $i$. Thus, the total cost of the insertions is
$$
\sum_{i=1}^n i=\frac{n(n+1)}{2} .
$$
For the deletions, the first deletion has a cost of $n-1$, since $n-1$ elements need to be copied to a new array of length $n-1$. The second deletion has a cost of $n-2$, since $n-2$ elements need to be copied to a new array of length $n-2$. In general, the $i^{\text {th }}$ deletion has a cost of $n-i$. Thus, the total cost of the deletions is
$$
\sum_{i=1}^n(n-i)=\sum_{i=0}^{n-1} i=\frac{n(n-1)}{2} .
$$
Summing these costs yields a total cost of
$$
\frac{n(n+1)}{2}+\frac{n(n-1)}{2}=n^2
$$
and dividing by a total of $2 n$ operations gives an amortized cost of $\frac{n}{2}$ per operation.","Your good friend Gegina Reorge really likes how dynamic arrays can append and delete_ last in $O(1)$ amortized time, but now she wants an data structure with a new delete_first function that can remove the element at the front in $O(1)$ amortized time. She also requires prepend, an operation that can insert at the front in $O(1)$ amortize time. More specifically, she wants a data structure that will support the following operations:
\begin{center}
$\begin{array}{cc}\text { init empty } & O(1) \\ \text { set/get at index } & O(1) \\ \text { prepend/delete front } & O\left(1_{A}\right) \\ \text { append/delete back } & O\left(1_{A}\right) \\ \text { as_list } & O(n)\end{array}$
\end{center}
as_list should return a standard dynamic array with all the elements in order.
Exasperated, Gegina turns to you. Please describe a data structure that achieves all the requested runtimes. Briefly argue the runtime of each operation. For the constant time amortized operations, it is sufficient to argue why the following sequences of operations are on average constant time (to do this, show that the total work for each sequence is $O(n))$ :
• prepend $n$ values, delete_ last $n$ times
• prepend $n$ values, delete_ first $n$ times
• append $n$ values, delete_first $n$ times
• append $\mathrm{n}$ values, delete_last $\mathrm{n}$ times
Finally, a correct data structure is required, but you do not have to argue correctness.","We implement this by building off of Wetchen's implementation. However, whenever we try to delete from an empty subarray, we split the other array in half so that each array has $O(n)$ elements. Although the splitting costs $O(n)$ time, after each split we can run delete first or last another $O(n)$ times with constant amortized runtime before having to split again.
An alternative solution is to keep a single dynamic array with an extra pointer (pointing somewhere in the ""middle"") indicating where the first element is. Then to PREPEND we jsut move the index to the left.
A particular elegant solution (written by one of the students) is to use a Circular Dynamic Array. This is like a regular dynamic array but where indexing is done modulo the size of the array. Then one can keep two extra pointers pointing to the start and end of the BACKFRONT datat structure. This solution has the nice property that space is not wasted if only APPEND operations are done."
146,Mathematics,18.6,Probability and Random Variables,18.02,None,Final Exam,Moment Generating Function,4,d,1.25,Text,"Let $X, Y$, and $Z$ be discrete random variables whose joint probability distribution is given by the following table:
\begin{tabular}{c|c|c|c}
$\mathrm{X}$ & $\mathrm{Y}$ & $\mathrm{Z}$ & Prob. \\
\hline \hline 0 & 1 & 3 & $0.2$ \\
\hline 1 & $-3$ & 2 & $0.1$ \\
\hline 1 & 2 & 2 & $0.2$ \\
\hline 1 & 4 & 1 & $0.1$ \\
\hline 2 & 0 & 0 & $0.3$ \\
\hline 3 & 1 & $-1$ & $0.1$ \\
\hline
\end{tabular}
(This means, for example, that $p_{X, Y, Z}(1,-3,2)=0.1$.) Remember that you don't need to compute everything out-an answer like ""(0.01+0.02)/(0.03+2)"" is fine.
Use your answer from part (c) to compute $E[X Y+2 Z]$ and $\operatorname{Var}(X Y+2 Z)$. [Note: To get full credit, you must do this using the moment generating function from (c). If you do it some other way, you will get partial credit.]",Numerical,"We have
$$
\begin{aligned}
& M_{X Y+2 Z}^{\prime}(t)=0.2 e^{t}+3 e^{6 t} \\
& M_{X Y+2 Z}^{\prime \prime}(t)=0.2 e^{t}+18 e^{6 t}
\end{aligned}
$$
So
$$
\begin{aligned}
E[X Y+2 Z] & =M_{X Y+2 Z}^{\prime}(0)=0.2+3=3.2 . \\
E\left[(X Y+2 Z)^{2}\right] & =M_{X Y+2 Z}^{\prime \prime}(0)=0.2+18=18.2 \\
\operatorname{Var}(X Y+2 Z) & =E\left[(X Y+2 Z)^{2}\right]-(E[X Y+2 Z])^{2}=18.2-3.2^{2}=7.96.
\end{aligned}
$$","Let $X, Y$, and $Z$ be discrete random variables whose joint probability distribution is given by the following table:
\begin{tabular}{c|c|c|c}
$\mathrm{X}$ & $\mathrm{Y}$ & $\mathrm{Z}$ & Prob. \\
\hline \hline 0 & 1 & 3 & $0.2$ \\
\hline 1 & $-3$ & 2 & $0.1$ \\
\hline 1 & 2 & 2 & $0.2$ \\
\hline 1 & 4 & 1 & $0.1$ \\
\hline 2 & 0 & 0 & $0.3$ \\
\hline 3 & 1 & $-1$ & $0.1$ \\
\hline
\end{tabular}
(This means, for example, that $p_{X, Y, Z}(1,-3,2)=0.1$.) Remember that you don't need to compute everything out-an answer like ""(0.01+0.02)/(0.03+2)"" is fine.
What is the moment generating function of $X Y+2 Z$?","Using our answer from (b), we get:
$$
M_{X Y+2 Z}(t)=E\left[e^{t(X Y+2 Z)}\right]=0.3 e^{0 t}+0.2 e^{1 t}+0.5 e^{6 t}=0.3+0.2 e^{t}+0.5 e^{6 t}.
$$","Let $X, Y$, and $Z$ be discrete random variables whose joint probability distribution is given by the following table:
\begin{tabular}{c|c|c|c}
$\mathrm{X}$ & $\mathrm{Y}$ & $\mathrm{Z}$ & Prob. \\
\hline \hline 0 & 1 & 3 & $0.2$ \\
\hline 1 & $-3$ & 2 & $0.1$ \\
\hline 1 & 2 & 2 & $0.2$ \\
\hline 1 & 4 & 1 & $0.1$ \\
\hline 2 & 0 & 0 & $0.3$ \\
\hline 3 & 1 & $-1$ & $0.1$ \\
\hline
\end{tabular}
(This means, for example, that $p_{X, Y, Z}(1,-3,2)=0.1$.) Remember that you don't need to compute everything out-an answer like ""(0.01+0.02)/(0.03+2)"" is fine.
What is the probability mass function of $X Y+2 Z$?","Below is the table from the problem with an added column for $X Y+2 Z$:
\begin{tabular}{c|c|c|c|c}
$\mathrm{X}$ & $\mathrm{Y}$ & $\mathrm{Z}$ & $\mathrm{XY}+2 \mathrm{Z}$ & Prob. \\
\hline \hline 0 & 1 & 3 & 6 & $0.2$ \\
\hline 1 & $-3$ & 2 & 1 & $0.1$ \\
\hline 1 & 2 & 2 & 6 & $0.2$ \\
\hline 1 & 4 & 1 & 6 & $0.1$ \\
\hline 2 & 0 & 0 & 0 & $0.3$ \\
\hline 3 & 1 & $-1$ & 1 & $0.1$ \\
\hline
\end{tabular}
So
$$
p_{X Y+2 Z}(a)= \begin{cases}0.3 & \text { if } a=0 \\ 0.1+0.1=0.2 & \text { if } a=1 \\ 0.2+0.2+0.1=0.5 & \text { if } a=6 \\ 0 & \text { otherwise }\end{cases}
$$","Let $X, Y$, and $Z$ be discrete random variables whose joint probability distribution is given by the following table:
\begin{tabular}{c|c|c|c}
$\mathrm{X}$ & $\mathrm{Y}$ & $\mathrm{Z}$ & Prob. \\
\hline \hline 0 & 1 & 3 & $0.2$ \\
\hline 1 & $-3$ & 2 & $0.1$ \\
\hline 1 & 2 & 2 & $0.2$ \\
\hline 1 & 4 & 1 & $0.1$ \\
\hline 2 & 0 & 0 & $0.3$ \\
\hline 3 & 1 & $-1$ & $0.1$ \\
\hline
\end{tabular}
(This means, for example, that $p_{X, Y, Z}(1,-3,2)=0.1$.) Remember that you don't need to compute everything out-an answer like ""(0.01+0.02)/(0.03+2)"" is fine.
What is the conditional probability $p_{Y \mid X}(2 \mid 1)$?","$$
p_{Y \mid X}(2 \mid 1)=\frac{P((Y=2) \cap(X=1))}{P(X=1)}=\frac{0.2}{0.1+0.2+0.1}=0.5.
$$"
89,Mathematics,18.02,Calculus II,18.01,None,Midterm Exam 2,Critical Points,3,a,0.5625,Text,"Let $f(x, y)=x^2+x y+2 y^2-7 x$ be defined in $\mathbb{R}^2$. 
Find the critical points of $f$.",Expression,"There is one critical point: $(4,-1)$.","Let $f(x, y)=x^2+x y+2 y^2-7 x$ be defined in $\mathbb{R}^2$. 
For each critical point you found, determine whether it is a local minimum, local maximum or saddle point.","Since $f_{x x}=2>0$ and $f_{x x} f_{y y}-f_{x y}^2=2 \cdot 4-1^2=7>0$, the critical point is a local minimum.","Let $f(x, y)=x+4 y+\frac{2}{x y}$. 
Find the critical point(s) of $f(x, y)$.","There is one critical point at $(x, y)=(2,1 / 2)$.","Let $f(x, y)=x+4 y+\frac{2}{x y}$. 
Use the second-derivative test to test the critical point(s).","$f_{x x}=4 /\left(x^2 y\right), \quad f_{y y}=4 /\left(x y^3\right), \quad f_{x y}=f_{y x}=2 /\left(x^2 y^2\right)$
$A=f_{x x}(2,1 / 2)=1, \quad C=f_{y y}(2,1 / 2)=16, \quad B=f_{x y}(2,1 / 2)=2$
$\Rightarrow A C-B^2=12>0, A>0 \Rightarrow f$ has a relative minimum at $(2,1 / 2)$."
110,Mathematics,18.03,Differential Equations,None,18.02,Problem Set 9,Periodic Functions,5,c,0.08042895442,Text,"(Story time begins, again) Let's now make the connection between this finite dimensional problem and our ODE problem. Define
$$
\mathcal{V}=\{f(t): \mathbb{R} \rightarrow \mathbb{C}: f(t+2 \pi)=f(t), \text { and } f(t) \text { is infinitely differentiable }\}
$$
We have seen that $\mathcal{V}$ is a vector space over $\mathbb{C}$. If
$$
P(x)=a_{n} x^{n}+\cdots+a_{1} x+a_{0}
$$
is a polynomial with $a_{0}, a_{1}, \ldots, a_{n} \in \mathbb{R}$ and $a_{n} \neq 0$, then we can define a differential operator
$$
P(D) y=a_{n} y^{(n)}+\cdots+a_{1} y^{\prime}+a_{0} y .
$$
If $y \in \mathcal{V}$, then $P(D) y \in \mathcal{V}$, since the derivative of a infinitely differentiable $2 \pi$ periodic function is itself infinitely differentiable and $2 \pi$-periodic. Futhermore, $P(D)$ is a linear, in the sense that
$$
P(D)\left(c_{1} y_{1}+c_{2} y_{2}\right)=c_{1} P(D) y_{1}+c_{2} P(D) y_{2} .
$$
Thus, $P(D): \mathcal{V} \rightarrow \mathcal{V}$ is a linear map, which we can view as analogous to the linear map $A$ from part (a). (Story time ends, again). 
Show that $e^{i n t}$ is an eigenvector of $P(D)$ with eigenvalue $P($ in $)$.",Open,"We recall from the ERF formula that $P(D) e^{i n t}=P(i n) e^{i n t}$, which is exactly the condition that $e^{i n t}$ is an eigenvector with eigenvalue $P($ in $)$.","(Story time begins, again) We can now draw a parallel with the finite dimensional case discussed in part (a). Fourier's theorem says that $\left\{e^{i n t}: n \in \mathbb{Z}\right\}$ is a basis of $\mathcal{V}$. That is, any function $f \in \mathcal{V}$ can be written as
$$
f=\sum_{n=-\infty}^{\infty} c_{n} e^{i n t}
$$
where the coefficients can be calculated by
$$
c_{n}=\frac{1}{2 \pi} \int_{-\pi}^{\pi} f(t) e^{-i n t} d t .
$$
We can now adapt the argument from part (a).
Suppose that $P(i n) \neq 0$ for any $n \in \mathbb{Z}$. Find a solution to $P(D) y=f$.","We will use exponential response. In particular, we guess
$$
y(t)=\sum_{n=-\infty}^{\infty} d_{n} e^{i n t}
$$
for some $d_{n}$. Then a solution y satisfies
$$
P(D) y=\sum_{n=-\infty}^{\infty} P(i n) d_{n} e^{i n t}=f=\sum_{n=-\infty}^{\infty} c_{n} e^{i n t}
$$
For this to hold, we need that $P($ in $) d_{n}=c_{n}$ Because $P($ in $) \neq 0$ for any integer, we obtain such a solution by $d_{n}=c_{n} / P($ in $)$.","(Story time begins, again) We can now draw a parallel with the finite dimensional case discussed in part (a). Fourier's theorem says that $\left\{e^{i n t}: n \in \mathbb{Z}\right\}$ is a basis of $\mathcal{V}$. That is, any function $f \in \mathcal{V}$ can be written as
$$
f=\sum_{n=-\infty}^{\infty} c_{n} e^{i n t}
$$
where the coefficients can be calculated by
$$
c_{n}=\frac{1}{2 \pi} \int_{-\pi}^{\pi} f(t) e^{-i n t} d t .
$$
We can now adapt the argument from part (a).
As in part (b), if $P($ in $)=0$ for some set of integers, find a condition on $f$ guaranteeing the existence of a periodic solution to $P(D) y=f$.","As in part (b), we can do the above procedure to find a solution to $P(D) y=f$ exactly when $c_{n}=0$ for every integer $n$ such that $P(i n)=0$. In other words, there exists a solution when $f$ is in the span of the $e^{i n t}$ for which $P(i n)$ is not zero.","(Story time) In this problem we'll build some intuition, based on linear algebra, about why we can solve ODEs with periodic inputs using Fourier series and exponential response. Let's begin with a simple case (Story time ends).
Suppose $A: \mathbb{R}^{n} \rightarrow \mathbb{R}^{n}$ is a linear map, and suppose there are $n$ linearly independent eigenvectors $\vec{v}_{1}, \ldots, \vec{v}_{n}$ with non-zero eigenvalues
$$
A \vec{v}_{i}=\lambda_{i} \vec{v}_{i}, \quad \lambda_{i} \neq 0 .
$$
Suppose $\vec{x} \in \mathbb{R}^{n}$. Since $\vec{v}_{1}, \ldots, \vec{v}_{n}$ span $\mathbb{R}^{n}$ we can write
$$
\vec{x}=\sum_{i=1}^{n} c_{i} \vec{v}_{i} .
$$
Find the unique vector $\vec{y}$ such that $A \vec{y}=\vec{x}$.","Since $\vec{v}_{1}, \ldots, \vec{v}_{n}$ span $\mathbb{R}^{n}$ we may also write
$$
\vec{y}=\sum_{i=1}^{n} d_{i} \vec{v}_{i}
$$
for some $d_{i}$. Then $A \vec{y}=\sum_{i=1}^{n} d_{i} \lambda_{i} \vec{v}_{i}$. So if $A \vec{y}=\vec{x}$ then comparing coefficients of $\vec{v}_{i}$, there exists such $a \vec{y}$ if and only if for each $i$ there exists $d_{i}$ such that $d_{i} \lambda_{i}=c_{i} . A s \lambda_{i} \neq 0$, this implies $d_{i}=c_{i} / \lambda_{i}$, so
$$
\vec{y}=\sum_{i=1}^{n} \frac{c_{i}}{\lambda_{i}} \vec{v}_{i}
$$"
23,Mathematics,18.100B,Real Analysis,18.02,None,Problem Set 4,Completeness,5,nan,0.7142857143,Text,"Suppose that $X$ is a metric in which $d(x, y)$ is always a (nonnegative) integer. Show that $X$ is complete.",Open,"Set $\epsilon=1$ in the Cauchy property. There is an $N$ such that $d\left(x_{n}, x_{m}\right)<1$ for $m, n \geq N$. By assumption, this means that $d\left(x_{n}, x_{m}\right)=0$, so $x_{n}=x_{m}$, meaning that the sequence is eventually constant, $x_{n}=x$ for $n \geq N$. It is clear from the definition that $x_{n}$ converges to $x$.","Suppose $E \subset \mathbb{R}$ has the property that for every non-empty $B \subset E$ which is bounded, $\sup B$ and $\inf B$ are in $E$. Show that $E$ is closed with respect to the standard metric.","By a theorem in Rudin, any limit point of a set in a metric space is the limit of a sequence, the sequence in the set, $E$, the limit in the metric space. Thus if $x \in E^{\prime}$ is a limit point of $E$ then there is a sequence $x_{n} \in E$ with $x_{n} \rightarrow x$ in $\mathbb{R}$. Consider all $n \in \mathbb{N}$ such that $x_{n} \leq x$. If this is infinite, then there is a subsequence $x_{n_{j}}$ with $x_{n_{j}} \leq x$. If not then there is a subsequence $x_{n_{j}}$ with $x_{n_{j}}>x$. In either case, $x_{n_{j}} \rightarrow x$ so we can change notation and just assume that either $x_{n} \leq x$ or $x_{n}>x$ for all $n$. Let $B \subset E$ be the range of this sequence, this set is bounded, since any convergent sequence is bounded. Moreover in the first case $\sup B=x$ and in the second $\inf B=x$, since other wise the sequence could not converge to $x$. Thus $x \in E$ and hence $E^{\prime} \subset E$ and $E$ is necessarily closed.
Of course there are many variants of this. One can certainly avoid using sequences. For instance, suppose $x \in E^{\prime}$ but $x \notin E$. Then the sets $B(x, 1 / n) \cap E$ are all infinite, for $n \in \mathbb{N}$. Consider $(x, 1 / n) \cap E$; either this is infinite for all $n$ or else it is empty for large $n$, in which case $(x-1 / n, x) \cap E$ must be infinite for all $n$. So, we can choose either $x_{n} \in(x, x+1 / n)$ for all $n$ or $x_{n} \in(x-1 / n, x)$ for all $n$. Let $B$ be the subset of $E$ consisting of these choices, then $x=\inf B$ in the first case and $x=\sup B$ in the second case, and in both cases $B$ is bounded. Thus in fact $x \in E$ by the assumption, contradicting the assumption that $x \notin E$. Thus $E$ is closed.
I rather like the following proof from Yunjian Xu which neatly avoids the division into two pieces: Let $p$ be a limit point of $E$. Then for every $n \in \mathbb{N}$, $D_{n}=B(p, 1 / n) \cap E$ is a bounded, infinite subset of $E$, so by assumption $q_{n}=\sup D_{n} \in E$. This sequence is bounded since it lies in $B(p, 1)$; let $B$ be its range. This is again a bounded nonempty subset of $E$ and we claim $p=\inf B$, so $p \in E$. Indeed $q_{n}$ is a non-increasing (the sets are getting smaller) sequence which is bounded below so it converges to the infimum of its range, but since $\left|q_{n}-p\right| \leq 1 / n$ the limit must be $p$.
Main shortcomings: Not making sure that $x$ was the sup or inf of a chosen subset. Minor problems included assuming that just because $(x-1, x) \cap E$ was infinite then $x$ has to be the supremum $-E \cap(x-1, x) \subset\left(x-1, x-\frac{1}{2}\right)$ is a possibility (but then of course $x=\inf (x, x+1) \cap E)$.","Let $X$ be a metric space which is totally bounded. Show that there is a countable subset $B \subset X$ such that, for every point $l \in X$, there is a sequence in $B$ which converges to $l$.","For each $n \geq 1$, set $\varepsilon=\frac{1}{n}$. Since $X$ is totally bounded, there exists a finite set $F_{n}$ such that for each $x \in X$, there is a $y \in F_{n}$ with $d(x, y)<\varepsilon$. Let $B=\bigcup_{n \geq 1} F_{n}$. Since $B$ is a countable union of finite sets, it is countable.
Let $l \in X$ be given. For each $n \in \mathbb{N}$, let $x_{n}$ be a point in $F_{n}$ such that $d\left(x_{n}, k\right)<\frac{1}{n}$. Then $\left(x_{n}\right)$ is a sequence in $B$ converging to $l$.","Let $\left(x_{n}\right)$ and $\left(y_{n}\right)$ be Cauchy sequences in a metric space. Show that $d\left(x_{n}, y_{n}\right)$ converges.","Note that
$$
\begin{aligned}
d\left(x_{m}, y_{m}\right)-d\left(x_{n}, y_{n}\right) & \leq d\left(x_{m}, x_{n}\right)+d\left(x_{n}, y_{m}\right)-d\left(x_{n}, y_{n}\right) \\
& \leq d\left(x_{m}, x_{n}\right)+d\left(x_{n}, y_{n}\right)+d\left(y_{n}, y_{m}\right)-d\left(x_{n}, y_{n}\right) \\
& =d\left(x_{m}, x_{n}\right)+d\left(y_{n}, y_{m}\right)
\end{aligned}
$$
Let $\varepsilon>0$ be given. Since $\left(x_{i}\right)$ and $\left(y_{i}\right)$ are Cauchy, there exists $N$ large so that $d\left(x_{m}, x_{n}\right)<$ $\varepsilon / 2, d\left(y_{n}, y_{m}\right)<\varepsilon / 2$ for $n, m>N$. By the inequality displayed above, $d\left(x_{n}, y_{n}\right)$ is a Cauchy sequence in $\mathbb{R}$, hence converges.
Remark. [The parts designated ""remark"" here and below are not required for the solution of the problems; you can get full credit without discussing that material.] Since we do not know if our metric space is complete, we cannot apply Lemma $3.3$ (because our sequences may not converge)."
555,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Midterm Exam,Gradient Descent,10,a,0.25,Text,"Mark each of the following statements as true or false, and provide a correct - and brief - explanation for the validity of each of your answers:
The purpose of step_size_fn is to allow step sizes to increase with iteration index k, so that sgd and gd can converge faster.",Open,"False.
The purpose of step_size_fn is to allow step sizes to get smaller, so that sgd converges.","Mark each of the following statements as true or false, and provide a correct - and brief - explanation for the validity of each of your answers:
If $\theta=$ tho were luckily at a local minimum of the objective function, then the output of stochastic gradient descent sgd would always be $\theta$, independent of num_steps.","False.
For SGD, the update rule $\mathrm{th}=\mathrm{th}$ - step_size_fn $(k) * d J\left(\mathrm{X}_{j}, \mathrm{yj}\right.$, th) means that the gradient is dependent on which datapoint is chosen. In general, this gradient will be nonzero for some datapoints, even if the gradient is zero when averaged over all datapoints.","Mark each of the following statements as true or false, and provide a correct - and brief - explanation for the validity of each of your answers:
If $\theta=\operatorname{th} 0$ were luckily at a local minimum of the objective function, then the output of gradient descent gd would always be $\theta$, independent of num_steps.","True.
At a local minimum, $\mathrm{dJ}(\mathrm{th})=d J / d \theta=0$, so for gd the update rule $\mathrm{th}=\mathrm{th}$ - step_size_fn(k)*dJ(th) would reduce to $t h=\mathrm{th}$.","Mark each of the following statements as true or false, and provide a correct - and brief - explanation for the validity of each of your answers:
If $\theta=\operatorname{th} 0$ were luckily at a local maximum of the objective function, then the output of gradient descent gd would always be $\theta$, independent of num_steps.","True.
At a local maximum, $\mathrm{dJ}(\mathrm{th})=d J / d \theta=0$, so for gd the update rule $\mathrm{th}=\mathrm{th}$ - step_size_fn(k)*dJ(th) would reduce to $\mathrm{th}=\mathrm{th}$."
47,Mathematics,18.701,Algebra I,18.100B,None,Problem Set 7,Conjugation in the Symmetric Group,3,nan,0.8333333333,Text,Determine the class equations of $S_6$ and $A_6$.,Open,"The conjugacy classes in $S_{6}$ correspond to the partitions of 6 , which are listed below. Because we know the conjugacy classes, this is one case in which computing the orders of the conjugacy classes is simpler than computing their centralizers, though is is easy to make a mistake.
$$
\begin{aligned}
& C_{1}: 1+1+1+1+1+1 \\
& C_{2}: 2+1+1+1+1 \\
& C_{3}: 2+2+1+1 \\
& C_{4}: 2+2+2 \\
& C_{5}: 3+1+1+1 \\
& C_{6}: 3+2+1 \\
& C_{7}: 3+3 \\
& C_{8}: 4+1+1 \\
& C_{9}: 4+2 \\
& C_{10}: 5+1 \\
& C_{11}: 6
\end{aligned}
$$
The orders of these conjugacy classes are:
$$
\begin{aligned}
& \left|C_{1}\right|=1,\left|C_{2}\right|=15,\left|C_{3}\right|=45,\left|C_{4}\right|=15,\left|C_{5}\right|=40,\left|C_{6}\right|=120, \\
& \left|C_{7}\right|=40,\left|C_{8}\right|=90,\left|C_{9}\right|=90,\left|C_{10}\right|=144,\left|C_{11}\right|=120
\end{aligned}
$$
So the Class Equation of $S_{6}$ is
$$
720=1+15+45+15+40+120+40+90+90+144+120
$$
The conjugacy classes consisting of even permutations are $C_{1}, C_{3}, C_{5}, C_{7}, C_{9}$, and $C_{10}$. They have orders $1,45,40,40,90$, and 144 , respectively. We are supposed to know that, if $C_{S}(p)$ is the conjugacy class in $S_{6}$ of an even permutation $p$ there are two cases: If the centralizer $Z_{S}(p)$ of $p$ in $S_{6}$ contains an odd permutation, $C_{S}(p)$ is also the conjugacy class $C_{A}(p)$ of $p$ in $A_{6}$. If the centralizer $Z_{S}(p)$ contains only even permutations, then the class $C_{S}(p)$ splits into two conjugacy classes in $A_{6}$, each having a half of the order of $C_{S}(p)$. The first five conjugacy classes don't split. For example, the permutation $p=(123)(456)$ commutes with the odd permutation $q=(14)(25)(36)$. The last class splits, one reason being that 144 doesn't divide 360 .
The Class Equation of $A_{6}$ is
$$
360=1+45+40+40+90+72+72
$$",Determine the possible Class Equations for a group $G$ of order 8.,"The class of the identity has order 1 . The order of any conjugacy class divides 8 , so it can be 1,2 or 4 . Since 8 is even, there must be at least one other 1 in the class equation. Therefore the center $Z$ of $G$ is a nontrivial subgroup of order $>1$. Since $G$ isn't abelian, $|Z|$ can be 2 or 4 .
Let $x$ be an element of $G$ not in the center. Its centralizer $Z(x)$ isn't the whole group, but it contains $x$ and it also contains the center $Z$. Therefore $|Z|$ is a proper divisor of $|Z(x)|$ and $|Z(x)|$ is a proper divisor of $|G|=8$. It follows that $|Z|=2$ and $|Z(x)|=4$. So $|C(x)|=2$. The Class Equation has two 1s and the other classes have order 2. It is $8=1+1+2+2+2$. ",Verify the class equation (7.2.10) of $S L_2\left(\mathbb{F}_3\right)$.,"The order of $G$ is 168.
The characteristic polynomial of an element $A$ of $G$ can be any cubic polynomial whose constant term $\operatorname{det} A$ is $-1$, and $-1=+1$. There are four such polynomials: $t^{3}+t^{2}+t+1, t^{3}+1, t^{3}+t+1, t^{3}+t^{2}+1$.
Aside: I noticed that some of you had to work to compute the coefficient of $t$ in the characteristic polynomial. Here is the formula: The coefficient of $t$ in the characteristic polynomial of the $3 \times 3$ matrix $\left(a_{i j}\right)$, is the sum of the three symmetric $2 \times 2$ minors:
$$
\operatorname{det}\left(\begin{array}{ll}
a_{11} & a_{12} \\
a_{21} & a_{22}
\end{array}\right)+\operatorname{det}\left(\begin{array}{ll}
a_{11} & a_{13} \\
a_{31} & a_{33}
\end{array}\right)+\operatorname{det}\left(\begin{array}{ll}
a_{22} & a_{23} \\
a_{32} & a_{33}
\end{array}\right)
$$
The first of the polynomials listed above has $t=1$ as a triple root: $(t+1)^{3}=t^{3}+t^{2}+t+1$ modulo 2. There are three classes of matrices with this characteristic polynomial, including the identity. The other classes are represented by the matrices
$$
A_{1}=\left(\begin{array}{ccc}
1 & 1 & \cdot \\
\cdot & 1 & \cdot \\
\cdot & \cdot & 1
\end{array}\right) \quad \text { and } \quad A_{2}=\left(\begin{array}{ccc}
1 & 1 & \cdot \\
\cdot & 1 & 1 \\
\cdot & \cdot & 1
\end{array}\right)
$$
The centralizer of $A_{1}$ is the same as that of the simpler matrix $e_{12}=I+A_{1}$. We compute the centralizer of $e_{12}$ by solving the equation $P e_{12}=e_{12} P$ with indeterminate $P$:
$$
\left(\begin{array}{lll}
a & b & c \\
d & e & f \\
g & h & i
\end{array}\right)\left(\begin{array}{lll}
. & 1 & . \\
. & . & . \\
. & . & .
\end{array}\right)=\left(\begin{array}{lll}
\cdot & a & . \\
\cdot & d & . \\
\cdot & g & .
\end{array}\right) \quad \text { and }\left(\begin{array}{lll}
. & 1 & \cdot \\
\cdot & . & . \\
\cdot & . & .
\end{array}\right)\left(\begin{array}{lll}
a & b & c \\
d & e & f \\
g & h & i
\end{array}\right)=\left(\begin{array}{lll}
d & e & f \\
\cdot & \cdot & \cdot \\
\cdot & . & .
\end{array}\right)
$$
If $P$ commutes with $e_{12}, d=f=g=0$ and $a=e$. So $P$ has the form
$$
\left(\begin{array}{ccc}
a & b & c \\
\cdot & a & \cdot \\
\cdot & h & i
\end{array}\right)
$$
Since $P$ must be invertible, $a=i=1$, while $b, c, h$ can be arbitrary elements of $\mathbb{F}_{2}$. The centralizer $Z\left(e_{12}\right)=Z\left(A_{1} n\right)$ has order 8, and the conjugacy class $C\left(A_{1}\right)$ has order $168 / 8=21$.
A similar computation for the matrix $A_{2}$ shows that its centralizer consists of invertible matrices of the form
$$
P=\left(\begin{array}{ccc}
a & b & c \\
\cdot & a & b \\
\cdot & \cdot & a
\end{array}\right)
$$
Here $a$ must be 1, while $b$ and $c$ can be arbitrary. The centralizer of $A_{2}$ has order 4 and the conjugacy class $C\left(A_{2}\right)$ has order $268 / 4=42$.
The cyclic permutation matrix
$$
B=\left(\begin{array}{ccc}
\cdot & \cdot & 1 \\
1 & \cdot & \cdot \\
\cdot & 1 & \cdot
\end{array}\right)
$$
is a good choice for a matrix with characteristic polynomial $t^{3}+1$. Its centralizer consists of the three matrices $I, B, B^{2}$. So $Z(B)$ has order 3 and $C(B)$ has order 56. The matrices for the two remaining characteristic polynomials aren't quite so simple. One matrix with characteristic polynomial $t^{3}+t^{2}+1$ is
$$
D=\left(\begin{array}{ccc}
1 & 1 & . \\
1 & . & 1 \\
\cdot & 1 & \cdot
\end{array}\right)
$$
and $E=I+D$ has characteristic polynomial $t^{3}+t+1$. The centralizers of $D$ and $E$ are the same, so their conjugacy classes have the same order. We compute the centralizer of $D$:
$$
\left(\begin{array}{lll}
a & b & c \\
d & e & f \\
g & h & i
\end{array}\right)\left(\begin{array}{lll}
1 & 1 & \cdot \\
1 & \cdot & 1 \\
\cdot & 1 & .
\end{array}\right)=\left(\begin{array}{ccc}
a+b & a+c & b \\
d+e & d+f & e \\
g+h & g+i & h
\end{array}\right),\left(\begin{array}{ccc}
1 & 1 & \cdot \\
1 & \cdot & 1 \\
\cdot & 1 & .
\end{array}\right)\left(\begin{array}{ccc}
a & b & c \\
d & e & f \\
g & h & i
\end{array}\right)=\left(\begin{array}{ccc}
a+d & b+e & c+f \\
a+g & b+h & c+i \\
d & e & f
\end{array}\right)
$$
Equating these matrices, one finds that an element in the centralizer must have the form
$$
P=\left(\begin{array}{ccc}
a & b & c \\
b & a+b+c & b+c \\
c & b+c & a+b
\end{array}\right)
$$
The determinant is
$$
\operatorname{det} P=a^{3}+b^{3}+c^{3}+a b^{2}+b c^{2}+c a^{2}+a b c
$$
There are 8 such matrices, and all of them except 0 have determinant 1 . The centralizer of $D$ consists of the 7 nonzero matrices. They happen to be the powers of $D$:
$$
\begin{aligned}
& D^{1}=\left(\begin{array}{lll}1 & 1 & \cdot \\1 & . & 1 \\. & 1 & .\end{array}\right) \quad, \quad D^{2}=\left(\begin{array}{lll}\cdot & 1 & 1 \\1 & . & . \\1 & . & 1\end{array}\right) \quad, \quad D^{3}=\left(\begin{array}{lll}1 & 1 & 1 \\1 & 1 & . \\1 & . & .\end{array}\right) \\
& D^{4}=\left(\begin{array}{ccc}\cdot & . & 1 \\\cdot & 1 & 1 \\1 & 1 & .\end{array}\right) \quad, \quad D^{5}=\left(\begin{array}{ccc}\cdot & 1 & \cdot \\1 & 1 & 1 \\\cdot & 1 & 1\end{array}\right)=E, \quad D^{6}=\left(\begin{array}{ccc}1 & \cdot & 1 \\\cdot & \cdot & 1 \\1 & 1 & 1\end{array}\right) \quad, \quad D^{7}=I
\end{aligned}
$$
So the Class Equation of $G L_{3}\left(\mathbb{F}_{2}\right)$ is
$$
168=1+21+42+56+24+24
$$
Note that there are rather few conjugacy classes. One can use this Class Equation to show that $G L_{2}\left(\mathbb{F}_{2}\right)$ is a simple group by verifying that the only sums of elements on the right side of the equation that includes 1 and that divides 168 are the trivial sums: 1 and 168 . The group $G L_{2}\left(\mathbb{F}_{2}\right)$ is the second smallest simple group, apart from the groups of prime order. The smallest nonabelian simple group is $I \approx A_{5}$. ",Prove Example 6.3 from the class.,"Let $\alpha$ be an irrational number. Let $y_{n} \in \mathbb{R}$ be a sequence converging to $\alpha$. We'll prove that $f\left(y_{n}\right)$ converges to $f(\alpha)=0$. Let $\varepsilon>0$ be given. Let $M$ be a large integer so that $\frac{1}{M}<\varepsilon$. Let $N$ be a large integer so that $y_{n} \notin\left\{x_{1}, \ldots, x_{M}\right\}$ for every $n>N$ (we can do this since we're aiming to avoid a finite set). Then for any $n>N$, either $y_{n}$ is irrational, so $f\left(y_{n}\right)=0$, or $y_{n}=x_{k}, k>M$, so $f\left(y_{n}\right)=1 / k<\varepsilon$. Therefore $\left|f\left(y_{n}\right)\right|<\varepsilon$ for every $n>N$. It follows that $f$ is continuous at $\alpha$ (we used Definition 6.1).
Let $\beta=x_{n}$ be a rational number. Since $\mathbb{Q}$ is dense in $\mathbb{R}, \sqrt{2}+\mathbb{Q}$ is also dense in $\mathbb{R}$. It follows that for every $\delta>0$, the open ball $(\beta-\delta, \beta+\delta)$ contains an irrational number $\gamma$. Therefore, setting $\varepsilon=\frac{1}{n}$ in Definition $6.4$, there does not exist $\delta>0$ such that $|f(\beta)-f(y)|<\frac{1}{n}$ for any $y \in B(\beta, \delta)$. Hence $f$ is discontinuous at all rational numbers."
264,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Midterm Exam,Symbolic Representations,4,bv,0.4,Text,"Let's continue the theme of keys and rooms, but this time writing operator descriptions. Use the following predicate definitions, with the obvious interpretations when $\mathrm{k}$ is a key and $\mathrm{r}$ is a room.
(opens ?k ?r)
(connected ?r1 ?r2)
(unlocked ?r)
(robot-in ?r)
(robot-holding ?k)
(in ?k ?r)
Assume there is one more operator
(:action pick-up
:parameters (?r ?k)
:precondition (and (robot-in ?r)
(in ?k ?r))
:effect (and (robot-holding ?k) (not (in ?k ?r))))
Here is an initial state:
(connected R0 R1) (connected R1 R2) (connected R2 R3)
(connected R1 R0) (connected R2 R1) (connected R3 R2)
(unlocked R1) (unlocked R2) (unlocked R3)
(robot-in R1) (opens K0 R0) (in K0 R3)
And goal: (and (robot-in R0) (unlocked R0) (robot-holding K0))
We want to base a heuristic on a relaxed plan graph for this problem.
What is the value of $H_{\text{max}}$ for this goal?",Numerical,5,"Let's continue the theme of keys and rooms, but this time writing operator descriptions. Use the following predicate definitions, with the obvious interpretations when $\mathrm{k}$ is a key and $\mathrm{r}$ is a room.
(opens ?k ?r)
(connected ?r1 ?r2)
(unlocked ?r)
(robot-in ?r)
(robot-holding ?k)
(in ?k ?r)
Assume there is one more operator
(:action pick-up
:parameters (?r ?k)
:precondition (and (robot-in ?r)
(in ?k ?r))
:effect (and (robot-holding ?k) (not (in ?k ?r))))
Here is an initial state:
(connected R0 R1) (connected R1 R2) (connected R2 R3)
(connected R1 R0) (connected R2 R1) (connected R3 R2)
(unlocked R1) (unlocked R2) (unlocked R3)
(robot-in R1) (opens K0 R0) (in K0 R3)
And goal: (and (robot-in R0) (unlocked R0) (robot-holding K0))
We want to base a heuristic on a relaxed plan graph for this problem.
What is the value of $H_{\text{add}}$ for this goal?",12,"Let's continue the theme of keys and rooms, but this time writing operator descriptions. Use the following predicate definitions, with the obvious interpretations when $\mathrm{k}$ is a key and $\mathrm{r}$ is a room.
(opens ?k ?r)
(connected ?r1 ?r2)
(unlocked ?r)
(robot-in ?r)
(robot-holding ?k)
(in ?k ?r)
Assume there is one more operator
(:action pick-up
:parameters (?r ?k)
:precondition (and (robot-in ?r)
(in ?k ?r))
:effect (and (robot-holding ?k) (not (in ?k ?r))))
Here is an initial state:
(connected R0 R1) (connected R1 R2) (connected R2 R3)
(connected R1 R0) (connected R2 R1) (connected R3 R2)
(unlocked R1) (unlocked R2) (unlocked R3)
(robot-in R1) (opens K0 R0) (in K0 R3)
And goal: (and (robot-in R0) (unlocked R0) (robot-holding K0))
We want to base a heuristic on a relaxed plan graph for this problem.
First, what is the shortest solution for this problem? Please list the actions.","(move R1 R2) (move R2 R3)
(pick-up K0) (move R3 R2) (move R2 R1)
(unlock R1 R0 K0) (move R1 R0)","Let's continue the theme of keys and rooms, but this time writing operator descriptions. Use the following predicate definitions, with the obvious interpretations when $\mathrm{k}$ is a key and $\mathrm{r}$ is a room.
(opens ?k ?r)
(connected ?r1 ?r2)
(unlocked ?r)
(robot-in ?r)
(robot-holding ?k)
(in ?k ?r)
Assume there is one more operator
(:action pick-up
:parameters (?r ?k)
:precondition (and (robot-in ?r)
(in ?k ?r))
:effect (and (robot-holding ?k) (not (in ?k ?r))))
Here is an initial state:
(connected R0 R1) (connected R1 R2) (connected R2 R3)
(connected R1 R0) (connected R2 R1) (connected R3 R2)
(unlocked R1) (unlocked R2) (unlocked R3)
(robot-in R1) (opens K0 R0) (in K0 R3)
And goal: (and (robot-in R0) (unlocked R0) (robot-holding K0))
We want to base a heuristic on a relaxed plan graph for this problem.
At what level in the RPG is the fluent (robot-holding K0)?",3
194,Mathematics,18.01,Calculus I,None,None,Problem Set 5,Integrals and Sums,4,d,0.06335797254,Text,"Remember that $m$ ! means $m$ times $m-1$ times ... times 2 times 1 . For instance $4 !=4 \cdot 3 \cdot 2 \cdot 1=24$. Factorials play an important role in probability, as we will discuss later in the course. It's useful to estimate the value of $m$ !, for instance - about how big is 100!? We will start thinking about this problem here, and we will continue in the next weeks.
Logarithms are a helpful tool in this problem. We know that $\ln (a b)=\ln a+\ln b$. So $\ln (4 !)=\ln 4+\ln 3+\ln 2+\ln 1$.
Approximate the number of digits in 100! (when it's written in base 10, the way we usually write numbers). For reference $\log _{10} e=.43 \ldots$ Is the number of digits closest to 137 or 157 or 177 ? Explain your reasoning.",Numerical,"The number of digits $N$ in $Q$ is approximately $\log _{10} Q$, which is $\ln Q / \ln 10$. Using $\ln 100 ! \approx 100 \ln 100-100$ (from the preceding part),
$$
N \approx \frac{100 \ln 100-100}{\ln 10} .
$$
In the first term, the $\ln 100 / \ln 10$ is just $\log _{10} 100$, which is 2 . The second term, $100 / \ln 10$ is $100 \log _{10} e$, which is roughly 43 . Thus,
$$
N \approx 100 \times 2-43=157 .
$$","Remember that $m$ ! means $m$ times $m-1$ times ... times 2 times 1 . For instance $4 !=4 \cdot 3 \cdot 2 \cdot 1=24$. Factorials play an important role in probability, as we will discuss later in the course. It's useful to estimate the value of $m$ !, for instance - about how big is 100!? We will start thinking about this problem here, and we will continue in the next weeks.
Logarithms are a helpful tool in this problem. We know that $\ln (a b)=\ln a+\ln b$. So $\ln (4 !)=\ln 4+\ln 3+\ln 2+\ln 1$.
Write a sum for $\ln (100$!).",$\ln 100 !=\sum_{k=1}^{100} \ln k$.,"Remember that $m$ ! means $m$ times $m-1$ times ... times 2 times 1 . For instance $4 !=4 \cdot 3 \cdot 2 \cdot 1=24$. Factorials play an important role in probability, as we will discuss later in the course. It's useful to estimate the value of $m$ !, for instance - about how big is 100!? We will start thinking about this problem here, and we will continue in the next weeks.
Logarithms are a helpful tool in this problem. We know that $\ln (a b)=\ln a+\ln b$. So $\ln (4 !)=\ln 4+\ln 3+\ln 2+\ln 1$.
Approximate this sum by an integral.",$\int_{1}^{100} \ln x d x$.,"Remember that $m$ ! means $m$ times $m-1$ times ... times 2 times 1 . For instance $4 !=4 \cdot 3 \cdot 2 \cdot 1=24$. Factorials play an important role in probability, as we will discuss later in the course. It's useful to estimate the value of $m$ !, for instance - about how big is 100!? We will start thinking about this problem here, and we will continue in the next weeks.
Logarithms are a helpful tool in this problem. We know that $\ln (a b)=\ln a+\ln b$. So $\ln (4 !)=\ln 4+\ln 3+\ln 2+\ln 1$.
Evaluate the integral.","From Problem 3, it's $x \ln x-x$ evaluated between 1 and 100, which is
$$
(100 \ln 100-100)-(1 \ln 1-1)=100 \ln 100-99 .
$$"
115,Mathematics,18.02,Calculus II,18.01,None,Midterm Exam 4,Flux,3,d,0.5625,Text,"Let $\vec{F}=x z \hat{i}+y z \hat{j}-\left(z^2+1\right) \hat{k}$. Let $H$ be the solid hemisphere of radius 1 , consisting of the half of the solid sphere of radius 1 centered at the origin and above the $x y$-plane. Let $S$ be the surface of $H$. So $S$ includes the curved top surface $T$ and the flat bottom surface $B$. 
Use the results to calculate the flux of $\vec{F}$ through $T$ (not by evaluating the surface integral directly). Assume that $T$ is oriented upward. ",Numerical,$0-\pi=-\pi$.,"Let $\vec{F}=x z \hat{i}+y z \hat{j}-\left(z^2+1\right) \hat{k}$. Let $H$ be the solid hemisphere of radius 1 , consisting of the half of the solid sphere of radius 1 centered at the origin and above the $x y$-plane. Let $S$ be the surface of $H$. So $S$ includes the curved top surface $T$ and the flat bottom surface $B$. 
Calculate the flux of $\vec{F}$ through $B$ by any method. Assume $B$ is oriented downward.",$\oiint_B \vec{F} \cdot \vec{n} d S=1 \cdot \operatorname{Area}(B)=\pi$.,"Let $\vec{F}=x z \hat{i}+y z \hat{j}-\left(z^2+1\right) \hat{k}$. Let $H$ be the solid hemisphere of radius 1 , consisting of the half of the solid sphere of radius 1 centered at the origin and above the $x y$-plane. Let $S$ be the surface of $H$. So $S$ includes the curved top surface $T$ and the flat bottom surface $B$. 
Calculate the flux of $\vec{F}$ through $S$ using the divergence theorem, by evaluating the triple integral (not the surface integral). Assume $S$ is oriented outward.","$$
\oiint_S \vec{F} \cdot d \vec{S}=\iiint_S \vec{\nabla} \cdot \vec{F} d V=0 .
$$","Let $\vec{F}=x z \hat{i}+y z \hat{j}-\left(z^2+1\right) \hat{k}$. Let $H$ be the solid hemisphere of radius 1 , consisting of the half of the solid sphere of radius 1 centered at the origin and above the $x y$-plane. Let $S$ be the surface of $H$. So $S$ includes the curved top surface $T$ and the flat bottom surface $B$. 
Compute the divergence $\vec{\nabla} \cdot \vec{F}$.","$$
\vec{\nabla} \cdot \vec{F}=\partial_x(x z)+\partial_y(y z)+\partial_z\left(-\left(z^2+1\right)\right)=z+z-2 z=0 .
$$"
33,Mathematics,18.2,Principles of Discrete Applied Mathematics,None,18.C06,Problem Set 6,Zero-Sum Game,3,a,0.6790123457,Text,"Consider the zero-sum game with the following payoff matrix:
$$
C=\left(\begin{array}{ccc}
0 & 2 & -4 \\
-2 & 0 & 3 \\
4 & -3 & 0
\end{array}\right)
$$
(Notice that this matrix is square (both players have the same number of strategies) and $C$ is skew-symmetric: $C=-C^{T}$.)
Write the linear programs associated with both players.",Expression,"The linear program for player $\mathcal{C}$ is given by
$$
\begin{aligned}
\max & w \\
\text { s.t. } & w \leq e_{1}^{T} C y=2 y_{2}-4 y_{3} \\
& w \leq e_{2}^{T} C y=-2 y_{1}+3 y_{3} \\
& w \leq e_{3}^{T} C y=4 y_{1}-3 y_{2} \\
& y_{1}+y_{2}+y_{3}=1 \\
& y_{1}, y_{2}, y_{3} \geq 0 .
\end{aligned}
$$
The linear program for player $\mathcal{R}$ is given by
$$
\begin{aligned}
\min & z \\
\text { s.t. } & z \geq x^{T} C e_{1}=-2 x_{2}+4 x_{3} \\
& z \geq x^{T} C e_{2}=2 x_{1}-3 x_{3} \\
& z \geq x^{T} C e_{3}=-4 x_{1}+3 x_{2} \\
& x_{1}+x_{2}+x_{3}=1 \\
& x_{1}, x_{2}, x_{3} \geq 0 .
\end{aligned}
$$","Consider the zero-sum game with the following payoff matrix:
$$
C=\left(\begin{array}{ccc}
0 & 2 & -4 \\
-2 & 0 & 3 \\
4 & -3 & 0
\end{array}\right)
$$
(Notice that this matrix is square (both players have the same number of strategies) and $C$ is skew-symmetric: $C=-C^{T}$.)
Find the optimal strategies for both players.","From the previous part, we know that $x^{*}=y^{*}$, so it suffices to just look at the linear program for player $\mathcal{C}$. Since $w^{*}=z^{*}=0$, we have that
$$
\begin{aligned}
& 0 \leq 2 y_{2}-4 y_{3} \\
& 0 \leq-2 y_{1}+3 y_{3} \\
& 0 \leq 4 y_{1}-3 y_{2} \\
& y_{1}+y_{2}+y_{3}=1 \\
& y_{1}, y_{2}, y_{3} \geq 0 .
\end{aligned}
$$
Rearranging the terms of the first three inequalities and scaling appropriately, we get
$$
\begin{aligned}
& 3 y_{2} \geq 6 y_{3} \\
& 6 y_{3} \geq 4 y_{1} \\
& 4 y_{1} \geq 3 y_{2} .
\end{aligned}
$$
For all these inequalities to hold, we must have $4 y_{1}=3 y_{2}=6 y_{3}$, so $\left(y_{1}, y_{2}, y_{3}\right)$ is a multiple of $(3,4,2)$. From the condition $y_{1}+y_{2}+y_{3}=1$, we get that $\left(y_{1}, y_{2}, y_{3}\right)=$ $(1 / 3,4 / 9,2 / 9)$. Thus, we get that $x^{*}=y^{*}=(1 / 3,4 / 9,2 / 9)$.","Consider the zero-sum game with the following payoff matrix:
$$
C=\left(\begin{array}{ccc}
0 & 2 & -4 \\
-2 & 0 & 3 \\
4 & -3 & 0
\end{array}\right)
$$
(Notice that this matrix is square (both players have the same number of strategies) and $C$ is skew-symmetric: $C=-C^{T}$.)
Show that these linear programs are equivalent in the sense that if $x$ is a mixed strategy for the row player with value $z$ then $y=x$ is a mixed strategy for the column player of value $w=-z$. Prove that $z^{*}=w^{*}=0$.","If $(x, z)$ is feasible for player $\mathcal{R}$ 's linear program, then $z \geq x^{T} C e_{i}$ for $i=1,2,3$. Note that
$$
e_{i}^{T} C x=-e_{i}^{T} C^{T} x=-x^{T} C e_{i}
$$
so we also have $-z \leq e_{i}^{T} C x$. Thus, $(x,-z)$ is feasible for player $\mathcal{C}$ 's linear program. One similarly proves the other direction. This tells us that $\left(y^{*},-w^{*}\right)$ is feasible for the linear program for player 2 , so $-w^{*} \geq z$. We also get that $\left(x^{*},-z^{*}\right)$ is feasible for the linear program for player 1 , so $w^{*} \geq-z^{*}$. Combined, we get that $w^{*}=-z^{*}$. Von Neumann's minimax theorem tells us that $w^{*}=z^{*}$ so we see that $w^{*}=z^{*}=0$.","Suppose we are playing poker and there are $n$ players sitting around a circular table. Player $i$ has $x_{i}$ chips in front of her. Now suppose everyone takes their pile, divides it in half, and gives half to the player on their left and half to the player on their right. At the end player $i$ has $y_{i}$ chips. (No need to worry about whether these are integers or not, and it won't matter for what we'll ask you.)
For both $n=4$ and $n=5$ write down a linear system that describes the problem of finding the $x_{i}$ 's from the $y_{i}$ 's.","We can write the systems in matrix form as follows.
For $n=4$:
$$
\left[\begin{array}{llll}
0 & 1 & 0 & 1 \\
1 & 0 & 1 & 0 \\
0 & 1 & 0 & 1 \\
1 & 0 & 1 & 0
\end{array}\right]\left[\begin{array}{l}
x_{1} \\
x_{2} \\
x_{3} \\
x_{4}
\end{array}\right]=2\left[\begin{array}{l}
y_{1} \\
y_{2} \\
y_{3} \\
y_{4}
\end{array}\right].
$$
For $n=5$:
$$
\left[\begin{array}{lllll}
0 & 1 & 0 & 0 & 1 \\
1 & 0 & 1 & 0 & 0 \\
0 & 1 & 0 & 1 & 0 \\
0 & 0 & 1 & 0 & 1 \\
1 & 0 & 0 & 1 & 0
\end{array}\right]\left[\begin{array}{l}
x_{1} \\
x_{2} \\
x_{3} \\
x_{4} \\
x_{5}
\end{array}\right]=2\left[\begin{array}{l}
y_{1} \\
y_{2} \\
y_{3} \\
y_{4} \\
y_{5}
\end{array}\right].
$$"
11,EECS,6.102,Elements of Software Construction,6.101,None,Problem Set 1,Flashcards,1,e,2.4,Text,"Have you ever used flashcards – maybe to improve your vocabulary either in your native language or in a foreign language you want to learn? A flashcard has two sides, a front and a back, which might be a vocabulary word and its meaning. To use a flashcard for learning practice, you look at the front and try to recall what’s on the back, then look at the back to see if you were right. Flashcards are an example of active learning, which is much more effective than passive reading or listening.
A flashcard system is a scheduling algorithm that decides when to practice each flashcard for the most efficient learning. Flashcard systems take advantage of spaced repetition, the principle that we learn more durably when practice is spaced out over time rather than crammed together, and furthermore that the rate of forgetting something is slower the more we have practiced it, so that the spacing between practice can increase as a concept or skill becomes more learned.
This problem set uses a spaced repetition flashcard algorithm that we will call the Modified-Leitner system, because it is inspired by the Leitner system but differs in the details. In a Leitner system, flashcards are grouped into numbered learning buckets. Low-numbered buckets contain flashcards that are less well-learned, so low-numbered buckets are scheduled for practice more often than high-numbered buckets. As a flashcard receives more and more successful practice, it moves up to higher buckets, until finally reaching a retired bucket (e.g., bucket 5). Flashcards in the retired bucket are considered well-enough learned not to need practice anymore.
Here is the specific behavior of our Modified-Leitner algorithm:
• A new card, before its first practice, is assumed to be in bucket 0.
• On day n of the learning process, the user collects all the buckets that are scheduled for practice that day, and practices every card found in those buckets.
  • Cards in the retired bucket are not scheduled for practice.
  • Bucket 0 cards are practiced every day, bucket 1 cards every two days, bucket 2 cards every four days, and so forth. In general, bucket i is practiced every 2i days.
  • The user is of course free to practice new cards, or unscheduled cards of their own choice, or to practice cards repeatedly.
• Whenever the user practices a flashcard:
  • if they get the card wrong – they are unable to correctly recall what’s on the back of the card – then the card is put back in bucket 0.
  • if they find the card easy – getting it right without much mental effort – then the card moves up from bucket i to bucket i+1 (unless the card is already in the retired bucket).
  • if they find the card hard – getting it right but only with effort – then the card moves down to bucket i-1 (unless the card is already in bucket 0).
This problem set consists of a group of functions that can be used to implement the Modified-Leitner flashcard system:
• toBucketSets() converts a Map representation of learning buckets into a Array-of-Set representation
• getBucketRange() finds the range of buckets that contain flashcards, as a rough measure of progress
• practice() selects cards to practice on a particular day
• update() updates a card’s bucket number after a practice trial
• deduplicate() consolidates flashcards by combining redundant cards
In addition to implementing these functions yourself, you will also write a test suite for each function, carefully following the function’s spec. Your test suites will be graded in part by running them against various staff implementations of the function, some of which obey the spec and some which don’t. A good test suite should pass the good implementations and reject the bad ones.
You are also asked to change exactly one of these function specs, deduplicate(). Its current spec is very weak, so you will strengthen the spec, and test and implement your stronger spec. Unlike your test suites for other functions, your deduplicate() tests won’t be run against good and bad staff implementations, because you’ll be changing the spec.
Implement deduplicate().
deduplicate
deduplicate(card1: Flashcard, card2: Flashcard): false | Flashcard
Deduplicate a pair of flashcards.
Requires that card1 and card2 are English word-definition flashcards, where the front is a single English word and the back defines the word. Two cards in the English word-definition domain are ""redundant"" if and only if their fronts are identical.
Parameters
card1: Flashcard
a flashcard
card2: Flashcard
a flashcard
Returns false | Flashcard
false if card1 and card2 are not ""redundant"" as defined above, otherwise a card that contains all the information from the redundant card1 and card2 that is relevant to learning.",Programming,"/**
 * Deduplicate a pair of flashcards.
 * 
 * Requires that card1 and card2 are English word-definition flashcards, 
 * where the front is a single English word and the back defines the word.
 * 
 * --- Second domain is 12 x 12 times tables ---
 * A card in the times table domain must have a front with a string 
 * containing exactly two integers in [0, 12] separated from any other characters
 * by at least one space on either side.
 * It must also have a back containing exactly one integer that is the product
 * of the front two integers.
 * Any other number of integers will be considered an English word-definition.
 * 
 * Two cards in the English word-definition domain are ""redundant"" 
 * if and only if their fronts are identical.
 * 
 * Two cards in the times-tables definition domain are ""redundant"" 
 * if their fronts are identical or if their fronts contain the same 
 * two integers in the same order. (e.g. ""10 x 8"" = ""10 times 8"")
 * 
 * If two english cards are redundant,
 * return a card with same front as the input, but a back
 * made of a string containing the first card's back, followed 
 * by a "" |OR| "", followed by the back of the other card.
 * 
 * If two times-tables cards are redundant, 
 * return a card with a front in the format ""num1 x num2""
 * and a back with the single integer representing the result
 * as a string (e.g. front: ""10 x 8"", back: ""80"")
 * 
 * @param card1 a flashcard
 * @param card2 a flashcard
 * @returns false if `card1` and `card2` are not ""redundant"" as defined above,
 *          otherwise a card that with front and back as defined above.
 */
export function deduplicate(card1: Flashcard, card2: Flashcard): false|Flashcard {
    const card1Ints: Array<number> | false = isTimesTable(card1);
    const card2Ints: Array<number> | false = isTimesTable(card2);
    if (card1Ints === false || card2Ints === false) {
        if (card1.front === card2.front) {
            return Flashcard.make(card1.front, card1.back + ' |OR| ' + card2.back);
        } else {
            return false;
        }
    } else {
        if (card1Ints[0] === card2Ints[0] && card1Ints[1] === card2Ints[1]) {
            return Flashcard.make(card1Ints[0].toString() + "" x "" + card1Ints[1].toString(), (card1Ints[0] * card1Ints[1]).toString());
        }
        return false;
    }
}

/**
 * Determine if card is a timesTable card or not
 * 
 * @param   card    flashcard to check
 * @returns false if card is not a timestable card as defined
 *          in dedpulicate otherwise returns the numbers 
 *          of the card in the order they appear from left
 *          to right.
 */
function isTimesTable(card: Flashcard): false|Array<number> {
    const cardSplit: Array<string> = card.front.split("" "");
    const cardInts: Array<number> = [];
    for (const segment of cardSplit) {
        const potentialInt = Number(segment);
        if (!isNaN(potentialInt)  && potentialInt % 1 === 0) {
            cardInts.push(potentialInt);
        }
    }
    const expectedNumInts = 2;
    if (cardInts.length === expectedNumInts) {
        return cardInts;
    }

    return false;
}","Have you ever used flashcards – maybe to improve your vocabulary either in your native language or in a foreign language you want to learn? A flashcard has two sides, a front and a back, which might be a vocabulary word and its meaning. To use a flashcard for learning practice, you look at the front and try to recall what’s on the back, then look at the back to see if you were right. Flashcards are an example of active learning, which is much more effective than passive reading or listening.
A flashcard system is a scheduling algorithm that decides when to practice each flashcard for the most efficient learning. Flashcard systems take advantage of spaced repetition, the principle that we learn more durably when practice is spaced out over time rather than crammed together, and furthermore that the rate of forgetting something is slower the more we have practiced it, so that the spacing between practice can increase as a concept or skill becomes more learned.
This problem set uses a spaced repetition flashcard algorithm that we will call the Modified-Leitner system, because it is inspired by the Leitner system but differs in the details. In a Leitner system, flashcards are grouped into numbered learning buckets. Low-numbered buckets contain flashcards that are less well-learned, so low-numbered buckets are scheduled for practice more often than high-numbered buckets. As a flashcard receives more and more successful practice, it moves up to higher buckets, until finally reaching a retired bucket (e.g., bucket 5). Flashcards in the retired bucket are considered well-enough learned not to need practice anymore.
Here is the specific behavior of our Modified-Leitner algorithm:
• A new card, before its first practice, is assumed to be in bucket 0.
• On day n of the learning process, the user collects all the buckets that are scheduled for practice that day, and practices every card found in those buckets.
  • Cards in the retired bucket are not scheduled for practice.
  • Bucket 0 cards are practiced every day, bucket 1 cards every two days, bucket 2 cards every four days, and so forth. In general, bucket i is practiced every 2i days.
  • The user is of course free to practice new cards, or unscheduled cards of their own choice, or to practice cards repeatedly.
• Whenever the user practices a flashcard:
  • if they get the card wrong – they are unable to correctly recall what’s on the back of the card – then the card is put back in bucket 0.
  • if they find the card easy – getting it right without much mental effort – then the card moves up from bucket i to bucket i+1 (unless the card is already in the retired bucket).
  • if they find the card hard – getting it right but only with effort – then the card moves down to bucket i-1 (unless the card is already in bucket 0).
This problem set consists of a group of functions that can be used to implement the Modified-Leitner flashcard system:
• toBucketSets() converts a Map representation of learning buckets into a Array-of-Set representation
• getBucketRange() finds the range of buckets that contain flashcards, as a rough measure of progress
• practice() selects cards to practice on a particular day
• update() updates a card’s bucket number after a practice trial
• deduplicate() consolidates flashcards by combining redundant cards
In addition to implementing these functions yourself, you will also write a test suite for each function, carefully following the function’s spec. Your test suites will be graded in part by running them against various staff implementations of the function, some of which obey the spec and some which don’t. A good test suite should pass the good implementations and reject the bad ones.
You are also asked to change exactly one of these function specs, deduplicate(). Its current spec is very weak, so you will strengthen the spec, and test and implement your stronger spec. Unlike your test suites for other functions, your deduplicate() tests won’t be run against good and bad staff implementations, because you’ll be changing the spec.
Implement update().
update
update(card: Flashcard, answer: AnswerDifficulty, bucketMap: Map<Flashcard, number>, retiredBucket: number): void
Update step for the Modified-Leitner algorithm.
Parameters
card: Flashcard
a flashcard the user just saw
answer: AnswerDifficulty
the user's answer to the flashcard
bucketMap: Map<Flashcard, number>
represents learning buckets before the flashcard was seen. Maps each flashcard in the map to a nonnegative integer bucket number in the range [0...retiredBucket] inclusive. Mutated by this method to put card in the appropriate bucket, as determined by the Modified-Leitner algorithm.
retiredBucket: number
number of retired bucket. Must be an integer >= 0.
Returns void","/**
 * Update step for the Modified-Leitner algorithm.
 * 
 * @param card a flashcard the user just saw
 * 
 * @param answer the user's answer to the flashcard
 * 
 * @param bucketMap represents learning buckets before the flashcard was seen.
 *                  Maps each flashcard in the map to a nonnegative integer 
 *                  bucket number in the range [0...retiredBucket] inclusive.
 *                  Mutated by this method to put `card` in the appropriate bucket,
 *                  as determined by the Modified-Leitner algorithm.
 * 
 * @param retiredBucket number of retired bucket. Must be an integer >= 0.
 */
export function update(card: Flashcard, answer: AnswerDifficulty, bucketMap: Map<Flashcard, number>, retiredBucket: number): void {
    if (!bucketMap.has(card)) {
        bucketMap.set(card, 0);
    }
    if (answer === AnswerDifficulty.WRONG) {
        bucketMap.set(card, 0);
    } else if (answer === AnswerDifficulty.HARD) {
        const currentBucket = bucketMap.get(card);
        if (currentBucket != null) {
            bucketMap.set(card, Math.max(0, currentBucket - 1));
        } else {
            throw new Error(""card not in bucketMap (something is really wrong)"");
        }
    } else {
        const currentBucket = bucketMap.get(card);
        if (currentBucket != null) {
            bucketMap.set(card, Math.min(retiredBucket, currentBucket + 1));
        } else {
            throw new Error(""card not in bucketMap (something is really wrong)"");
        }
    }
}","Have you ever used flashcards – maybe to improve your vocabulary either in your native language or in a foreign language you want to learn? A flashcard has two sides, a front and a back, which might be a vocabulary word and its meaning. To use a flashcard for learning practice, you look at the front and try to recall what’s on the back, then look at the back to see if you were right. Flashcards are an example of active learning, which is much more effective than passive reading or listening.
A flashcard system is a scheduling algorithm that decides when to practice each flashcard for the most efficient learning. Flashcard systems take advantage of spaced repetition, the principle that we learn more durably when practice is spaced out over time rather than crammed together, and furthermore that the rate of forgetting something is slower the more we have practiced it, so that the spacing between practice can increase as a concept or skill becomes more learned.
This problem set uses a spaced repetition flashcard algorithm that we will call the Modified-Leitner system, because it is inspired by the Leitner system but differs in the details. In a Leitner system, flashcards are grouped into numbered learning buckets. Low-numbered buckets contain flashcards that are less well-learned, so low-numbered buckets are scheduled for practice more often than high-numbered buckets. As a flashcard receives more and more successful practice, it moves up to higher buckets, until finally reaching a retired bucket (e.g., bucket 5). Flashcards in the retired bucket are considered well-enough learned not to need practice anymore.
Here is the specific behavior of our Modified-Leitner algorithm:
• A new card, before its first practice, is assumed to be in bucket 0.
• On day n of the learning process, the user collects all the buckets that are scheduled for practice that day, and practices every card found in those buckets.
  • Cards in the retired bucket are not scheduled for practice.
  • Bucket 0 cards are practiced every day, bucket 1 cards every two days, bucket 2 cards every four days, and so forth. In general, bucket i is practiced every 2i days.
  • The user is of course free to practice new cards, or unscheduled cards of their own choice, or to practice cards repeatedly.
• Whenever the user practices a flashcard:
  • if they get the card wrong – they are unable to correctly recall what’s on the back of the card – then the card is put back in bucket 0.
  • if they find the card easy – getting it right without much mental effort – then the card moves up from bucket i to bucket i+1 (unless the card is already in the retired bucket).
  • if they find the card hard – getting it right but only with effort – then the card moves down to bucket i-1 (unless the card is already in bucket 0).
This problem set consists of a group of functions that can be used to implement the Modified-Leitner flashcard system:
• toBucketSets() converts a Map representation of learning buckets into a Array-of-Set representation
• getBucketRange() finds the range of buckets that contain flashcards, as a rough measure of progress
• practice() selects cards to practice on a particular day
• update() updates a card’s bucket number after a practice trial
• deduplicate() consolidates flashcards by combining redundant cards
In addition to implementing these functions yourself, you will also write a test suite for each function, carefully following the function’s spec. Your test suites will be graded in part by running them against various staff implementations of the function, some of which obey the spec and some which don’t. A good test suite should pass the good implementations and reject the bad ones.
You are also asked to change exactly one of these function specs, deduplicate(). Its current spec is very weak, so you will strengthen the spec, and test and implement your stronger spec. Unlike your test suites for other functions, your deduplicate() tests won’t be run against good and bad staff implementations, because you’ll be changing the spec.
Implement toBucketSets().
toBucketSets
toBucketSets(bucketNumbers: Map<Flashcard, number>): Set<Flashcard>[]
Reorganize learning buckets from a map representation to a list-of-sets representation.
Parameters
bucketNumbers: Map<Flashcard, number>
maps each flashcard to a (nonnegative integer) bucket number
Returns Set<Flashcard>[]
a list of disjoint sets whose union is the set of cards in bucketNumbers, and where list[i] is the set of cards that bucketNumbers maps to i, for all i in [0, list.length).","/**
 * Reorganize learning buckets from a map representation to a list-of-sets
 * representation.
 *
 * @param bucketNumbers maps each flashcard to a (nonnegative integer) bucket number
 * 
 * @returns a list of disjoint sets whose union is the set of cards in
 *          bucketNumbers, and where list[i] is the set of cards that
 *          bucketNumbers maps to i, for all i in [0, list.length).
 */
export function toBucketSets(bucketNumbers: Map<Flashcard, number>): Array<Set<Flashcard>> {
    const maxBucketNumber: number = Math.max(...bucketNumbers.values());
    const buckets: Array<Set<Flashcard>> = [];
    for (let i=0; i<maxBucketNumber+1; i++) {
        buckets.push(new Set());
    }
    for (const [card, bucketNum] of bucketNumbers.entries()) {
        buckets[bucketNum].add(card);
    }
    return buckets;
}","Have you ever used flashcards – maybe to improve your vocabulary either in your native language or in a foreign language you want to learn? A flashcard has two sides, a front and a back, which might be a vocabulary word and its meaning. To use a flashcard for learning practice, you look at the front and try to recall what’s on the back, then look at the back to see if you were right. Flashcards are an example of active learning, which is much more effective than passive reading or listening.
A flashcard system is a scheduling algorithm that decides when to practice each flashcard for the most efficient learning. Flashcard systems take advantage of spaced repetition, the principle that we learn more durably when practice is spaced out over time rather than crammed together, and furthermore that the rate of forgetting something is slower the more we have practiced it, so that the spacing between practice can increase as a concept or skill becomes more learned.
This problem set uses a spaced repetition flashcard algorithm that we will call the Modified-Leitner system, because it is inspired by the Leitner system but differs in the details. In a Leitner system, flashcards are grouped into numbered learning buckets. Low-numbered buckets contain flashcards that are less well-learned, so low-numbered buckets are scheduled for practice more often than high-numbered buckets. As a flashcard receives more and more successful practice, it moves up to higher buckets, until finally reaching a retired bucket (e.g., bucket 5). Flashcards in the retired bucket are considered well-enough learned not to need practice anymore.
Here is the specific behavior of our Modified-Leitner algorithm:
• A new card, before its first practice, is assumed to be in bucket 0.
• On day n of the learning process, the user collects all the buckets that are scheduled for practice that day, and practices every card found in those buckets.
  • Cards in the retired bucket are not scheduled for practice.
  • Bucket 0 cards are practiced every day, bucket 1 cards every two days, bucket 2 cards every four days, and so forth. In general, bucket i is practiced every 2i days.
  • The user is of course free to practice new cards, or unscheduled cards of their own choice, or to practice cards repeatedly.
• Whenever the user practices a flashcard:
  • if they get the card wrong – they are unable to correctly recall what’s on the back of the card – then the card is put back in bucket 0.
  • if they find the card easy – getting it right without much mental effort – then the card moves up from bucket i to bucket i+1 (unless the card is already in the retired bucket).
  • if they find the card hard – getting it right but only with effort – then the card moves down to bucket i-1 (unless the card is already in bucket 0).
This problem set consists of a group of functions that can be used to implement the Modified-Leitner flashcard system:
• toBucketSets() converts a Map representation of learning buckets into a Array-of-Set representation
• getBucketRange() finds the range of buckets that contain flashcards, as a rough measure of progress
• practice() selects cards to practice on a particular day
• update() updates a card’s bucket number after a practice trial
• deduplicate() consolidates flashcards by combining redundant cards
In addition to implementing these functions yourself, you will also write a test suite for each function, carefully following the function’s spec. Your test suites will be graded in part by running them against various staff implementations of the function, some of which obey the spec and some which don’t. A good test suite should pass the good implementations and reject the bad ones.
You are also asked to change exactly one of these function specs, deduplicate(). Its current spec is very weak, so you will strengthen the spec, and test and implement your stronger spec. Unlike your test suites for other functions, your deduplicate() tests won’t be run against good and bad staff implementations, because you’ll be changing the spec.
Implement practice().
practice
practice(day: number, buckets: Set<Flashcard>[], retiredBucket: number): Flashcard[]
Generate a sequence of flashcards for practice on a particular day.
Parameters
day: number
day of the learning process. Must be integer >= 1.
buckets: Set<Flashcard>[]
a list of disjoint sets representing learning buckets, where buckets[i] is the set of cards in the ith bucket for all 0 <= i <= retiredBucket
retiredBucket: number
number of retired bucket. Must be an integer >= 0.
Returns Flashcard[]
a sequence of flashcards such that a card appears in the sequence if and only if its bucket number is some i < retiredBucket such that day is divisible by 2^i","/**
 * Generate a sequence of flashcards for practice on a particular day.
 *
 * @param day day of the learning process. Must be integer >= 1.
 * 
 * @param buckets a list of disjoint sets representing learning buckets,
 *                where buckets[i] is the set of cards in the ith bucket
 *                for all 0 <= i <= retiredBucket
 * 
 * @param retiredBucket number of retired bucket. Must be an integer >= 0.
 * 
 * @returns a sequence of flashcards such that a card appears in the sequence if
 *          and only if its bucket number is some i < retiredBucket such that
 *          `day` is divisible by 2^i
 */
export function practice(day: number, buckets: Array<Set<Flashcard>>, retiredBucket: number): Array<Flashcard> {
    const sequence: Array<Flashcard> = [];
    for (let i=0; i<retiredBucket; i++) {
        if (day % Math.pow(2, i) === 0) {
            sequence.push(...buckets[i]);
        }
    }
    return sequence;
}"
375,Mathematics,18.01,Calculus I,None,None,Problem Set 8,Probability Distributions,8,d,0.07919746568,Text,"Suppose we spin a biased spinner. The biased spinner gives a number $x$ between 0 and $\pi / 2$, but the number $x$ is not evenly distributed. Instead, if $a$ and $b$ are between 0 and $\pi / 2$ the probability that $x$ lies between $a$ and $b$ is 
$$
\int_{a}^{b} \sin (x) d x
$$
Consider a game where we spin this spinner and if you spin $x$, you win $x$ dollars. What is the average amount you would win? First write the answer as an integral, and then evaluate it.",Expression,"The average value of the game is
$$
\int_{0}^{\pi / 2} x \sin x d x
$$
Calculate this integral by integration by parts. Set $u=x$ and $d v=\sin x d x$. Then $d u=d x$ and $v=-\cos x$, so the integral is
$$
\begin{aligned}
-\left.x \cos x\right|_{0} ^{\pi / 2}-\int_{0}^{\pi / 2}(-\cos x) d x & =(-\pi / 2 \cos (\pi / 2)+0 \cos 0)+\left.\sin x\right|_{0} ^{\pi / 2} \\
& =-(\pi / 2)(0)+\sin (\pi / 2)-\sin (0) \\
& =1 .
\end{aligned}
$$","Suppose we spin a biased spinner. The biased spinner gives a number $x$ between 0 and $\pi / 2$, but the number $x$ is not evenly distributed. Instead, if $a$ and $b$ are between 0 and $\pi / 2$ the probability that $x$ lies between $a$ and $b$ is 
$$
\int_{a}^{b} \sin (x) d x
$$
Now consider a game where we spin this spinner and if you spin $x$, you win $x^{2}$ dollars. What is the average amount you would win? This time just write the answer as an integral and don't evaluate it.","The average value of the game is
$$
\int_{0}^{\pi / 2} x^{2} \sin x d x
$$
The average value of a probability distribution $f(x) d x$ is $\int_{-\infty}^{\infty} x f(x) d x$. If you imagine a biased spinner which spins a number $x$ according to the probability distribution $f(x) d x$, then this integral is the average value of $x$. The average value of a probability distribution is also called the mean value.","Suppose we spin a biased spinner. The biased spinner gives a number $x$ between 0 and $\pi / 2$, but the number $x$ is not evenly distributed. Instead, if $a$ and $b$ are between 0 and $\pi / 2$ the probability that $x$ lies between $a$ and $b$ is 
$$
\int_{a}^{b} \sin (x) d x
$$
Check that the probability of getting a number between 0 and $\pi / 2$ is 1.","Calculate
$$
\int_{0}^{\pi / 2} \sin x d x=-\left.\cos x\right|_{0} ^{\pi / 2}=-\cos (\pi / 2)+\cos (0)=0+1=1.
$$","Suppose we spin a biased spinner. The biased spinner gives a number $x$ between 0 and $\pi / 2$, but the number $x$ is not evenly distributed. Instead, if $a$ and $b$ are between 0 and $\pi / 2$ the probability that $x$ lies between $a$ and $b$ is 
$$
\int_{a}^{b} \sin (x) d x
$$
Compute the probability of spinning a number $x$ in the range $0 \leq$ $x \leq \pi / 4$.","$$
\int_{0}^{\pi / 4} \sin x d x=-\left.\cos x\right|_{0} ^{\pi / 4}=-\cos (\pi / 4)+\cos (0)=-\frac{1}{\sqrt{2}}+1
$$
Note that $-\frac{1}{\sqrt{2}}+1<\frac{1}{2}$ since this inequality is the same as $\frac{1}{\sqrt{2}}>\frac{1}{2}$ and $2>\sqrt{2}$."
31,EECS,6.121,Introduction to Algorithms,"6.100A, 6.1200",6.101,Problem Set 3,Critter Sort,1,c,0.125,Text,"Professor Oak is trying to organize his $n$ Critters so he can study them more efficiently. For each of the following scenarios, provide the most efficient algorithm for sorting the Critters, and state whether the asymptotic complexity is $\Theta(n), \Theta(n \log n)$, or $\Theta\left(n^{2}\right)$. Briefly justify your answers (a sentence or two suffices). Choose only one of the following sorting algorithms from lecture and recitation: insertion sort, selection sort, merge sort, counting sort, and radix sort.
After Professor Oak sorts his Critters by their weight, one of the Critters got heavier. Professor Oak wants to resort his Critters by weight.",Open,"Only one Critter has a different weight from before, and so insertion sort will only need to do $\Theta(n)$ work to put this Critter into its new correct position.","Professor Oak is trying to organize his $n$ Critters so he can study them more efficiently. For each of the following scenarios, provide the most efficient algorithm for sorting the Critters, and state whether the asymptotic complexity is $\Theta(n), \Theta(n \log n)$, or $\Theta\left(n^{2}\right)$. Briefly justify your answers (a sentence or two suffices). Choose only one of the following sorting algorithms from lecture and recitation: insertion sort, selection sort, merge sort, counting sort, and radix sort.
Professor Oak wants to sort his Critters by their weight. The only tool that he has is a large balance in his lab, with which he can compare any two Critters to determine which one is heavier.","We must use a comparison based sorting algorithm here, e.g. merge sort in $\Theta(n \log n)$ time.","Professor Oak is trying to organize his $n$ Critters so he can study them more efficiently. For each of the following scenarios, provide the most efficient algorithm for sorting the Critters, and state whether the asymptotic complexity is $\Theta(n), \Theta(n \log n)$, or $\Theta\left(n^{2}\right)$. Briefly justify your answers (a sentence or two suffices). Choose only one of the following sorting algorithms from lecture and recitation: insertion sort, selection sort, merge sort, counting sort, and radix sort.
Professor Oak's Critters like to battle each other. Each Critter has participated in at least one battle, and each pair of Critters has battled each other at most once. Professor Oak wants to sort his Critters by the number of times that they have battled.","The sorting key is an integer in the range $[1, n]$, and so radix sort takes $\Theta(n)$ time.","Professor Oak is trying to organize his $n$ Critters so he can study them more efficiently. For each of the following scenarios, provide the most efficient algorithm for sorting the Critters, and state whether the asymptotic complexity is $\Theta(n), \Theta(n \log n)$, or $\Theta\left(n^{2}\right)$. Briefly justify your answers (a sentence or two suffices). Choose only one of the following sorting algorithms from lecture and recitation: insertion sort, selection sort, merge sort, counting sort, and radix sort.
Professor Oak wants to sort his Critters by their species' ID number, which is a positive integer less than 894.","The sorting key comes from a constant-size set, and so counting sort runs in $\Theta(n)$ time."
141,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Midterm Exam 1,Boolean Algebra,6,e,0.3,Text,Below you are given the delays for the different gates you were permitted to use in part $\mathrm{D}$ above. Compute the propagation delay of your circuit from D.,Numerical,tPD (ns) = 9.5.,"In the circuit below, $\mathrm{D}$ is a constant and has a value of $0<\mathrm{D}<1$.
For the circuit shown in part (C) below, calculate the voltage on the load resistor $\mathrm{V}_{\mathrm{L}}$. Express your answer using $V_{S}, R_{S}, D$ and $R_{L}$.","$$
V_{L}=\frac{(1-D) R_{L}}{(1-D)^{2} R_{L}+R_{S}} V_{S}
$$","In the circuit below, $\mathrm{D}$ is a constant and has a value of $0<\mathrm{D}<1$.
Calculate the short circuit current from the labelled port $i_{s c}$, as shown in the figure below. Express your answer using $\mathrm{V}_{\mathrm{s}}, \mathrm{R}_{\mathrm{s}}$ and $\mathrm{D}$.","$$
i_{s c}=(D-1) \frac{V_{s}}{R_{s}}
$$","You are given a module, named “F.” This module has two inputs, X and Y, and two outputs, A and B. You are told that the circuit functions, but its throughput is too low. You decide to take a look and try to pipeline the circuit.
For each of the questions below, please create a valid K-stage pipeline of the given circuit. Each component in the circuit is annotated with its propagation delay in nanoseconds. Show your pipelining contours and place large black circles (●) on the signal arrows to indicate the placement of pipeline registers. Give the latency and throughput of each design, assuming ideal registers (tPD=0, tSETUP=0). Remember that our convention is to place a pipeline register on each output.
What is the propagation delay of the whole circuit shown below as-is without pipelining?",$t_{pd}$ (ns): 26.
351,Mathematics,18.01,Calculus I,None,None,Problem Set 7,Probability,19,b,0.04751847941,Text,"Now suppose we start to gamble with this spinner. If I spin $x$, I win $x^{2}-4$ dollars. Notice that $x^{2}-4$ could be negative, and then I lose money. For instance, if I spin the number 1 , then I lose 3 dollars.
If I spin once, what is the probability that I lose money?",Numerical,$\operatorname{Prob}\left(x^{2}-4<0\right)=\operatorname{Prob}(x<2)=2 / 3$.,"Now suppose we start to gamble with this spinner. If I spin $x$, I win $x^{2}-4$ dollars. Notice that $x^{2}-4$ could be negative, and then I lose money. For instance, if I spin the number 1 , then I lose 3 dollars.
Estimate the probability that I win at least 4 dollars. Is it closest to $1 / 6$ or $1 / 9$ or $1 / 18 ?$ Explain your reasoning.","Since $\left[\frac{d}{d x} x^{2}-4\right]_{x=3}=[2 x]_{x=3}=6$, near the top payoff of 5 we have that a range of outcomes $3-\Delta \leq x \leq 3$ of the spin corresponds to a range of payoffs from approximately $5-6 \Delta x$ to 5 . We want this range to be from 4 to 5 , so pick $\Delta x=1 / 6$. The range of spin outcomes from $3-1 / 6$ to 3 has probability $\frac{1 / 6}{3}=\frac{1}{18}$.","Now suppose we start to gamble with this spinner. If I spin $x$, I win $x^{2}-4$ dollars. Notice that $x^{2}-4$ could be negative, and then I lose money. For instance, if I spin the number 1 , then I lose 3 dollars.
What is the most I could win on one spin? What is the most I could lose on one spin?",The payoff is between $-4$ and $3^{2}-4=5$.,"Consider the following game. You spin a fair spinner that gives a number $x$ between 0 and 3. If $x<2$, then you win 10 dollars. But if $x>2$, then you lose $10 x$ dollars. For instance, if you spin 2.5, then you would lose 25 dollars.
If you played this game 1000 times, how much money would you expect to win or lose?","The probability density of $x$ is
$$
f(x)= \begin{cases}1 / 3, & 0 \leq x \leq 3 \\ 0, & \text { otherwise }\end{cases}
$$
The winning function is
$$
W(x)= \begin{cases}10, & x<2 \\ -10 x, & x>2\end{cases}
$$
The expected winning of one spin is
$$
\begin{aligned}
E(W(x)) & =\int_{0}^{3} f(x) W(x) d x=\frac{1}{3} \int_{0}^{2} 10 d x+\frac{1}{3} \int_{2}^{3}-10 x d x \\
& =\frac{20}{3}-\frac{10}{3}\left[\frac{x^{2}}{2}\right]_{2}^{3}=-\frac{5}{3} .
\end{aligned}
$$
If we play 1000 times, then we expect to lose $5000 / 3$ dollars. "
9,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Prelab Questions 1,Assembly,2,h,0.006060606061,Text,"Please assume that all registers are initialized to 0, and the instructions in the section below are executed one after another.
addi a1, a2, 9
lui a2, 3
li a3, 3 
sub a3, a3, a1
slt a4, a3, zero
sltu a5, a3, zero
li a4, 1
beq a5, zero, L1
slli a4, a4, 2
L1:
slli a4, a4, 5
What final value (answer in 32-bit hexadecimal format like 0x0CDEF1AF) will be inside the register a4 after all entire code snippet above is executed?",Numerical,"0x00000020.
The instruction li a4, 1 first sets the value inside a4 to be 1.
Then, the instruction beq a5, zero, L1 checks whether the value inside a5 is equal to the value in zero or not. In this case, the value inside a5 from the previous section is 0, so the beq jumps to the specified label, L1, and continues its execution there.
Finally, the instruction slli a4, a4, 5. It shifts the value inside a4 the left by 5 bits and writes the shifted result back into a4. a4 was just set to 1 or 0b0000 0000 0000 0000 0000 0000 0000 0001. Shifting this value by 5 bits to the left results in a value of 0b0000 0000 0000 0000 0000 0000 0010 0000 which is 0x00000020 in hexadecimal. This result is written to the destination register which also happens to be a4 in this instruction.","Please assume that all registers are initialized to 0, and the instructions in the section below are executed one after another.
addi a1, a2, 9
lui a2, 3
li a3, 3 
sub a3, a3, a1
slt a4, a3, zero
sltu a5, a3, zero
What value (answer in 32-bit hexadecimal format like 0xDCDEF1AF) is written into register a3? Note that all values are stored as 2's complement numbers.","0xFFFFFFFA.
The command sub rd, rs1, rs2 subtracts the value of rs2 from rs1 treating them as 2's complement numbers. It then store the result into register rd. For the command sub a3, a3, a1, the former value in a3 is 3 and the former value in a1 is 9. The subtraction's result is $-6$. We can represent $-6$ in 2's complement representation by
$$
6 \stackrel{\text { binary }}{\longrightarrow} \ldots 000110 \stackrel{\text { invert bits }}{\longrightarrow} \ldots 111001 \stackrel{\text { add } 1}{\longrightarrow} \ldots 111010 \stackrel{\text { hex }}{\longrightarrow} \ldots F F A
$$
Hence, the value written into the register a3 is 0xFFFFFFFA.","Please assume that all registers are initialized to 0, and the instructions in the section below are executed one after another.
addi a1, a2, 9
lui a2, 3
li a3, 3 
sub a3, a3, a1
slt a4, a3, zero
sltu a5, a3, zero
What is the value written into the register a4?
(a) 0.
(b) 1.","(b) 1.
The command slt rd, rs1, rs2 sets rd to 1 (True) if the value of register rs1 is less than the value of register $\mathrm{rs} 2$. Otherwise, it sets it to 0 (False). slt a4, a3, zero checks if the value in register a3 (which is $-6$ ) is less than the value in register zero (which is 0). Since it is, it stores the value 1 (Boolean True) into the destination register a4. ","Please assume that all registers are initialized to 0, and the instructions in the section below are executed one after another.
addi a1, a2, 9
lui a2, 3
li a3, 3 
What value (answer in 32-bit hexadecimal format like 0x0CDEF1AF) is written into the register a3?","0x00000003.
The command li rd, imm writes the value of imm into rd as a 32-bit 2's complement number. So the value written into a3 is 0b0000 0000 0000 0000 0000 0000 0000 0011 which is 0x00000003 in hexadecimal."
454,Mathematics,18.01,Calculus I,None,None,Midterm Exam 3,Variance,4,b,0.875,Text,"Suppose we spin a fair spinner which gives a number $x$ between 0 and 4. (Fair means that the probability that $x$ is between 2 and 3 is $1 / 4$, etc.)
Write down an integral for the variance of $x$. (You don't need to evaluate it.)",Expression,"$$
\operatorname{Var}(X)=E\left[(x-E(x))^{2}\right]=E\left[(x-2)^{2}\right]=\int_{0}^{4} f(x)(x-2)^{2} d x=\int_{0}^{4} \frac{(x-2)^{2}}{4} d x
$$","Suppose we spin a fair spinner which gives a number $x$ between 0 and 4. (Fair means that the probability that $x$ is between 2 and 3 is $1 / 4$, etc.)
Write down an integral for the mean value of $x$ and evaluate the integral.","The probability density of $x$ is
$$
f(x)= \begin{cases}1 / 4, & \text { if } 0 \leq x \leq 4 \\ 0, & \text { otherwise. }\end{cases}
$$
Therefore, the mean value of $x$ is
$$
E(x)=\int_{-\infty}^{\infty} x f(x) d x=\int_{0}^{4} x f(x) d x=\frac{1}{4} \int_{0}^{4} x d x=\frac{1}{4}\left[\frac{x^{2}}{2}\right]_{0}^{4}=2.
$$","Suppose you spin a fair spinner that gives a number $x$ between 0 and 3.
If you roll an $x$, then you win $x^{2}$ dollars. What is the average amount that you win?","The probability density function for $x$ is $f(x)=1 / 3$ when $0 \leq x \leq 3$ and 0 everywhere else. This means that the average value of $x^{2}$ is
$$
\int_{0}^{3} x^{2} \frac{1}{3} d x=\left.\frac{1}{3}\left(\frac{x^{3}}{3}\right)\right|_{0} ^{3}=3.
$$","Suppose we spin a biased spinner. The biased spinner gives a number $x$ between 0 and $\pi / 2$, but the number $x$ is not evenly distributed. Instead, if $a$ and $b$ are between 0 and $\pi / 2$ the probability that $x$ lies between $a$ and $b$ is 
$$
\int_{a}^{b} \sin (x) d x
$$
Now consider a game where we spin this spinner and if you spin $x$, you win $x^{2}$ dollars. What is the average amount you would win? This time just write the answer as an integral and don't evaluate it.","The average value of the game is
$$
\int_{0}^{\pi / 2} x^{2} \sin x d x
$$
The average value of a probability distribution $f(x) d x$ is $\int_{-\infty}^{\infty} x f(x) d x$. If you imagine a biased spinner which spins a number $x$ according to the probability distribution $f(x) d x$, then this integral is the average value of $x$. The average value of a probability distribution is also called the mean value."
17,Mathematics,18.102,Introduction to Functional Analysis,"18.C06, 18.100B",None,Problem Set 3,Measure Zero,3,b,0.25,Text,"Let $E$ be the set obtained as follows. Take the interval [0,1], delete the (open) middle quarter, then from the two remaining intervals delete the middle $1 / 9$-th, then from each of the four remaining intervals delete the middle $1 / 16$-th, etc. (each time delete the middle $1 / n^{2}$-th). The set $E$ is obtained in the limit (the set of remaining points). Does $E$ have measure 0? Is the characteristic function $\chi_{E}$ of $E$ in $\mathcal{L}^{1}(\mathbb{R})$ ? If so, compute $\int \chi_{E}$.",Open,"Let $E_{n}$ be the set obtained as in the question after the step that deleting the middle $1 / n^{2}$-th. The set $E_{n}$ is a finite union of intervals and it has length
$$
\prod_{k=2}^{n}\left(1-\frac{1}{k^{2}}\right)=\prod_{k=2}^{n} \frac{(k-1)(k+1)}{k^{2}}=\frac{n+1}{2 n} .
$$
The series $\chi_{E_{n}}$ converges pointwise to $\chi_{E}$ and is dominated by $\chi_{[0,1]}$. Therefore by Lebesgue dominated convergence theorem (theorem 2.2), we conclude that $\chi_{E} \in \mathcal{L}^{1}(\mathbb{R})$ and
$$
\int \chi_{E}=\lim _{n \rightarrow \infty} \int \chi_{E_{n}}=\lim _{n \rightarrow \infty} \frac{n+1}{2 n}=\frac{1}{2}.
$$","Suppose $E \subset \mathbb{R}$ has the following (well-known) property:
$$
\forall \epsilon>0 \exists \text { a countable collection of intervals }\left(a_{i}, b_{i}\right) \text { s.t. }
$$
$$
\sum_{i}\left(b_{i}-a_{i}\right)<\epsilon, E \subset \bigcup_{i}\left(a_{i}, b_{i}\right) \text {. }
$$
Show that $E$ is a set of measure zero in the sense used in lectures and the notes.","Choose a continuous function $h: \mathbb{R} \longrightarrow[0,1]$ which vanishes in $x<-1, x>2$ and is equal to 1 on $[0,1]$ as we did earlier, by adding 'legs' to the characteristic function for $[0,1]$. Then for any pair of real numbers $b>a$ set
$$
h(x ; a, b)=h\left(\frac{x-a}{b-a}\right) .
$$
Thus $h(x, a, b)=1$ on $[a, b], 0 \leq h(x, a, b) \leq 1$ and $\int_{\mathbb{R}} h(x ; a, b) \leq$ $3(b-a)$. Now, for each $j \in \mathbb{N}$, we can find a collection of intervals $\left(a_{i}(j), b_{i}(j)\right)$, with $b_{i}(j)>a_{i}(j), \sum_{i}\left(b_{i}(j)-a_{i}(j)\right)<2^{-j}$ and $E \subset \bigcup_{i}\left(b_{i}(j), a_{i}(j)\right)$. Set $u_{i, j}=h\left(x ; a_{i}(j), b_{i}(j)\right)$. Let $v_{k} \in \mathcal{C}_{\mathrm{c}}(\mathbb{R})$ be an arrangement of the $u_{i, j}$ as a single sequence. Both sequences $\int v_{k}$ and $v_{k}(x)$ are non-negative, so convergence is equivalent to convergence of the corresponding double sum. Thus
$$
\begin{gathered}
\sum_{j} \sum_{i} \int u_{i, j} \leq 3 \sum_{j} 2^{-j}<\infty \Longrightarrow \sum_{k} \int v_{k}<\infty \\
x \in E \Longrightarrow \sum_{i} u_{i, j}(x) \geq 1 \forall j \geq 1 \Longrightarrow \sum_{k} v_{k}(x)=\infty
\end{gathered}
$$
so $E$ is a set of measure zero.","A subset $E \subset \mathbb{R}$ is said to be of measure zero if there exists an absolutely summable sequence $f_{n} \in \mathcal{C}_{\mathrm{c}}(\mathbb{R})\left(\right.$ so $\left.\sum_{n} \int\left|f_{n}\right|<\infty\right)$ such that
$$
E \subset\left\{x \in \mathbb{R} ; \sum_{n}\left|f_{n}(x)\right|=+\infty\right\}
$$
Show that if $E$ is of measure zero and $\epsilon>0$ is given then there exists $f_{n} \in \mathcal{C}_{\mathrm{c}}(\mathbb{R})$ satisfying (13) and in addition
$$
\sum_{n} \int\left|f_{n}\right|<\epsilon
$$","Take such a series $f_{n}$ with $\sum_{n} \int\left|f_{n}(x)\right|=C$ and replace it by $\frac{\epsilon}{C+1} f_{n}$ or choose $N$ so large that
$$
\sum_{n \leq N} \int\left|f_{n}(x)\right|>C-\epsilon
$$
and consider the new series $u_{n}=f_{n+N}$ which has
$$
\sum_{n} \int\left|u_{n}(x)\right|<\epsilon
$$
and for which $\sum_{n}\left|u_{n}(x)\right| C$ diverges wherever $\sum_{n}\left|f_{n}(x)\right|$ diverges, so in particular on $E$. ","Suppose $u_{n} \in \mathcal{C}_{\mathrm{c}}(\mathbb{R})$ form an absolutely summable series with respect to the $L^{1}$ norm and set
$$
E=\left\{x \in \mathbb{R} ; \sum_{n}\left|u_{n}(x)\right|=\infty\right\}
$$
Conclude that $E$ has the standard property of a set of measure zero - for each $\epsilon>0$ it is covered by a countable collection of open intervals the sum of the lengths of which is less than $\epsilon$.",Follows immediately from 3 by taking $O_{\epsilon / C+1}$.
84,EECS,6.18,Computer Systems Engineering,"6.1010, 6.1910",None,Midterm Exam 2,Passwords,8,a,0.3,Text,"Consider the following schemes for storing username and password information. We consider a single line containing the fields that are needed for a single user's login lookup; the table as a whole consists of a large number of these lines.
The different fields in the line are separated by commas (field1, field2, field3). ""salt"" is a randomly generated 10-digit number. Assume there are no issues with the random number generator. ""|"" means concatenate. The hash function is ""slow"" - it takes a substantial amount of computation.
We want to defend against a so-called ""rainbow table"" attack, in which the adversary has already computed hashes of many common passwords.
For each scheme, select Yes or No to the question: Is this scheme resistant to rainbow table attacks?
username, salt, hash(password) $\mid$ hash(salt)",Multiple Choice,No.,"Consider the following schemes for storing username and password information. We consider a single line containing the fields that are needed for a single user's login lookup; the table as a whole consists of a large number of these lines.
The different fields in the line are separated by commas (field1, field2, field3). ""salt"" is a randomly generated 10-digit number. Assume there are no issues with the random number generator. ""|"" means concatenate. The hash function is ""slow"" - it takes a substantial amount of computation.
We want to defend against a so-called ""rainbow table"" attack, in which the adversary has already computed hashes of many common passwords.
For each scheme, select Yes or No to the question: Is this scheme resistant to rainbow table attacks?
username, salt, hash(password) $\mid$ hash(password $\mid$ salt)",No.,"Consider the following schemes for storing username and password information. We consider a single line containing the fields that are needed for a single user's login lookup; the table as a whole consists of a large number of these lines.
The different fields in the line are separated by commas (field1, field2, field3). ""salt"" is a randomly generated 10-digit number. Assume there are no issues with the random number generator. ""|"" means concatenate. The hash function is ""slow"" - it takes a substantial amount of computation.
We want to defend against a so-called ""rainbow table"" attack, in which the adversary has already computed hashes of many common passwords.
For each scheme, select Yes or No to the question: Is this scheme resistant to rainbow table attacks?
username, salt, hash(hash(password) $\mid$ salt)",Yes.,"Analysis of hashing usually assumes SUHA: regardless of what has happened in the past, the key that appears in the next INSERT operation in the sequence is equally likely to be one that hashes to any location in the table. This problem considers what happens when keys happen to hash to the same location, resulting in hash collisions.
In each example, the hash table has $m$ cells numbered $0, \ldots, m-1$. We are considering a scenario in which $n$ INSERT operations occur for distinct keys $k_{1}, k_{2}, \ldots, k_{n}$, and all keys map to the same location. This is not likely but it could happen. The inserts are followed by a single SEARCH operation for a key $k$ different from those inserted (so the operation will fail to find the given key). You can assume $m>n$.
Suppose that collisions are now resolved using open addressing with linear probing. Now, each cell in the hash table only stores one key. During an INSERT operation, if the hashed location is occupied, linear probing searches the table for the next free cell and inserts the new key there.
Suppose that again $n$ inserts happen, all (but the first) resulting in collisions. Find the expected number of probes needed to perform a SEARCH operation for a key $k$ not in the table.","Since there were $n$ collisions, all $n$ keys must be consecutive (or wrap around).
By our assumption about the new Search operation, the probability that the key we search for will hash to one of the $m-n$ empty locations is $(m-n) / m$. The probability it will hash to any individual of the $n$ locations is $1 / \mathrm{m}$.
If the key hashes to an empty location, only one probe happens. If the key hashes to an occupied location, the number of probes depends on how far along the occupied cells that location is. For example, if the key hashes to an occupied location and the next cell is free, this would result in two probes.
Let $C$ be a random variable that denotes the number of probes the search makes. The expected search time will be:
$$
\begin{aligned}
E[C] & =\sum_{c \in C} P(C=c) \cdot c \\
& =P(C=1) \cdot 1+\sum_{i=2}^{n+1} P(C=i) \cdot i \\
& =\frac{m-n}{m} \cdot 1+\sum_{i=2}^{n+1} \frac{1}{m} \cdot i \\
& =\frac{m-n}{m}+\frac{n}{2} \cdot\left(\frac{2}{m}+\frac{n+1}{m}\right) \\
& =\frac{m-n}{m}+\frac{n^{2}+3 n}{2 m} \\
& =\frac{2 m-2 n+n^{2}+3 n}{2 m} \\
& =\frac{2 m+n^{2}+n}{2 m}.
\end{aligned}
$$"
60,EECS,6.122,Design and Analysis of Algorithms,6.121,None,Problem Set 6,Game Theory,3,c,0.2727272727,Text,"Alice recently enrolled in $6.046$ and learned the Median Finding algorithm. The details of the algorithm can be found in Recitation 1 notes.
Alice learned that a good pivot is always one that could make the size of the recursion call a constant fraction of the size of the input. For example, the ""median of medians"" for group of 5 on an array of length $n$ makes sure that the next recursion call has size of $\frac{7}{10} n$. However, Alice abhorred this idea of using ""median of medians"" as a pivot (she cried during quiz 1 after seeing the devilish MOMOM). Instead, she decides to choose her pivot in a randomized way. Alice's roommate Bob, however, did not enjoy randomization and wanted to sabotage her algorithm.
For simplicity, let's assume that the inputs to the median finding problem are permutations of $\{1,2, \ldots, n\}$. Formally, for a permutation $\sigma$ of odd length $n$, Alice designated a probability distribution $\mathcal{D}_A$ over all possible index. She chooses the $i$-th item in $\sigma, \sigma[i]$, as her pivot with probability $\mathcal{D}_A(i)$. Alice is satisfied if her algorithm provides a good pivot (as an easily satisfied person, she does not even care about the overall running time!) and her goal is to make her partition balanced in a way that minimizes the expected size of her recursion call.
Seeing Alice's probability distribution for pivots, Bob decides to generate adversarial input in a way that maximize the size of her recursion call. Formally, for an array of length $n$, Bob designated a probability distribution $\mathcal{D}_B$ over all possible length- $n$ permutations. For every permutation $\sigma$ of $\{1,2, \ldots, n\}$, he chooses $\sigma$ as his adversarial input with probability $\mathcal{D}_B(\sigma)$
Both Alice and Bob wonder what the expected size of Alice's recursion call would be if both of them choose their probability distributions optimally.
For an input permutation $\sigma$ and an index $i$, let $s_\sigma(i)$ be the size of the recursion call if $\sigma[i]$ is used as the pivot. Show that $\sum_i s_\sigma(i) \leq \frac{3}{4} n^2$. (Hint: first show that $s_\sigma(i) \leq \max (\operatorname{rank}(\sigma[i]-1, n-\operatorname{rank}(\sigma[i]))$.)",Open,"If $\operatorname{rank}(\sigma[i])<\frac{n+1}{2}$, then $n-\operatorname{rank}(\sigma[i])>\operatorname{rank}(\sigma[i])$, and also the next recursive call contains the elements greater than $\operatorname{rank}(\sigma[i])$ and has size $n-\operatorname{rank}(\sigma[i])$
If $\operatorname{rank}(\sigma[i])=\frac{n+1}{2}$, then the next recursive call has size $0 \leq \max (\operatorname{rank}(\sigma[i])-$ $1, n-\operatorname{rank}(\sigma[i]))$.
If $\operatorname{rank}(\sigma[i]) \frac{n+1}{2}$, then $\operatorname{rank}(\sigma[i])>n-\operatorname{rank}(\sigma[i])$, and also the next recursive call contains the elements smaller than $\operatorname{rank}(\sigma[i])$ and has $\operatorname{size} \operatorname{rank}(\sigma[i])$.
Therefore, $s_\sigma(i) \leq \sum_i \max (\operatorname{rank}(\sigma[i])-1, n-\operatorname{rank}(\sigma[i]))$. Note that for $i \in[1, n]$, $\sigma[i]$ takes all values in $[1, n]$ exactly once. Therefore,
$$
\begin{aligned}
s_\sigma(i) & \leq \sum_i \max (\operatorname{rank}(\sigma[i])-1, n-\operatorname{rank}(\sigma[i])) \\
&=\sum_{i<\frac{n+1}{2}}(n-i)+\sum_{i \geq \frac{n+1}{2}}(i-1) \\
&=\frac{3}{4} n^2-\frac{n}{2}-\frac{1}{4} \\
& \leq \frac{3}{4} n^2
\end{aligned}
$$","Alice recently enrolled in $6.046$ and learned the Median Finding algorithm. The details of the algorithm can be found in Recitation 1 notes.
Alice learned that a good pivot is always one that could make the size of the recursion call a constant fraction of the size of the input. For example, the ""median of medians"" for group of 5 on an array of length $n$ makes sure that the next recursion call has size of $\frac{7}{10} n$. However, Alice abhorred this idea of using ""median of medians"" as a pivot (she cried during quiz 1 after seeing the devilish MOMOM). Instead, she decides to choose her pivot in a randomized way. Alice's roommate Bob, however, did not enjoy randomization and wanted to sabotage her algorithm.
For simplicity, let's assume that the inputs to the median finding problem are permutations of $\{1,2, \ldots, n\}$. Formally, for a permutation $\sigma$ of odd length $n$, Alice designated a probability distribution $\mathcal{D}_A$ over all possible index. She chooses the $i$-th item in $\sigma, \sigma[i]$, as her pivot with probability $\mathcal{D}_A(i)$. Alice is satisfied if her algorithm provides a good pivot (as an easily satisfied person, she does not even care about the overall running time!) and her goal is to make her partition balanced in a way that minimizes the expected size of her recursion call.
Seeing Alice's probability distribution for pivots, Bob decides to generate adversarial input in a way that maximize the size of her recursion call. Formally, for an array of length $n$, Bob designated a probability distribution $\mathcal{D}_B$ over all possible length- $n$ permutations. For every permutation $\sigma$ of $\{1,2, \ldots, n\}$, he chooses $\sigma$ as his adversarial input with probability $\mathcal{D}_B(\sigma)$
Both Alice and Bob wonder what the expected size of Alice's recursion call would be if both of them choose their probability distributions optimally.
Show that even if the input permutation $\sigma$ is drawn from an adversarial probability distribution $\mathcal{D}_B(\sigma)$ that Bob comes up with, there is an index $i$ such that if Alice uses $\sigma[i]$ as index, her recursion call has an expected size at $\operatorname{most} \frac{3}{4} n$. 
(Hint: combine your result from (c) with linearity of expectation to bound $\sum_i \mathbb{E}_\sigma\left(s_\sigma(i)\right)$, and apply the pigeonhole principle.)","By linearity of expectation,
$$
\begin{aligned}
\sum_i \mathbb{E}_\sigma\left(s_\sigma(i)\right) &=\mathbb{E}_\sigma\left(\sum_i s_\sigma(i)\right) \\
& \leq \mathbb{E}_\sigma\left(\frac{3}{4} n^2\right) \\
&=\frac{3}{4} n^2
\end{aligned}
$$
By the pigeonhole principle, there exist an $i$ such that $\mathbb{E}_\sigma\left(s_\sigma(i)\right) \leq \frac{3}{4} n^2 / n=\frac{3}{4} n$.","Alice recently enrolled in $6.046$ and learned the Median Finding algorithm. The details of the algorithm can be found in Recitation 1 notes.
Alice learned that a good pivot is always one that could make the size of the recursion call a constant fraction of the size of the input. For example, the ""median of medians"" for group of 5 on an array of length $n$ makes sure that the next recursion call has size of $\frac{7}{10} n$. However, Alice abhorred this idea of using ""median of medians"" as a pivot (she cried during quiz 1 after seeing the devilish MOMOM). Instead, she decides to choose her pivot in a randomized way. Alice's roommate Bob, however, did not enjoy randomization and wanted to sabotage her algorithm.
For simplicity, let's assume that the inputs to the median finding problem are permutations of $\{1,2, \ldots, n\}$. Formally, for a permutation $\sigma$ of odd length $n$, Alice designated a probability distribution $\mathcal{D}_A$ over all possible index. She chooses the $i$-th item in $\sigma, \sigma[i]$, as her pivot with probability $\mathcal{D}_A(i)$. Alice is satisfied if her algorithm provides a good pivot (as an easily satisfied person, she does not even care about the overall running time!) and her goal is to make her partition balanced in a way that minimizes the expected size of her recursion call.
Seeing Alice's probability distribution for pivots, Bob decides to generate adversarial input in a way that maximize the size of her recursion call. Formally, for an array of length $n$, Bob designated a probability distribution $\mathcal{D}_B$ over all possible length- $n$ permutations. For every permutation $\sigma$ of $\{1,2, \ldots, n\}$, he chooses $\sigma$ as his adversarial input with probability $\mathcal{D}_B(\sigma)$
Both Alice and Bob wonder what the expected size of Alice's recursion call would be if both of them choose their probability distributions optimally.
Suppose $n=3$ and Alice chooses the following distribution for pivots:
\begin{tabular}{|c|c|}
\hline$i$ & $\mathcal{D}_A(i)$ \\
\hline 1 & $1 / 2$ \\
2 & $1 / 2$ \\
3 & 0 \\
\hline
\end{tabular}
Seeing Alice's distribution, Bob came up wiht the following distribution for his adversarial inputs.
\begin{tabular}{|c|c|}
\hline$\sigma$ & $\mathcal{D}_B(\Sigma)$ \\
\hline$(1,2,3)$ & 0 \\
$(1,3,2)$ & $1 / 2$ \\
$(2,1,3)$ & 0 \\
$(2,3,1)$ & 0 \\
$(3,1,2)$ & 0 \\
$(3,2,1)$ & $1 / 2$ \\
\hline
\end{tabular}
Given their distributions, what is the expected size of Alice's recursion call? (If Alice is lucky enough to choose the median as her pivot, we treat the size of the recursion call to be zero.)
A. $1 / 2$
B. 1
C. $3 / 2$
D. 2","There are four combinations of Bob's input and Alice's pivot, each with probability $\frac{1}{4}$. Except for when Bob picks $(3,2,1)$ and Alice picks the median 2 (hence the size is zero), all other combinations result in a recursion call of size 2 . The answer is $2 \times \frac{3}{4}=\frac{3}{2}$.","Alice recently enrolled in $6.046$ and learned the Median Finding algorithm. The details of the algorithm can be found in Recitation 1 notes.
Alice learned that a good pivot is always one that could make the size of the recursion call a constant fraction of the size of the input. For example, the ""median of medians"" for group of 5 on an array of length $n$ makes sure that the next recursion call has size of $\frac{7}{10} n$. However, Alice abhorred this idea of using ""median of medians"" as a pivot (she cried during quiz 1 after seeing the devilish MOMOM). Instead, she decides to choose her pivot in a randomized way. Alice's roommate Bob, however, did not enjoy randomization and wanted to sabotage her algorithm.
For simplicity, let's assume that the inputs to the median finding problem are permutations of $\{1,2, \ldots, n\}$. Formally, for a permutation $\sigma$ of odd length $n$, Alice designated a probability distribution $\mathcal{D}_A$ over all possible index. She chooses the $i$-th item in $\sigma, \sigma[i]$, as her pivot with probability $\mathcal{D}_A(i)$. Alice is satisfied if her algorithm provides a good pivot (as an easily satisfied person, she does not even care about the overall running time!) and her goal is to make her partition balanced in a way that minimizes the expected size of her recursion call.
Seeing Alice's probability distribution for pivots, Bob decides to generate adversarial input in a way that maximize the size of her recursion call. Formally, for an array of length $n$, Bob designated a probability distribution $\mathcal{D}_B$ over all possible length- $n$ permutations. For every permutation $\sigma$ of $\{1,2, \ldots, n\}$, he chooses $\sigma$ as his adversarial input with probability $\mathcal{D}_B(\sigma)$
Both Alice and Bob wonder what the expected size of Alice's recursion call would be if both of them choose their probability distributions optimally.
Model the interaction between Alice and Bob as a zero sum game, and define the pay-off matrix. ",Let the $n \times n$ ! matrix $A_{i \sigma}$ be payoff matrix for Alice. The payoff matrix for Bob is its negation. Then $A_{i \sigma}$ is equal to the size of the recursive call if the input is $\sigma$ and the pivot is $\sigma[i]$.
38,EECS,18.C06,Linear Algebra and Optimization,18.02,None,Problem Set 2,Matrix Inverse,4,nan,0.1234567901,Text,"Find a $2 \times 2$ matrix $A$ so that
$$
A\left[\begin{array}{l}
1 \\
0
\end{array}\right]=\left[\begin{array}{l}
3 \\
2
\end{array}\right] \text { and } A\left[\begin{array}{l}
1 \\
2
\end{array}\right]=\left[\begin{array}{l}
1 \\
8
\end{array}\right].
$$",Expression,"We can write the given conditions as the matrix equation
$$
A\left[\begin{array}{ll}
1 & 1 \\
0 & 2
\end{array}\right]=\left[\begin{array}{ll}
3 & 1 \\
2 & 8
\end{array}\right] \text {. }
$$
Since
$$
\left[\begin{array}{ll}
1 & 1 \\
0 & 2
\end{array}\right]^{-1}=\left[\begin{array}{cc}
1 & -1 / 2 \\
0 & 1 / 2
\end{array}\right]
$$
right-multiplying by this matrix we obtain
$$
A=\left[\begin{array}{ll}
3 & 1 \\
2 & 8
\end{array}\right]\left[\begin{array}{cc}
1 & -1 / 2 \\
0 & 1 / 2
\end{array}\right]=\left[\begin{array}{cc}
3 & -1 \\
2 & 3
\end{array}\right]
$$
which is the unique matrix with the desired property.","Find a $2 \times 2$ matrix $A$ where
$$
A\left[\begin{array}{l}
1 \\
2
\end{array}\right]=\left[\begin{array}{c}
-3 \\
7
\end{array}\right] \quad \text { and } \quad A\left[\begin{array}{c}
-1 \\
2
\end{array}\right]=\left[\begin{array}{c}
-5 \\
1
\end{array}\right]
$$
Is there a unique matrix that satisfies the above equations?","There are four unknowns in the matrix $A$ and we can write down a linear system constraining them, based on where we want it to send the vectors above. Writing it out, we have
$$
\left[\begin{array}{cccc}
1 & 2 & 0 & 0 \\
0 & 0 & 1 & 2 \\
-1 & 2 & 0 & 0 \\
0 & 0 & -1 & -1
\end{array}\right]\left[\begin{array}{c}
A_{1,1} \\
A_{1,2} \\
A_{2,1} \\
A_{2,2}
\end{array}\right]=\left[\begin{array}{c}
-3 \\
7 \\
-5 \\
1
\end{array}\right]
$$
The matrix is invertible so the solution is unique. Solving the linear system (using Gaussian elimination) we get
$$
\left[\begin{array}{c}
A_{1,1} \\
A_{1,2} \\
A_{2,1} \\
A_{2,2}
\end{array}\right]=\left[\begin{array}{c}
1 \\
-2 \\
3 \\
2
\end{array}\right] \Rightarrow A=\left[\begin{array}{cc}
1 & -2 \\
3 & 2
\end{array}\right]
$$","Consider the matrix $A=\left(\begin{array}{ll}2 & 1 \\ 0 & 2\end{array}\right)$.
Write down the general solution of (1).","The general solution is
$$
\vec{x}(t)=\left(\begin{array}{c}
c_{1} e^{2 t} \\
0
\end{array}\right)+\left(\begin{array}{c}
c_{2} t e^{2 t} \\
c_{2} e^{2 t}
\end{array}\right)=\left(\begin{array}{c}
c_{1} e^{2 t}+c_{2} t e^{2 t} \\
c_{2} e^{2 t}
\end{array}\right) .
$$",There is a $3 \times 3$ real matrix $A$ so that $A^{2}=-I$. Hint: Think about determinants.,False. Suppose there is such an $A$. Then $\operatorname{det}\left(A^{2}\right)=\operatorname{det}(A)^{2}>0$. But $\operatorname{det}(-I)=(-1)^{3}=-1$. Thus we reach a contradiction and there can be no such $A$.
12,Mathematics,18.404,Theory of Computation,6.1210/18.200,None,Problem Set 2,Context-Free Language,2,a,0.3703703704,Text,"Let $D = \set{ztz}z\in\st0^*$
and $t\in\st0^*\st1\st0^*\st1\st0^*$ where $|t|=|z|\setend$.
Show that $D$ is not a \cfl.",Open,"Assume (for contradiction) that $D$ is a CFG and apply the pumping lemma to obtain the pumping length $p$. Let $s=0^{p+2} 10^{p} 10^{p+2}$. Because $s \in D$ and $|s| \geq p$ the pumping lemma says that we may write $s=u v x y z$ satisfying the lemma's three conditions. If either $v$ or $y$ contains a 1, then the string $u x z$ contains fewer than two $1 \mathrm{~s}$ and thus it cannot be a member of $D$. By condition three of the pumping lemma, parts $v$ and $y$ cannot together contain 0s from both of the two outer runs of 0s. Hence in the string $u v^{2} x y^{2} z$ the 1s cannot both remain in the middle third and so $u v^{2} x y^{2} z$ is not in $D$.","Let $D = \set{ztz}z\in\st0^*$
and $t\in\st0^*\st1\st0^*\st1\st0^*$ where $|t|=|z|\setend$.
Is $D \union (\SS\SS\SS)^*$ a \cfl?  Why or why not?",$D \cup(\Sigma \Sigma \Sigma)^{*}$ equals $(\Sigma \Sigma \Sigma)^{*}$ which is a CFL.,"Let $D = \set{ztz}z\in\st0^*$
and $t\in\st0^*\st1\st0^*\st1\st0^*$ where $|t|=|z|\setend$.
Is $D \union \SS(\SS\SS\SS)^*$ a \cfl?  Why or why not?","If $D \cup \Sigma(\Sigma \Sigma \Sigma)^{*}$ were a CFL, then its intersection with the regular language $(\Sigma \Sigma \Sigma)^{*}$ would also be a CFL. However that intersection equals $D$ which we've shown isn't a CFL, and thus $D \cup \Sigma(\Sigma \Sigma \Sigma)^{*}$ isn't a CFL.","Let $C=\set{zuz} z\in\st0^*$ and $u\in\st0^*\st1\st0^*$
where $|u|=|z|\setend$.  Show that $C$ is a \cfl\ by giving a \pda\ that recognizes $C$.","$\quad C$ is the language of all strings $s$ whose length is a multiple of 3 and where $s$ contains a single 1 in the middle third and os everywhere else.
The PDA for $C$ operates by using the same idea. It begins by reading 0 s and pushing them on the stack. At any point it nondeterministically reads 010. From that point on it reads either 0 and pops 00 , or reads 00 and pops 0 , and continues by repeating this process. If the stack is ever empty at the end of the input, it accepts."
36,Mathematics,18.404,Theory of Computation,6.1210/18.200,None,Problem Set 5,P and NP Classes,2,nan,1.111111111,Text,"Say that two Boolean formulas are
\defin{equivalent} if they have the same set of variables and are
true on the same set of assignments to those variables (i.e., they
describe the same Boolean function).  A Boolean formula is
\defin{minimal} if no shorter Boolean formula is equivalent to it. 
(For definiteness, say that the length of a Boolean formula is the
number of symbols it has.)
Let \lang{MIN-FORMULA} be the collection of minimal Boolean formulas. \\
Show that $\lang{MIN-FORMULA}\in\pspace$.  ",Open,"The following algorithm shows MIN-FORMULA $\quad$ PSPACE.
""On input $\phi$ :
1. For each formula $\psi$ shorter than $\phi$:
2. For each assignment to the variables of $\phi$:
3. If $\phi$ and $\psi$ differ on that assignment, continue with the next $\psi$, else continue with the next assignment.
4. Reject: $\phi$ and $\psi$ are equivalent.
5. Accept: no shorter equivalent formula was found.""
The space used by this algorithm is for storing one formula and one assignment, and is therefore linear in the size of $\phi$.","See the definition of \lang{MIN-FORMULA} given in Problem 2.  
Explain why the following argument fails to show that
$\lang{MIN-FORMULA} \in \conp$:
\begin{enumerate}
\item If $\phi \not\in \lang{MIN-FORMULA}$, then $\phi$ has a smaller
equivalent formula. 
\item An \ntm\ can verify that $\phi \in \overline{\lang{MIN-FORMULA}}$
by guessing that formula.
\end{enumerate}","If $\phi \in \overline{M I N-F O R M U L A}$, some smaller formula $\psi$ is equivalent to $\phi$. However, this formula $\psi$ may not be an good certificate for confirming "" $\phi \in \overline{M I N-F O R M U L A}$ "" because we may not be able to check the certificate within polynomial time. Checking whether two formulas are equivalent may require exponential time.","Let $\lang{SAT}_{\ge 2}=\setb{\phi} \phi$ is a Boolean formula
that has at least two satisfying assignments\setend. \\
Let $\lang{SAT}_{=2}=\setb{\phi} \phi$ is a Boolean formula
that has exactly two satisfying assignments\setend.
Show that $\lang{SAT}_{= 2} \in \poly^\mathit{SAT}$. ","A similar argument shows that the analogous language $S A T_{\geq 3} \in \mathrm{NP} \subseteq \mathrm{P}^{S A T}$. Observing that $S A T_{=2}=S A T_{\geq 2} \cap \overline{S A T_{\geq 3}}$ and that $\mathrm{P}^{S A T}$ is closed under intersection and complement for the same reasons that $\mathrm{P}$ is closed under intersection and complement, we conclude that $S A T_{=2} \in \mathrm{P}^{S A T}$.","See the definition of \lang{MIN-FORMULA} given in Problem 2.  
Show (despite part a) that if $\poly = \np$, then
$\lang{MIN-FORMULA}\in\poly$.","The language of all pairs $\left\langle\phi_{1}, \phi_{2}\right\rangle$ of inequivalent Boolean formulas is an NP language. The certificate is the assignment on which their values differ. Assuming $\mathrm{P}=\mathrm{NP}$, this language and its complement are in P. A formula is not minimal if a smaller equivalent formula exists. Thus, given the above, $\overline{\text { MIN-FORMULA }} \in \mathrm{NP}$ because we can guess a smaller formula and check equivalence. Again, assuming $\mathrm{P}=\mathrm{NP}$, we have $\overline{M I N \text {-FORMULA }} \in \mathrm{P}$ and hence $M I N$-FORMULA $\in \mathrm{P}$."
325,Mathematics,18.01,Calculus I,None,None,Problem Set 7,Second Order Differential Equations,11,a,0.07919746568,Text,"On the last problem set, you computed the work done by the spring if the mass starts at $x=2$ and the spring pulls the mass back to $x=0$. The work was $\int_{0}^{2} k x d x=\frac{1}{2} k 2^{2}=2 k$. In general, if the mass starts at $x$ and moves to 0 , then the work done by the spring is $\frac{1}{2} k x^{2}$. Therefore, when the mass is at $x$ the potential energy in the spring is $\frac{1}{2} k x^{2}$. The kinetic energy is $\frac{1}{2} m x^{\prime}(t)^{2}$. So the total energy (kinetic plus potential) is
$$
E(t)=\frac{1}{2} m x^{\prime}(t)^{2}+\frac{1}{2} k x(t)^{2} .
$$
In physics, we learn that the total energy is conserved, so $E(t)$ is constant in time. We can check that mathematically by checking that $E^{\prime}(t)=0$.
Suppose that $x(t)$ obeys the equation (spring). Let $E(t)$ denote the energy at time $t$ as defined in (energy).
Compute $E^{\prime}(t)$.",Expression,"$$
\frac{d}{d t}\left(x^{\prime}(t)^{2}\right)=x^{\prime \prime}(t) \cdot 2 x^{\prime}(t) \quad \text { and } \quad \frac{d}{d t}\left(x(t)^{2}\right)=x^{\prime}(t) \cdot 2 x(t)
$$
So differentiating $E$ yields
$$
E^{\prime}(t)=\frac{m}{2} \cdot \frac{d}{d t}\left(x^{\prime}(t)^{2}\right)+\frac{k}{2} \cdot \frac{d}{d t}\left(x(t)^{2}\right)=m x^{\prime \prime}(t) x^{\prime}(t)+k x^{\prime}(t) x(t) .
$$","On the last problem set, you computed the work done by the spring if the mass starts at $x=2$ and the spring pulls the mass back to $x=0$. The work was $\int_{0}^{2} k x d x=\frac{1}{2} k 2^{2}=2 k$. In general, if the mass starts at $x$ and moves to 0 , then the work done by the spring is $\frac{1}{2} k x^{2}$. Therefore, when the mass is at $x$ the potential energy in the spring is $\frac{1}{2} k x^{2}$. The kinetic energy is $\frac{1}{2} m x^{\prime}(t)^{2}$. So the total energy (kinetic plus potential) is
$$
E(t)=\frac{1}{2} m x^{\prime}(t)^{2}+\frac{1}{2} k x(t)^{2} .
$$
In physics, we learn that the total energy is conserved, so $E(t)$ is constant in time. We can check that mathematically by checking that $E^{\prime}(t)=0$.
Suppose that $x(t)$ obeys the equation (spring). Let $E(t)$ denote the energy at time $t$ as defined in (energy).
Simplify the expression by using the equation (spring) for $x^{\prime \prime}(t)$.","By (spring) we then have
$$
E^{\prime}(t)=m\left(-\frac{k}{m} x(t)\right) x^{\prime}(t)+k x^{\prime}(t) x(t).
$$","On the last problem set, you computed the work done by the spring if the mass starts at $x=2$ and the spring pulls the mass back to $x=0$. The work was $\int_{0}^{2} k x d x=\frac{1}{2} k 2^{2}=2 k$. In general, if the mass starts at $x$ and moves to 0 , then the work done by the spring is $\frac{1}{2} k x^{2}$. Therefore, when the mass is at $x$ the potential energy in the spring is $\frac{1}{2} k x^{2}$. The kinetic energy is $\frac{1}{2} m x^{\prime}(t)^{2}$. So the total energy (kinetic plus potential) is
$$
E(t)=\frac{1}{2} m x^{\prime}(t)^{2}+\frac{1}{2} k x(t)^{2} .
$$
In physics, we learn that the total energy is conserved, so $E(t)$ is constant in time. We can check that mathematically by checking that $E^{\prime}(t)=0$.
Suppose that $x(t)$ obeys the equation (spring). Let $E(t)$ denote the energy at time $t$ as defined in (energy).
Show that $E^{\prime}(t)=0$.","By (spring) we then have
$$
E^{\prime}(t)=m\left(-\frac{k}{m} x(t)\right) x^{\prime}(t)+k x^{\prime}(t) x(t)=0 .
$$","In this problem, we continue modeling a mass-spring system. In the last problem set, we modelled a mass-spring system by
$$
x^{\prime \prime}(t)=-\frac{k}{m} x(t) .
$$
This model doesn't take friction into account. The force of friction pushes in the opposite direction of the velocity. We model the force of friction by a force of the form $-f x^{\prime}(t)$, where $f$ is a friction constant that depends on the spring.
$$
x^{\prime \prime}(t)=-\frac{k}{m} x(t)-\frac{f}{m} x^{\prime}(t) .
$$
For a spring without friction, you showed on the last problem set that $E(t)=$ $(1 / 2) m x^{\prime}(t)^{2}+(1 / 2) k x(t)^{2}$ is constant in $t$, by checking that $E^{\prime}(t)=0$. This means that the kinetic energy of the spring plus the potential energy of the spring is conserved.
Again let $E(t)=(1 / 2) m x^{\prime}(t)^{2}+(1 / 2) k x(t)^{2}$. If $x(t)$ obeys $(*)$, show that $E^{\prime}(t) \leq 0$. If $x^{\prime}(t) \neq 0$, then show that $E^{\prime}(t)<0$.
(Physically, friction converts some of the kinetic energy in the spring into heat energy. The total energy in the universe is still conserved, but if we just consider how much energy there is in the kinetic energy of the spring plus the potential energy of the spring, that amount of energy is decreasing.)","Calculate $E^{\prime}(t)$ :
$$
E^{\prime}(t)=\frac{m}{2} 2 x^{\prime}(t) x^{\prime \prime}(t)+\frac{k}{2} 2 x(t) x^{\prime}(t)=x^{\prime}(t)\left(m x^{\prime \prime}(t)+k x(t)\right) .
$$
Using the formula for $x^{\prime \prime}(t)$ from part a leads to
$$
\begin{aligned}
E^{\prime}(t) & =x^{\prime}(t)\left(m\left(-\frac{k}{m} x(t)-\frac{f}{m} x^{\prime}(t)\right)+k x(t)\right) \\
& =x^{\prime}(t)\left(-k x(t)-f x^{\prime}(t)+k x(t)\right)=-f \cdot\left(x^{\prime}(t)\right)^{2} .
\end{aligned}
$$
Since $f$ is a positive constant and $\left(x^{\prime}(t)\right)^{2}$ is squared, so it is always nonnegative, $E^{\prime}(t) \leq 0$. In particular, if $x^{\prime}(t) \neq 0$, then $\left(x^{\prime}(t)\right)^{2}>0$, so $E^{\prime}(t)=-f\left(x^{\prime}(t)\right)^{2}<$ 0."
435,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Problem Set 3,Gradient Descent,3,a,0.03125,Text,"Although squared loss has a lot of good properties, it can also be very sensitive to ""outliers"" (points that may have been generated by some kind of underlying error in the data-generation process that we don't really want to model). We'll consider some alternative loss functions.
We could just penalize the absolute difference between $g$ and $a$ (where $g$ denotes the guess and $a$ denotes the actual label of a data point), so $L_{1}(g, a)=|g-a|$. Select all that are true about this loss function:
(a) It is continuous.
(b) Its first derivative w.r.t. $g$ is continuous.
(c) It penalizes big distances between $g$ and $a$ much less than squared error.",Multiple Choice,"(a) It is continuous.
(c) It penalizes big distances between $g$ and $a$ much less than squared error.","Although squared loss has a lot of good properties, it can also be very sensitive to ""outliers"" (points that may have been generated by some kind of underlying error in the data-generation process that we don't really want to model). We'll consider some alternative loss functions.
We could consider an alternative called pseudo huber loss, where $L_{h}(g, a)=\sqrt{1+(g-a)^{2}}-1$. Select all that are true about this loss function:
(a) It is continuous.
(b) Its first derivative w.r.t. $g$ is continuous.
(c) It penalizes big distances between $g$ and $a$ much less than squared error.","(a) It is continuous.
(b) Its first derivative w.r.t. $g$ is continuous.
(c) It penalizes big distances between $g$ and $a$ much less than squared error.","Although squared loss has a lot of good properties, it can also be very sensitive to ""outliers"" (points that may have been generated by some kind of underlying error in the data-generation process that we don't really want to model). We'll consider some alternative loss functions.
What is $\frac{\partial}{\partial g} L_{h}(g, a) ?$ Enter a Python expression involving $\mathrm{g}$ and $\mathrm{a}$.
Use $* *$ for exponentiation and $\operatorname{sqrt}(x)$ for the square root of $x$.",(g-a)/sqrt(1 + (g - a)**2),"We use gradient descent to minimize an objective function. In $\mathrm{ML}$, we typically either use a standard objective function, or we design our own objective functions for specific applications. The choice of objective function is critical, since this specifies our optimization target. This choice is one of many technical decisions in which we encode human values (with or without intentionality!).
When we prioritize one objective or value, we inevitably introduce trade-offs with others. We'll take a look at this by considering two common objective functions: L1 loss, or Mean Absolute Error (MAE), and L2 loss, or Mean Squared Error (MSE).
Say you have $n$ data points $\left(x_{i}, y_{i}\right)$, and you're trying to fit the parameters $\theta$ of a function $f_{\theta}\left(x_{i}\right)$ such that you can predict $y_{i}$ from $x_{i}$. The $L 1$ objective function minimizes the absolute differences between target values $y_{i}$ and predicted values $f_{\theta}\left(x_{i}\right)$.
$$
J(\theta)=\frac{1}{n} \sum_{i=1}^{n}\left|y_{i}-f_{\theta}\left(x_{i}\right)\right|
$$
The L2 objective function minimizes the squared differences between target values $y_{i}$ and predicted values $f_{\theta}\left(x_{i}\right)$.
$$
J(\theta)=\frac{1}{n} \sum_{i=1}^{n}\left(y_{i}-f_{\theta}\left(x_{i}\right)\right)^{2}
$$
How do you think each of these loss functions would handle outliers?","Since the difference is squared, L2 loss is much more sensitive to outliers. Imagine you are trying to fit a line to some data, and most of your points can be fit to a line with error $\varepsilon<1$, but one point has large error $\mathrm{E}>>1$. While both losses are affected by the outlier, the effect is linear in $\mathrm{L} 1$ and squared in $\mathrm{L} 2$."
86,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 2,Propositional Logic,3,biv,0.0744047619,Text,"Consider a domain with propositions $\mathrm{A}, \mathrm{B}, \mathrm{C}$, and $\mathrm{D}$, and the particular model $m=\{A=t, B=f, C=t, D=f\}$. For each of these sentences, indicate whether it is valid, unsatisifiable, not valid but true in $\mathrm{m}$, or not unsatisifiable but false in $\mathrm{m}$.
$A \Rightarrow C \wedge D$",Multiple Choice,"not unsatisfiable, but false in m.","Consider a domain with propositions $\mathrm{A}, \mathrm{B}, \mathrm{C}$, and $\mathrm{D}$, and the particular model $m=\{A=t, B=f, C=t, D=f\}$. For each of these sentences, indicate whether it is valid, unsatisifiable, not valid but true in $\mathrm{m}$, or not unsatisifiable but false in $\mathrm{m}$.
$$
B \Rightarrow C \wedge D
$$","not valid, but true in m.","Consider a domain with propositions $\mathrm{A}, \mathrm{B}, \mathrm{C}$, and $\mathrm{D}$, and the particular model $m=\{A=t, B=f, C=t, D=f\}$. For each of these sentences, indicate whether it is valid, unsatisifiable, not valid but true in $\mathrm{m}$, or not unsatisifiable but false in $\mathrm{m}$.
$$
\begin{aligned}
& (A \wedge C) \Leftrightarrow(B \wedge D)\\
\end{aligned}
$$","not unsatisfiable, but false in m.","Consider a domain with propositions $\mathrm{A}, \mathrm{B}, \mathrm{C}$, and $\mathrm{D}$, and the particular model $m=\{A=t, B=f, C=t, D=f\}$. For each of these sentences, indicate whether it is valid, unsatisifiable, not valid but true in $\mathrm{m}$, or not unsatisifiable but false in $\mathrm{m}$.
$$
A \Rightarrow \neg A
$$","not unsatisfiable, but false in m."
21,Mathematics,18.100B,Real Analysis,18.02,None,Problem Set 4,Convergence,3,nan,0.7142857143,Text,"Prove Corollary 3.4: In a metric space, a sequence can't converge to two different points. (Obviously, you can't use Corollary $3.4$ or anything that comes after that in the lecture notes.)",Open,"Suppose that $\left(x_{n}\right)$ converges to $l$ and to $l^{\prime}$. We use Lemma $3.3$ with $\left(x_{n}^{\prime}\right)=\left(x_{n}\right)$. Since $d\left(x_{n}, x_{n}^{\prime}\right)=$ 0, it follows that $d\left(l, l^{\prime}\right)=0$, so $l=l^{\prime}$.","Prove Lemma 3.5: in a metric space, every convergent sequence is Cauchy. (Same remark as before applies.)","Suppose that $\left(x_{n}\right)$ converges to $l$. This means that for every $\epsilon>0$, there is an $N$ such that $d\left(x_{n}, l\right)<\epsilon$ for $n \geq N$. Applying the triangle inequality, one gets
$$
d\left(x_{m}, x_{n}\right)<2 \epsilon \text { for } m, n \geq N
$$
Replacing $\epsilon$ by $\epsilon / 2$ in the original argument yields the Cauchy property.","Prove Lemma $2.17$ from the lecture summaries: any convergent sequence is Cauchy. (Obviously, you can't use Lemma $2.17$ or anything that came after that in the course.)","Let $\left(x_{n}\right)$ be a sequence converging to some limit $l$. Let $\varepsilon>0$ be given. Since $\left(x_{n}\right)$ is convergent, there exists $N \in \mathbb{N}$ such that $\left|x_{n}-l\right|<\frac{\varepsilon}{2}$ for $n>N$. Then for such $N$, and $m, n \geq N$
$$
\left|x_{m}-x_{n}\right|=\left|x_{m}-l+l-x_{n}\right| \leq\left|x_{m}-l\right|+\left|l-x_{n}\right|<\varepsilon
$$
by choice of $N$. Therefore $\left(x_{n}\right)$ is Cauchy.","Let $X$ be a metric space which is totally bounded. Show that there is a countable subset $B \subset X$ such that, for every point $l \in X$, there is a sequence in $B$ which converges to $l$.","For each $n \geq 1$, set $\varepsilon=\frac{1}{n}$. Since $X$ is totally bounded, there exists a finite set $F_{n}$ such that for each $x \in X$, there is a $y \in F_{n}$ with $d(x, y)<\varepsilon$. Let $B=\bigcup_{n \geq 1} F_{n}$. Since $B$ is a countable union of finite sets, it is countable.
Let $l \in X$ be given. For each $n \in \mathbb{N}$, let $x_{n}$ be a point in $F_{n}$ such that $d\left(x_{n}, k\right)<\frac{1}{n}$. Then $\left(x_{n}\right)$ is a sequence in $B$ converging to $l$."
69,Mathematics,18.01,Calculus I,None,None,Problem Set 2,Integration,10,a,0.03959873284,Text,"Suppose that a train is moving. It starts at time $t=0$ and ends at time $t=5$. At time $t$, its velocity is equal to $5-t$.
Approximately how far did the train go from time $t=2$ to time $t=2.1-5$ or 3 or $.5$ or $.3$ or $.1 ?$",Multiple Choice,From time 2 to $2.1$ the velocity is approximately $5-2=3$. This goes on for an amount of time $\Delta t=.1$. The distance traversed in this time is approximately $3 \Delta t=.3$.,"Suppose that a train is moving. It starts at time $t=0$ and ends at time $t=5$. At time $t$, its velocity is equal to $5-t$.
Approximately how far did the train go from time $t$ to time $t+\Delta t$?",From time $t$ to $\Delta t$ the velocity is approximately $5-\Delta t$. This goes on for an amount of time $\Delta t$. The distance traversed in this time is approximately $(5-t) \Delta t$.,"Suppose that a train is moving. It starts at time $t=0$ and ends at time $t=5$. At time $t$, its velocity is equal to $5-t$.
Write down an integral for the total change in the position of the train.","As the times $0=t_{0}, t_{1}, \ldots, t_{n}=5$ get closer together $\left(\Delta t_{i}=t_{i+1}-t_{i} \rightarrow 0\right)$, the sum $\sum_{i=0}^{n-1}(5-t) \Delta t_{i}$ approximating the total distance converges to the integral:
$$
\int_{0}^{5}(5-t) d t .
$$","Suppose that a train is moving. It starts at time $t=0$ and ends at time $t=5$. At time $t$, its velocity is equal to $5-t$.
Compute the integral.","$$
\int_{0}^{5}(5-t) d t=\left.\left(5 t-\frac{t^{2}}{2}\right)\right|_{0} ^{5}=\frac{25}{2} .
$$"
238,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 7,Reductions,2,b,0.78125,Text,"In this section, we will consider reductions between MDPs. Intuitively, $A$ can be reduced to $B$ if $B$ is at least as hard as A. More formally, we will say that a set of MDPs $A$ can be reduced to another set of MDPs $B$ if it is possible to do the following:
1. Given an MDP in $A$, convert it to an MDP in $B$ (by any procedure, ignoring its complexity);
2. Given that MDP in $B$, find an optimal policy, e.g., using value iteration;
3. Convert the optimal policy back into an optimal policy for the original MDP in $A$ (using some fixed polynomial-time procedure).
For example, if $A$ is the set of all MDPs with $0<R\left(s, a, s^{\prime}\right)<100$ for all $s, a, s^{\prime}$, and $B$ is the set of all MDPs with all $0<R\left(s, a, s^{\prime}\right)<1$, then $A$ can be reduced to $B$ : given an MDP in $A$, we can construct an MDP in $B$ by dividing all rewards by 100 . The resulting optimal policy for the MDP in $B$ will automatically be an optimal policy for original MDP, so the conversion (step 3) is trivial.
Another example: if $A$ is the set of all MDPs with action space $\{0,1\}$, and $B$ is the set of all MDPs with action space \{""up"", ""down"", ""left"", ""right""\}, then A can be reduced to $\mathrm{B}$ : given an MDP in $A$, we can construct an MDP in $B$ by replacing all instances of the action 0 with ""up"", and all instances of the action 1 with ""down"" in $R$ and $P$. We could then ensure that the ""left"" and ""right"" actions will not be used by the optimal policy, for example, by making those actions always get $-\infty$ reward. With an optimal policy found, we can convert it to an optimal policy for the original MDP by replacing all instances of ""up"" with 0 , and all ""down"" with 1.
The set of all MDPs with rewards $R\left(s, a, s^{\prime}\right)$ can be reduced to the set of all MDPs with rewards $R^{\prime}(s)$, that is, specified only in terms of the current state.
Which of the following informal descriptions would help prove this reduction?
(a) Given an MDP with rewards $R^{\prime}(s)$, we can create an MDP with rewards $R\left(s, a, s^{\prime}\right)=R^{\prime}(s)$, ignoring the $a$ and $s^{\prime}$ inputs. 
(b) Given an MDP with rewards $R\left(s, a, s^{\prime}\right)$, we can create an MDP with state space $\mathcal{S} \times \mathcal{A} \times \mathcal{S}^{\prime}$, where being in the state $\left(s, a, s^{\prime}\right)$ means that we are in state $s^{\prime}$ from the original MDP, after having just executed action $a$ from state $s$.
(c) Given an MDP with rewards $R\left(s, a, s^{\prime}\right)$, we can use set the discounting factor $\gamma$ in the new MDP in such a way that the rewards only depend on $s$.
(d) Given an MDP with rewards $R\left(s, a, s^{\prime}\right)$, select one action $a_{*}$ and one possible next state $s_{* \prime}^{\prime}$ and define $R^{\prime}(s)=$ $R\left(s, a_{*}, s_{*}^{\prime}\right)$.",Multiple Choice,"(b) Given an MDP with rewards $R\left(s, a, s^{\prime}\right)$, we can create an MDP with state space $\mathcal{S} \times \mathcal{A} \times \mathcal{S}^{\prime}$, where being in the state $\left(s, a, s^{\prime}\right)$ means that we are in state $s^{\prime}$ from the original MDP, after having just executed action $a$ from state $s$.","In this section, we will consider reductions between MDPs. Intuitively, $A$ can be reduced to $B$ if $B$ is at least as hard as A. More formally, we will say that a set of MDPs $A$ can be reduced to another set of MDPs $B$ if it is possible to do the following:
1. Given an MDP in $A$, convert it to an MDP in $B$ (by any procedure, ignoring its complexity);
2. Given that MDP in $B$, find an optimal policy, e.g., using value iteration;
3. Convert the optimal policy back into an optimal policy for the original MDP in $A$ (using some fixed polynomial-time procedure).
For example, if $A$ is the set of all MDPs with $0<R\left(s, a, s^{\prime}\right)<100$ for all $s, a, s^{\prime}$, and $B$ is the set of all MDPs with all $0<R\left(s, a, s^{\prime}\right)<1$, then $A$ can be reduced to $B$ : given an MDP in $A$, we can construct an MDP in $B$ by dividing all rewards by 100 . The resulting optimal policy for the MDP in $B$ will automatically be an optimal policy for original MDP, so the conversion (step 3) is trivial.
Another example: if $A$ is the set of all MDPs with action space $\{0,1\}$, and $B$ is the set of all MDPs with action space \{""up"", ""down"", ""left"", ""right""\}, then A can be reduced to $\mathrm{B}$ : given an MDP in $A$, we can construct an MDP in $B$ by replacing all instances of the action 0 with ""up"", and all instances of the action 1 with ""down"" in $R$ and $P$. We could then ensure that the ""left"" and ""right"" actions will not be used by the optimal policy, for example, by making those actions always get $-\infty$ reward. With an optimal policy found, we can convert it to an optimal policy for the original MDP by replacing all instances of ""up"" with 0 , and all ""down"" with 1.
Here we will show that the set of all MDPs with finite horizons can be reduced to the set of all MDPs with infinite horizon. Given a finite-horizon $\operatorname{MDP}(\mathcal{S}, \mathcal{A}, P, R, H)$, we will construct an infinite-horizon MDP $\left(\mathcal{S}^{\prime}, \mathcal{A}, P^{\prime}, R^{\prime}, \gamma\right)$. Which of the following are good choices for $\mathcal{S}^{\prime}, P^{\prime}, R^{\prime}$, and $\gamma$? Note that you may need to check multiple boxes to fully define $P^{\prime}$ and $R^{\prime}$.
(a) $\mathcal{S}^{\prime}=\mathcal{S}$
(b) $\mathcal{S}^{\prime}=\mathcal{S} \times\{1,2, \ldots, H\}$
(c) $\mathcal{S}^{\prime}=(\mathcal{S} \times\{1,2, \ldots, H\}) \cup\{\operatorname{sink}\}$
(d) $\mathcal{S}^{\prime}=(\mathcal{S} \times\{1,2, \ldots, H, H+1, \ldots\}) \cup\{\operatorname{sink}\}$
(e) $\gamma=H$
(f) $\gamma=0$
(g) $\gamma=0.99$
(h) $\gamma=1$
(i) $P^{\prime}\left(s^{\prime} \mid s, a\right)=P\left(s^{\prime} \mid s, a\right)$
(j) $P^{\prime}(\operatorname{sink} \mid(s, H), a)=1$
(k) $P^{\prime}(\sin k \mid \sin k, a)=1$
(l) $P^{\prime}\left(\left(s^{\prime}, h+1\right) \mid(s, h), a\right)=P\left(s^{\prime} \mid s, a\right)$ for $h<H$
(m) $P^{\prime}(\cdot \mid(s, h), a)=0$ if not otherwise specified
(n) $R^{\prime}(\operatorname{sink}, \cdot, \cdot)=\infty$
(o) $R^{\prime}(\sin \mathrm{k}, \cdot, \cdot)=0$
(p) $R^{\prime}\left((s, h), a,\left(s^{\prime}, h+1\right)\right)=R\left(s, a, s^{\prime}\right)$.
(q) $R^{\prime}(\cdot, \cdot, \cdot)=0$ if not otherwise specified","(c) $\mathcal{S}^{\prime}=(\mathcal{S} \times\{1,2, \ldots, H\}) \cup\{\operatorname{sink}\}$
(h) $\gamma=1$
(j) $P^{\prime}(\operatorname{sink} \mid(s, H), a)=1$
(k) $P^{\prime}(\sin k \mid \sin k, a)=1$
(l) $P^{\prime}\left(\left(s^{\prime}, h+1\right) \mid(s, h), a\right)=P\left(s^{\prime} \mid s, a\right)$ for $h<H$
(m) $P^{\prime}(\cdot \mid(s, h), a)=0$ if not otherwise specified
(o) $R^{\prime}(\sin \mathrm{k}, \cdot, \cdot)=0$
(p) $R^{\prime}\left((s, h), a,\left(s^{\prime}, h+1\right)\right)=R\left(s, a, s^{\prime}\right)$.
(q) $R^{\prime}(\cdot, \cdot, \cdot)=0$ if not otherwise specified","A stochastic shortest paths problem is a specific type of MDP in which
\begin{itemize}
\item $\mathcal{S}$ and $\mathcal{A}$ are discrete sets of states and actions, as in a standard MDP.
\item There is a goal set $G \subset S$.
\item The transition function $T\left(s, a, s^{\prime}\right)=P\left(S_{t+1}=s^{\prime} \mid S_{t}=s, A_{t}=a\right)$, is almost as usual, except that all states in $G$ are absorbing; that is, for all $s \in G$, and all $a \in A, T(s, a, s)=1$.
\item The reward function is $R\left(s, a, s^{\prime}\right)=0$ for all $s \in G$ and $R\left(s, a, s^{\prime}\right)=-1$ otherwise (it can really be any negative value, but we will restrict our attention to this case).
\item The discount factor $\gamma=1$.
\end{itemize}
What is the optimal $Q$ function for the following state-action pairs? You can write an unevaluated numerical expression, but it may help to be reminded that $\sum_{i=1}^{\infty} a r^{i}=(a r) /(1-r)$.
$$
\begin{aligned}
& Q\left(s_{1}, a\right) \\
& Q\left(s_{1}, b\right) \\
& Q\left(s_{2}, a\right) \\
& Q\left(s_{3}, a\right) \\
\end{aligned}
$$","$$
\begin{aligned}
& Q\left(s_{1}, a\right) = -2.11 \\
& Q\left(s_{1}, b\right) = -3 \\
& Q\left(s_{2}, a\right) = -1.11 \\
& Q\left(s_{3}, a\right) = -2 \\
\end{aligned}
$$","A stochastic shortest paths problem is a specific type of MDP in which
\begin{itemize}
\item $\mathcal{S}$ and $\mathcal{A}$ are discrete sets of states and actions, as in a standard MDP.
\item There is a goal set $G \subset S$.
\item The transition function $T\left(s, a, s^{\prime}\right)=P\left(S_{t+1}=s^{\prime} \mid S_{t}=s, A_{t}=a\right)$, is almost as usual, except that all states in $G$ are absorbing; that is, for all $s \in G$, and all $a \in A, T(s, a, s)=1$.
\item The reward function is $R\left(s, a, s^{\prime}\right)=0$ for all $s \in G$ and $R\left(s, a, s^{\prime}\right)=-1$ otherwise (it can really be any negative value, but we will restrict our attention to this case).
\item The discount factor $\gamma=1$.
\end{itemize}
For each of the SSPs, is there a finite number of iterations after which you could terminate value iteration and extract an optimal policy? Explain your answer. (You don't have to provide a precise number).","There is a point at which the estimated value of action $b$ is worse than the value of action a and after that, if we stop, the greedy policy will in fact be optimal."
79,EECS,6.121,Introduction to Algorithms,"6.100A, 6.1200",6.101,Mini Quiz 2,Hash Tables,4,nan,0.2222222222,Text,"Assume we have use a chaining hash table with $m=8$ locations in the direct access array (i.e., we have 8 chains, including the empty chains). Suppose we use the hash function $h(k)=k \bmod m$. Choose all correct answers:
After inserting the set of keys $\{1,4,9,16,25,36,49,64,81,100\}$,
1. The average chain length is $\frac{5}{4}$.
2. There is no chain longer than 4.
3. There are only 4 empty chains.
4. We can use an open address table of size $m=8$ to store the set of keys.",Multiple Choice,"1. The average chain length is $\frac{5}{4}$.
Correct. We have 10 keys in a hash table of size 8, so 10/8 = 5/4.
2. There is no chain longer than 4.
Incorrect. There are 5 keys (i.e., keys 1, 9, 25, 49, and 81) that hash to location 1.
3. There are only 4 empty chains.
Incorrect. Locations 0, 1, and 4 have non-empty chains and all other locations have empty chains.
4. We can use an open address table of size $m=8$ to store the set of keys.
Incorrect. We cannot use open addressing when $n>m$.","After graduating from MIT, Ben went to work for Atem Inc. where he had a chance to apply what he learned about hash tables in 6.046. Consider a hash table with $n$ items and $m=n$ slots where collisions are resolved by chaining. The hash function is chosen from a pairwise independent hash family $\mathcal{H}$ consisting of functions $h: \mathcal{U} \rightarrow\{0,1, \ldots, m-1\}$.
Ben remembered the definition of a pairwise independent hash family from a $6.046$ problem set and a recitation: $\mathcal{H}$ is pairwise independent if for every pair of distinct $x, y \in \mathcal{U}$, when $h$ is chosen uniformly at random from $\mathcal{H}$, the probability distribution of $(h(x), h(y))$ is uniformly random in the set $\{0,1, \ldots, m-1\} \times\{0,1, \ldots, m-1\}$. In particular, $h(x)$ and $h(y)$ are independent random variables.
Ben learned in $6.046$ how to analyze the expected length of any given chain, but he realizes there is more to the story. His implementation showed that some chains can be rather long. In this problem, you will help Ben bound the length of the longest chain.
Show that with probability at least $3 / 4$, no chain is longer than $2 \sqrt{m}$.","We know by part (b) that the probability that any given chain is longer than $2 \sqrt{m}$ is at most $1 / 4 m$. By a union bound, the probability that there exists a chain (out of $m$ ) that is longer than $2 \sqrt{m}$ is at most $m \cdot 1 / 4 m=1 / 4$. Thus, with probability at least $3 / 4$, no chain is longer than $2 \sqrt{m}$. ","After graduating from MIT, Ben went to work for Atem Inc. where he had a chance to apply what he learned about hash tables in 6.046. Consider a hash table with $n$ items and $m=n$ slots where collisions are resolved by chaining. The hash function is chosen from a pairwise independent hash family $\mathcal{H}$ consisting of functions $h: \mathcal{U} \rightarrow\{0,1, \ldots, m-1\}$.
Ben remembered the definition of a pairwise independent hash family from a $6.046$ problem set and a recitation: $\mathcal{H}$ is pairwise independent if for every pair of distinct $x, y \in \mathcal{U}$, when $h$ is chosen uniformly at random from $\mathcal{H}$, the probability distribution of $(h(x), h(y))$ is uniformly random in the set $\{0,1, \ldots, m-1\} \times\{0,1, \ldots, m-1\}$. In particular, $h(x)$ and $h(y)$ are independent random variables.
Ben learned in $6.046$ how to analyze the expected length of any given chain, but he realizes there is more to the story. His implementation showed that some chains can be rather long. In this problem, you will help Ben bound the length of the longest chain.
Ben (still) loves tail bounds and wants to analyze the probability that for a fixed slot $j$, the chain at slot $j$ is (strictly) longer than $2 \sqrt{m}$. Show that this probability is at most $\frac{1}{4 m}$.","We first compute the variance of $L$. By pairwise independence,
$$
\operatorname{Var}[L]=\sum_{i=1}^{n} \operatorname{Var}\left[X_{i}\right]=\sum_{i=1}^{n} \mathrm{E}\left[I_{i}^{2}\right]-\mathrm{E}\left[I_{i}\right]^{2}=n \cdot\left(1 / m-1 / m^{2}\right) \leq n / m=1
$$
Applying Chebyshev's inequality, we get
$$
\operatorname{Pr}[L>2 \sqrt{m}]=\operatorname{Pr}[L \geq 1+2 \sqrt{m}] \leq \operatorname{Pr}[|L-1| \geq 2 \sqrt{m}] \leq 1 / 4 m.
$$","After graduating from MIT, Ben went to work for Atem Inc. where he had a chance to apply what he learned about hash tables in 6.046. Consider a hash table with $n$ items and $m=n$ slots where collisions are resolved by chaining. The hash function is chosen from a pairwise independent hash family $\mathcal{H}$ consisting of functions $h: \mathcal{U} \rightarrow\{0,1, \ldots, m-1\}$.
Ben remembered the definition of a pairwise independent hash family from a $6.046$ problem set and a recitation: $\mathcal{H}$ is pairwise independent if for every pair of distinct $x, y \in \mathcal{U}$, when $h$ is chosen uniformly at random from $\mathcal{H}$, the probability distribution of $(h(x), h(y))$ is uniformly random in the set $\{0,1, \ldots, m-1\} \times\{0,1, \ldots, m-1\}$. In particular, $h(x)$ and $h(y)$ are independent random variables.
Ben learned in $6.046$ how to analyze the expected length of any given chain, but he realizes there is more to the story. His implementation showed that some chains can be rather long. In this problem, you will help Ben bound the length of the longest chain.
Let's start with what Ben learned in 6.046. For a fixed slot $j$, show that the expected length of the chain at slot $j$ is 1.","Let the items be $x_{1}, \ldots, x_{n}$. Define indicator random variables $I_{1}, \ldots, I_{n}$ where
$$
I_{i}=\left\{\begin{array}{cc}
1 & \text { if } h\left(x_{i}\right)=j \\
0 & \text { otherwise }
\end{array}\right.
$$
Note that the length of the chain is $L=\sum_{i=1}^{n} I_{i}$. The expectation of each $I_{i}$ is the same as $\operatorname{Pr}_{h \in \mathcal{H}}\left[I_{i}=1\right]$ which is $1 / m$. The expected length $L$ of the chain at slot $j$ is
$$
\mathbb{E}_{h \in \mathcal{H}}[L]=\mathbb{E}_{h \in \mathcal{H}}\left[\sum_{i=1}^{n} I_{i}\right]=\sum_{i=1}^{n} \mathbb{E}_{h \in \mathcal{H}}\left[I_{i}\right]=n \cdot \frac{1}{m}=1
$$
where we use linearity of expectation to go from the second to the third term. "
19,EECS,6.18,Computer Systems Engineering,"6.1010, 6.1910",None,Hands-on 3,MapReduce,6,nan,0.1428571429,Text,Which invocations run in parallel? (Assuming there are enough cores.),Open,"The invocations to doMap() run in parallel, and then the invocations of doReduce() run in parallel.",How many invocations are there to doMap and how many to doReduce? Why?,"There are maptask calls to doMap and reducetask calls to reduce. In the specific case constructed in the provided code, maptask=reducetask=2, and so there are 2 doMap() calls and 2 doReduce() calls. This comes from the specific details of the code in the run() method, which actually instructs the individual processes to call doMap() and doReduce().","For which parameters of maptask and reducetask do you see speedup? Why do you observe no speedup for some parameters? (You might see no speedup at all on a busy machine or a machine with a single core.  You can calculate the speedup by creating a start time and an end time in the code, and subtracting.)","It is clear that for up to 3 different processes, we see performance gains. After that, my machine cannot schedule any more jobs, and the tasks simply queue up. In addition, there is marginal overhead required for each task (extra split files have to be made, and extra inputs need to be combined), which could lead to an actual slowdown from creating too many tasks relative to the number of machines. Calling multiprocessing.cpu_count() tells me that I have 8 cpus available for computation (although python may not have access to all of them, resulting in the apparent slow down after 3 processes running simultaneously). ","As a result of a fork, there are two processes running on a machine: the parent and the child $\mathrm{A}$. Immediately after returning from the fork() call, the parent forks again, creating child B. Neither child process has been scheduled yet (i.e., they have not yet had an opportunity to execute anything after the return from fork()). We are asking about an instant when the two children are fully created and completely ready to run, but before either has had a chance to run.
Select True or False for the following statement:
If virtual address $a$ maps to physical address $p$ in process $A$, then virtual address $a$ maps to physical address $p$ in process $B$.",False.
503,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Problem Set 4,Logistic Regression,4,g,0.02551020408,Text,"Our eventual goal is to do gradient descent on the logistic regression objective $J_{\text {nll }}$. In this problem, we'll take the first step toward deriving that gradient update. We'll focus on the gradient of the loss at a single point with respect to parameters $\theta$ and $\theta_{0}$.
What is the derivative of $L_{\text {nll }}$ with respect to $\theta_{0}$ ? Enter a Python expression involving $\mathrm{x}, \mathrm{y}$, and $\mathrm{g}$.",Expression,(g-y)*x,"Our eventual goal is to do gradient descent on the logistic regression objective $J_{\text {nll }}$. In this problem, we'll take the first step toward deriving that gradient update. We'll focus on the gradient of the loss at a single point with respect to parameters $\theta$ and $\theta_{0}$.
What is the derivative of $L_{\mathrm{nll}}$ with respect to $\theta$ ? Enter a Python expression involving $\mathrm{x}, \mathrm{y}$, and $\mathrm{g}$.
Hint: Use the chain rule and your expression from $5.3$.",(g-y)*x,"Our eventual goal is to do gradient descent on the logistic regression objective $J_{\text {nll }}$. In this problem, we'll take the first step toward deriving that gradient update. We'll focus on the gradient of the loss at a single point with respect to parameters $\theta$ and $\theta_{0}$.
The loss, $L_{\mathrm{nll}}(g, y)$ is defined as:
$$
L_{\mathrm{nll}}(g, y)=-(y \log g+(1-y) \log (1-g))
$$
What is the derivative of the loss with respect to $g$? Enter a Python expression involving y and $g$. ","Solution 1: -y/g + (1-y)/(1-g)
Solution 2: -(y/g - (1-y)/(1-g))
Solution 3: (g-y)/(g*(1-g))","Our eventual goal is to do gradient descent on the logistic regression objective $J_{\text {nll }}$. In this problem, we'll take the first step toward deriving that gradient update. We'll focus on the gradient of the loss at a single point with respect to parameters $\theta$ and $\theta_{0}$.
Given the output of the model
$$
g=\sigma\left(\theta^{T} x+\theta_{0}\right)=\frac{1}{1+e^{-\left(\theta^{T} x+\theta_{0}\right)}}
$$
what is the derivative of $\mathrm{g}$ with respect to $\theta$ ? Enter a Python expression involving $\mathrm{g}$ and $\mathrm{x}$.
Hint: Use chain rule and the expression you found for the derivative of the sigmoid in part $5.2$.",g*(1-g)*x
69,EECS,6.121,Introduction to Algorithms,"6.100A, 6.1200",6.101,Problem Set 8,Evenly Weighted,3,b,0.15625,Text,"$G=(V, E, w)$ is a weighted DAG with all weights being integers. An even path is defined as a path with total even weight.
For the following problem parts, even though there may be other solutions, the only solutions that will be considered are DP solutions with a self contained SRTBOT. In particular, your SRTBOT should not reference modifications of the original graph $G$.
Modify your solution so that given a node $s \in V$, it computes the number of optimal even paths from $s$ to all nodes $u \in V$.
Your algorithm must run in $O(|V|+|E|)$ time. For full credit, you should use the SRTBOT framework. Non-DP solutions will not be graded.",Open,"$\mathbf{S}$ Let $E[u]$ denote the length of the shortest even path from $s$ to $u$ and $O[u]$ denote the length of the shortest odd path from $s$ to $u$. E $E_{\text {num }}[u]$ stores the number of shortest even paths from $s$ to $u$, and $O_{\text {num }}[u]$ similarly the number of shortest odd paths.
$\mathbf{R}$ We keep the same relations for $E$ and $O$, but now we will also compute $E_{\text {num }}[u]$ by summing the number of paths from the incoming vertices that have weight of $E[u]$. Similarly we calculate $O_{\text {num }}$.
$$
\begin{aligned}
& E[u]=\min \left\{\begin{array}{l}\min _{v \in \operatorname{Adj}_{e}^{-}(u)}\{E[v]+w(v, u)\} \\\min _{v \in \operatorname{Adj}_{o}^{-}(u)}\{O[v]+w(v, u)\} \\\infty\end{array}\right. \\
& O[u]=\min \left\{\begin{array}{l}\min _{v \in \operatorname{Adj}_{o}^{-}(u)}\{E[v]+w(v, u)\} \\\min _{v \in \operatorname{Adj}_{e}^{-}(u)}\{O[v]+w(v, u)\} \\\infty\end{array}\right. \\
& E_{\text {num }}[u]=\sum \begin{cases}\sum_{v \in \operatorname{Adj}_{o}^{-}(u)} O_{n u m}[v], & \text { if } O[v]+w(v, u)==E[u] \text { else } 0 \\ \sum_{v \in \operatorname{Adj}_{e}^{-}(u)} E_{\text {num }}[v], & \text { if } E[v]+w(v, u)==E[u] \text { else } 0 \\ 0\end{cases} \\
& O_{n u m}[u]=\sum \begin{cases}\sum_{v \in \operatorname{Adj}_{o}^{-}(u)} E_{n u m}[v], & \text { if } E[v]+w(v, u)==O[u] \text { else } 0 \\ \sum_{v \in \operatorname{Adj}_{e}^{-}(u)} O_{n u m}[v], & \text { if } O[v]+w(v, u)==O[u] \text { else } 0 \\ 0\end{cases}
\end{aligned}
$$
$\mathbf{T}$ Topological order of G.
$\mathbf{B}$ $E[s]=0$ and $O[s]=\infty$ and $O_{n u m}[s]=0$ and $E_{\text {num }}[s]=1$.
$\mathbf{O}$ $E_{\text {num }}[v]$ for $v \in V$.
$\mathbf{T}$ Both $E$ and $O$ can be computed in time $O(|V|+|E|)$ as in part a. Then by similar logic, $E_{\text {num }}$ and $O_{\text {num }}$ can be calculated in time $O(|V|+|E|)$.","$G=(V, E, w)$ is a weighted DAG with all weights being integers. An even path is defined as a path with total even weight.
For the following problem parts, even though there may be other solutions, the only solutions that will be considered are DP solutions with a self contained SRTBOT. In particular, your SRTBOT should not reference modifications of the original graph $G$.
Given a node $s \in V$, compute, using DP, the weight of the shortest even path from $s$ to all nodes $u \in V$.
Your algorithm must run in $O(|V|+|E|)$ time. For full credit, you should use the SRTBOT framework. Non-DP solutions will not be graded.","A bit of notation goes a long way. For a node $u$, let $\operatorname{Adj}_{e}^{-}(u)$ denote the set of all nodes $v$ such that there is a directed edge from $v$ to $u$ with $w(v, u)$ even, and define $A d j_{o}^{-}(u)$ similarly.
$\mathbf{S}$ Let $E[u]$ denote the length of the shortest even path from $s$ to $u$ and $O[u]$ denote the length of the shortest odd path from $s$ to $u$.
$\mathbf{R}$ The main idea is that, to get an even path from $s$ to a node $u$, we must go to a node $v$ with an edge of weight $w$ to $u$. If $w$ is even, then we must come from a node $v$ with a shortest even path. If $w$ is odd, we must come from a node with a shortest odd path.
$$
\begin{aligned}
& E[u]=\min \left\{\begin{array}{l}
\min _{v \in \operatorname{Adj}_{e}^{-}(u)}\{E[v]+w(v, u)\} \\
\min _{v \in \operatorname{Adj}_{-}^{-}(u)}\{O[v]+w(v, u)\} \\
\infty
\end{array}\right. \\
& O[u]=\min \left\{\begin{array}{l}
\min _{v \in \operatorname{Adj}_{o}^{-}(u)}\{E[v]+w(v, u)\} \\
\min _{v \in \operatorname{Adj}_{e}^{-}(u)}\{O[v]+w(v, u)\} \\
\infty
\end{array}\right.
\end{aligned}
$$
$\mathbf{T}$ Topological order of $G$
$\mathbf{B}$ $E[s]=0$ and $O[s]=\infty$
$\mathbf{O}$ $E[v]$ for $v \in V$
$\mathbf{T}$ Both $E$ and $O$ can be computed in time $O(|V|+|E|)$ since the subproblems are $|V|$ and the total work is equivalent to the total number of incoming edges. The topological order can also be computed in $O(|V|+|E|)$ time. ","$G=(V, E, w)$ is a weighted DAG with all weights being integers. An even path is defined as a path with total even weight.
For the following problem parts, even though there may be other solutions, the only solutions that will be considered are DP solutions with a self contained SRTBOT. In particular, your SRTBOT should not reference modifications of the original graph $G$.
Implement even_weight that implements your algorithm from Part (b). ","##################################################
# Problem Set 8 Coding Problem: Evenly Weighted
##################################################

def opt_even_path(rev_adj, node, opt_even, opt_odd):
    if node in opt_even:
        return opt_even[node]
    best = float(""infinity"")
    for u, w in rev_adj[node].items():
        if w % 2 == 0:
            best = min(best, opt_even_path(rev_adj, u, opt_even, opt_odd)+w)
        else:
            best = min(best, opt_odd_path(rev_adj, u, opt_even, opt_odd)+w)
    opt_even[node] = best
    return best

def opt_odd_path(rev_adj, node, opt_even, opt_odd):
    if node in opt_odd:
        return opt_odd[node]
    best = float(""infinity"")
    for u, w in rev_adj[node].items():
        if w % 2 == 0:
            best = min(best, opt_odd_path(rev_adj, u, opt_even, opt_odd)+w)
        else:
            best = min(best, opt_even_path(rev_adj, u, opt_even, opt_odd)+w)
    opt_odd[node] = best
    return best

def num_even_paths(rev_adj, node, opt_num_even, opt_num_odd, opt_even, opt_odd):
    if node in opt_num_even:
        return opt_num_even[node]
    num_opt_paths = 0
    for u, w in rev_adj[node].items():
        if w % 2 == 0:
            if opt_even[u] + w == opt_even[node]:
                num_opt_paths += num_even_paths(rev_adj, u, opt_num_even, opt_num_odd, opt_even, opt_odd)
        elif opt_odd[u] + w == opt_even[node]:
            num_opt_paths += num_odd_paths(rev_adj, u, opt_num_even, opt_num_odd, opt_even, opt_odd)
    opt_num_even[node] = num_opt_paths
    return num_opt_paths

def num_odd_paths(rev_adj, node, opt_num_even, opt_num_odd, opt_even, opt_odd):
    if node in opt_num_odd:
        return opt_num_odd[node]
    num_opt_paths = 0
    for u, w in rev_adj[node].items():
        if w % 2 == 0:
            if opt_odd[u] + w == opt_odd[node]:
                num_opt_paths += num_odd_paths(rev_adj, u, opt_num_even, opt_num_odd, opt_even, opt_odd)
        elif opt_even[u] + w == opt_odd[node]:
            num_opt_paths += num_even_paths(rev_adj, u, opt_num_even, opt_num_odd, opt_even, opt_odd)
    opt_num_odd[node] = num_opt_paths
    return num_opt_paths

def num_opt_even_weight_paths(graph, s):
    """"""
    The num_opt_even_weight_paths function should return a dictionary mapping node v to the number of optimal
    paths of even weight from s to v.
    graph - an adjacency list of a DAG in the form {u: {v:w(u,v)} mapping nodes to a dictionary 
            where the keys are their adjacencies and the values are the edge weights
            graph[u][v] would be equal to the weight of the edge u to v.
            you may assume that graph.keys() represents all nodes present
    s - start node

    return: a dictionary mapping node v to the number of optimal paths of even weight from s to v. 
            optimal[s] should be 1.
    """"""
    rev_adj = {}
    for start_node in graph:
        for end_node, weight in graph[start_node].items():
            if end_node not in rev_adj:
                rev_adj[end_node] = {}
            rev_adj[end_node][start_node] = weight
    opt_even = {s:0}
    opt_odd = {s:float(""infinity"")}
    for node in graph:
        opt_even_path(rev_adj, node, opt_even, opt_odd)
    opt_num_even = {s:1}
    opt_num_odd = {s:0}
    for node in graph:
        num_even_paths(rev_adj, node, opt_num_even, opt_num_odd, opt_even, opt_odd)
    return opt_num_even","Please select True or False for the following.
Consider the following algorithm for approximating the weight of the minimum spanning tree. Given an undirected graph $G=(V, E)$ with positive weights on edges as input, pick the first vertex, $s \in V$, from the input, and compute the tree of shortest paths between $s$ and all $v \in V$. The tree of shortest paths is the tree rooted at $s$ where the distance from $s$ to any node $v$ is the length of the shortest path from $s$ to $v$. Output the sum of the weights of all the edges in the tree. This sum is at most a factor of 2 more than the weight of the minimum spanning tree.","False. Consider the graph that connects $s$ to $D$ other vertices with weight 100 , and connects the $D$ vertices between themselves in weight 0 edges. Then, the minimum spanning tree is of weight 100 , while the weight of the tree the algorithm returns is $100 D$."
101,Mathematics,18.03,Differential Equations,None,18.02,Problem Set 8,Fourier Series,4,f,0,Text,"(Story time) In this problem we'll work out why
$$
\begin{aligned}
&\int_{-\pi}^{\pi} \cos (n t) \cos (m t) d t=0 \text { if } n \neq m \\
&\int_{-\pi}^{\pi} \sin (n t) \sin (m t) d t=0 \text { if } n \neq m \\
&\int_{-\pi}^{\pi} \cos (n t) \sin (m t) d t=0 \text { for all } n, m .
\end{aligned}
$$
As we have seen, these identities are key to Fourier's Theorem. Of course, one could just compute these integrals directly, but we're going to look at these identities from a more high-minded point of view, which will be helpful when we study applications to the heat equation next week. Recall that we defined an $n \times n$ matrix $A$ to be symmetric if
$$
A^{T}=A
$$
where $A^{T}$ is the transpose of $A$. The next problem gives a way of defining ""symmetric"" in terms of an inner product (note inner products were discussed in Week 10 , and the associated explain everything videos). (Story time ends)
Consider $\mathbb{R}^{n}$ with the inner product $\langle v, w\rangle:=v \cdot w$ given by the dot product. Notice that we have the formula
$$
v \cdot w=v^{T} w
$$
where the right-hand side is matrix multiplication of a row vector and a column vector. We will use the following fact: if $A$ is an $m \times n$ matrix and $B$ is an $n \times p$ matrix then
$$
(A B)^{T}=B^{T} A^{T}
$$
Using this fact show that an $n \times n$ matrix is symmetric if and only if
$$
\langle A v, w\rangle=\langle v, A w\rangle
$$
for all vectors $v, w \in \mathbb{R}^{n}$.",Open,"$$
(A B)_{i j}^{T}=(A B)_{j i}=\sum_{k} A_{j k} B_{k i}=\sum_{k} A_{k j}^{T} B_{i k}^{T}=\left(B^{T} A^{T}\right)_{i j} .
$$","(Story time) In this problem we'll work out why
$$
\begin{aligned}
&\int_{-\pi}^{\pi} \cos (n t) \cos (m t) d t=0 \text { if } n \neq m \\
&\int_{-\pi}^{\pi} \sin (n t) \sin (m t) d t=0 \text { if } n \neq m \\
&\int_{-\pi}^{\pi} \cos (n t) \sin (m t) d t=0 \text { for all } n, m .
\end{aligned}
$$
As we have seen, these identities are key to Fourier's Theorem. Of course, one could just compute these integrals directly, but we're going to look at these identities from a more high-minded point of view, which will be helpful when we study applications to the heat equation next week. Recall that we defined an $n \times n$ matrix $A$ to be symmetric if
$$
A^{T}=A
$$
where $A^{T}$ is the transpose of $A$. The next problem gives a way of defining ""symmetric"" in terms of an inner product (note inner products were discussed in Week 10 , and the associated explain everything videos). (Story time ends)
Consider $\mathbb{R}^{n}$ with the inner product $\langle v, w\rangle:=v \cdot w$ given by the dot product. Notice that we have the formula
$$
v \cdot w=v^{T} w
$$
where the right-hand side is matrix multiplication of a row vector and a column vector. We will use the following fact: if $A$ is an $m \times n$ matrix and $B$ is an $n \times p$ matrix then
$$
(A B)^{T}=B^{T} A^{T}
$$","If $A$ is symmetric, then
$$
\begin{aligned}
\langle A v, w\rangle &=(A v)^{T} w \\
&=v^{T} A^{T} w \\
&=v^{T} A w \\
&=v^{T}(A w) \\
&=\langle v, A w\rangle .
\end{aligned}
$$
Conversely, if $\langle A v, w\rangle=\langle v, A w\rangle$ for all $v, w \in \mathbb{R}^{n}$, then from the equalities we used above, $v^{T} A w=v^{T} A^{T} w$ for all $v, w \in \mathbb{R}^{n}$.
Now we can conveniently choose $v=e_{i}$ and $w=e_{j}$ to be standard basis vectors $\left(e_{k}\right.$ is the vector with 1 in coordinate $k$ and 0 in all other coordinates). Then $v^{T} A w=$ $(A)_{i j}$ and $v^{T} A^{T} w=\left(A^{T}\right)_{i j}$ (make sure you understand why this is true). Hence $(A)_{i j}=\left(A^{T}\right)_{i j}$ for all $1 \leq i, j \leq n$, so $A=A^{T}$, so $A$ is symmetric.
Note that the paragraph above is a general proof of the fact that $v^{T} A w=v^{T} B w$ for all $v, w \in \mathbb{R}^{n}$ implies $A=B$. We are just applying it to $A$ and $A^{T}$.","(Story time) In this problem we'll work out why
$$
\begin{aligned}
&\int_{-\pi}^{\pi} \cos (n t) \cos (m t) d t=0 \text { if } n \neq m \\
&\int_{-\pi}^{\pi} \sin (n t) \sin (m t) d t=0 \text { if } n \neq m \\
&\int_{-\pi}^{\pi} \cos (n t) \sin (m t) d t=0 \text { for all } n, m .
\end{aligned}
$$
As we have seen, these identities are key to Fourier's Theorem. Of course, one could just compute these integrals directly, but we're going to look at these identities from a more high-minded point of view, which will be helpful when we study applications to the heat equation next week. Recall that we defined an $n \times n$ matrix $A$ to be symmetric if
$$
A^{T}=A
$$
where $A^{T}$ is the transpose of $A$. The next problem gives a way of defining ""symmetric"" in terms of an inner product (note inner products were discussed in Week 10 , and the associated explain everything videos). (Story time ends)
Suppose $A$ is a symmetric $n \times n$ matrix, and $v_{1}, v_{2}$ are eigenvectors of $A$ with eigenvalues $\lambda_{1} \neq \lambda_{2}$. Show that
$$
\left\langle v_{1}, v_{2}\right\rangle=0
$$
(Hint: Compare $\left\langle A v_{1}, v_{2}\right\rangle$, and $\left\langle v_{1}, A v_{2}\right\rangle$.)","We know that $\left\langle A v_{1}, v_{2}\right\rangle=\left\langle v_{1}, A v_{2}\right\rangle$. However,
$$
\begin{aligned}
\left\langle A v_{1}, v_{2}\right\rangle &=\left\langle\lambda_{1} v_{1}, v_{2}\right\rangle \\
&=\lambda_{1}\left\langle v_{1}, v_{2}\right\rangle \\
\left\langle v_{1}, A v_{2}\right\rangle &=\left\langle v_{1}, \lambda_{2} v_{2}\right\rangle \\
&=\lambda_{2}\left\langle v_{1}, v_{2}\right\rangle .
\end{aligned}
$$
Since $\lambda_{1} \neq \lambda_{2}$,
$$
\begin{aligned}
\lambda_{1}\left\langle v_{1}, v_{2}\right\rangle &=\lambda_{2}\left\langle v_{1}, v_{2}\right\rangle \\
\Longrightarrow\left\langle v_{1}, v_{2}\right\rangle &=0 .
\end{aligned}
$$","(Story time) In this problem we'll work out why
$$
\begin{aligned}
&\int_{-\pi}^{\pi} \cos (n t) \cos (m t) d t=0 \text { if } n \neq m \\
&\int_{-\pi}^{\pi} \sin (n t) \sin (m t) d t=0 \text { if } n \neq m \\
&\int_{-\pi}^{\pi} \cos (n t) \sin (m t) d t=0 \text { for all } n, m .
\end{aligned}
$$
As we have seen, these identities are key to Fourier's Theorem. Of course, one could just compute these integrals directly, but we're going to look at these identities from a more high-minded point of view, which will be helpful when we study applications to the heat equation next week. Recall that we defined an $n \times n$ matrix $A$ to be symmetric if
$$
A^{T}=A
$$
where $A^{T}$ is the transpose of $A$. The next problem gives a way of defining ""symmetric"" in terms of an inner product (note inner products were discussed in Week 10 , and the associated explain everything videos). (Story time ends)
The only thing left to show is that $\int_{-\pi}^{\pi} \cos (n t) \sin (n t) d t=0$. Do this by showing that if $f(t)$ is even and $g(t)$ is odd, then
$$
\int_{-\pi}^{\pi} f(t) g(t) d t=0
$$","Since $f(x)$ is even and $g(x)$ is odd, $f(x) g(x)$ is odd, so its integral over an interval symmetric about 0 must equal 0."
3,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 0,Breadth-First Search,3,b,1.041666667,Text,"Complete the following implementation of breadth-first search. Note that the expected output is a list of actions. The search should not revisit any states.
For reference, our solution is 15 line(s) of code.
def breadth_first_search(initial_state, check_goal_fn, successor_fn, max_expansions=1000):
'''Finds a plan from initial state to goal using BFS.
Args:
initial_state: Any state representation.
check_goal_fn: A function that takes a state and returns a bool
indicating whether the goal is reached.
successor_fn: A function that takes a state and yields zero or
more (action, next state).
max_expansions: An int bounding the number of times that thhe
successor_fn is called before giving up.
Returns:
plan: A list of actions or None.
'''
raise NotImplementedError(""Implement me!"")",Programming,"def breadth_first_search(initial_state, check_goal_fn, successor_fn, max_expansions=1000):
'''Finds a plan from initial state to goal using BFS.
Args:
initial_state: Any state representation.
check_goal_fn: A function that takes a state and returns a bool
indicating whether the goal is reached.
successor_fn: A function that takes a state and yields zero or
more (action, next state).
max_expansions: An int bounding the number of times that thhe
successor_fn is called before giving up.
Returns:
plan: A list of actions or None.
'''
queue = [([], initial_state)]
visited = set()
for _ in range(max_expansions):
if len(queue) == 0:
return None
plan, state = queue.pop(0)
if check_goal_fn(state):
return plan
for (action, next_state) in successor_fn(state):
if next_state in visited:
continue
next_plan = plan + [action]
queue.append((next_plan, next_state))
visited.add(next_state)
return None","Complete an implementation of the best-first search, encompassing $A^{*}$, GBFS, or UCS. You can assume any heuristics are consistent. You should follow the psuedocode given in lecture closely. In particular, your implementation should prune redundant paths by remembering the reached states.
For reference, our solution is 55 line(s) of code. 
def run_best_first_search(
problem: PathCostProblem,
get_priority: Callable[[Node], float],
step_budget: int = 1000) -> Tuple[StateSeq, ActionSeq, CostSeq, int]:
'''A generic heuristic search implementation.
Depending on `get_priority`, can implement A*, GBFS, or UCS.
The `get_priority` function here should determine the order
in which nodes are expanded. For example, if you want to
use path cost as part of this determination, then the
path cost (node.g) should appear inside of get_priority,
rather than in this implementation of `run_best_first_search`.
Important: for determinism (and to make sure our tests pass),
please break ties using the state itself. For example,
if you would've otherwise sorted by `get_priority(node)`, you
should now sort by `(get_priority(node), node.state)`.
Args:
problem: a path cost problem.
get_priority: a callable taking in a search Node and returns the priority
step_budget: maximum number of `problem.step` before giving up.
Returns:
state_sequence: A list of states.
action_sequence: A list of actions.
cost_sequence: A list of costs.
num_steps: number of taken `problem.step`s. Must be less than or equal to `step_budget`.
Raises:
error: SearchFailed, if no plan is found.
'''
raise NotImplementedError(""Implement me!"")","def run_best_first_search(
problem: PathCostProblem,
get_priority: Callable[[Node], float],
step_budget: int = 1000) -> Tuple[StateSeq, ActionSeq, CostSeq, int]:
'''A generic heuristic search implementation.
Depending on `get_priority`, can implement A*, GBFS, or UCS.
The `get_priority` function here should determine the order
in which nodes are expanded. For example, if you want to
use path cost as part of this determination, then the
path cost (node.g) should appear inside of get_priority,
rather than in this implementation of `run_best_first_search`.
Important: for determinism (and to make sure our tests pass),
please break ties using the state itself. For example,
if you would've otherwise sorted by `get_priority(node)`, you
should now sort by `(get_priority(node), node.state)`.
Args:
problem: a path cost problem.
get_priority: a callable taking in a search Node and returns the priority
step_budget: maximum number of `problem.step` before giving up.
Returns:
state_sequence: A list of states.
action_sequence: A list of actions.
cost_sequence: A list of costs.
num_steps: number of taken `problem.step`s. Must be less than or equal to `step_budget`.
Raises:
error: SearchFailed, if no plan is found.
'''
num_steps = 0
frontier = []
reached = {}
root_node = Node(state=problem.initial,
parent=None,
action=None,
cost=None,
g=0)
hq.heappush(frontier, (get_priority(root_node), problem.initial, root_node))
reached[problem.initial] = root_node
num_expansions = 0
while frontier:
pri, s, node = hq.heappop(frontier)
# If reached the goal, return
if problem.goal_test(node.state):
return (*finish_plan(node), num_steps)
num_expansions += 1
# Generate successors
for action in problem.actions(node.state):
if num_steps >= step_budget:
raise SearchFailed(f""Failed to find a plan in {step_budget} steps"")
child_state = problem.step(node.state, action)
num_steps += 1
cost = problem.step_cost(node.state, action, child_state)
path_cost = node.g + cost
# If the state is already in explored or reached, don't bother
if not child_state in reached or path_cost < reached[child_state].g:
# Add new node
child_node = Node(state=child_state,
parent=node,
action=action,
cost=cost,
g=path_cost)
priority = get_priority(child_node)
hq.heappush(frontier, (priority, child_state, child_node))
reached[child_state] = child_node
def finish_plan(node: Node):
'''Helper for run_best_first_search.'''
state_sequence = []
action_sequence = []
cost_sequence = []
while node.parent is not None:
action_sequence.insert(0, node.action)
state_sequence.insert(0, node.state)
cost_sequence.insert(0, node.cost)
node = node.parent
state_sequence.insert(0, node.state)
return state_sequence, action_sequence, cost_sequence","In this problem, we will consider planning paths through an infinite grid. We will represent each state in this search space as a tuple $(r, c)$ where $r$ is a row index and $c$ is a column index for position in the grid. Because the grid is infinite, $r$ and $c$ can take on any integer values, $-\infty<r<\infty$ and $-\infty<c<\infty$. Furthermore, there are no obstacles, so all locations are valid.
First Attempt
Intrigued by this problem, Ben Bitdiddle writes the ben_search algorithm to find a path between a start state and a goal state in this space:
def successors(state):
      (r,c) = state
      return [(r+i, c+j) for (i,j) in [(0,1), (1,0), (0,-1), (-1,0)]]
def ben_search(start, goal_point):
       agenda = [(start,)]
       while len(agenda) > 0:
             current = agenda.pop(0)
             for child in successors(current[-1]):
                 new = current + (child,)
                 if child == goal_point:
                     return new
                 agenda = [new] + agenda
       return None
Which of the following best describes Ben’s search? 
(a) BFS
(b) DFS
(c) neither
Which of the following best describes the elements in the agenda in Ben’s code?
(a) a boolean representing whether the terminal vertex is the goal state,
(b) a single state in the search space,
(c) a tuple containing a single state in the search space,
(d) a tuple containing a path from the start state to some other state,
(e) a list containing a single state in the search space, or
(f) a list containing a path from the start state to some other state","(b) DFS.
(d) a tuple containing a path from the start state to some other state.","In this problem, we will consider planning paths through an infinite grid. We will represent each state in this search space as a tuple $(r, c)$ where $r$ is a row index and $c$ is a column index for position in the grid. Because the grid is infinite, $r$ and $c$ can take on any integer values, $-\infty<r<\infty$ and $-\infty<c<\infty$. Furthermore, there are no obstacles, so all locations are valid.
Ivana de Bugyu (another friend of Ben’s) tries running Ben’s code on some input, but she finds that it gets caught in an infinite loop! She decides to take on the task of fixing Ben’s code. Eventually, she is able to make Ben’s code work to the point where she can guarantee that it will return the shortest path between any arbitrary start and goal state. What’s even more impressive is that she did this by changing only a single line of Ben’s original code! What line did she change, and what single line did she replace it with? Ben’s code is reproduced here for convenience, labeled with line numbers.
01 | def ben_search(start, goal_point):
02 |        agenda = [(start,)]
03 |        while len(agenda) > 0:
04 |               current = agenda.pop(0)
05 |               for child in successors(current[-1]):
06 |                     new = current + (child,)
07 |                     if child == goal_point:
08 |                          return new
09 |                     agenda = [new] + agenda
10 |        return None
Note that there may be multiple correct answers to this question; any correct answer will suffice.","Line number: 4
Should read: current = agenda.pop()
Line number: 9
Should read: agenda.append(new)"
146,EECS,18.C06,Linear Algebra and Optimization,18.02,None,Midterm Exam 1,Basis and Dimension,7,a,0.9375,Text,"Consider the subspace
$$
U=\operatorname{span}\left\{\left[\begin{array}{c}
1 \\
-1 \\
0
\end{array}\right],\left[\begin{array}{l}
0 \\
2 \\
1
\end{array}\right],\left[\begin{array}{l}
1 \\
1 \\
1
\end{array}\right]\right\}.
$$
Find a basis for $U$. What is its dimension?",Expression,"The third vector is the sum of the first two vectors. But the first two vectors are linearly independent so a possible basis is:
$$
\left\{\left[\begin{array}{c}
1 \\
-1 \\
0
\end{array}\right],\left[\begin{array}{l}
0 \\
2 \\
1
\end{array}\right]\right\}
$$
and the dimension of $U$ is two. ","Consider the subspace
$$
U=\operatorname{span}\left\{\left[\begin{array}{c}
1 \\
-1 \\
0
\end{array}\right],\left[\begin{array}{l}
0 \\
2 \\
1
\end{array}\right],\left[\begin{array}{l}
1 \\
1 \\
1
\end{array}\right]\right\}.
$$
Find a set of equations describing $U$.","Since $U$ has dimension two, we just need to find one equation. Thus we need to find a nonzero solution to
$$
\left[\begin{array}{ccc}
1 & -1 & 0 \\
0 & 2 & 1
\end{array}\right]\left[\begin{array}{l}
x_{1} \\
x_{2} \\
x_{3}
\end{array}\right]=\left[\begin{array}{l}
0 \\
0
\end{array}\right]
$$ 
It is easy to check that the vector
$$
\left[\begin{array}{c}
1 \\
1 \\
-2
\end{array}\right]
$$
is a solution, which implies
$$
U=\left\{x \in \mathbb{R}^{3}: x_{1}+x_{2}-2 x_{3}=0\right\} .
$$","Consider the following subspaces of $\mathbb{R}^{4}$ :
$$
U=\operatorname{span}\left\{\left[\begin{array}{l}
0 \\
0 \\
1 \\
1
\end{array}\right],\left[\begin{array}{l}
3 \\
0 \\
1 \\
1
\end{array}\right],\left[\begin{array}{c}
0 \\
-1 \\
2 \\
-1
\end{array}\right],\left[\begin{array}{l}
0 \\
1 \\
0 \\
3
\end{array}\right]\right\}
$$
and
$$
V=\left\{\left(x_{1}, x_{2}, x_{3}, x_{4}\right): x_{1}+x_{2}=x_{3}+x_{4}\right\} .
$$
Compute the dimension and a basis for $U+V$.","We can compute a basis of $V$ (either by hand, or with the procedure described in recitation), to obtain:
$$
V=\operatorname{span}\left\{\left[\begin{array}{c}
-1 \\
1 \\
0 \\
0
\end{array}\right],\left[\begin{array}{l}
1 \\
0 \\
1 \\
0
\end{array}\right],\left[\begin{array}{l}
1 \\
0 \\
0 \\
1
\end{array}\right]\right\}
$$
Putting these together with the generators of $U$, a simple rank calculation shows that they span the whole space, so $U+V=\mathbb{R}^{4}$. To obtain a basis, we just need four linearly independent vectors. For instance, we can choose the first three generators of $U$ and the first one of $V$. Alternatively, we can use the standard basis $e_{1}, \ldots, e_{4}$.","Consider the following subspaces of $\mathbb{R}^{4}$ :
$$
U=\operatorname{span}\left\{\left[\begin{array}{l}
0 \\
0 \\
1 \\
1
\end{array}\right],\left[\begin{array}{l}
3 \\
0 \\
1 \\
1
\end{array}\right],\left[\begin{array}{c}
0 \\
-1 \\
2 \\
-1
\end{array}\right],\left[\begin{array}{l}
0 \\
1 \\
0 \\
3
\end{array}\right]\right\}
$$
and
$$
V=\left\{\left(x_{1}, x_{2}, x_{3}, x_{4}\right): x_{1}+x_{2}=x_{3}+x_{4}\right\} .
$$
Compute the dimension and a basis for $U \cap V$.","We compute now a minimal set of equations to describe $U$. As explained in the lecture/recitation, we can use Gaussian elimination to obtain the description
$$
U=\left\{\left(x_{1}, x_{2}, x_{3}, x_{4}\right):-3 x_{2}-x_{3}+x_{4}=0\right\} .
$$
Putting this equation together with the null-space description of $V$, by computing a basis we obtain that $U \cap V$ is two-dimensional:
$$
U \cap V=\operatorname{span}\left\{\left[\begin{array}{c}
4 \\
-1 \\
3 \\
0
\end{array}\right],\left[\begin{array}{l}
2 \\
1 \\
0 \\
3
\end{array}\right]\right\} \text {. }
$$"
48,EECS,6.121,Introduction to Algorithms,"6.100A, 6.1200",6.101,Problem Set 4,Dog Show Leaderboard,3,b,0.625,Text,"Alice is running a day-long regional dog show. Throughout the day, for each dog d that performs in the show, a panel of judges gives the dog a score $s_d$. Alice would like to maintain a leaderboard for the audience to keep track of the highest-scoring dogs as the competition progresses. Note that these scores may update throughout the day – new dogs who compete may have their high scores added to their leaderboard. At any given point in time, the highest-scoring dog may be disqualified from the competition, and may have its score removed from the leaderboard.
Alice is requesting a data structure that would allow her to efficiently maintain her leaderboard. Assuming a total of n dogs, she would like to insert dogs and their scores to the data structure in O(log n) time. She would also like to remove the highest-scoring dog and its score from the data structure in O(log n) time. Additionally, given an initial array of n dogs and their scores, she would like to be able to construct the data structure in O(n) time.
Note that these operations may potentially be called multiple times in succession.
Alice would like a more efficient way to display the highest-scoring k dogs on her leaderboard. She realizes that the audience no longer cares if the k dogs are shown in order on the leaderboard, as long as they are the highest-scoring set of k dogs. Also, she is willing to take O(n log k) time to construct the data structure given an initial array of n dogs. Design a data structure that, in addition to the insert and remove operations described above, adds an operation that returns the highest-scoring set of k dogs, as a pointer to an array containing these dogs, in O(1) time. Note that there is not enough time to construct the desired array of k dogs (which would take O(k) time), but it is sufficient to return a pointer to an array that has already been constructed as a part of the data structure, which would only take O(1) time. Also, recall that you must support insertion of new dogs in O(log n) time, and deletion of the highest-scoring dog in O(log n) time.",Open,"The main idea is to construct a min-heap of size $k$ to find the top $k$ dogs, and maintain this heap alongside a max-heap of size $n-k$ to store the rest of the dogs. Let us denote the min-heap of size $k$ by $H_k$, and the max-heap of size $n-k$ by $H_{n-k}$. In order to support deletion of the highest-scoring dog, we also maintain the same max-heap as in the previous part, of size $n$ containing all of the dogs; let us denote this heap by $H_n$. We maintain pointers of each element in this heap $H_n$ to the corresponding dogs in $H_k$ and $H_{n-k}$. Because we maintain pointers, we can ensure that even as elements move through $H_k$ and $H_{n-k}$, these moves will be reflected in $H_n$.
In order to construct this data structure from an initial array of $n$ dogs, we will additionally maintain an array of size $n-k$, say $A_{n-k}$. We start by inserting the first $k$ dogs into $H_k$. Then, for each dog remaining, if the dog's score is greater than the root of $H_k$, we pop the root of $H_k$ (the lowest-scoring dog), and we insert the new dog into $H_k$. We insert the dog that we removed from $H_k$ into the array $A_{n-k}$. If the dog's score was not greater than the root of $H_k$, then we simply insert the dog into $A_{n-k}$. We repeat this process until we have processed every dog in our initial array. Then, we construct the max-heap $H_{n-k}$ from $A_{n-k}$. Additionally, we can note the pointer to each dog in $H_k$ and $H_{n-k}$ alongside our initial array, and then construct $H_n$ from this array in $O(n)$ time.
Now, note that $H_k$ contains exactly the highest-scoring set of $k$ dogs, which Alice can return in $O(1)$ time, since a min-heap can be compactly maintained as an array.
It remains to claim that we can efficiently process insertions and deletions into this data structure. Our insertion procedure follows directly from the construction procedure. For a new dog that we would like to insert, we can compare the dog's score with that of the root of $H_k$, and if the dog's score is greater than the root, then we pop the root of $H_k$, insert our new dog into $H_k$, and insert the dog that we removed into $H_{n-k}$. We also insert this dog into our heap $H_n$, with a pointer to its location in either $H_k$ or $H_{n-k}$
For our deletion procedure, the dog must be in $H_k$. We can pop the root of $H_n$ to remove the dog from $H_n$ and obtain its location in $H_k$. We delete the corresponding node from $H_k$ in $O(\log k)$ time (using standard heap deletion, by swapping the node with the last node in $H_k$, deleting the last node in $H_k$, and heapify-ing), and we pop the maximum dog in $H_{n-k}$. Then, we insert the popped dog into $H_k$, to maintain the property that $H_k$ contains $k$ dogs. This takes $O(\log n)$ time.
Note that it is possible to use a different data structure rather than a min-heap to store the top $k$ dogs. For instance, an AVL tree would also be acceptable. However, there must be justification on how to maintain a compact array corresponding to the dogs in the tree, such that this array can be returned in $O(1)$ time.","Alice is running a day-long regional dog show. Throughout the day, for each dog d that performs in the show, a panel of judges gives the dog a score $s_d$. Alice would like to maintain a leaderboard for the audience to keep track of the highest-scoring dogs as the competition progresses. Note that these scores may update throughout the day – new dogs who compete may have their high scores added to their leaderboard. At any given point in time, the highest-scoring dog may be disqualified from the competition, and may have its score removed from the leaderboard.
Alice is requesting a data structure that would allow her to efficiently maintain her leaderboard. Assuming a total of n dogs, she would like to insert dogs and their scores to the data structure in O(log n) time. She would also like to remove the highest-scoring dog and its score from the data structure in O(log n) time. Additionally, given an initial array of n dogs and their scores, she would like to be able to construct the data structure in O(n) time.
Note that these operations may potentially be called multiple times in succession.
Alice would like to display the highest-scoring k dogs on her leaderboard in order (where k ≤ n), so that the audience can see all high-scoring dogs, rather than just a single dog on the leaderboard. Design a data structure that, in addition to the insert and remove operations described above, adds an operation that returns the highest-scoring sequence of k dogs in order in O(k log n) time.","Use a max-heap to store the dogs using the scores as the key. To find the set of k dogs with the highest scores, pop k items from the heap, and store them in an array. This array contains precisely the desired dogs. Then, reinsert the k items in the array to the heap, to allow for future operations. Popping and reinserting takes O(k log n) time.","Today is your first day working at FlixChill, the newest movie streaming service. Your task is to design a data structure to maintain the different movies in their catalogue. Each movie has a unique identifier $m$ and can only be streamed on or after a given date $s_{m}$ (by contract) and has a given ranking $r_{m}$.
The basic operations needed are:
1. insert $(m, s, r)$ : Inserts movie with ID $m$, starting date $s$ and ranking $r$.
2. delete $(m)$ : Deletes movie with ID $m$.
3. earliest $(s)$ : Outputs the movie that can be streamed earliest on or after the given date $s$.
4. highest $(s)$ : Outputs the movie that has the highest ranking and which starts on or after the given date $s$.
You need to implement each in worst-case $O(\log n)$ time where $n$ is the number of movies currently in the catalogue. For full credit, briefly describe your data structure and algorithms and analyze their runtime. You do not need to prove correctness. You do not need to describe or analyze algorithms discussed in class.","Store movies in AVL tree keyed by $s$ (breaking ties arbitrarily, such as by the movie ID $m$ ) and augmented by the highest ranking of a movie in the sub-tree. Also, store movies in a second AVL tree indexed by their ID $m$ and keeping a pointer to the node in the first AVL tree.
To insert or delete, one needs to maintain the cross-relationship between the two AVL trees in a straightforward manner.
The method earliest is a straight-forward extension of $f$ ind modified to output a node with the smallest key greater than or equal to than the given key.
The method highest goes down the tree to ""find"" the first movie $m$ with date greater than or equal to s. Once found, it goes up the tree, computing the maximum ranking of $m$ and all ancestor nodes after $m$ 's node and their right subtrees' augmented values. This can be done in time $O(\log n)$ given the augmentation.","Professor Oak is trying to organize his $n$ Critters so he can study them more efficiently. For each of the following scenarios, provide the most efficient algorithm for sorting the Critters, and state whether the asymptotic complexity is $\Theta(n), \Theta(n \log n)$, or $\Theta\left(n^{2}\right)$. Briefly justify your answers (a sentence or two suffices). Choose only one of the following sorting algorithms from lecture and recitation: insertion sort, selection sort, merge sort, counting sort, and radix sort.
Professor Oak wants to sort his Critters alphabetically by the names he has given them, which are strings of length at $\operatorname{most} \log _{2} n+1$, containing lowercase letters of the English alphabet. Each string is stored as contiguous bits in memory.","There are 26 choices for each letter. Therefore, the names can be interpreted as positive integers bounded by $26^{\log _{2} n+1}=O\left(n^{6}\right)$, so we can use radix sort in $\Theta(n)$ time."
126,EECS,18.C06,Linear Algebra and Optimization,18.02,None,Mini Project 1,Image Blurring,2,f,0.4,Text,"Finally, we extend convolutions to two dimensions and create some hybrid images. A hybrid image is a kind of visual illusion where its interpretation changes with viewing distance. It is made of a blurred image combined with a sharpened image, so that we perceive the blurred image when viewed afar but the sharpened image when viewed up close.
Other operations related to blurring are sharpening and edge detection. To enhance the edges of an image, we can simply subtract the blurred version from the original image, i.e.,
$$
\operatorname{edge}(X)=X-\operatorname{blur}(X) .
$$
This operation is also known as an edge detector.
We now consider what happens when we apply these operators several times in a row. For an integer $p \geq 1$, we define blur $_{p}$ as applying blur $p$ times in a row, i.e.,
$$
\operatorname{blur}_{1}(X)=\operatorname{blur}(X), \quad \text { and } \quad \operatorname{blur}_{p}(X)=\operatorname{blur}\left(\operatorname{blur}_{p-1}(X)\right).
$$
Similarly, we define
$$
\operatorname{edge}_{p}(X)=X-\operatorname{blur}_{p}(X) .
$$
Give ""linear algebra"" expressions for these two operations, in terms of matrix powers and matrix multiplications. Implement blur b and edge $_{p}$ in your code.",Programming,"We have $\operatorname{blur}_{p}(X)=M_{n}^{p} X M_{m}^{T^{p}}$ and edge $(X)=X-M_{n}^{p} X M_{m}^{T^{p}}$.

function blur(X, p, K=[1,2,1]/4)
    #### Your code here ####
    m,n = size(X)
    getM(m, K)^p * X * getM(n, K)^p
end

function edge(X, p, K=[1,2,1]/4)
    #### Your code here ####
    X - blur(X, p, K)
end","Finally, we extend convolutions to two dimensions and create some hybrid images. A hybrid image is a kind of visual illusion where its interpretation changes with viewing distance. It is made of a blurred image combined with a sharpened image, so that we perceive the blurred image when viewed afar but the sharpened image when viewed up close.
A convenient way to apply our smoothing operation to $2 \mathrm{D}$ images is to first apply it to all the rows, then apply it to all the columns. This can be done very efficiently, using the properties of matrix multiplication.
Concretely, if $X$ is a $n \times m$ image represented as a matrix (each entry is a grayscale pixel), and $M_{n}$ and $M_{m}$ are the matrix representations of $\operatorname{conv}_{K}$ on vectors of length $n$ and $m$ respectively, the smoothing operation is the following linear map:
$$
\operatorname{blur}(X)=M_{n} X M_{m}^{T}
$$
Explain why this is the case.","The columns of $X$ are vectors in $\mathbb{R}^{n}$, while the rows of $X$ are vectors in $\mathbb{R}^{m}$. Applying the transform $M_{n}$ to a column vector $x$ gives us another column vector $M_{n} x$, while applying the transform $M_{m}$ to a row vector $x^{T}$ gives us another row vector $M_{m}^{T} x^{T}$. Thus the applying $M_{n}$ to all the rows of $X$ forms the map $X \mapsto M_{n} X$, whereas applying $M_{m}$ to all the columns of $X$ forms the map $X \mapsto X M_{m}^{T}$. Since matrix multiplication is associative, these two maps can be performed in any order, giving us the map $X \mapsto M_{n} X M_{m}^{T}$.","Using the provided images monroe and einstein (and the kernels $K=$ $\left[\begin{array}{lll}1 / 4 & 2 / 4 & 1 / 4\end{array}\right]$ for blur and edge), compute the result of applying blur ${ }_{50}$ to the first image, and $e d g e_{2}$ to the second image. Display the two resulting images side by side.","edge2 = edge(einstein, 2) #### Your code here ####
blur60 = blur(monroe, 60) #### Your code here ####
[10edge2 blur60] # Plot images side by side below, the factor of 10 is to make the edges more visible","Let's re-visit the 3-block tetris example. There, we were able to train a linear classifier that could perfectly classify Lines and Corners on our $3 \times 3$ gameboard after performing some feature engineering.
Here, we will explore using convolutional filters on the Tetris dataset. Let's plot the dataset to remind ourselves of all the different shapes (black pixel are encoded as 1 and white pixels are 0).
Let's return to the Sobel filters introduced in Problem 1. By now you hopefully understand the purposes of the two Sobel filters for edge detection. As a reminder, here are the two Sobel filters:
(Vertical) Sobel Filter:
$$
\frac{1}{8} \times\left[\begin{array}{rrr}
-1 & 0 & 1 \\
-2 & 0 & 2 \\
-1 & 0 & 1
\end{array}\right]
$$
(Horizontal) Sobel Filter:
$$
\frac{1}{8} \times\left[\begin{array}{ccc}
1 & 2 & 1 \\
0 & 0 & 0 \\
-1 & -2 & -1
\end{array}\right]
$$
Now, let's expand our architecture to two convolutional filters. In the first layer of the convolutional neural network, we now apply two filters to the input image instead of one. We make no changes to the training procedure.
Here are the convergence plots that result from training a model with two convolutional filters.
What do you notice about the difference between these convergence plots and the convergence plots from training models that only have one filter? What might be an explanation as to why these differences would exist?","In this experiment, there is less variation across initializations for the 2 filter models, and the 2 filter models converge faster. This could be because two filters can detect two features/patterns, not just 1. Also, any individual filter might not be initialized in a way that enables gradient descent to find a good solution. By having two filters, there might be some ""division of labor"" between them.
However, it's important to stress that this doesn't mean two filters always ""win"". Factors like the random initial weights and SGD can come to influence the training loss."
2,EECS,6.100A,Introduction to Computer Science Programming in Python,None,None,Finger Exercise Lecture 2,Iteration,2,nan,0.7142857143,Text,"Assume you are given a positive integer variable named N. Write a piece of Python code that prints hello world on separate lines, N times. You can use either a while loop or a for loop.",Programming,"for i in range(N):
      print(""hello world"")",Assume you are given a positive integer variable named N. Write a piece of Python code that finds the cube root of N. The code prints the cube root if N is a perfect cube or it prints error if N is not a perfect cube. Hint: use a loop that increments a counter -- you decide when the counter should stop.,"for i in range(N + 1):
      if i ** 3 == N:
         print(i)
         break
      if i ** 3 > N:
         print(""error"")
         break","Assume you are given a variable named number (has a numerical value). Write a piece of Python code that
prints out one of the following strings:
• positive if the variable number is positive.
• negative if the variable number is negative.
• zero if the variable number is equal to zero.","if number > 0:
   print(""positive"")
elif number < 0:
   print(""negative"")
else:
   print(""zero"")","Assume you are given a string variable named my_str. Write a piece of Python code that prints out a new string containing the even indexed characters of my_str. For example, if my_str = ""abcdefg"" then your code should print out aceg.","result = """"
for i in range(len(my_str)):
      if i%2 == 0:
         result += my_str[i]
print(result)"
76,Mathematics,18.701,Algebra I,18.100B,None,Midterm Exam 1,Cosets,5,nan,5,Text,"Let $H$ and $K$ be subgroups of a group $G$, of orders $|H|=3$ and $|K|=5$. Some cosets of $H$ contain elements of $K$. How many such cosets could there be?",Open,"First, the intersection $H \cap K$ is the trivial subgroup $<1>$ of $G$, because $H \cap K$ is a subgroup of $H$ and also a subgroup of $K$. Its order divides $|H|=3$ and $|K|=5$.
Each element $k$ of $K$ is in the coset $k H$, and because the cosets of $H$ partition $G, k H$ is the only coset that contains $k$. We show that, if $k$ and $k^{\prime}$ are elements of $K$, and if the cosets $k H$ and $k^{\prime} H$ are equal, then $k=k^{\prime}$. This will prove that there are 5 distinct cosets that contain elements of $K$.
If $k H=k^{\prime} H$, then $k^{\prime}$ will be an element of $k H$, say $k^{\prime}=k h$, with $h \in H$. Then $k^{-1} k^{\prime}=h$. The left side of this equation is in $K$, and the right side is in $H$. Since $H \cap K=<1>, k^{-1} k^{\prime}=1$ and $k^{\prime}=k$.","Let $G \stackrel{\varphi}{\rightarrow} C_{6}$ be a surjective homomorphism from a group $G$ to a cyclic group of order 6 , and let $K$ be the kernel of $\varphi$. How many subgroups of $G$ contain $K$?","The answer is 4.
The Correspondence Theorem asserts that subgroups of $G$ that contain $K$ correspond bijectively to subgroups of the cyclic group $C_{6}$. The cyclic group has four subgroups. If $x$ is a generator of $C_{6}$, the subgroups of $C_{6}$ are:
$\langle x\rangle$, which has order 6 ,
$<x^{2}>$, which has order 3 ,
$\left\langle x^{3}\right\rangle$, which has order 2 , and
$<1>$, which has order 1 . ",Let $G$ be a cyclic group of order 15. How many of the elements of $G$ are generators for the group?,"There are 8 such elements.
Say that $G$ is the cyclic group generated by an element $x$. A power $x^{k}$ will generate the group if and only if $k$ and 15 have no common factor. The eight integers between 0 and 14 that are relatively prime to 15 are $\mathrm{t} 1,2,4,7,8,11,13,14$.","Let $H$ be a nonempty subset of a group $G$. Suppose that $H$ is a finite set, and that it is closed under multiplication. Prove that $H$ is a subgroup.","To show that a nonempty subset $H$ is a subgroup, one must verify closure, which is given, that the identity is in $H$, and that $H$ contains the inverse of every one of its elements.
Let $x$ be an arbitrary element of $H$. Such an element exists because $H$ isn't empty. The powers $x, x^{2}, \ldots$ are in $H$, and they aren't distinct because $H$ is a finite set. Therefore $x^{m}=x^{n}$ for some distinct integers $m>n$. When wey cancel $x^{n}$ from this equation, we obtain $x^{m-n}=1$. Therefore 1 is in $H$, and the inverse $x^{-1}=x^{m-n-1}$ is in $H$ too."
23,Mathematics,18.2,Principles of Discrete Applied Mathematics,None,18.C06,Problem Set 5,Euclidean Algorithm,2,nan,1.222222222,Text,"Does 327 have a multiplicative inverse modulo 1024? If so, find it.",Numerical,"Note that $1024=2^{10}$ and 327 is odd. So they are relatively prime, and thus 327 will have a multiplicative inverse modulo 1024. We use the extended Euclidean algorithm to find the inverse. As we compute the gcd, we maintain $x$ and $y$ such that $1024 x+327 y$ equals the current iterate:
\begin{tabular}{c|c|c} 
& $x$ & $y$ \\
1024 & 1 & 0 \\
327 & 0 & 1 \\
43 & 1 & $-3$ \\
26 & $-7$ & 22 \\
17 & 8 & $-25$ \\
9 & $-15$ & 47 \\
8 & 23 & $-72$ \\
1 & $-38$ & 119
\end{tabular}
In the end we see that $1=1024 \times(-37)+327 \times 119$. Taking modulo 1024 on both sides, we get
$$
327 \times 119 \equiv 1 \quad(\bmod 1024) .
$$
So the inverse is $119(\bmod 1024)$. ",Compute the multiplicative inverse to $5 \bmod 97$.,"We use the Euclidean algorithm to compute an expression of the form $a \times 5+b \times 97=1$. The following table shows the steps of the algorithm.
$$
\begin{array}{c|c}
97 & 0 \times 5+1 \times 97 \\
5 & 1 \times 5+0 \times 97 \\
2 & (-19) \times 5+1 \times 97 \\
1 & (39) \times 5+(-2) \times 97
\end{array}
$$
This tells us that 39 is the multiplicative inverse of $5 \bmod 97$.","Give one solution of
$$
x^{5} \equiv 1 \quad \bmod 1001
$$
different than $x \equiv 1 \bmod$ 1001. (Notice that 1001 is a composite number...) (If you'd like to explore, you could like at the number of solutions of this modular equation.)","Note that $1001=7 \times 11 \times 13$. The Chinese remainder theorem then says that any solution of our problem must simultaneously satisfy the three equations
$$
\begin{array}{cc}
x^{5} \equiv 1 & (\bmod 7) \\
x^{5} \equiv 1 & (\bmod 11)
\end{array}
$$
and
$$
x^{5} \equiv 1 \quad(\bmod 13) .
$$
From the previous part, we know that $x$ must satisfy
$$
x \equiv 1 \quad(\bmod 7)
$$
and
$$
x \equiv 1 \quad(\bmod 13),
$$
so the Chinese remainder theorem tells us that
$$
x \equiv 1 \quad(\bmod 91) .
$$
The solutions to $x^{5} \equiv 1(\bmod 11)$ are given by $x \equiv 1,3,4,5,9(\bmod 11)$.
We will compute a solution using $x \equiv 3(\bmod 11)$, and the other solutions can be done similarly. We know that
$$
x=1+91 k \equiv 3 \quad(\bmod 11),
$$
so we need
$$
3 k \equiv 2 \quad(\bmod 11) .
$$
Since $3^{10} \equiv 1(\bmod 11)$, we know that $3^{9} \equiv 4(\bmod 11)$ is the inverse of 3, and we get
$$
k \equiv 3^{-1} \cdot 2 \equiv 4 \cdot 2 \equiv 8 \quad(\bmod 11) .
$$
Thus, we get $x=729+1001 n$ for some integer $n$ in the case where $x \equiv 3(\bmod 11)$. All five solutions are given by
$$
x \equiv 1,729,92,456,911 \quad(\bmod 11) .
$$","Find a solution to the equation
$$
x^{2} \equiv 1 \quad \bmod 91
$$
such that $x \not \equiv \pm 1 \bmod 91$.","The Chinese Remainder Theorem tells us that finding a solution to this equation is equivalent to solving
$$
x^{2} \equiv 1 \quad \bmod 7
$$
and
$$
x^{2} \equiv 1 \quad \bmod 13.
$$
These two equations are solved by $x \equiv \pm 1 \bmod 7$ and $x \equiv \pm 1 \bmod 13$ respectively.
In order to get a solution $x \not \equiv \pm 1 \bmod 91$, we must have that $x$ satisfies both $x \equiv 1$ $\bmod 7$ and $x \equiv-1 \bmod 13$ or $x$ satisfies both $x \equiv-1 \bmod 7$ and $x \equiv 1 \bmod 13$. In the first case, we have that $x=-1+13 k$ and $k$ needs to satisfy that $-1+13 k \equiv 1$ $\bmod 7$, or $13 k \equiv 6 k \equiv 2 \bmod 7$. We can try every value $0 \leq k \leq 6$ to find that $k=5$ works. One can also find this by computing that the multiplicative inverse of $6 \bmod 7$ is 6 . This gives us 64 as a solution. (A similar strategy works in the second case, where we get 27 . But only one solution was asked in the statement of the question.)"
88,EECS,6.121,Introduction to Algorithms,"6.100A, 6.1200",6.101,Mini Quiz 4,Priority-Queue Sort,3,nan,0.2222222222,Text,True or False: PRIORITY-QUEUE-SORT takes $O(n \log n)$ time regardless of the implementation of the Priority Queue.,Multiple Choice,False. Implementations where INSERT or DELETE take $\Omega(n)$ time will result in worst case run-times of $\Omega\left(n^{2}\right)$.,"Please select True or False for the following.
Suppose a data structure has amortized $O(\log n)$ running time for all operations, where $n$ is the number of operations performed. Then, it is possible for a sequence of $n$ operations to take $\omega(n \log n)$ time.","False. Amortization is a worst-case guarantee, so any $n$ operations must use at $\operatorname{most} O(n \log n)$ time.","True or False. Assume that a problem $P$, with inputs consisting on $n$ integers, has a Pseudo-Polynomial time algorithm $A$. If we restrict all inputs to be positive integers smaller than $3 n \log n$, then $A$ runs in polynomial time.","True. The algorithm $A$ runs in time polynomial on $n$ and a bound $L$ on the size of the integers. If $L \leq 3 n \log n$, then the run time is polynomial on $n$. ","Which of the following statements is true about Priority Queues?
(a) Regardless of the application, a Heap implementation is preferable to an AVL-tree implementation.
(b) Regardless of the application, an AVL-tree implementation is preferable to a Heap implementation.
(c) None of the above.","(c) A Heap implementation is in-place whereas the AVL implementation is not. On the other hand, if the number of elements is not known in advance, the insert and delete_max operations in the Heap implementation take $O(\log n)$ amortized time whereas the AVL implementation has a worst-case guarantee."
92,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 2,Propositional Logic,5,nan,1.041666667,Text,"Write a function that takes a propositional sentence and evaluates it against a single model. You may find python's builtin is instance useful. For example, is instance(sentence, And) returns whether a sentence is an And.
For reference, our solution is 15 line(s) of code. 
def evaluate_propositional_sentence(sentence, model):
'''Evaluate a propositional sentence against a single model.
Args:
sentence: A Proposition, And, Or, Not, or Implies.
model: A PropositionalModel.
Returns:
holds: A bool representing the truth value of the sentence
under the model.
'''
raise NotImplementedError(""Implement me!"")",Programming,"def evaluate_propositional_sentence(sentence, model):
'''Evaluate a propositional sentence against a single model.
Args:
sentence: A Proposition, And, Or, Not, or Implies.
model: A PropositionalModel.
Returns:
holds: A bool representing the truth value of the sentence
under the model.
'''
if isinstance(sentence, Proposition):
return model[sentence]
elif isinstance(sentence, And):
return (evaluate_propositional_sentence(sentence.sentence1, model) and
evaluate_propositional_sentence(sentence.sentence2, model))
elif isinstance(sentence, Or):
return (evaluate_propositional_sentence(sentence.sentence1, model) or
evaluate_propositional_sentence(sentence.sentence2))
elif isinstance(sentence, Not):
return not evaluate_propositional_sentence(sentence.sentence, model)
elif isinstance(sentence, Implies):
return ((not evaluate_propositional_sentence(sentence.sentence1, model))
or evaluate_propositional_sentence(sentence.sentence2, model))
raise NotImplementedError(""Unrecognized sentence type"")","Use your implementation of evaluate_atom to complete the following implementation of FOL sentence evaluation.
For reference, our solution is 37 line(s) of code.
In addition to all the utilities defined at the top of the Colab notebook, the following functions are available in this question environment: evaluate_atom. You may not need to use all of them.
def evaluate_fol_sentence(sentence, model, substitution=None):
'''Evaluate a first-order logic sentence against a single model.
Note that Literals are not used here (we use them in later problems).
Be careful about updating `substitution` recursively. You may want
to create a copy of the dict (`substitution.copy()`) before each
recursive call.
Args:
sentence: An Atom, And, Or, Not, Implies, ForAll, or Exists.
model: A FOLModel.
substitution: A dict mapping variables to objects, or None,
representing an empty dict.
Returns:
holds: A bool representing the truth value of the sentence
under the model.
'''
raise NotImplementedError(""Implement me!"")","def evaluate_fol_sentence(sentence, model, substitution=None):
'''Evaluate a first-order logic sentence against a single model.
Note that Literals are not used here (we use them in later problems).
Be careful about updating `substitution` recursively. You may want
to create a copy of the dict (`substitution.copy()`) before each
recursive call.
Args:
sentence: An Atom, And, Or, Not, Implies, ForAll, or Exists.
model: A FOLModel.
substitution: A dict mapping variables to objects, or None,
representing an empty dict.
Returns:
holds: A bool representing the truth value of the sentence
under the model.
'''
if substitution is None:
substitution = {}
else:
substitution = substitution.copy()
if isinstance(sentence, Atom):
return evaluate_atom(sentence, model,
substitution=substitution)
elif isinstance(sentence, And):
return evaluate_fol_sentence(sentence.sentence1, model,
substitution=substitution) and
evaluate_fol_sentence(sentence.sentence2, model,
substitution=substitution)
elif isinstance(sentence, Or):
return evaluate_fol_sentence(sentence.sentence1, model,
substitution=substitution) or
evaluate_fol_sentence(sentence.sentence2, model,
substitution=substitution)
elif isinstance(sentence, Not):
return not evaluate_fol_sentence(sentence.sentence, model,
substitution=substitution)
elif isinstance(sentence, Implies):
return (not evaluate_fol_sentence(sentence.sentence1, model,
substitution=substitution)) or
evaluate_fol_sentence(sentence.sentence2, model,
substitution=substitution)
elif isinstance(sentence, ForAll):
assert sentence.variable not in substitution
return all([evaluate_fol_sentence(sentence.sentence, model,
{**substitution, **{sentence.variable: assignment}})
for assignment in model.objects])
elif isinstance(sentence, Exists):
assert sentence.variable not in substitution
return any([evaluate_fol_sentence(sentence.sentence, model,
{**substitution, **{sentence.variable: assignment}})
for assignment in model.objects])
raise NotImplementedError(""Unrecognized sentence type"")","Write a function that takes a FOL atom and evaluates it against a single model.
For reference, our solution is 10 line(s) of code.
def evaluate_atom(atom, model, substitution):
'''Evaluate if an atom holds under the model.
Args:
atom: An Atom.
model: A FOLModel.
substitution: A dict mapping variables to objects.
Returns:
holds: A bool.
'''
raise NotImplementedError(""Implement me!"")","def evaluate_atom(atom, model, substitution):
'''Evaluate if an atom holds under the model.
Args:
atom: An Atom.
model: A FOLModel.
substitution: A dict mapping variables to objects.
Returns:
holds: A bool.
'''
relation = model.interpretation.predicate_map[atom.predicate]
objects = []
for term in atom.terms:
if term in model.interpretation.constant_map:
obj = model.interpretation.constant_map[term]
else:
obj = substitution[term]
objects.append(obj)
return tuple(objects) in relation","Let's explore proof by model checking. We are interested in finding out which other sentences are entailed by the sentence $(A \Rightarrow B) \Rightarrow C$. We can do this by comparing the sets of models (assignments of truth values to propositions) in which the sentences are true.
Consider a domain with three propositional variables, $A, B$, and $C$.
Check all models in which $A \Rightarrow(B \Rightarrow C)$ is true. 
(a) A=t, B=t, C=t
(b) A=t, B=t, C=f
(c) A=t, B=f, C=t
(d) A=t, B=f, C=f
(e) A=f, B=t, C=t
(f) A=f, B=t, C=f
(g) A=f, B=f, C=t
(h) A=f, B=f, C=f","(a) A=t, B=t, C=t
(c) A=t, B=f, C=t
(d) A=t, B=f, C=f
(e) A=f, B=t, C=t
(f) A=f, B=t, C=f
(g) A=f, B=f, C=t
(h) A=f, B=f, C=f"
46,Mathematics,18.6,Probability and Random Variables,18.02,None,Problem Set 5,Exponential Random Variable,1,a,0.1,Text,"Suppose that the total number of thousands of miles that a car can be driven before it would need to be junked is an exponential random variable with parameter $\frac{1}{20}$. If Alice purchases a used car that has already been driven for $10,000$ miles, what is the probability that she would get at least $20,000$ additional miles out of it?",Numerical,"Let the exponential random variable $X$ be the total number of thousands of miles that Alice's car can be driven before it would need to be junked.
$P(X \geq 30 | X \geq 10) = \dfrac{P(X \geq 30 \cap X \geq 10)}{P(X \geq 10)} = \dfrac{P(X \geq 30)}{P(X \geq 10)} = \dfrac{e^{-30/20}}{e^{-10/20}} = \dfrac{1}{e}$.","Repeat this calculation under the assumption that the lifetime mileage of the car is not exponentially distributed but rather is (in thousands of miles): uniformly distributed over $(0,40)$.","Let the uniform random variable $Y$ be the total number of thousands of miles that Alice's car can be driven before it would need to be junked.
$P(Y \geq 30 | Y \geq 10) = \dfrac{P(Y \geq 30 \cap Y \geq 10)}{P(Y \geq 10)} = \dfrac{P(Y \geq 30)}{P(Y \geq 10)} = \dfrac{\frac{10}{40}}{\frac{30}{40}} = \dfrac{1}{3}$.","Repeat this calculation under the assumption that the lifetime mileage of the car is not exponentially distributed but rather is (in thousands of miles): normal with parameters $(\mu, \sigma^2) = (15,25)$.","Let the normal random variable $Z$ be the total number of thousands of miles that Alice's car can be driven before it would need to be junked.
$P(Z \geq 30 | Z \geq 10) = \dfrac{P(Z \geq 30 \cap Z \geq 10)}{P(Z \geq 10)} = \dfrac{P(Z \geq 30)}{P(Z \geq 10)} = \dfrac{1 - P(Z < 30)}{1 - P(Z < 10)} = \dfrac{1 - \phi(3)}{1 - \phi(-1)} = 0.0016$.","Economists often make use of an exponential utility function for money: $U(x)=-e^{-x / R}$, where $R$ is a positive constant representing an individual's risk tolerance. Risk tolerance reflects how likely an individual is to accept a lottery with a particular expected monetary value (EMV) versus some certain payoff. As $R$ (which is measured in the same units as $x$ ) becomes larger, the individual becomes less risk-averse.
Assume Mary has an exponential utility function with $R=\$ 400$. Mary is given the choice between receiving $\$ 400$ with certainty (probability 1 ) or participating in a lottery which has a $60 \%$ probability of winning $\$ 5000$ and a $40 \%$ probability of winning nothing.
In 1713, Nicolas Bernoulli stated a puzzle, now called the St. Petersburg paradox, which works as follows. You have the opportunity to play a game in which a fair coin is tossed repeatedly until it comes up heads. If the first heads appears on the $n$th toss, you win $2^{n}$ dollars.
How much would you, personally, pay to play the game?",We would pay something like $3.
6,EECS,6.18,Computer Systems Engineering,"6.1010, 6.1910",None,Hands-on 2,Unix,1,b,0.0625,Text,"Give a series of UNIX commands that will produce the number of words in the file /usr/share/dict/words which do not contain any of the letters a, e, i, o, or u (upper and lower case).",Open,"I then used: 
rarnott@buzzword-bingo:/$ grep ""[^aeiou]"" /usr/share/dict/words | wc -l
99166","Give a series of UNIX commands that will produce a ""long"" listing of the smallest 5 files in the /etc directory whose name contains the string "".conf"", sorted by increasing file size.","I used the sequence of commands: cd /etc | ls -S -r | grep .conf | head -5. 
It returned:
fuse.conf.debathena
pine.conf
krb5.conf
fuse.conf
hesiod.conf","The UNIX paper explains in section 6.3 that a user can type two commands together in parenthesis separated by a semicolon, and redirect the output to a file. The file will then contain the concatenation of the two commands. The example from the paper is roughly:
athena% (date ; ls) > temp1 & 
Note that this example uses the & operator to run the process asynchronously. The authors also mention that one can use the & operator multiple times on one line. For example, we can do almost the same thing:
athena% (date & ls) > temp2 &
Let’s try to figure out the difference between these two commands. First, we will write a very simple variation on the yes command. To do so, we will use the ""command file"" functionality described in section 6.4 of the paper. Most people call these command files shell scripts, since they are essentially simple scripts that are executed by the shell.
First, start up a copy of emacs editing a new file called ""myyes"".
athena% emacs myyes 
Now, enter the following lines into your file:
#!/bin/sh
echo y
sleep 1
echo n
(If you are having trouble with backspace, use the delete key.)
Save the file (Ctrl-x Ctrl-s) and exit emacs (Ctrl-x Ctrl-c). If you don't already know what the echo and sleep commands do, look them up in the man pages. Lastly, make the file executable by running the following command:
athena% chmod a+rx myyes
Now let's try running the following two commands:
athena% (./myyes ; ./myyes) > temp3 
athena% (./myyes & ./myyes) > temp4 
Compare the two temp files. Based on your understanding of file I/O in UNIX, what is going on here, and why? Is this different from what you would expect? (If there is more than one difference between the two files, it is the ordering of the letters y and n that we are interested in). ","In the case of the first temp file (temp3), the semicolon enforces the sequential nature of the two commands. The second execution of myyes does not start until the first ends, so we see “y n y n” in sequence.
In the case of the second temp file (temp4), the “&” allows both executions to take place at the same time, and so the order can be jumbled, and as stated, on faster, multi-core machines output might be lost. In particular, I get the output “y y n”. Clearly the second call to myyes started before the first ended, and a second “n” was not printed.
This is what we would expect given the description of the function of “&.”","The authors explain that the following two commands are functionally equivalent (except that you have to remove the temp file afterwards in the second case).  We’ll use athena% to indicate the command-line prompt:
athena% ls | head -1 
athena% ls > temp; head -1 < temp
Try the above commands in the /etc directory on athena; it will fail. How else can the second command not produce the same output as the first? Can you think of any negative side effects that the second construction might cause for the user? ","The second command fails because the user does not have permission to create files in /etc. The second output would also fail if there is already a temp file that does not allow the user to write.
In addition to the two issues raised above, the second construction ends up creating dummy files, which can waste space. It also is not atomic, and there is more of a chance that the true output (what would be returned by the first construction) could change before the second construction outputs its answer."
139,EECS,18.C06,Linear Algebra and Optimization,18.02,None,Midterm Exam 1,Matrix Rank,3,nan,0.9375,Text,"Let $A$ be an $m \times n$ matrix and suppose that $v$ is an $m$ dimensional vector. Now let
$$
B=\left[\begin{array}{ll}
A & v
\end{array}\right]
$$
Then $\operatorname{rank}(B) \geq \operatorname{rank}(A)$.",Open,True. The rank of $A$ is equal to the maximum number of linearly independent columns of $A$. Appending another column means that the size of the largest set of linearly independent columns can only go up.,"Consider two $n \times n$ projection matrices
$$
P=I-v_{1} v_{1}^{\top} \quad \text { and } \quad Q=I-v_{2} v_{2}^{\top}
$$
where $v_{1}$ and $v_{2}$ have unit norm and are orthogonal to each other. Let $A=P Q$.
What is the rank of $A$?","By the rank-nullity theorem, we have that
$$
\operatorname{rank}(A)+\operatorname{dim} N(A)=n .
$$
By the previous item, $\operatorname{dim} N(A)=2$, and thus the rank of $A$ is $n-2$.","Let $A$ be an $m \times n$ matrix of $\operatorname{rank} r$, let $I$ be a set of $r$ row indices such that the corresponding rows of $A$ are independent, and let $J$ be a set of $r$ column indices such that the corresponding columns of $A$ are independent. Let $M$ denote the $r \times r$ submatrix of $A$ obtained by taking rows from $I$ and columns from $J$. Prove that $M$ is invertible.",Let's permute rows and columns to make $M$ into the upper left $r \times r$ submatrix of $A$. We can make row operations using the $r$ rows at the top to clear out the rows with indices $>r$. The $r$ rows of $A$ at the top and the $r$ columns on the left of $A$ remain independent. Then we use column operations to clear out the columns with indices $>r$. etc...,"Given an $n \times m$ matrix $A$ with SVD
$$
A=\sum_{i=1}^{r} \sigma_{i} u_{i} v_{i}^{\top}
$$
and consider the truncated SVD for $k<r$ given by
$$
B=\sum_{i=1}^{k} \sigma_{i} u_{i} v_{i}^{\top}
$$
Show that $C(B) \subseteq C(A)$ and $N(A) \subseteq N(B)$. Are these inclusions strict? You may assume that $\sigma_{1}, \sigma_{2}, \ldots, \sigma_{r}$ are all strictly positive.","Since any vector $x \in \mathbb{R}^{m}$ can be written as a linear combination of orthogonal vectors $v_{1}, \ldots, v_{m}$, every $B x \in C(B)$ can be written as a linear combination of $u_{1}, \ldots, u_{k}$:
$$
\begin{aligned}
x & =a_{1} v_{1}+\cdots+a_{m} v_{m} \\
B x & =\sum_{i=1}^{k} \sum_{j=1}^{m} \sigma_{i} a_{j} u_{i} v_{i}^{\top} v_{j} \\
& =\sum_{i=1}^{k} \sigma_{i} a_{i} u_{i} .
\end{aligned}
$$
By a similar argument, every $A x \in C(A)$ can be written as a linear combination of $u_{1}, \ldots, u_{r}$. Since $r>k, C(B)$ is a strict subset of $C(A)$ as $u_{i}$ are linearly independent.
Similarly, any vector in $N(A)$ can be written as a linear combination of $v_{r+1}, \ldots, v_{m}$ and any vector in $N(B)$ can be written as a linear combination of $v_{k+1}, \ldots, v_{m}$. Since $k+1<r+1$, and $v_{i}$ are linearly independent, $N(A)$ is a strict subset of $N(B)$."
193,EECS,18.C06,Linear Algebra and Optimization,18.02,None,Final Exam,Inverse Matrix,13,d,0.6956521739,Text,"Let $a, b$ be vectors in $\mathbb{R}^{n}$. In this problem we will find an expression for the inverse of $M=I-a b^{T}$ and explore some implications for optimization.
Consider the minimization problem
$$
\min _{x} f(x), \quad f(x):=\|x\|^{2}-\left(c^{T} x\right)^{2}-2 d^{T} x.
$$
You can assume $\|c\|<1$ in which case the function is strictly convex. Write down the optimality conditions and use your answer from part (c) to find the optimal solution.",Open,"The cost function can be written as
$$
f(x)=x^{T}\left(I-c c^{T}\right) x-2 d^{T} x,
$$
so the gradient optimality condition is
$$
\nabla f(x)=2\left(I-c c^{T}\right) x-2 d=0,
$$
or equivalently, $x=\left(I-c c^{T}\right)^{-1} d$. Taking $a=b=c$ in the expression for $M^{-1}$, we have
$$
x=\left(I-c c^{T}\right)^{-1} d=\left(I-\frac{c c^{T}}{1-c^{T} c}\right) d.
$$","Let $a, b$ be vectors in $\mathbb{R}^{n}$. In this problem we will find an expression for the inverse of $M=I-a b^{T}$ and explore some implications for optimization.
What is the minimum of $f(x)$ when $\|c\|>1$? Give a geometric interpretation. ","When $\|c\|>1$ the function is unbounded below, so the minimum is $-\infty$. To see this, notice that for $x=\lambda c$ we have
$$
f(\lambda c)=\lambda^{2}\left(c^{T} c\right)\left(1-c^{T} c\right)-\lambda d^{T} c,
$$
which goes to $-\infty$ as $\lambda \rightarrow \infty$.","Let $a, b$ be vectors in $\mathbb{R}^{n}$. In this problem we will find an expression for the inverse of $M=I-a b^{T}$ and explore some implications for optimization.
Suppose that $a^{T} b=1$. Find a nonzero vector in $N(M)$.","By the assumption, both $a$ and $b$ are nonzero. We have
$$
M a=\left(I-a b^{T}\right) a=a-a\left(b^{T} a\right)=\left(1-a^{T} b\right) a=0,
$$
so $a \in N(M)$.","Let $a, b$ be vectors in $\mathbb{R}^{n}$. In this problem we will find an expression for the inverse of $M=I-a b^{T}$ and explore some implications for optimization.
Recall that for any matrix $A$ with $\|A\|<1$ we have the identity
$$
(I-A)^{-1}=\sum_{k=0}^{\infty} A^{k}=I+A+A^{2}+\cdots
$$
Use this formula to compute $M^{-1}$ and simplify to get an expression of the form
$$
M^{-1}=I+\alpha a b^{T}
$$
What is the value of $\alpha$?","Applying the formula, we have
$$
\begin{aligned}
\left(I-a b^{T}\right)^{-1} & =I+a b^{T}+\left(a b^{T}\right)\left(a b^{T}\right)+\left(a b^{T}\right)\left(a b^{T}\right)\left(a b^{T}\right)+\cdots \\
& =I+a b^{T}+\left(b^{T} a\right)\left(a b^{T}\right)+\left(b^{T} a\right)^{2}\left(a b^{T}\right)+\cdots \\
& =I+a b^{T}\left(1+\left(b^{T} a\right)+\left(b^{T} a\right)^{2}+\cdots\right) \\
& =I+a b^{T}\left(1-b^{T} a\right)^{-1},
\end{aligned}
$$
i.e., $\alpha=1 /\left(1-b^{T} a\right)$. "
106,EECS,6.122,Design and Analysis of Algorithms,6.121,None,Midterm Exam 1,Probability,3,b,2.5,Text,"After graduating from MIT, Ben went to work for Atem Inc. where he had a chance to apply what he learned about hash tables in 6.046. Consider a hash table with $n$ items and $m=n$ slots where collisions are resolved by chaining. The hash function is chosen from a pairwise independent hash family $\mathcal{H}$ consisting of functions $h: \mathcal{U} \rightarrow\{0,1, \ldots, m-1\}$.
Ben remembered the definition of a pairwise independent hash family from a $6.046$ problem set and a recitation: $\mathcal{H}$ is pairwise independent if for every pair of distinct $x, y \in \mathcal{U}$, when $h$ is chosen uniformly at random from $\mathcal{H}$, the probability distribution of $(h(x), h(y))$ is uniformly random in the set $\{0,1, \ldots, m-1\} \times\{0,1, \ldots, m-1\}$. In particular, $h(x)$ and $h(y)$ are independent random variables.
Ben learned in $6.046$ how to analyze the expected length of any given chain, but he realizes there is more to the story. His implementation showed that some chains can be rather long. In this problem, you will help Ben bound the length of the longest chain.
Ben (still) loves tail bounds and wants to analyze the probability that for a fixed slot $j$, the chain at slot $j$ is (strictly) longer than $2 \sqrt{m}$. Show that this probability is at most $\frac{1}{4 m}$.",Open,"We first compute the variance of $L$. By pairwise independence,
$$
\operatorname{Var}[L]=\sum_{i=1}^{n} \operatorname{Var}\left[X_{i}\right]=\sum_{i=1}^{n} \mathrm{E}\left[I_{i}^{2}\right]-\mathrm{E}\left[I_{i}\right]^{2}=n \cdot\left(1 / m-1 / m^{2}\right) \leq n / m=1
$$
Applying Chebyshev's inequality, we get
$$
\operatorname{Pr}[L>2 \sqrt{m}]=\operatorname{Pr}[L \geq 1+2 \sqrt{m}] \leq \operatorname{Pr}[|L-1| \geq 2 \sqrt{m}] \leq 1 / 4 m.
$$","After graduating from MIT, Ben went to work for Atem Inc. where he had a chance to apply what he learned about hash tables in 6.046. Consider a hash table with $n$ items and $m=n$ slots where collisions are resolved by chaining. The hash function is chosen from a pairwise independent hash family $\mathcal{H}$ consisting of functions $h: \mathcal{U} \rightarrow\{0,1, \ldots, m-1\}$.
Ben remembered the definition of a pairwise independent hash family from a $6.046$ problem set and a recitation: $\mathcal{H}$ is pairwise independent if for every pair of distinct $x, y \in \mathcal{U}$, when $h$ is chosen uniformly at random from $\mathcal{H}$, the probability distribution of $(h(x), h(y))$ is uniformly random in the set $\{0,1, \ldots, m-1\} \times\{0,1, \ldots, m-1\}$. In particular, $h(x)$ and $h(y)$ are independent random variables.
Ben learned in $6.046$ how to analyze the expected length of any given chain, but he realizes there is more to the story. His implementation showed that some chains can be rather long. In this problem, you will help Ben bound the length of the longest chain.
Show that with probability at least $3 / 4$, no chain is longer than $2 \sqrt{m}$.","We know by part (b) that the probability that any given chain is longer than $2 \sqrt{m}$ is at most $1 / 4 m$. By a union bound, the probability that there exists a chain (out of $m$ ) that is longer than $2 \sqrt{m}$ is at most $m \cdot 1 / 4 m=1 / 4$. Thus, with probability at least $3 / 4$, no chain is longer than $2 \sqrt{m}$. ","After graduating from MIT, Ben went to work for Atem Inc. where he had a chance to apply what he learned about hash tables in 6.046. Consider a hash table with $n$ items and $m=n$ slots where collisions are resolved by chaining. The hash function is chosen from a pairwise independent hash family $\mathcal{H}$ consisting of functions $h: \mathcal{U} \rightarrow\{0,1, \ldots, m-1\}$.
Ben remembered the definition of a pairwise independent hash family from a $6.046$ problem set and a recitation: $\mathcal{H}$ is pairwise independent if for every pair of distinct $x, y \in \mathcal{U}$, when $h$ is chosen uniformly at random from $\mathcal{H}$, the probability distribution of $(h(x), h(y))$ is uniformly random in the set $\{0,1, \ldots, m-1\} \times\{0,1, \ldots, m-1\}$. In particular, $h(x)$ and $h(y)$ are independent random variables.
Ben learned in $6.046$ how to analyze the expected length of any given chain, but he realizes there is more to the story. His implementation showed that some chains can be rather long. In this problem, you will help Ben bound the length of the longest chain.
Let's start with what Ben learned in 6.046. For a fixed slot $j$, show that the expected length of the chain at slot $j$ is 1.","Let the items be $x_{1}, \ldots, x_{n}$. Define indicator random variables $I_{1}, \ldots, I_{n}$ where
$$
I_{i}=\left\{\begin{array}{cc}
1 & \text { if } h\left(x_{i}\right)=j \\
0 & \text { otherwise }
\end{array}\right.
$$
Note that the length of the chain is $L=\sum_{i=1}^{n} I_{i}$. The expectation of each $I_{i}$ is the same as $\operatorname{Pr}_{h \in \mathcal{H}}\left[I_{i}=1\right]$ which is $1 / m$. The expected length $L$ of the chain at slot $j$ is
$$
\mathbb{E}_{h \in \mathcal{H}}[L]=\mathbb{E}_{h \in \mathcal{H}}\left[\sum_{i=1}^{n} I_{i}\right]=\sum_{i=1}^{n} \mathbb{E}_{h \in \mathcal{H}}\left[I_{i}\right]=n \cdot \frac{1}{m}=1
$$
where we use linearity of expectation to go from the second to the third term. ","Ben Bitdiddle hears about perfect hashing and thinks that two-level hash tables are too complex. Instead, he has an idea to use one level of hashing but with two hash functions. For this problem, assume that Ben can generate hash functions which are completely random. That is, over $h \in \mathcal{H}$, for all $n$, and for any distinct $x_1, x_2, \ldots, x_n$, the probability distribution of $\left\langle h\left(x_1\right), h\left(x_2\right), \ldots, h\left(x_n\right)\right\rangle$ is uniform over $\{0, \ldots, m-1\}^n$.
Ben uses the two hash functions $h_1$ and $h_2$ in order to place items into $m$ slots, in the following way. Given an item with key $x$ :
• Compute $h_1(x)$ and $h_2(x)$.
• If the slot $h_1(x)$ is empty, place the item there; else, if the slot $h_2(x)$ is empty, place the item there; else, FAIL.
If Ben managed to insert all $n$ items into the tables without a failure event, he can later search for a key $x$ by looking at slots $h_1(x)$ and $h_2(x)$. This gives him worst-case constant time search, which makes him happy. To be completely happy with his method, Ben wants to analyze how long it takes to build the table. In this problem, you will help him figure this out.
Ben starts to do the analysis by considering a random graph $G$, where there are $m$ vertices numbered 0 to $m-1$ corresponding to the slots in the hash tables and $n$ edges corresponding to the pair of hashed values for an item (with possible self-loops). In this representation, edge $e_i$ has endpoints at vertices $h_1\left(x_i\right)$ and $h_2\left(x_i\right)$. Note that a given edge $(u, v)$ is defined by key $k$ if either $h_1(k)=u$ and $h_2(k)=v$ or $h_1(k)=v$ and $h_2(k)=u$.
In the next few parts, you are going to show that, the probability of a failure event (a collision) is less than $1 / 2$ when $m=10 n$.
Show that the probability of any cycle (of length 1 or greater) appearing in $G$ when $m=10 n$ is no greater than $1 / 4$.","By union bound, the probability a cycle exists is bounded by the sum of the probabilities that any $\ell$-cycle exists for all $1 \leq l \leq n$. Thus we sum the answer from (c) for each $\ell$ from 1 to $n$.
$\begin{aligned} \sum_{\ell=1}^n\left(\frac{2 n}{m}\right)^{\ell} & \leq \sum_{\ell=1}^{\infty}\left(\frac{2 n}{m}\right)^{\ell} & \\ &=\frac{2 n / m}{1-2 n / m} & \\ &=\frac{2 n}{m-2 n} & & \\ &=\frac{2 n}{8 n} & \text { for } m=10 n \\ &=\frac{1}{4}\end{aligned}$
By (b) and (e), we can conclude that, for a pair of random hash functions, the probability that Ben can assign $n$ items to $m=10 n$ slots using the hashes is at least $3 / 4$."
16,Mathematics,18.102,Introduction to Functional Analysis,"18.C06, 18.100B",None,Problem Set 3,Measure Zero,3,a,0.25,Text,"Write out proof (I described one briefly in lectures) that a nontrivial interval $[a, b] \subset \mathbb{R}$ were $b>a$, is not of measure zero.",Open,"Suppose that $[a, b]$ has measure zero, then by Prop 2.4, we deduce $\int \chi_{[a, b]}=0$. However, we already have $\int \chi_{[a, b]}=b-a$. This gives contradiction and therefore $[a, b]$ does not have measure zero.","Show that a non-empty open subset of $(-1,1)$ can be written as an at most countable union of open intervals $\left(a_{n}, b_{n}\right)$ where $\left(a_{n}, b_{n}\right) \cap\left(a_{k}, b_{k}\right)=\emptyset$ if $k \neq n$.","Let $O$ be the open subset. Consider the rational points in $O$. For each such $q$ let $O_{q}=\bigcup(a, b)$, where $q \in(a, b) \subset O$. Each $O_{q}$ is open, being the union of open sets, and is non-empty since $O$ being open contains an interval around $q$. Set $a(q)=\inf O_{q}$ and $b(q)=\sup O_{q}$, which exist since $O_{q} \subset(-1,1)$. Then in fact $O_{q}=(a(q), b(q))$ is an interval. Indeed, $a(q) \notin O_{q}$ since otherwise the complement could not be closed, and similarly $b(q) \notin O) q$. However, given $\epsilon>0$ there exists $a<a(q)+\epsilon$ with $(a, q] \subset O_{q}$ since $a(q)$ is the limit of lower points of intervals containing $q$ in $O$. Similarly $[q, b) \subset O_{q}$ for some $b>b(q)-\epsilon$. Thus in fact $O_{q}=(a(q), b(q))$ as claimed. Now, $O_{q}=O_{q^{\prime}}$ for any other $q^{\prime} \in O_{q} \cap \mathbb{Q}$, since $O_{q}$ is an interval containing $q^{\prime}$ so $O_{q} \subset O_{q^{\prime}}$ but then $O_{q^{\prime}}$ is an interval containing $q$ (in $O$ of course) so $O_{q^{\prime}} \subset O_{q}$ and they are equal. It follows that any two of the $O_{q}$ 's for rational points in $O$ are either equal or disjoint. Now, enumerating the rational points in $O$ and dropping repeated intervals gives the intervals $\left(a_{n}, b_{n}\right)$ which form a decomposition of $O$ as an at most countable union of open intervals, since any point of $O$ is in an interval $(a, b) \subset O$ and hence in an $\left(a_{n}, b_{n}\right)$.","Show that every open interval (a,b)⊂(0,1)(a,b)⊂(0,1)(a, b) \subset(0,1) contains a number xxx such that: neither xxx nor any of its powers xm(m=2,3,…)xm(m=2,3,…)x^{m}(m=2,3, \ldots) lies in the Cantor set. In your argument, you may use freely the fact that every number in (am,bm)(am,bm)\left(a^{m}, b^{m}\right) has an mmm-th root in (a,b)(a,b)(a, b). (This is the nastiest problem I've put on a pset so far; among other things, it uses Baire's theorem.)","Let $C$ denote the Cantor set. We have seen that $C$ is closed and contains no open interval. For any $m \in \mathbb{N}$, define
$$
C_{m}:=\left\{x \in[0,1] \mid x^{m} \in C\right\} .
$$
We claim that $C_{m}$ is closed. Indeed, if $x_{n} \in C_{m}$ form a sequence $\left(x_{n}\right)$ converging to some $l, x_{n}^{m}$ converges to $l^{m}$ (Lemma 2.8). But $C$ is closed, so $l^{m} \in C$. Since $0 \leq x_{n} \leq 1$ for all $n, l \in[0,1]$. By definition, $l \in C_{m}$. Suppose that $C_{m}$ contained an open interval $(a, b) \subset(0,1)$. Let $x \in\left(a^{m}, b^{m}\right)$. Then $x$ has an $m$ th root $y \in(a, b)$. By definition of $C_{m}, y^{m}=x \in C$. So $C$ would contain the open interval $\left(a^{m}, b^{m}\right)$, which is a contradiction. Therefore, $C_{m}$ contains no open interval.
By Theorem 4.21, $\bigcup_{m \geq 1} C_{m}$ contains no open interval. Therefore, given any interval $(a, b) \subset(0,1)$, there exists $x$ such that $x \notin \bigcup_{m \geq 1} C_{m}$. This means that no powers of $x$ lie in $C$.","Suppose $E \subset \mathbb{R}$ has the following (well-known) property:
$$
\forall \epsilon>0 \exists \text { a countable collection of intervals }\left(a_{i}, b_{i}\right) \text { s.t. }
$$
$$
\sum_{i}\left(b_{i}-a_{i}\right)<\epsilon, E \subset \bigcup_{i}\left(a_{i}, b_{i}\right) \text {. }
$$
Show that $E$ is a set of measure zero in the sense used in lectures and the notes.","Choose a continuous function $h: \mathbb{R} \longrightarrow[0,1]$ which vanishes in $x<-1, x>2$ and is equal to 1 on $[0,1]$ as we did earlier, by adding 'legs' to the characteristic function for $[0,1]$. Then for any pair of real numbers $b>a$ set
$$
h(x ; a, b)=h\left(\frac{x-a}{b-a}\right) .
$$
Thus $h(x, a, b)=1$ on $[a, b], 0 \leq h(x, a, b) \leq 1$ and $\int_{\mathbb{R}} h(x ; a, b) \leq$ $3(b-a)$. Now, for each $j \in \mathbb{N}$, we can find a collection of intervals $\left(a_{i}(j), b_{i}(j)\right)$, with $b_{i}(j)>a_{i}(j), \sum_{i}\left(b_{i}(j)-a_{i}(j)\right)<2^{-j}$ and $E \subset \bigcup_{i}\left(b_{i}(j), a_{i}(j)\right)$. Set $u_{i, j}=h\left(x ; a_{i}(j), b_{i}(j)\right)$. Let $v_{k} \in \mathcal{C}_{\mathrm{c}}(\mathbb{R})$ be an arrangement of the $u_{i, j}$ as a single sequence. Both sequences $\int v_{k}$ and $v_{k}(x)$ are non-negative, so convergence is equivalent to convergence of the corresponding double sum. Thus
$$
\begin{gathered}
\sum_{j} \sum_{i} \int u_{i, j} \leq 3 \sum_{j} 2^{-j}<\infty \Longrightarrow \sum_{k} \int v_{k}<\infty \\
x \in E \Longrightarrow \sum_{i} u_{i, j}(x) \geq 1 \forall j \geq 1 \Longrightarrow \sum_{k} v_{k}(x)=\infty
\end{gathered}
$$
so $E$ is a set of measure zero."
441,Mathematics,18.01,Calculus I,None,None,Midterm Exam 2,Derivatives,4,nan,1.75,Text,Suppose that $x^{\prime}(t)=\frac{t}{x(t)}$ and $x(0)=2$. Find $x(t)$.,Expression,"Here we use separation of variables. This gives us
$$
\frac{d x}{d t}=\frac{t}{x} \Rightarrow x d x=t d t \Rightarrow \int x d x=\int t d t \Rightarrow \frac{x^{2}}{2}=\frac{t^{2}}{2}+C \Rightarrow x(t)=\pm \sqrt{t^{2}+C} .
$$
However, we know that $x(0)=2$. This tells us to take the positive solution branch. In addition, this also gives us $C=4$, for a final answer of $x(t)=\sqrt{t^{2}+4}$. ","Suppose that $x(t)$ solves the differential equation $x^{\prime}(t)=x(t)^{2}$ and that $x(0)=2$. Using separation of variables, find $x(t)$.","$$
\frac{d x}{d t}=x^{2} \Longrightarrow \frac{d x}{x^{2}}=d t \Longrightarrow \int \frac{d x}{x^{2}}=\int d t .
$$
There exists a constant $C$ such that
$$
-\frac{1}{x}=t+C .
$$
We determine $C$ using the initial condition $t=0, x=2$ and get $C=-1 / 2$. Therefore,
$$
x(t)=-\frac{1}{t+C}=-\frac{\mathbf{1}}{\mathbf{t}-\mathbf{1} / \mathbf{2}} .
$$","Suppose that $x^{\prime}(t)=\frac{1}{x(t)}$ and $x(0)=1$.
Using separation of variables, find $x(t)$.","Write $\frac{d x}{d t}=\frac{1}{x}$ and manipulate to put all $x^{\prime} s$ on one side and all $t^{\prime} s$ on the other:
$$
x d x=d t .
$$
Then integrate
$$
\int x d x=\int d t
$$
and solve the integrals:
$$
\frac{x^{2}}{2}=t+C .
$$
Use the initial condition to find $C$.
$$
\frac{1}{2}=\frac{x(0)^{2}}{2}=0+C,
$$
so $C=\frac{1}{2}$ and $x(t)=\sqrt{2 t+1}$ (note that we chose the positive square root since $x(0)=1)$.","Suppose that $x^{\prime}(t)=f(x(t))$ where the function $f(x)$ is shown in the picture below. 
Check that $x(t)=2$ for all $t$ is a solution of this differential equation.","$x^{\prime}(t)=0$ and $f(x(t))=f(2)=0$, so the differential equation is satisfied."
230,Mathematics,18.01,Calculus I,None,None,Problem Set 5,Differential Equations,17,c,0.06335797254,Text,"Consider the equation $x^{\prime \prime}(t)=-16 x(t)$. Based on the last problem, we might try to sines and cosines. But $\sin t$ is not a solution of this equation.
Find a solution of the equation $x^{\prime \prime}(t)=-16 x(t)$ with $x(0)=1$ and $x^{\prime}(0)=-1$.",Expression,"The general form is
$$
x=A \sin 4 t+B \cos 4 t .
$$
(For the cosine term, the possible $-4$ coefficient on $t$ doesn't give anything new because $\cos (-u)=\cos u$. For the sine term, the possible $-4$ coefficient is taken care of by $A$, because $\sin (-u)=-\sin u$.)
To make $x(0)=1$, set $B=1$. Thus, so far,
$$
x=A \sin 4 t+\cos 4 t .
$$
To make $x^{\prime}(0)=-1$, make $A=-1 / 4$.
$$
x=-\frac{\sin 4 t}{4}+\cos 4 t .
$$","Consider the equation $x^{\prime \prime}(t)=-16 x(t)$. Based on the last problem, we might try to sines and cosines. But $\sin t$ is not a solution of this equation.
For which value or values of $\omega$ does $\sin (\omega t)$ solve the equation?","When $x=\sin \omega t, x^{\prime \prime}=-\omega^{2} \sin \omega t$. So, $\omega=\pm 4$ again.","Consider the equation $x^{\prime \prime}(t)=-16 x(t)$. Based on the last problem, we might try to sines and cosines. But $\sin t$ is not a solution of this equation.
Consider $x(t)=\cos (\omega t)$, where $\omega$ is a constant. For which values of $\omega$ does $\cos (\omega t)$ solve the equation? (Hint: There are two different values of $\omega$, but $\cos \left(\omega_{1} t\right)$ and $\cos \left(\omega_{2} t\right)$ are actually the same function.)","With $x=\cos \omega t, x^{\prime \prime}=-\omega^{2} \cos \omega t$ (two uses of the chain rule, each giving one factor of $\omega$ ). To make $x^{\prime \prime}=-16 x$, set $\omega^{2}=16$. Thus, $\omega=\pm 4$.","Consider the equation $x^{\prime \prime}(t)=-x(t)$.
Find a solution of the equation $x^{\prime \prime}(t)=-x(t)$ where $x(0)=1$ and $x^{\prime}(0)=-1$. (Hint: the solution has the form $A \sin t+B \cos t$. You have to find $A$ and $B$ to arrange that $x(0)=1$ and $x^{\prime}(0)=-1$.)","To make $x(0)=1$, set $B=1$. To make $x^{\prime}(0)=-1$, set $A=-1$. Thus,
$$
x(t)=-\sin t+\cos t .
$$"
40,Mathematics,18.404,Theory of Computation,6.1210/18.200,None,Problem Set 5,L and NL Classes,4,b,0.5555555556,Text,"For any positive integer $x$, let $x^{\mathcal R}$ be the integer
whose binary representation is the reverse of the binary representation
of $x$.  (Assume no leading \st{0}s in the binary representation of $x$.)
Define the function $\fcn{\mathcal R^+}{\IN}{\IN}$ where
$\mathcal R^+(x)=x+x^{\mathcal R}$.
Let $A_3=\setb{x,y} {\mathcal R^+}({\mathcal R^+}(x)) = y\setend$.
Show $A_3 \in$ L.",Open,"Log space isn't enough to write down the $\operatorname{sum} x+x^{\mathcal{R}}$, so we employ the compute-on-the-fly technique introduced in Theorem $8.23$ (if $A \leq_{\mathrm{L}} B$ and $B \in \mathrm{L}$, then $A \in \mathrm{L}$ ). The technique saves space by computing and recomputing the bits of that sum when each one is needed to compute $\mathcal{R}^{+}$of that sum. Thus $A_{3} \in \mathrm{L}$.","For any positive integer $x$, let $x^{\mathcal R}$ be the integer
whose binary representation is the reverse of the binary representation
of $x$.  (Assume no leading \st{0}s in the binary representation of $x$.)
Define the function $\fcn{\mathcal R^+}{\IN}{\IN}$ where
$\mathcal R^+(x)=x+x^{\mathcal R}$.
Let $A_2=\setb{x,y} {\mathcal R^+}(x) = y\setend$.
Show $A_2 \in$ L.",The function which sums two binary numbers is computable in log space by implementing the usual addition procedure that starts with the low order bits and maintains the carry bit. Log space is sufficient to keep track of a location in $x$ and the corresponding locations in $x^{\mathcal{R}}$ and $y$ to do this sum. Each computed digit is compared to the corresponding digit of $\mathrm{y}$ and then forgotten. Thus $A_{2} \in \mathrm{L}$.,"Given $x \in[0,1)$, consider its base 3 expansion and let $f(x)$ be this expansion but regarded as a decimal expansion. For example, if $x=5 / 8$ then $x=0.121212 \ldots$ as a base 3 fraction, so $f(x)=0.121212 \ldots$ as a decimal, i.e., $f(x)=4 / 33$. Show that $f \in \mathcal{L}^{1}[0,1)$ and compute $\int f$.","Let $a_{n 1}(x)$ be the characteristic function of the set of numbers whose $n$-th ternary digit is 1 and $a_{n 2}(x)$ be the characteristic function of the set of numbers whose $n$-th ternary digit is 2 . Each of these sets is a finite union of intervals of total length $1 / 3$. Hence $a_{n i}$ is integrable with $\int a_{n i}=1 / 3$. Now
$$
f=\sum_{n \geq 1} 10^{-n}\left(a_{n 1}(x)+2 a_{n 2}(x)\right),
$$
so by the monotonicity lemma $f$ is integrable and $\int f=\sum_{n \geq 1} 10^{-n}=1 / 9$. ","Let $R$ denote the set of sequences $a=\left(a_1, a_2, a_3, \ldots\right)$ of real numbers that are eventually constant: $a_n=a_{n+1}=\ldots$ for sufficiently large $n$. Addition and multiplication are componentwise, that is, addition is vector addition and multiplication is defined by $a b=\left(a_1 b_1, a_2 b_2, \ldots\right)$. Prove that $R$ is a ring, and determine its maximal ideals.","The map that sends a sequence $a=\left(a_{1}, a_{2}, \ldots\right)$ to $a_{i}$ is a homomorphism $R \longrightarrow \mathbb{R}$. Its kernel $\mathfrak{m}_{i}$, is the set of sequences $a$ such that $a_{i}=0$. It is a maximal ideal. The only other maximal ideal is $\mathfrak{M}$, the kernel of the homomorphism to $\mathbb{R}$ that sends a sequence $a$ to its limit.
Let $M$ be any maximal ideal. If $M \neq \mathfrak{m}_{i}$ then because $M$ is maximal, $M \not \subset \mathfrak{m}_{i}$. So there is a sequence $a$ in $M$ with $a_{i} \neq 0$. Let $e_{i}$ be the sequence that is identically zero except for a 1 in position $i$. Then the sequence $e_{i} a$, which is in the ideal $M$, is zero except for position $i$, its entry in that position is $a_{i}$, and it is an element of $M$. Since we can multiply elements of $M$ by $a_{i}^{-1}, e_{i}$ is an element of $M$.
Using the elements $e_{i}$, we can construct any element of $R$ whose limit is zero. Thus $M$ contains the set of such sequences. They form the ideal $\mathfrak{M}$. So $\mathfrak{m}_{1}, \mathfrak{m}_{2}, \ldots$ and $\mathfrak{M}$ are the only maximal ideals."
184,EECS,18.C06,Linear Algebra and Optimization,18.02,None,Final Exam,Recurrence,10,b,1.565217391,Text,"In this problem we will be interested in the recurrence
$$
x_{k}=3 x_{k-1}+\beta x_{k-2}
$$
where $\beta$ is a nonnegative parameter to be chosen later.
What is the largest value of $\beta$ for which the recurrence satisfies the growth condition
$$
x_{k} \leq C 4^{k}
$$
for any initial condition? Note: The constant $C$ can depend on the initial condition itself.",Expression,"Using the expression for $A$ above, we compute the eigenvalues through the trace and determinant. In particular we have $\lambda_{1}+\lambda_{2}=3$ and $\lambda_{1} \lambda_{2}=-\beta$. Substituting for $\lambda_{2}$ we obtain
$$
\lambda_{1}\left(3-\lambda_{1}\right)=-\beta
$$
and using the quadratic equation we obtain
$$
\lambda_{1}=\frac{3 \pm \sqrt{9+4 \beta}}{2}
$$
Thus we get that $\beta \leq 4$ is a necessary condition (since otherwise $\lambda_{1}$ would be too big). We can check that for this value we $\lambda_{2}=-1$ and thus neither eigenvalue is too big. ","In this problem we will be interested in the recurrence
$$
x_{k}=3 x_{k-1}+\beta x_{k-2}
$$
where $\beta$ is a nonnegative parameter to be chosen later.
Write the recurrence in matrix vector notation as
$$
\left[\begin{array}{c}
x_{k} \\
x_{k-1}
\end{array}\right]=A\left[\begin{array}{c}
x_{k-1} \\
x_{k-2}
\end{array}\right]
$$
for some $A$. Suppose the eigenvalues of $A$ are $\lambda_{1}$ and $\lambda_{2}$ with eigenvectors $u$ and $v$ respectively. Show that there is an initial condition for $x_{1}$ and $x_{2}$ so that
$$
\left|x_{k}\right| \geq C\left|\lambda_{1}\right|^{k-2}
$$
for some constant $C$.","In matrix vector notation we have
$$
\left[\begin{array}{c}
x_{k} \\
x_{k-1}
\end{array}\right]=\left[\begin{array}{ll}
3 & \beta \\
1 & 0
\end{array}\right]\left[\begin{array}{l}
x_{k-1} \\
x_{k-2}
\end{array}\right]
$$
Now suppose we choose
$$
\left[\begin{array}{l}
x_{2} \\
x_{1}
\end{array}\right]=u
$$
Then
$$
\left[\begin{array}{c}
x_{k} \\
x_{k-1}
\end{array}\right]=A^{k-2} u=\lambda_{1}^{k-2} u
$$
which implies that
$$
\left|x_{k}\right| \geq\left|\lambda_{1}\right|^{k-2}\left|u_{1}\right|.
$$","Solve the following recurrence using generating functions:
$$
a_{n}=3 a_{n-1}+4 a_{n-2} \text { for } n \geq 2
$$
with the initial conditions $a_{0}=3, a_{1}=2$.","We let
$$
A(x)=a_{0}+a_{1} x+a_{2} x^{2}+\ldots=\sum_{i=0}^{\infty} a_{i} x^{i}
$$
be the generating function for our sequence $\left\{a_{i}\right\}_{i \in \mathbb{N}}$. Then we get that
$$
A(x)=3 x A(x)+4 x^{2} A(x)-7 x+3.
$$
Rearranging the terms, we get that
$$
A(x)\left(1-3 x-4 x^{2}\right)=-7 x+3,
$$
or equivalently,
$$
A(x)=\frac{-7 x+3}{1-3 x-4 x^{2}}.
$$
We have the factorization $1-3 x-4 x^{2}=(1-4 x)(1+x)$, so we will get a partial fraction decomposition of the form
$$
A(x)=\frac{A}{1-4 x}+\frac{B}{1+x}.
$$
This tells us that $A+B=3$ and $A-4 B=-7$. Solving these equations, we get $A=1$ and $B=2$, so
$$
A(x)=\frac{1}{1-4 x}+\frac{2}{1+x}.
$$
Recalling that $\frac{1}{1-x}=\sum_{i=0}^{\infty} x^{i}$, we get that
$$
A(x)=\sum_{i=0}^{\infty}\left(4^{i}+2 \times(-1)^{i}\right) x^{i}
$$
Thus, we find that $a_{i}=4^{i}+2 \times(-1)^{i}$.","Solve the following recurrence, providing rigorous proof for your answer using either induction or a recursion tree:
$$
T(n)=3 T(n / 7)+T(5 n / 9)+\Theta(n) .
$$","Via recursion tree: Since the cost at each subproblem is $\Theta(m)$ (where $m$ is the size of the subproblem), we can upper bound it with $\mathrm{cm}$ for some constant $c$. We prove by induction that the cost at the $k^{t h}$ level of the tree the cost is at most $\left(\frac{62}{63}\right)^{k-1} \mathrm{cn}$. Consider the base case first: at the top level of the tree, the cost is at most $c n$ as the original problem is of size $n$. Suppose, by our inductive hypothesis, that at the $k^{t h}$ level of the tree the cost is at most $\left(\frac{62}{63}\right)^{k-1} \mathrm{cn}$ : then, at the $(k+1)^{t h}$ level we have at most a cost of
$$
3\left(\frac{62}{63}\right)^{k-1} c \cdot \frac{n}{7}+\left(\frac{62}{63}\right)^{k-1} c \cdot \frac{5 n}{9}=\left(3 \cdot \frac{1}{7}+\frac{5}{9}\right)\left(\frac{62}{63}\right)^{k-1} c n=\left(\frac{62}{63}\right)^k c n .
$$
This proves our inductive step. Hence, by induction, the cost at the $k^{t h}$ level of the tree the cost is at most $\left(\frac{62}{63}\right)^{k-1} \mathrm{cn}$. The total cost is the sum of the costs at all levels, that is $\sum\left(\frac{62}{63}\right)^{k-1} c n$, which is a geometric sum converging to $\Theta(n)$.
Via induction: We guess $T(n) \leq c \cdot n$ and prove using induction. The intuition for this guess comes from the fact that the subproblem sizes sum to $n / 7+n / 7+n / 7+5 n / 9=62 n / 63$, which is a constant multiple of $n$ with a coefficient less than 1 .
Our base case is $T(1) \leq c \cdot 1=c$, which is true if we choose $c \geq T(1)$.
For the inductive step, assume that $T(n) \leq d \cdot n$ for all $n<k$. Then we consider $T(k)$. Let $\Theta(n)$ be of the form $c \cdot n$ as before. Applying the recursive definition of $T(n)$ and then the inductive hypothesis, we have
$$
\begin{aligned}
T(k) &=3 T(k / 7)+T(5 k / 9)+c \cdot k \\
& \leq 3 \cdot\left(d \cdot \frac{k}{7}\right)+d \cdot \frac{5 k}{9}+c \cdot k \\
&=\left(\frac{62}{63} d+c\right) \cdot k \\
& \leq d \cdot k,
\end{aligned}
$$
where the last step follows if we choose $\frac{62}{63} d+c \leq d$, or $d \geq 63 c$. Thus, both steps of the proof follow if we choose any $d \geq \max \{T(1), 63 c\}$, and we have a valid proof by induction showing that $T(n) \in O(n)$, as desired. 
Note that to prove a tight asymptotic bound of $\Theta(n)$, we must prove not only $T(n) \in O(n)$ but also $T(n) \in \Omega(n)$. However, the latter is easier, since even without the recursive terms $T(n / 7)$ and $T(5 n / 9)$, we have a work term of $\Theta(n)$ in our recurrence for $T(n)$, meaning that $T(n) \in \Omega(n)$ and thus implying that $T(n) \in \Theta(n)$, as desired."
286,Mathematics,18.01,Calculus I,None,None,Problem Set 6,Taylor Series,20,b,0.06335797254,Text,"Suppose that $x^{\prime}(t)=x(t)-x(t)^{3}$.
Suppose that $x(0)=1.1$. Will $x(t)$ decrease and drop below 1, or will it decrease and approach 1, or will it increase? Explain your reasoning.
Hint: You might want to sketch the graph of $x-x^{3}$.",Open,"If $x(0)=1.1$, then $x^{\prime}(0)=f(x(0))=f(1.1)<0$. As $x(t)$ decreases, $f(x(t))$ continues to be negative, but closer to $0 . x(t)$ continues decreasing, and as it gets close to $1, f(x(t))$ approaches 0 , so there is a horizontal asymptote at $x=1$.","Suppose that $x^{\prime}(t)=x(t)-x(t)^{3}$.
Does $x_{1}(t)$ decrease and drop below 1, or does it decrease and approach 1, or does it increase?","$x_{1}(t)=.1 e^{-2 t}+1$. As $t$ increases, $e^{-2 t}$ gets closer and closer to 0 , so $x_{1}(t)$ decreases and approaches 1.","Suppose that $x^{\prime}(t)=f(x(t))$ where the function $f(x)$ is shown in the picture below. 
Suppose that $x(0)=2.1$. Will $x(t)$ decrease and drop below 2 , or decrease and approach 2, or increase?","$x^{\prime}(0)=f(2.1)>0$, so $x(t)$ is increasing. The larger $x(t)$ gets, the larger $f(x(t))$ gets, so $x^{\prime}(t)$ stays positive. This means that $x(t)$ will increase.","Suppose that $x^{\prime}(t)=g(x(t))$ where the function $g(x)$ is shown in the picture below.
Suppose that $x(0)=2.1$. Will $x(t)$ decrease and drop below 2 , or decrease and approach 2 , or increase? ","$x^{\prime}(0)=g(2.1)<0$. As $x(t)$ decreases from 2.1, the value of $g(x(t))$ increases, getting closer to 0. Since 2 is a constant solution and solutions don't intersect, $x(t)$ decreases and approaches 2."
143,Mathematics,18.02,Calculus II,18.01,None,Final Exam,Cylindrical Coordinates,12,b,0.6,Text,"Let $G$ be the solid 3-D cone bounded by the lateral surface given by $z=2 \sqrt{x^2+y^2}$ and by the plane $z=2$. The problem is to compute $\bar{z}=$ the $z$-coordinate of the center of mass of $G$, in the case where the density is equal to the height above the xy-plane. 
Set up the calculation for $\bar{z}$ using cylindrical coordinates. (Answers should be ready to integrate out - but do not evaluate.)",Expression,"$$
\bar{z}=\frac{1}{M} \iiint_G z \cdot \delta d V=\frac{1}{\pi} \int_0^{2 \pi} \int_0^1 \int_{2 r}^2 z^2 d z r d r d \theta .
$$","Let $G$ be the solid 3-D cone bounded by the lateral surface given by $z=2 \sqrt{x^2+y^2}$ and by the plane $z=2$. The problem is to compute $\bar{z}=$ the $z$-coordinate of the center of mass of $G$, in the case where the density is equal to the height above the xy-plane. 
Set up the calculation for $\bar{z}$ using spherical coordinates. (Answers should be ready to integrate out - but do not evaluate.)","$$
\bar{z}=\frac{1}{M} \iiint_G z \cdot \delta d V=\frac{1}{\pi} \int_0^{2 \pi} \int_0^{\tan ^{-1}(1 / 2)} \int_0^{2 \sec \phi}(\rho \cos \phi)^2 \rho^2 \sin \phi d \rho d \phi d \theta
$$","Let $G$ be the solid 3-D cone bounded by the lateral surface given by $z=2 \sqrt{x^2+y^2}$ and by the plane $z=2$. The problem is to compute $\bar{z}=$ the $z$-coordinate of the center of mass of $G$, in the case where the density is equal to the height above the xy-plane. 
Find the mass of $G$ using cylindrical coordinates.",$M=\iiint_G z d V=\int_0^{2 \pi} \int_0^1 \int_{2 r}^2 z d z r d r d \theta=\int_0^{2 \pi} \int_0^1 2\left(1-r^2\right) r d r d \theta=4 \pi \cdot \frac{1}{4}=\pi$.,"Now suppose that we have the same ball of radius 2 , and it has variable density, and the density near a point $(x, y, z)$ is $2+z$.
Approximate the mass of the part of the ball where the $z$ coordinate is between $z$ and $z+\Delta z$.","Volume $\left(4-z^{2}\right) \pi \Delta x$ as in problem 12 .b. Density $\approx 2+z$. Mass of the ""coin""
$$
\Delta m \approx(2+z)\left(4-z^{2}\right) \pi \Delta x .
$$"
103,Mathematics,18.02,Calculus II,18.01,None,Midterm Exam 3,Gradient,4,a,0.5625,Text,"Let $\vec{F}=\left(z^2-2\right) \hat{i}+3 y^2 \hat{j}+2 x z \hat{k}$ be a vector field. 
Show that if $f(x, y, z)=x z^2-2 x+y^3$ then $\vec{F}=\nabla f$.",Open,"$$
\begin{aligned}
\nabla f &=\left(\begin{array}{c}
f_x \\
f_y \\
f_z
\end{array}\right) \\
&=\left(\begin{array}{c}
z^2-2 \\
3 y^2 \\
2 x z
\end{array}\right) \\
&=\vec{F}
\end{aligned}
$$","$\mathbf{F}(x, y, z)=\left(y+y^2 z\right) \mathbf{i}+(x-z+2 x y z) \mathbf{j}+\left(-y+x y^2\right) \mathbf{k}$. Show that $\mathbf{F}(x, y, z)$ is a gradient field using the derivative conditions.","We have $\mathbf{F}=\langle P, Q, R\rangle$, where $P=y+y^2 z, \quad Q=x-z+2 x y z, \quad R=-y+x y^2$.
$$
\frac{\partial P}{\partial z}=y^2=\frac{\partial R}{\partial x} ; \quad \frac{\partial Q}{\partial z}=-1+2 x y=\frac{\partial R}{\partial y} ; \quad \frac{\partial P}{\partial y}=1+2 y z=\frac{\partial Q}{\partial x} .
$$","Let $\vec{F}=\left(z^2-2\right) \hat{i}+3 y^2 \hat{j}+2 x z \hat{k}$ be a vector field. 
Compute the line integral $\int_C \vec{F} \cdot d \vec{r}$ for $C$ parametrized by
$$
\vec{r}(t)=e^t \cos t \hat{i}+e^t \sin t \hat{j}+2 t \hat{k}, \quad 0 \leq t \leq \pi .
$$","$$
\int_C \vec{F} \cdot d \vec{r}=-4 \pi^2 e^\pi+2 e^\pi+2 .
$$","$\mathbf{F}(x, y, z)=\left(y+y^2 z\right) \mathbf{i}+(x-z+2 x y z) \mathbf{j}+\left(-y+x y^2\right) \mathbf{k}$. Find a potential function $f(x, y, z)$ for $\mathbf{F}(x, y, z)$, using any systematic method. Show the method used and all work clearly.","$$
\begin{aligned}
&f\left(x_{1}, y_{1}, z_{1}\right)=\int_{0}^{x_{1}} P(x, 0,0) d x+\int_{0}^{y_{1}} Q\left(x_{1}, y, 0\right) d y+\int_{0}^{z_{1}} Q\left(x_{1}, y_{1}, z\right) d z . \\
&P(x, 0,0)=0 ; \quad Q\left(x_{1}, y, 0\right)=x_{1} ; \quad R\left(x_{1}, y_{1}, z\right)=-y_{1}+x_{1} y_{1}^{2} . \\
&f\left(x_{1}, y_{1}, z_{1}\right)=0+\int_{0}^{y_{1}} x_{1} d y+\int_{0}^{z_{1}}\left(-y_{1}+x_{1} y_{1}^{2}\right) d z \\
&\Rightarrow f\left(x_{1}, y_{1}, z_{1}\right)=x_{1} y_{1}-y_{1} z_{1}+x_{1} y_{1}^{2} z_{1} \Rightarrow f(x, y, z)=x y-y z+x y^{2} z+C.
\end{aligned}
$$"
118,EECS,6.122,Design and Analysis of Algorithms,6.121,None,Midterm Exam 2,Minimum Spanning Tree,2,nan,2.5,Text,"You are given a graph $G$, and an MST of the graph, call it $T$. Prove that the unique path in the MST T between any two nodes is a bottleneck shortest path in the graph $G$. A bottleneck shortest path is a path where the weight of the maximum-weight edge is minimum.
For example, say that there are three paths between nodes $A$ and $B$ in $G$, with edge weights $3,3,3$ and $1,4,2$, and 1,5 , respectively. Then, $3,3,3$ is the bottleneck shortest path since its maximum weight edge is 3, versus 4 for the second path, and 5 for the third.",Open,"We will prove this by contradiction.
Suppose a bottleneck shortest path between two nodes $A$ and $B$ in $G$ has a largest weight edge with weight $w_{0}$. Consider an edge $e$ in the unique path between $A$ and $B$ in an MST $T$ with maximum weight, call it $w(e)$. Note that $w(e)$ cannot be less than $w_{0}$ by definition of the bottleneck shortest path. If $w(e)=w_{0}$, then the unique path between $A$ and $B$ is a bottleneck shortest path. Consider the case where $w(e)>w_{0}$, meaning the unique path between $A$ and $B$ in $T$ is not a bottleneck shortest path between $A$ and $B$ in $G$.
Remove $e$ from $T . T$ is now two disjoint trees, with $A$ in one subtree and $B$ in another subtree, since $e$ was on the path from $A$ to $B$. Look at each edge on the bottleneck path between $A$ and $B$ in the input graph $G$. One of these edges $e_{0}$ will connect these two subtrees of now broken $T$, since the path was from $A$ to $B$, and $A$ and $B$ are in different subtrees.
The edge weight of $e_{0} \leq w_{0}$, since $w_{0}$ was the largest weight edge in the bottleneck shortest path in $G$. We have assumed that $w(e)>w_{0}$. This means $T-\{e\} \cup\left\{e_{0}\right\}$ is a spanning tree whose weight is less than $T$. Meaning $T$ is not an MST, and we have a contradiction. ","Let $G=(V, E)$ be an undirected, connected graph whose weight function is $w: E \rightarrow \mathbb{R}$, and suppose that $|E| \geq|V|$ and all edge weights are distinct.
We define a second-best minimum spanning tree as follows. Let $\mathcal{T}$ be the set of all spanning trees of $G$, and let $T^{\prime}$ be a minimum spanning tree of $G$. Then a second-best minimum spanning tree is a spanning tree $T$ such that $W(T)=\min _{T^{\prime \prime} \in \mathcal{T}-\left\{T^{\prime}\right\}}\left\{w\left(T^{\prime \prime}\right)\right\}$.
Let $T$ be a spanning tree of $G$ and, for any two vertices $u, v \in V$ let $\max [u, v]$ denote an edge of maximum weight on the unique simple path between $u$ and $v$ in $T$. Describe an $O\left(V^2\right)$-time algorithm that, given $T$, computes $\max [u, v]$ for all $u, v \in V$.","For every vertex $u \in V$, we will perform a DFS on $T$ (BFS would also work) to calculate $\max [u, x]$, for all $x \in V-\{u\}$. The pseudocode will look as follows:
$\operatorname{DFS}(u, x)$ :
     Mark $x$ as visited
     For every unvisited child $\mathrm{v}$ of $\mathrm{x}$ :
          $\max [u, v] \leftarrow \arg \max _w\{\max [u, x], \quad(x, v)\}$
          $\operatorname{DFS}(u, v)$
Each DFS call takes $O(V)$ time, since we are performing DFS on a spanning tree of $G$ which has exactly $|V|-1=O(V)$ edges. We will perform $O(V)$ calls of DFS, so the total running time is $O\left(V^2\right)$.","Let $G=(V, E)$ be an undirected, connected graph whose weight function is $w: E \rightarrow \mathbb{R}$, and suppose that $|E| \geq|V|$ and all edge weights are distinct.
We define a second-best minimum spanning tree as follows. Let $\mathcal{T}$ be the set of all spanning trees of $G$, and let $T^{\prime}$ be a minimum spanning tree of $G$. Then a second-best minimum spanning tree is a spanning tree $T$ such that $W(T)=\min _{T^{\prime \prime} \in \mathcal{T}-\left\{T^{\prime}\right\}}\left\{w\left(T^{\prime \prime}\right)\right\}$.
Let $T$ be the minimum spanning tree of $G$, which has unique edge weights. Prove that $G$ contains an edge $(u, v) \in T$ and a different edge $(x, y) \notin$ $T$ such that $T-\{(u, v)\} \cup\{(x, y)\}$ is a second-best minimum spanning tree of $G$, and that every second-best minimum spanning tree can be found in this manner; that is, if a spanning tree $T^{\prime}$ differs from $T$ in more than one edge, then $T^{\prime}$ cannot be a second-best minimum spanning tree.","Since the edge weights in $G$ are unique, $T$ is unique; therefore a second-best minimum spanning tree will differ to $T$ on at least one edge. Pick a second-best MST $T^{\prime}$. If $T^{\prime}$ differs to $T$ on only one edge, we are happy. Otherwise, $T^{\prime}$ differs to $T$ on two or more edges, i.e. $\left|T-T^{\prime}\right| \geq 2$. We will show that $T^{\prime}$ cannot be a second best MST. Let $(u, v)$ be the edge in $T-T^{\prime}$ with minimum weight. Since edge weights are unique, there can be only one such edge. We can add $(u, v)$ to $T^{\prime}$, to get a cycle. The cycle contains an edge $(x, y)$ with $w(x, y)>w(u, v)$ because of the cycle property; $(u, v) \in T$, so there has to be a different edge on every cycle containing $(u, v)$ heavier than $(u, v)$, otherwise $(u, v)$ couldn't be part of $T$ (see recitation 4 notes, cycle property). We can therefore substitute $(x, y)$ with $(u, v)$ in $T^{\prime}$ to get a spanning tree with total weight less than $T^{\prime}$, but still more than $T$. Therefore, $T^{\prime}$ cannot be a second best MST. This implies that the only way to obtain a second-best MST is to replace exactly one edge of $T$.","Please select True or False for the following.
Suppose that an undirected graph $G=(V, E)$ with positive edge weights has a minimum spanning tree of weight $W$. For all pairs of nodes $u, v \in V$ the shortest path between $u$ and $v$ in $G$ has length less than or equal to $W$.","True. We can walk from any point to any other point using only edges on the MST. The edges we don't use in the MST have total weight greater than or equal to 0, thus the cost of the path we walk is at most $W$."
37,Mathematics,18.01,Calculus I,None,None,Problem Set 1,Exponentials and Logarithms,17,b,0.07919746568,Text,"Recall that $e$ is the number 2.71... It plays a special role in calculus because $\frac{d}{d x} e^{x}=e^{x}$.
Approximate $10^{.01}$. First write $10^{.01}=e^{t}$ and approximate $t$. You can use that $\log _{e} 10=2.30 \ldots$ Then use linear approximation to approximate $e^{t}$. Give an answer that is accurate to within .01.",Numerical,"Start with
$$
10 \equiv e^{\log _{e} 10} .
$$
Then,
$$
10^{0.01}=\left(e^{\log _{e} 10}\right)^{0.01}=e^{0.01 \times \log _{e} 10} \approx e^{0.023} .
$$
Using the linear approximation for $e^{x}$ gives
$$
10^{0.01} \approx 1.023 .
$$","Recall that $e$ is the number 2.71... It plays a special role in calculus because $\frac{d}{d x} e^{x}=e^{x}$.
Using the linear approximation of $e^{x}$ around $x=0$, approximate $e^{\cdot 1}$.","The linear approximation for $f(x)$ around $x=0$ is
$$
L(x)=f(0)+f^{\prime}(0) x.
$$
Here, with $f(x)=e^{x}, f(0)=1$. Because $f^{\prime}(x)=e^{x}, f^{\prime}(0)$ is also 1. Thus,
$$
L(x)=1+x.
$$
So, $e^{0.1} \approx 1.1$.",Estimate $e^{.1}$ using the degree 2 Taylor series. You can leave your answer as a sum of fractions.,"$$
e^{.1} \approx 1+.1+\frac{.1^{2}}{2}
$$",Estimate $e^{.1}$ using the degree 3 Taylor series. You can leave your answer as a sum of fractions. This approximation is really much better than the degree 2 Taylor approximation.,"$$
e^{.1} \approx 1+.1+\frac{.1^{2}}{2}+\frac{.1^{3}}{6}
$$"
78,Mathematics,18.03,Differential Equations,None,18.02,Problem Set 7,Gaussian Elimination,1,a,0.3217158177,Text,"For each of the following matrices $A: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m}$, do the following
(i) Find a basis for $\operatorname{Im}(A)$ (equivalently, the column space $C S(A)$ ).
(ii) Compute the dimension of $\operatorname{Ker}(A)$.
$A=\left(\begin{array}{ccc}1 & 5 & 2 \\ 4 & -1 & 7\end{array}\right)$.",Open,"(i) Applying the Gaussian elimination gives a row echelon form $\left(\begin{array}{ccc}1 & 5 & 2 \\ 0 & -21 & -1\end{array}\right)$ and thus the first two columns are pivots. Hence a basis of $\operatorname{Im}(A)$ is
$$
\left\{\left(\begin{array}{l}
1 \\
4
\end{array}\right),\left(\begin{array}{c}
5 \\
-1
\end{array}\right)\right\} .
$$
(ii) Since the rank of $A$ is 2 , the dimension of $\operatorname{Ker}(A)$ is $3-2=1$ by the rank-nulity theorem. (Or equivalently, two out of three columns are pivots, so the last one corresponds to a free variable with some vector that spans the $\operatorname{Ker}(A)$.","For each of the following matrices $A: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m}$, do the following
(i) Find a basis for $\operatorname{Im}(A)$ (equivalently, the column space $C S(A)$ ).
(ii) Compute the dimension of $\operatorname{Ker}(A)$.
$A=\left(\begin{array}{cccc}1 & 3 & -2 & 4 \\ 2 & 6 & 3 & 1\end{array}\right)$","(i) Applying the Gaussian elimination gives a row echelon form $\left(\begin{array}{cccc}1 & 3 & -2 & 4 \\ 0 & 0 & 7 & -7\end{array}\right)$ and thus the first and third columns are pivots. Hence a basis of $\operatorname{Im}(A)$ is
$$
\left\{\left(\begin{array}{l}
1 \\
2
\end{array}\right),\left(\begin{array}{c}
-2 \\
3
\end{array}\right)\right\} .
$$
(ii) Since the rank of $A$ is 2 , the dimension of $\operatorname{Ker}(A)$ is $4-2=2$ by the rank-nulity theorem.","Consider the matrix
$$
A=\left(\begin{array}{cccc}
1 & 2 & 4 & 5 \\
2 & 4 & 9 & 16 \\
1 & 2 & 3 & -1
\end{array}\right).
$$
Find a basis for $\operatorname{Im}(A)=\operatorname{ColumnSpace}(A)$.","A basis for the column space for $A$ is given by the columns of $A$ that correspond to pivot columns in the RREF for $A$. Here, we see that
$$
\left(\begin{array}{l}
1 \\
2 \\
1
\end{array}\right) \text { and }\left(\begin{array}{l}
4 \\
9 \\
3
\end{array}\right)
$$
is a basis for the range of $A$. ","For the following matrices $A: \mathbb{R}^{n} \rightarrow \mathbb{R}^{m}$, do the following
(i) Use Gaussian elimination to put $A$ into row echelon form.
(ii) Starting from the row echelon form of $A$ from $(i)$, perform Gauss-Jordan elimination to find the reduced row echelon form of $A$.
(ii) Find a basis for $\operatorname{Ker}(A)$ (equivalently, the null space $N S(A)$ ).
$A=\left(\begin{array}{lll}1 & 4 & 3 \\ 2 & 1 & 0 \\ 5 & 1 & 1\end{array}\right)$ .","(i)
$$
\begin{aligned}
\left(\begin{array}{lll}
1 & 4 & 3 \\
2 & 1 & 0 \\
5 & 1 & 1
\end{array}\right) & \rightarrow\left(\begin{array}{ccc}
1 & 4 & 3 \\
0 & -7 & -6 \\
5 & 1 & 1
\end{array}\right) \quad \text { Subtract row (1) multiplied by } 2 \text { from row (2). } \\
& \rightarrow\left(\begin{array}{ccc}
1 & 4 & 3 \\
0 & -7 & -6 \\
0 & -19 & -14
\end{array}\right) \quad \text { Subtract row (1) multiplied by } 5 \text { from row (3). } \\
& \rightarrow\left(\begin{array}{ccc}
1 & 4 & 3 \\
0 & -7 & -6 \\
0 & 0 & \frac{16}{7}
\end{array}\right) \quad \text { Subtract row (2) multiplied by } \frac{19}{7} \text { from row (3) }
\end{aligned}
$$
(ii)
$$
\begin{aligned}
\left(\begin{array}{ccc}
1 & 4 & 3 \\
0 & -7 & -6 \\
0 & 0 & \frac{16}{7}
\end{array}\right) & \rightarrow\left(\begin{array}{ccc}
1 & 4 & 3 \\
0 & 1 & \frac{6}{7} \\
0 & 0 & 1
\end{array}\right) \quad \text { Divide row (2) by }-7, \text { and row }(3) \text { by } \frac{16}{7} \\
& \rightarrow\left(\begin{array}{ccc}
1 & 4 & 0 \\
0 & 1 & \frac{6}{7} \\
0 & 0 & 1
\end{array}\right) \quad \text { Subtract row (3) multiplied by } 3 \text { from row (1). } \\
& \rightarrow\left(\begin{array}{lll}
1 & 4 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{array}\right) \quad \text { Subtract row (3) multiplied by } \frac{6}{7} \text { from row (2). } \\
& \rightarrow\left(\begin{array}{lll}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{array}\right) \quad \text { Subtract row (2) multiplied by } 4 \text { from row }(1) .
\end{aligned}
$$
(iii) From the row reduced echelon form, we have a linear system
$$
\begin{aligned}
&x=0 \\
&y=0 \\
&z=0
\end{aligned}
$$
Thus $\operatorname{ker}(A)=\{0\}$ and the basis is $\emptyset$."
25,Mathematics,18.02,Calculus II,18.01,None,Problem Set 3,Velocity and Acceleration,5,b,0.1602564103,Text,"Let $\vec{r}(t)$ be the position vector for the motion of a point in space and let $\vec{v}(t)$ and $\vec{a}(t)$ denote velocity and acceleration. Assume $\vec{v}=\hat{k} \times \vec{r},(\hat{k}=(0,0,1)$ is the unit vector along $z$-axis).
Show that the $z$-component of $\vec{r}(t)$ is constant, (i.e. the motion is on the horizontal plane).",Open,"Since $\vec{v}(t)=\langle-y(t),-x(t), 0\rangle$, we have that $z^{\prime}(t)=0$. Since the derivative is zero, the $z$-component of $\vec{r}(t)$ must be constant.","Let $\vec{r}(t)$ be the position vector for the motion of a point in space and let $\vec{v}(t)$ and $\vec{a}(t)$ denote velocity and acceleration. Assume $\vec{v}=\hat{k} \times \vec{r},(\hat{k}=(0,0,1)$ is the unit vector along $z$-axis).
Show that $|\vec{r}(t)|$ is constant.","We can show that $|\vec{r}(t)|$ is constant by showing that $|\vec{r}(t)|^{2}$ is constant. We will show that $\frac{d}{d t}|\vec{r}(t)|^{2}=0$. Recall that $|\vec{r}(t)|^{2}=x^{2}(t)+y^{2}(t)+z^{2}(t)$. Then we can write:
$$
\begin{aligned}
\frac{d}{d t}|\vec{r}(t)|^{2} &=\frac{d}{d t}\left[x^{2}(t)+y^{2}(t)+z^{2}(t)\right] \\
&=2 x(t) x^{\prime}(t)+2 y(t) y^{\prime}(t)+2 z(t) z^{\prime}(t) \\
&=2\langle x(t), y(t), z(t)\rangle \cdot\left\langle x^{\prime}(t), y^{\prime}(t), z^{\prime}(t)\right\rangle \\
&=2 \vec{r} \cdot \vec{v}
\end{aligned}
$$
Notice that we defined $\vec{v}=\hat{k} \times \vec{r}$. Then by definition of the cross product, $\vec{v}$ is perpendicular to $\vec{r}($ and $\hat{k})$. Then $\vec{r} \cdot \vec{v}=0$. Then we have:
$$
\frac{d}{d t}|\vec{r}(t)|^{2}=2 \vec{r} \cdot \vec{v}=0
$$
so $|\vec{r}(t)|^{2}$ is constant, therefore $|\vec{r}(t)|$ is constant and the problem is solved.","Let $\vec{r}(t)$ be the position vector for the motion of a point in space and let $\vec{v}(t)$ and $\vec{a}(t)$ denote velocity and acceleration. Assume $\vec{v}=\hat{k} \times \vec{r},(\hat{k}=(0,0,1)$ is the unit vector along $z$-axis).
Show that $\vec{a}=\hat{k} \times \vec{v}$.","Let's write $\vec{r}(t)$ to be $\langle x(t), y(t), z(t)\rangle$. By definition, $\vec{v}(t)=\left\langle x^{\prime}(t), y^{\prime}(t), z^{\prime}(t)\right\rangle$. We are given that $\vec{v}=\hat{k} \times \vec{r}$. Then we can write:
$$
\begin{aligned}
\vec{v}(t) &=\langle 0,0,1\rangle \times\langle x(t), y(t), z(t)\rangle \\
&=\left|\begin{array}{ccc}
\hat{i} & \hat{j} & \hat{k} \\
0 & 0 & 1 \\
x(t) & y(t) & z(t)
\end{array}\right| \\
&=\langle-y(t), x(t), 0\rangle
\end{aligned}
$$
By remembering that $\vec{a}(t)=\vec{v}^{\prime}(t)$ and taking derivatives, we find that $\vec{a}(t)=\left\langle-y^{\prime}(t), x^{\prime}(t), 0\right\rangle$. Now, if we set $\vec{v}(t)=\left\langle x^{\prime}(t), y^{\prime}(t), z^{\prime}(t)\right\rangle$, let's check what $\hat{k} \times \vec{v}$ results in:
$$
\begin{aligned}
\vec{a}(t) &=\langle 0,0,1\rangle \times\left\langle x^{\prime}(t), y^{\prime}(t), z^{\prime}(t)\right\rangle \\
&=\left|\begin{array}{ccc}
\hat{i} & \hat{j} & \hat{k} \\
0 & 0 & 1 \\
x^{\prime}(t) & y^{\prime}(t) & z^{\prime}(t)
\end{array}\right| \\
&=\left\langle-y^{\prime}(t), x^{\prime}(t), 0\right\rangle
\end{aligned}
$$
This is the same result for $\vec{a}(t)$ as above. Then indeed, if $\vec{k}=\hat{k} \times \vec{r}$, we get that $\vec{a}=\hat{k} \times \vec{v}$.","The position vector of a point $P$ moving in space is
$$
\vec{r}(t)=\overrightarrow{O P}=3 t \hat{\imath}+(t+2)^2 \hat{\jmath}-t \hat{k} .
$$
At what values of $t$ is $P$ on the plane $x+2y+3z=18$?","By definition, the values of such $t$ must satisfy
$$
3 t+2(t+2)^2-3 t=18 .
$$
We solve that $t=1,-5$ are the desired values."
101,EECS,6.122,Design and Analysis of Algorithms,6.121,None,Midterm Exam 1,Perfect Hashing,1,i,0.5,Text,"Please select True or False for the following.
A Pairwise Independent hash family (called the Vinod hash family in Problem Set 3, and also defined on Problem 3 of this quiz) satisfies the property $\operatorname{Pr}_{h \in \mathcal{H}}[h(x)=a]=\frac{1}{m}$ for any key $x \in \mathcal{U}$ and any $a \in\{0,1, \ldots, m-1\}$.",Multiple Choice,True.,"Let $H$ be a family of hash functions, where each hash function $h \in H$ maps keys from the universe $U$ to $\{0,1, \ldots, m-1\}$. We call $\mathrm{H}$ a Vinod Hash Family if for any distinct pair of keys $x_1, x_2 \in U$ such that $x_1 \neq x_2$, when $h$ is chosen uniformly at random from $H$, the pair $\left(h\left(x_1\right), h\left(x_2\right)\right)$ is equally likely to be any of the $m^2$ pairs $\left(y_1, y_2\right)$, where $y_1$ and $y_2$ are both elements of $\{0,1, \ldots, m-1\}$.
Consider the following two hash families $H_1=\left\{h_1, h_2, h_3, h_4\right\}, H_2=$ $\left\{h_5, h_6, h_7, h_8\right\}$.
\begin{tabular}{|c|c|c|c|}
\hline & $a$ & $b$ & $c$ \\
\hline$h_1$ & 1 & 1 & 1 \\
\hline$h_2$ & 1 & 0 & 0 \\
\hline$h_3$ & 0 & 1 & 0 \\
\hline$h_4$ & 0 & 0 & 1 \\
\hline
\end{tabular}
\begin{tabular}{|l|l|l|l|}
\hline & $a$ & $b$ & $c$ \\
\hline$h_5$ & 0 & 1 & 1 \\
\hline$h_6$ & 0 & 0 & 0 \\
\hline$h_7$ & 0 & 1 & 0 \\
\hline$h_8$ & 0 & 0 & 1 \\
\hline
\end{tabular}
What's the probability that $h(a)=0, h(b)=0$ if we select a hash function $h \in H_1$ randomly?","$h(a)=0, h(b)=0$ if $h=h_4$, which occurs with probability $\frac{1}{4}$.","Let $H$ be a family of hash functions, where each hash function $h \in H$ maps keys from the universe $U$ to $\{0,1, \ldots, m-1\}$. We call $\mathrm{H}$ a Vinod Hash Family if for any distinct pair of keys $x_1, x_2 \in U$ such that $x_1 \neq x_2$, when $h$ is chosen uniformly at random from $H$, the pair $\left(h\left(x_1\right), h\left(x_2\right)\right)$ is equally likely to be any of the $m^2$ pairs $\left(y_1, y_2\right)$, where $y_1$ and $y_2$ are both elements of $\{0,1, \ldots, m-1\}$.
Consider the following two hash families $H_1=\left\{h_1, h_2, h_3, h_4\right\}, H_2=$ $\left\{h_5, h_6, h_7, h_8\right\}$.
\begin{tabular}{|c|c|c|c|}
\hline & $a$ & $b$ & $c$ \\
\hline$h_1$ & 1 & 1 & 1 \\
\hline$h_2$ & 1 & 0 & 0 \\
\hline$h_3$ & 0 & 1 & 0 \\
\hline$h_4$ & 0 & 0 & 1 \\
\hline
\end{tabular}
\begin{tabular}{|l|l|l|l|}
\hline & $a$ & $b$ & $c$ \\
\hline$h_5$ & 0 & 1 & 1 \\
\hline$h_6$ & 0 & 0 & 0 \\
\hline$h_7$ & 0 & 1 & 0 \\
\hline$h_8$ & 0 & 0 & 1 \\
\hline
\end{tabular}
What's the probability that $h(a)=h(b)$ if we select a hash function $h \in H_1$ randomly?","The probability is just $\frac{2}{4}=\frac{1}{2}$ since $a$ and $b$ collide for the hash functions $h_1, h_4$.","Let $H$ be a family of hash functions, where each hash function $h \in H$ maps keys from the universe $U$ to $\{0,1, \ldots, m-1\}$. We call $\mathrm{H}$ a Vinod Hash Family if for any distinct pair of keys $x_1, x_2 \in U$ such that $x_1 \neq x_2$, when $h$ is chosen uniformly at random from $H$, the pair $\left(h\left(x_1\right), h\left(x_2\right)\right)$ is equally likely to be any of the $m^2$ pairs $\left(y_1, y_2\right)$, where $y_1$ and $y_2$ are both elements of $\{0,1, \ldots, m-1\}$.
Consider the following two hash families $H_1=\left\{h_1, h_2, h_3, h_4\right\}, H_2=$ $\left\{h_5, h_6, h_7, h_8\right\}$.
\begin{tabular}{|c|c|c|c|}
\hline & $a$ & $b$ & $c$ \\
\hline$h_1$ & 1 & 1 & 1 \\
\hline$h_2$ & 1 & 0 & 0 \\
\hline$h_3$ & 0 & 1 & 0 \\
\hline$h_4$ & 0 & 0 & 1 \\
\hline
\end{tabular}
\begin{tabular}{|l|l|l|l|}
\hline & $a$ & $b$ & $c$ \\
\hline$h_5$ & 0 & 1 & 1 \\
\hline$h_6$ & 0 & 0 & 0 \\
\hline$h_7$ & 0 & 1 & 0 \\
\hline$h_8$ & 0 & 0 & 1 \\
\hline
\end{tabular}
Which of $\mathrm{H}_1, \mathrm{H}_2$ are Vinod hash families?","$H_1$ is a Vinod hash family. If we consider any pair of nodes, we see that each hash function maps them to a unique ordered pair of values, so for each pair of inputs, we get any ordered pair of values in $\{0,1\}$ with probability $1 / 4=1 / m^2$.
$\mathrm{H}_2$ is not a Vinod hash family since $a$ always hashes to 0 , so the probability that $h(a)=1, h(b)=1$ is zero, which is not equal to $\frac{1}{m^2}=\frac{1}{4}$."
2,Mathematics,18.100B,Real Analysis,18.02,None,Problem Set 1,Axioms of Arithmetic,3,nan,0.7142857143,Text,"Suppose that we have any notion of number, satisfying the axioms of arithmetic. Let's change the operations as follows: we keep addition, $x+y=x+y$, but change multiplication to $x \cdot y=-(x \cdot y)$, where $-(\cdots)$ is the additive inverse for the old operation $+$. Do our new operations satisfy the axioms of arithmetic? Explain your answer.",Open,"During these computations, we will use $-(a \cdot b)=(-a) \cdot b=a \cdot(-b)$ many times. (Axiomatically, this follows from the distributive axiom, which shows that $(-a) \cdot b$ is an additive inverse to $a \cdot b$.)
Addition did not change, so we don't have to check any of its properties.
When we spell out axioms for $\cdot \cdot$ in terms of the old operations, we get:
$$
\begin{array}{ll}
-(x \cdot y)=-(y \cdot x) & \text { commutativity } \\
-(x \cdot(-(y \cdot z)))=-((-(x \cdot y)) \cdot z) & \text { associativity } \\
-(x \cdot(y+z))=(-(x \cdot y))+(-(x \cdot z)) & \text { distributivity. }
\end{array}
$$
The first line, commutativity, is obviously true. For the second line, we see that (using the fact mentioned at the beginning $)-(x \cdot(-(y \cdot z)))=x \cdot y \cdot z$, and the same applies to $-((-(x \cdot y)) \cdot z)$. Distributivity uses the same strategy, $-(x \cdot(y+z))=(-x) \cdot(y+z)=(-x) \cdot y+(-x) \cdot z=$ $(-(x \cdot y))+(-(x \cdot z))$
The final step is multiplicative neutral element and inverses. One has $-((-1) \cdot x)=1 \cdot x=x$, so $(-1)$ is a multiplicative neutral element for $\cdot \cdot$. One also has $-\left(\left(-x^{-1}\right) \cdot x\right)=x^{-1} \cdot x=1$, so $-x^{-1}$ is a multiplicative inverse with respect to $\cdot$.","Suppose that from the axioms of arithmetic, we remove the piece that says $1 \neq 0$. Is it true that then, there is a notion of ""number"" where only one number exists, and which satisfies the rest of the axioms of arithmetic? Explain your reasoning. [The axioms of arithmetic are those from the first lecture. Do not use the axioms introduced in later lectures.]","The answer is yes. The associative, commutative, and distributive laws are satisfied: both sides of the equalities in those laws describe a number, and in our context, equality between numbers is always true, because there's only one number. That number is also an additive neutral element (it automatically satisfies $0+0=0$ ) and is its own additive inverse (for the same reason). The number 0 is also a multiplicative neutral element, since we have $0 \cdot 0=0$. The last axiom (multiplicative inverse) is a statement about ""all numbers $\neq 0$ "", and since there is no such number, the statement is true (along the same lines as ""all oxygen-breathing rocks are pink"" is a logically true statement). ","Continuing the previous problem, suppose that our originally given numbers had a subset $P$ which satisfies the axioms of ordering (with respect to $+$ and $\cdot$ ). Is there a subset which does the same for our new $+$, . . operations? [Note that the axiom of completeness is not part of the axioms of ordering.]","We use $P=-P=\{-x \quad: \quad x \in P\}$ as subset of positive numbers for our new operations. Trichotomy for this $P$ says that for each $x$, either $x=0$, or $-x \in P$, or $-(-x) \in P$. But $-(-x)=x$, because both those numbers are the additive inverse of $-x$, and additive inverses are unique. So this statement is the same as trichotomy for $P$, which we know.
Suppose $x, y \in P$, so $-x \in P$ and $-y \in P$. Now $(-x)+(-y)$ is the additive inverse of $x+y$, because $(-x)+(-y)+x+y=((-x)+x)+((-y)+y)=0+0=0$. Therefore, it follows from the axioms of ordering for $P$ that $(-x)+(-y)=-(x+y) \in P$, which shows that $x+y \in P$.
Suppose $x, y \in P$, so $-x \in P$ and $-y \in P$. The statement that $x \cdot y \in P$ means that $-(-(x \cdot y)) \in P$, or equivalently (by what I've observed above) that $x \cdot y \in P$. But we know that to be true, because (as proved in lecture) $x \cdot y=(-x) \cdot(-y)$, where the right hand side lies in $P$ because of the axiom of ordering for $\cdot$.","Prove that the commutativity and associativity axioms for addition, together with the axiom of the existence of a neutral element for addition, imply that each $x$ can have at most one additive inverse. [This is Lemma 1.2 from the class summaries; obviously, you can't use either that Lemma, or anything that came after that. Argue strictly axiomatically.]","Suppose that $y$ and $z$ are both additive inverses of $x$, so $x+y=0$ and $x+z=0$. Then,
$$
y=y+0=y+(x+z).
$$
Here, we have used the defining property of the neutral element 0 , as well as the fact that $z$ is an inverse of $x$. Now we use associativity and commutativity:
$$
y+(x+z)=(y+x)+z=(x+y)+z .
$$
Now we use that $y$ is an inverse, and the defining property of the neutral element 0:
$$
(x+y)+z=0+z=z .
$$
Taking all that together, we have shown that $y=z$: any two additive inverses of $x$ must be equal, so there is at most one."
255,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Midterm Exam,Search,2,d,0.5,Text,"Now, let's assume that you are a drone, flying above the terrain, but staying at a fixed altitude.
\begin{itemize}
\item You can still go 1 mile per minute, your battery still holds $m$ units, and the chargers and charging time remain the same (this is a big drone)!
\item Drones never get bored.
\item There are some high peaks that prevent you from moving within some regions of the space at your fixed altitude, essentially forming obstacles in a planar problem.
\item This drone has no problem hovering and is insensitive to wind, so you can assume that forces and velocities are handled by the controller and you only need to worry about paths and charging.
\item Drone motion is holonomic; it can move in any direction.
\item The chargers are in the same place, and your start and goal locations will be towns, but the road network is irrelevant.
\end{itemize}
You can do long-distance induction charging (!). You are given a function charge-delta $\left(l_{i}, l_{j}\right)$ that returns the aggregate change in charge (which may be positive or negative) due to flying from $l_{i}$ to $l_{j}$ in a straight line. Your battery has over-charge protection, so that it will stop accumulating charges when it is at max-capacity.
You decided to use trajectory optimization to approach this problem.
The overall cost of the trajectory is the sum of the costs of $n$ individual linear segments.
$$
J\left(\left(\left(l_{0}, b_{0}\right),\left(l_{1}, b_{1}\right), \ldots,\left(l_{n}, b_{n}\right)\right)=\sum_{i} C\left(\left(l_{i}, b_{i}\right),\left(l_{i+1}, b_{i+1}\right)\right)\right.
$$
where $l_{0}=$ start, $b_{0}$ is the initial battery charge, and $l_{n}=$ goal. The cost for each segment includes several terms, including the segment length, the degree to which the segment penetrates an obstacle, and the degree to which the charging dynamics are respected ($\alpha$ and $\beta$ are constants that trade off the relative importance of the terms):
$C((l_{i}, b_{i}), (l_{j}, b_{j})) = |l_{i} - l_{j}|^{2} + \alpha \cdot penetration((l_{i}, l_{j}, obstacles)) + \beta \cdot charge_{i, j}$
Of these four terms (the three we listed, plus the one you provided), which ones, if any, need to be driven to 0 to obtain a legal trajectory?
(a) length.
(b) penetration.
(c) charge-delta.
(d) missing.",Multiple Choice,"(b) penetration.
(c) charge-delta.
(d) missing.","Now, let's assume that you are a drone, flying above the terrain, but staying at a fixed altitude.
\begin{itemize}
\item You can still go 1 mile per minute, your battery still holds $m$ units, and the chargers and charging time remain the same (this is a big drone)!
\item Drones never get bored.
\item There are some high peaks that prevent you from moving within some regions of the space at your fixed altitude, essentially forming obstacles in a planar problem.
\item This drone has no problem hovering and is insensitive to wind, so you can assume that forces and velocities are handled by the controller and you only need to worry about paths and charging.
\item Drone motion is holonomic; it can move in any direction.
\item The chargers are in the same place, and your start and goal locations will be towns, but the road network is irrelevant.
\end{itemize}
You can do long-distance induction charging (!). You are given a function charge-delta $\left(l_{i}, l_{j}\right)$ that returns the aggregate change in charge (which may be positive or negative) due to flying from $l_{i}$ to $l_{j}$ in a straight line. Your battery has over-charge protection, so that it will stop accumulating charges when it is at max-capacity.
You decided to use trajectory optimization to approach this problem.
The overall cost of the trajectory is the sum of the costs of $n$ individual linear segments.
$$
J\left(\left(\left(l_{0}, b_{0}\right),\left(l_{1}, b_{1}\right), \ldots,\left(l_{n}, b_{n}\right)\right)=\sum_{i} C\left(\left(l_{i}, b_{i}\right),\left(l_{i+1}, b_{i+1}\right)\right)\right.
$$
where $l_{0}=$ start, $b_{0}$ is the initial battery charge, and $l_{n}=$ goal. The cost for each segment includes several terms, including the segment length, the degree to which the segment penetrates an obstacle, and the degree to which the charging dynamics are respected ($\alpha$ and $\beta$ are constants that trade off the relative importance of the terms):
$C((l_{i}, b_{i}), (l_{j}, b_{j})) = |l_{i} - l_{j}|^{2} + \alpha \cdot penetration((l_{i}, l_{j}, obstacles)) + \beta \cdot charge_{i, j}$
However, we're missing a term! What is it?",A penalty for $c$ going negative.,"Now, let's assume that you are a drone, flying above the terrain, but staying at a fixed altitude.
\begin{itemize}
\item You can still go 1 mile per minute, your battery still holds $m$ units, and the chargers and charging time remain the same (this is a big drone)!
\item Drones never get bored.
\item There are some high peaks that prevent you from moving within some regions of the space at your fixed altitude, essentially forming obstacles in a planar problem.
\item This drone has no problem hovering and is insensitive to wind, so you can assume that forces and velocities are handled by the controller and you only need to worry about paths and charging.
\item Drone motion is holonomic; it can move in any direction.
\item The chargers are in the same place, and your start and goal locations will be towns, but the road network is irrelevant.
\end{itemize}
You can do long-distance induction charging (!). You are given a function charge-delta $\left(l_{i}, l_{j}\right)$ that returns the aggregate change in charge (which may be positive or negative) due to flying from $l_{i}$ to $l_{j}$ in a straight line. Your battery has over-charge protection, so that it will stop accumulating charges when it is at max-capacity.
You decided to use trajectory optimization to approach this problem.
The overall cost of the trajectory is the sum of the costs of $n$ individual linear segments.
$$
J\left(\left(\left(l_{0}, b_{0}\right),\left(l_{1}, b_{1}\right), \ldots,\left(l_{n}, b_{n}\right)\right)=\sum_{i} C\left(\left(l_{i}, b_{i}\right),\left(l_{i+1}, b_{i+1}\right)\right)\right.
$$
where $l_{0}=$ start, $b_{0}$ is the initial battery charge, and $l_{n}=$ goal. The cost for each segment includes several terms, including the segment length, the degree to which the segment penetrates an obstacle, and the degree to which the charging dynamics are respected ($\alpha$ and $\beta$ are constants that trade off the relative importance of the terms):
$C((l_{i}, b_{i}), (l_{j}, b_{j})) = |l_{i} - l_{j}|^{2} + \alpha \cdot penetration((l_{i}, l_{j}, obstacles)) + \beta \cdot charge_{i, j}$
Explain your choice from above.",The change in charge between the endpoints has to match the charge-delta.,"Now, let's assume that you are a drone, flying above the terrain, but staying at a fixed altitude.
\begin{itemize}
\item You can still go 1 mile per minute, your battery still holds $m$ units, and the chargers and charging time remain the same (this is a big drone)!
\item Drones never get bored.
\item There are some high peaks that prevent you from moving within some regions of the space at your fixed altitude, essentially forming obstacles in a planar problem.
\item This drone has no problem hovering and is insensitive to wind, so you can assume that forces and velocities are handled by the controller and you only need to worry about paths and charging.
\item Drone motion is holonomic; it can move in any direction.
\item The chargers are in the same place, and your start and goal locations will be towns, but the road network is irrelevant.
\end{itemize}
You can do long-distance induction charging (!). You are given a function charge-delta $\left(l_{i}, l_{j}\right)$ that returns the aggregate change in charge (which may be positive or negative) due to flying from $l_{i}$ to $l_{j}$ in a straight line. Your battery has over-charge protection, so that it will stop accumulating charges when it is at max-capacity.
You decided to use trajectory optimization to approach this problem.
The overall cost of the trajectory is the sum of the costs of $n$ individual linear segments.
$$
J\left(\left(\left(l_{0}, b_{0}\right),\left(l_{1}, b_{1}\right), \ldots,\left(l_{n}, b_{n}\right)\right)=\sum_{i} C\left(\left(l_{i}, b_{i}\right),\left(l_{i+1}, b_{i+1}\right)\right)\right.
$$
where $l_{0}=$ start, $b_{0}$ is the initial battery charge, and $l_{n}=$ goal. The cost for each segment includes several terms, including the segment length, the degree to which the segment penetrates an obstacle, and the degree to which the charging dynamics are respected ($\alpha$ and $\beta$ are constants that trade off the relative importance of the terms):
$C((l_{i}, b_{i}), (l_{j}, b_{j})) = |l_{i} - l_{j}|^{2} + \alpha \cdot penetration((l_{i}, l_{j}, obstacles)) + \beta \cdot charge_{i, j}$
Which of the following terms captures the degree to which charging dynamics are respected $\left(\right.$charge $\left._{i, j}\right)$ ?
$$
\begin{aligned}
 (a) & \left|b_{i}-b_{j}\right|^{2} \\
 (b) & \left|b_{i}+b_{j}\right|^{2} \\
 (c) & \mid b_{i}+\text {charge-delta}\left(l_{i}, l_{j}\right)+\left.b_{j}\right|^{2} \\
 (d) & \mid b_{i}+\text {charge-delta}\left(l_{i}, l_{j}\right)-\left.b_{j}\right|^{2}
\end{aligned}
$$","$$
(d) \mid b_{i}+\text {charge-delta}\left(l_{i}, l_{j}\right)-\left.b_{j}\right|^{2}
$$"
21,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Exercise 4,Logistic Regression,1,d,0.05208333333,Text,"Recall that the output of a logistic regression model given an input $x$ has the form:
$$
g=\sigma\left(\theta^{T} x+\theta_{0}\right)
$$
where
$$
\sigma(z)=\frac{1}{1+e^{-z}}
$$
is the sigmoid function. You start with the following set of points in two dimensions.
$$
\begin{array}{cc}
\text { Inputs } x^{(i)} & \text { Labels } y^{(i)} \\
{[1,1]^{T}} & 0 \\
{[0,0]^{T}} & 0 \\
{[1,0]^{T}} & 1 \\
{[0,1]^{T}} & 0
\end{array}
$$
Assume $\theta=[1,0]^{T}$ and $\theta_{0}=-0.5$. You may find it useful to sketch the dataset and the linear separator $\theta, \theta_{0}$.
Recall (from the notes on Classification, that the average negative log-likelihood (NLL) loss over $n$ data points has the form:
$$
\frac{1}{n} \sum \mathcal{L}_{n l l}\left(g^{(i)}, y^{(i)}\right)=-\frac{1}{n} \sum_{i=1}^{n}\left[y^{(i)} \log g^{(i)}+\left(1-y^{(i)}\right) \log \left(1-g^{(i)}\right)\right]
$$
Remember that $g^{(i)}=\sigma\left(\theta^{T} x^{(i)}+\theta_{0}\right)$ is our model's output (before thresholding) for training example $i$, and $y^{(i)}$ is the true label ( $+1$ or 0). For our purposes in this problem, $\log$ indicates the natural logarithm.
What is the value of the average NLL loss over the data - given the particular values of $\theta, \theta_{0}$ and the data given above (to max of two decimal places)?",Numerical,"$0.599075$.
Plugging into the formula, we get:
$$
\begin{aligned}
& \frac{1}{n} \sum \mathcal{L}_{n l l}\left(g^{(i)}, y^{(i)}\right)=-\frac{1}{4}(\log (1-0.6225)+\log (1-0.3775)+\log (0.6225)+\log (1- 0.3775))
\end{aligned}
$$","Recall that the output of a logistic regression model given an input $x$ has the form:
$$
g=\sigma\left(\theta^{T} x+\theta_{0}\right)
$$
where
$$
\sigma(z)=\frac{1}{1+e^{-z}}
$$
is the sigmoid function. You start with the following set of points in two dimensions.
$$
\begin{array}{cc}
\text { Inputs } x^{(i)} & \text { Labels } y^{(i)} \\
{[1,1]^{T}} & 0 \\
{[0,0]^{T}} & 0 \\
{[1,0]^{T}} & 1 \\
{[0,1]^{T}} & 0
\end{array}
$$
Assume $\theta=[1,0]^{T}$ and $\theta_{0}=-0.5$. You may find it useful to sketch the dataset and the linear separator $\theta, \theta_{0}$.
With the threshold at $0.5$, what are the corresponding predicted labels of these points? Give an answer as a list of four numbers (and recall that the label options are 1 or 0).","$[1,0,1,0]$.
Points whose $\sigma(z) \leq 0.5$ are classified as 0. Points whose $\sigma(z)>0.5$ are classified as 1.","Recall that the output of a logistic regression model given an input $x$ has the form:
$$
g=\sigma\left(\theta^{T} x+\theta_{0}\right)
$$
where
$$
\sigma(z)=\frac{1}{1+e^{-z}}
$$
is the sigmoid function. You start with the following set of points in two dimensions.
$$
\begin{array}{cc}
\text { Inputs } x^{(i)} & \text { Labels } y^{(i)} \\
{[1,1]^{T}} & 0 \\
{[0,0]^{T}} & 0 \\
{[1,0]^{T}} & 1 \\
{[0,1]^{T}} & 0
\end{array}
$$
Assume $\theta=[1,0]^{T}$ and $\theta_{0}=-0.5$. You may find it useful to sketch the dataset and the linear separator $\theta, \theta_{0}$.
What are the values of $z=\theta^{T} x+\theta_{0}$ for each value of $x^{(i)}$? Give an answer as a list of four numbers (to max of two decimal places).","$[0.5,-0.5,0.5,-0.5]$.
We plug each $x$ into the formula $z=\theta^{T} x+\theta_{0}$ with $\theta=[1,0]^{T}$ and $\theta_{0}=-0.5$. Plotting the separator reveals that it is a vertical line at $x=0.5$. Also plotting the points $(x, y)$ reveals that the points to the left of the line have a negative $z$ value, and the points to the right of the line have a positive $z$ value.","Recall that the output of a logistic regression model given an input $x$ has the form:
$$
g=\sigma\left(\theta^{T} x+\theta_{0}\right)
$$
where
$$
\sigma(z)=\frac{1}{1+e^{-z}}
$$
is the sigmoid function. You start with the following set of points in two dimensions.
$$
\begin{array}{cc}
\text { Inputs } x^{(i)} & \text { Labels } y^{(i)} \\
{[1,1]^{T}} & 0 \\
{[0,0]^{T}} & 0 \\
{[1,0]^{T}} & 1 \\
{[0,1]^{T}} & 0
\end{array}
$$
Assume $\theta=[1,0]^{T}$ and $\theta_{0}=-0.5$. You may find it useful to sketch the dataset and the linear separator $\theta, \theta_{0}$.
What are the corresponding values of $\sigma(z)$ ? Give an answer as a list of four numbers (to max of two decimal places)?","$[0.62245933,0.37754067,0.62245933,0.37754067]$.
Plugging into the formula $\sigma(z)=\frac{1}{1+e^{-z}}$ where $z^{\prime}$ s are found in question 1.1. Remember that in logistic regression, we can interpret these $\sigma(z)$ values as modeling the probability of the point having a label of 1."
195,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 5,Localization with Viterbi,4,e,0.2604166667,Text,"In this section, we will implement an HMM for a robot that is moving around randomly in a 2D grid with obstacles. The robot has sensors that allow it to detect obstacles in its immediate vicinity. It knows the grid map, with the locations of all obstacles, but it is uncertain about its own location in the grid. We will use Viterbi to determine the most likely locations for the robot given a sequence of local and potentially noisy observations. 
Concretely, we will represent the 2D grid with obstacles as a list of lists, where 1s represent obstacles and 0s represent free space. Example:
obstacle_map = [
[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
[1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1],
[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0],
[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
]
The state of the robot is its location in the grid, represented as a tuple of ints, (row, col). Transitions are uniformly distributed amongst the robot's current location and the neighboring free (not obstacle) locations, where neighboring = 4 cardinal directions (up, down, left, right).
Observations are a 4-tuple that list which directions have obstacles, in order [N E S W], with a 1 for an obstacle and 0 for no obstacle. Observations that are ""off the map"" are 1, as though they are obstacles. For instance, in the map above, if there were no observation noise, then the observation for the top left corner (state=(0, 0)) would be (1, 0, 1, 1). Observations can also be corrupted with noise; see the create_observation_potential docstring for more details.
Our ultimate task will be to take in a sequence of observations and return the corresponding sequence of most likely states.
Write a function that creates a potential for the observation distribution between $s_{t}$ and $z_{t}$.
For reference, our solution is 29 line(s) of code. 
def create_observation_potential(obstacle_map, state_rv, observation_rv,

noise_prob=0.):

'''Write a function to create a potential between state_rv
and observation_rv in an HMM that corresponds to the map.
You can assume that state_rv was created by `create_state_variable`
and observation_rv was created by `create_observation_variable`.
See `create_observation_variable` for a description of the
observation model. Recall the order is [N E S W].
If noise_prob = 0., then the observations are noise-free. That is,
you observe 0 if there is a free space and 1 otherwise.
In general, for each of the four observation entries, with
probability 1 - noise_prob, the entry will be ""correct""; with
probability noise_prob, the entry will be incorrect, that is,
the opposite of the true occupancy.
So if the noise-free observation would be (1, 0, 0, 1), then
the probability of observation (1, 1, 0, 1) would be
noise_prob*(1 - noise_prob)^3.
Args:
obstacle_map: A list of lists of ints;
see example and description in `create_state_variable`.
state_rv: An RV representing the state at time t.
observation_rv: An RV representing the observation at time t.
noise_prob: A float between 0 and 1 indicating the probability
that an observation flips.
Returns:
potential: A Potential for the distribution between st and zt.
'''
raise NotImplementedError(""Implement me!"")",Programming,"def create_observation_potential(obstacle_map, state_rv, observation_rv,

noise_prob=0.):

'''Write a function to create a potential between state_rv
and observation_rv in an HMM that corresponds to the map.
You can assume that state_rv was created by `create_state_variable`
and observation_rv was created by `create_observation_variable`.
See `create_observation_variable` for a description of the
observation model. Recall the order is [N E S W].
If noise_prob = 0., then the observations are noise-free. That is,
you observe 0 if there is a free space and 1 otherwise.
In general, for each of the four observation entries, with
probability 1 - noise_prob, the entry will be ""correct""; with
probability noise_prob, the entry will be incorrect, that is,
the opposite of the true occupancy.
So if the noise-free observation would be (1, 0, 0, 1), then
the probability of observation (1, 1, 0, 1) would be
noise_prob*(1 - noise_prob)^3.
Args:
obstacle_map: A list of lists of ints;
see example and description in `create_state_variable`.
state_rv: An RV representing the state at time t.
observation_rv: An RV representing the observation at time t.
noise_prob: A float between 0 and 1 indicating the probability
that an observation flips.
Returns:
potential: A Potential for the distribution between st and zt.
'''
def get_obs_for_loc(r, c):
# Out of bounds
if not (0 <= r < len(obstacle_map) and 0 <= c < len(obstacle_map[0])):
return 1
return obstacle_map[r][c]
def get_obs_prob(obs, true_obs):
p = 1.
for i, j in zip(obs, true_obs):
if i == j:
p *= (1 - noise_prob)
else:
p *= noise_prob
return p
table = np.zeros((state_rv.dim, observation_rv.dim))
for i, (r, c) in enumerate(state_rv.domain):
true_obs = (
get_obs_for_loc(r - 1, c), # North
get_obs_for_loc(r, c + 1), # East
get_obs_for_loc(r + 1, c), # South
get_obs_for_loc(r, c - 1), # West
)
for j, obs in enumerate(observation_rv.domain):
table[i, j] = get_obs_prob(obs, true_obs)
return Potential([state_rv, observation_rv], table)","In this section, we will implement an HMM for a robot that is moving around randomly in a 2D grid with obstacles. The robot has sensors that allow it to detect obstacles in its immediate vicinity. It knows the grid map, with the locations of all obstacles, but it is uncertain about its own location in the grid. We will use Viterbi to determine the most likely locations for the robot given a sequence of local and potentially noisy observations. 
Concretely, we will represent the 2D grid with obstacles as a list of lists, where 1s represent obstacles and 0s represent free space. Example:
obstacle_map = [
[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
[1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1],
[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0],
[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
]
The state of the robot is its location in the grid, represented as a tuple of ints, (row, col). Transitions are uniformly distributed amongst the robot's current location and the neighboring free (not obstacle) locations, where neighboring = 4 cardinal directions (up, down, left, right).
Observations are a 4-tuple that list which directions have obstacles, in order [N E S W], with a 1 for an obstacle and 0 for no obstacle. Observations that are ""off the map"" are 1, as though they are obstacles. For instance, in the map above, if there were no observation noise, then the observation for the top left corner (state=(0, 0)) would be (1, 0, 1, 1). Observations can also be corrupted with noise; see the create_observation_potential docstring for more details.
Our ultimate task will be to take in a sequence of observations and return the corresponding sequence of most likely states.
Write a function that creates a random variable for a state at a given time step in an obstacle HMM. The domain of the state variable should be a list of(row, col) indices into the map. Only free positions (not obstacles) should be included in the domain of the state variable. See docstring for more description.
For reference, our solution is 4 line(s) of code.
def create_state_variable(obstacle_map, name):
'''Creates a RV for the HMM state.
The state can be any position in the map.
Example map:
obstacle_map = [
[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
[1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1],
[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0],
[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
]
Ones are obstacles and zeros are free positions.
The domain of the state variable should be a list of (row, col)
indices into the map. Only free positions (not obstacles) should
be included in the domain of the state variable.
The domain should be in row-major order. For example, an empty
2x2 obstacle map should lead to the domain:
[(0, 0), (0, 1), (1, 0), (1, 1)].
Args:
obstacle_map: A list of lists of ints, see example above.
name: A str name for the state variable.
Returns:
state_var: A RV as described above.
'''
raise NotImplementedError(""Implement me!"")","def create_state_variable(obstacle_map, name):
'''Creates a RV for the HMM state.
The state can be any position in the map.
Example map:
obstacle_map = [
[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
[1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1],
[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0],
[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
]
Ones are obstacles and zeros are free positions.
The domain of the state variable should be a list of (row, col)
indices into the map. Only free positions (not obstacles) should
be included in the domain of the state variable.
The domain should be in row-major order. For example, an empty
2x2 obstacle map should lead to the domain:
[(0, 0), (0, 1), (1, 0), (1, 1)].
Args:
obstacle_map: A list of lists of ints, see example above.
name: A str name for the state variable.
Returns:
state_var: A RV as described above.
'''
domain = [(r, c) for r in range(len(obstacle_map))
for c in range(len(obstacle_map[0])) if obstacle_map[r][c] == 0]
return RV(name, domain)","In this section, we will implement an HMM for a robot that is moving around randomly in a 2D grid with obstacles. The robot has sensors that allow it to detect obstacles in its immediate vicinity. It knows the grid map, with the locations of all obstacles, but it is uncertain about its own location in the grid. We will use Viterbi to determine the most likely locations for the robot given a sequence of local and potentially noisy observations. 
Concretely, we will represent the 2D grid with obstacles as a list of lists, where 1s represent obstacles and 0s represent free space. Example:
obstacle_map = [
[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
[1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1],
[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0],
[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
]
The state of the robot is its location in the grid, represented as a tuple of ints, (row, col). Transitions are uniformly distributed amongst the robot's current location and the neighboring free (not obstacle) locations, where neighboring = 4 cardinal directions (up, down, left, right).
Observations are a 4-tuple that list which directions have obstacles, in order [N E S W], with a 1 for an obstacle and 0 for no obstacle. Observations that are ""off the map"" are 1, as though they are obstacles. For instance, in the map above, if there were no observation noise, then the observation for the top left corner (state=(0, 0)) would be (1, 0, 1, 1). Observations can also be corrupted with noise; see the create_observation_potential docstring for more details.
Our ultimate task will be to take in a sequence of observations and return the corresponding sequence of most likely states.
Write a function that creates a potential for the transition distribution between states $s_{t}$ and $s_{t+1}$. Refer to the previous question for more information about the state variables and their domains.
For reference, our solution is 13 line(s) of code. 
def create_transition_potential(obstacle_map, st, st1):
'''Write a function to create a potential for the transition from state s_t
to s_{t+1}, in an HMM that corresponds to the map.
Transitions are uniformly distributed amongst the robot's current
location and the neighboring free (not obstacle) locations, where
neighboring = 4 cardinal directions (up, down, left, right).
Hint: remember that if we have a potential with two variables A and B,
with dimension N and M, then the potential table will be a numpy array
of shape (N, M). Furthermore, the potential value for the i^{th} domain
value of A and the j^{th} domain value of B will be table[i, j]. With
this in mind, you may find it useful to use the following pattern in
your code somewhere:
```
for i, (prev_r, prev_c) in enumerate(st.domain):
...
for j, (next_r, next_c) in enumerate(st1.domain):
...
table[i, j] = ...
```
Args:
st: An RV representing the state at time t.
st1: An RV representing the state at time t+1.
obstacle_map: A list of lists of ints;
see example and description in `create_state_variable`.
Returns:
potential: A Potential for the transition between st and st1.
'''
raise NotImplementedError(""Implement me!"")","def create_transition_potential(obstacle_map, st, st1):
'''Write a function to create a potential for the transition from state s_t
to s_{t+1}, in an HMM that corresponds to the map.
Transitions are uniformly distributed amongst the robot's current
location and the neighboring free (not obstacle) locations, where
neighboring = 4 cardinal directions (up, down, left, right).
Hint: remember that if we have a potential with two variables A and B,
with dimension N and M, then the potential table will be a numpy array
of shape (N, M). Furthermore, the potential value for the i^{th} domain
value of A and the j^{th} domain value of B will be table[i, j]. With
this in mind, you may find it useful to use the following pattern in
your code somewhere:
```
for i, (prev_r, prev_c) in enumerate(st.domain):
...
for j, (next_r, next_c) in enumerate(st1.domain):
...
table[i, j] = ...
```
Args:
st: An RV representing the state at time t.
st1: An RV representing the state at time t+1.
obstacle_map: A list of lists of ints;
see example and description in `create_state_variable`.
Returns:
potential: A Potential for the transition between st and st1.
'''
table = np.zeros((st.dim, st1.dim))
for i, (prev_r, prev_c) in enumerate(st.domain):
possible_next_loc_idxs = set()
for j, (next_r, next_c) in enumerate(st1.domain):
# Check if neighbors or self
if abs(prev_r - next_r) + abs(prev_c - next_c) <= 1:
possible_next_loc_idxs.add(j)
# Next locs have uniform probability
p = 1. / len(possible_next_loc_idxs)
for j in possible_next_loc_idxs:
table[i, j] = p
return Potential([st, st1], table)","In this section, we will implement an HMM for a robot that is moving around randomly in a 2D grid with obstacles. The robot has sensors that allow it to detect obstacles in its immediate vicinity. It knows the grid map, with the locations of all obstacles, but it is uncertain about its own location in the grid. We will use Viterbi to determine the most likely locations for the robot given a sequence of local and potentially noisy observations. 
Concretely, we will represent the 2D grid with obstacles as a list of lists, where 1s represent obstacles and 0s represent free space. Example:
obstacle_map = [
[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],
[1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1],
[1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0],
[0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]
]
The state of the robot is its location in the grid, represented as a tuple of ints, (row, col). Transitions are uniformly distributed amongst the robot's current location and the neighboring free (not obstacle) locations, where neighboring = 4 cardinal directions (up, down, left, right).
Observations are a 4-tuple that list which directions have obstacles, in order [N E S W], with a 1 for an obstacle and 0 for no obstacle. Observations that are ""off the map"" are 1, as though they are obstacles. For instance, in the map above, if there were no observation noise, then the observation for the top left corner (state=(0, 0)) would be (1, 0, 1, 1). Observations can also be corrupted with noise; see the create_observation_potential docstring for more details.
Our ultimate task will be to take in a sequence of observations and return the corresponding sequence of most likely states.
Given a potential and a variable that occurs in it, return a new potential conditioned on the specified variable having value 0.
For reference, our solution is 2 line(s) of code.
def conditioning_warmup(potential, rv):
'''Given a potential and a variable that occurs in it, return a new
potential conditioned on the specified variable having value 0.
Args:
potential: Potential
rv: A RV in the potential that has 0 in its domain.
Returns:
new_potential: Potential
'''
raise NotImplementedError(""Implement me!"")","def conditioning_warmup(potential, rv):
'''Given a potential and a variable that occurs in it, return a new
potential conditioned on the specified variable having value 0.
Args:
potential: Potential
rv: A RV in the potential that has 0 in its domain.
Returns:
new_potential: Potential
'''
return condition_potential(potential, {rv: 0})"
47,EECS,6.121,Introduction to Algorithms,"6.100A, 6.1200",6.101,Problem Set 4,Dog Show Leaderboard,3,a,0.15625,Text,"Alice is running a day-long regional dog show. Throughout the day, for each dog d that performs in the show, a panel of judges gives the dog a score $s_d$. Alice would like to maintain a leaderboard for the audience to keep track of the highest-scoring dogs as the competition progresses. Note that these scores may update throughout the day – new dogs who compete may have their high scores added to their leaderboard. At any given point in time, the highest-scoring dog may be disqualified from the competition, and may have its score removed from the leaderboard.
Alice is requesting a data structure that would allow her to efficiently maintain her leaderboard. Assuming a total of n dogs, she would like to insert dogs and their scores to the data structure in O(log n) time. She would also like to remove the highest-scoring dog and its score from the data structure in O(log n) time. Additionally, given an initial array of n dogs and their scores, she would like to be able to construct the data structure in O(n) time.
Note that these operations may potentially be called multiple times in succession.
Alice would like to display the highest-scoring k dogs on her leaderboard in order (where k ≤ n), so that the audience can see all high-scoring dogs, rather than just a single dog on the leaderboard. Design a data structure that, in addition to the insert and remove operations described above, adds an operation that returns the highest-scoring sequence of k dogs in order in O(k log n) time.",Open,"Use a max-heap to store the dogs using the scores as the key. To find the set of k dogs with the highest scores, pop k items from the heap, and store them in an array. This array contains precisely the desired dogs. Then, reinsert the k items in the array to the heap, to allow for future operations. Popping and reinserting takes O(k log n) time.","Alice is running a day-long regional dog show. Throughout the day, for each dog d that performs in the show, a panel of judges gives the dog a score $s_d$. Alice would like to maintain a leaderboard for the audience to keep track of the highest-scoring dogs as the competition progresses. Note that these scores may update throughout the day – new dogs who compete may have their high scores added to their leaderboard. At any given point in time, the highest-scoring dog may be disqualified from the competition, and may have its score removed from the leaderboard.
Alice is requesting a data structure that would allow her to efficiently maintain her leaderboard. Assuming a total of n dogs, she would like to insert dogs and their scores to the data structure in O(log n) time. She would also like to remove the highest-scoring dog and its score from the data structure in O(log n) time. Additionally, given an initial array of n dogs and their scores, she would like to be able to construct the data structure in O(n) time.
Note that these operations may potentially be called multiple times in succession.
Alice would like a more efficient way to display the highest-scoring k dogs on her leaderboard. She realizes that the audience no longer cares if the k dogs are shown in order on the leaderboard, as long as they are the highest-scoring set of k dogs. Also, she is willing to take O(n log k) time to construct the data structure given an initial array of n dogs. Design a data structure that, in addition to the insert and remove operations described above, adds an operation that returns the highest-scoring set of k dogs, as a pointer to an array containing these dogs, in O(1) time. Note that there is not enough time to construct the desired array of k dogs (which would take O(k) time), but it is sufficient to return a pointer to an array that has already been constructed as a part of the data structure, which would only take O(1) time. Also, recall that you must support insertion of new dogs in O(log n) time, and deletion of the highest-scoring dog in O(log n) time.","The main idea is to construct a min-heap of size $k$ to find the top $k$ dogs, and maintain this heap alongside a max-heap of size $n-k$ to store the rest of the dogs. Let us denote the min-heap of size $k$ by $H_k$, and the max-heap of size $n-k$ by $H_{n-k}$. In order to support deletion of the highest-scoring dog, we also maintain the same max-heap as in the previous part, of size $n$ containing all of the dogs; let us denote this heap by $H_n$. We maintain pointers of each element in this heap $H_n$ to the corresponding dogs in $H_k$ and $H_{n-k}$. Because we maintain pointers, we can ensure that even as elements move through $H_k$ and $H_{n-k}$, these moves will be reflected in $H_n$.
In order to construct this data structure from an initial array of $n$ dogs, we will additionally maintain an array of size $n-k$, say $A_{n-k}$. We start by inserting the first $k$ dogs into $H_k$. Then, for each dog remaining, if the dog's score is greater than the root of $H_k$, we pop the root of $H_k$ (the lowest-scoring dog), and we insert the new dog into $H_k$. We insert the dog that we removed from $H_k$ into the array $A_{n-k}$. If the dog's score was not greater than the root of $H_k$, then we simply insert the dog into $A_{n-k}$. We repeat this process until we have processed every dog in our initial array. Then, we construct the max-heap $H_{n-k}$ from $A_{n-k}$. Additionally, we can note the pointer to each dog in $H_k$ and $H_{n-k}$ alongside our initial array, and then construct $H_n$ from this array in $O(n)$ time.
Now, note that $H_k$ contains exactly the highest-scoring set of $k$ dogs, which Alice can return in $O(1)$ time, since a min-heap can be compactly maintained as an array.
It remains to claim that we can efficiently process insertions and deletions into this data structure. Our insertion procedure follows directly from the construction procedure. For a new dog that we would like to insert, we can compare the dog's score with that of the root of $H_k$, and if the dog's score is greater than the root, then we pop the root of $H_k$, insert our new dog into $H_k$, and insert the dog that we removed into $H_{n-k}$. We also insert this dog into our heap $H_n$, with a pointer to its location in either $H_k$ or $H_{n-k}$
For our deletion procedure, the dog must be in $H_k$. We can pop the root of $H_n$ to remove the dog from $H_n$ and obtain its location in $H_k$. We delete the corresponding node from $H_k$ in $O(\log k)$ time (using standard heap deletion, by swapping the node with the last node in $H_k$, deleting the last node in $H_k$, and heapify-ing), and we pop the maximum dog in $H_{n-k}$. Then, we insert the popped dog into $H_k$, to maintain the property that $H_k$ contains $k$ dogs. This takes $O(\log n)$ time.
Note that it is possible to use a different data structure rather than a min-heap to store the top $k$ dogs. For instance, an AVL tree would also be acceptable. However, there must be justification on how to maintain a compact array corresponding to the dogs in the tree, such that this array can be returned in $O(1)$ time.","Today is your first day working at FlixChill, the newest movie streaming service. Your task is to design a data structure to maintain the different movies in their catalogue. Each movie has a unique identifier $m$ and can only be streamed on or after a given date $s_{m}$ (by contract) and has a given ranking $r_{m}$.
The basic operations needed are:
1. insert $(m, s, r)$ : Inserts movie with ID $m$, starting date $s$ and ranking $r$.
2. delete $(m)$ : Deletes movie with ID $m$.
3. earliest $(s)$ : Outputs the movie that can be streamed earliest on or after the given date $s$.
4. highest $(s)$ : Outputs the movie that has the highest ranking and which starts on or after the given date $s$.
You need to implement each in worst-case $O(\log n)$ time where $n$ is the number of movies currently in the catalogue. For full credit, briefly describe your data structure and algorithms and analyze their runtime. You do not need to prove correctness. You do not need to describe or analyze algorithms discussed in class.","Store movies in AVL tree keyed by $s$ (breaking ties arbitrarily, such as by the movie ID $m$ ) and augmented by the highest ranking of a movie in the sub-tree. Also, store movies in a second AVL tree indexed by their ID $m$ and keeping a pointer to the node in the first AVL tree.
To insert or delete, one needs to maintain the cross-relationship between the two AVL trees in a straightforward manner.
The method earliest is a straight-forward extension of $f$ ind modified to output a node with the smallest key greater than or equal to than the given key.
The method highest goes down the tree to ""find"" the first movie $m$ with date greater than or equal to s. Once found, it goes up the tree, computing the maximum ranking of $m$ and all ancestor nodes after $m$ 's node and their right subtrees' augmented values. This can be done in time $O(\log n)$ given the augmentation.","Professor Oak is trying to organize his $n$ Critters so he can study them more efficiently. For each of the following scenarios, provide the most efficient algorithm for sorting the Critters, and state whether the asymptotic complexity is $\Theta(n), \Theta(n \log n)$, or $\Theta\left(n^{2}\right)$. Briefly justify your answers (a sentence or two suffices). Choose only one of the following sorting algorithms from lecture and recitation: insertion sort, selection sort, merge sort, counting sort, and radix sort.
Professor Oak wants to sort his Critters alphabetically by the names he has given them, which are strings of length at $\operatorname{most} \log _{2} n+1$, containing lowercase letters of the English alphabet. Each string is stored as contiguous bits in memory.","There are 26 choices for each letter. Therefore, the names can be interpreted as positive integers bounded by $26^{\log _{2} n+1}=O\left(n^{6}\right)$, so we can use radix sort in $\Theta(n)$ time."
293,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Lab 12,Reinforcement Learning,1,bii,0.02976190476,Text,"We explore the Q-learning algorithm using a deterministic MDP with two possible actions $(b$ and $c)$ and four states $(s 0$, $s 1$, $s 2$, s3). The transition model is
$$
\begin{aligned}
& T(s 0, b, s 1)=1 \\
& T(s 0, c, s 2)=1 \\
& T(s 1, *, s 0)=1 \\
& T(s 2, *, s 3)=1 \\
& T(s 3, *, s 3)=1
\end{aligned}
where $*$ represents either $b$ or $c$.
Some notes:
1. All other transitions have probability 0.
2. The goal state is $s 2$, and $s 3$ is a terminal state (similar to $\$$ in the grid-world question we have looked at).
3. Assume that if there are ties in the $Q$ function for actions $b$ and $c$ in a state, then we pick action $b$.
4. Assume the $Q$ function is initialized to 0 for every state-action pair and that, after every episode (sequence of actions) of length 10 , the agent is restarted in state $s 0$.
5. Assume a learning rate $(\alpha)$ of $0.5$.
6. Assume an $\epsilon$-greedy strategy with $\epsilon=0$.
7. Assume a discount factor of 1.
Note that we restart the agent in state $s 0$ after every 10 steps because otherwise it may reach $s 3$ and stay there forever.
In the goal-reward case, every action taken from the goal state $s 2$ gives an immediate positive reward of 1, and leads to a zero reward next state (in fact terminal state) $s 3$ that can never be escaped. Taking any action from any state other than the goal state provides zero reward. In other words, we have a reward function which outputs 0 for every state-action pair, except for $R(s 2, *)=1$.
What action will be selected the first time the agent encounters $s 0$ ? And why (explain why during the checkoff)? b or c?",Multiple Choice,b.,"We explore the Q-learning algorithm using a deterministic MDP with two possible actions $(b$ and $c)$ and four states $(s 0$, $s 1$, $s 2$, s3). The transition model is
$$
\begin{aligned}
& T(s 0, b, s 1)=1 \\
& T(s 0, c, s 2)=1 \\
& T(s 1, *, s 0)=1 \\
& T(s 2, *, s 3)=1 \\
& T(s 3, *, s 3)=1
\end{aligned}
where $*$ represents either $b$ or $c$.
Some notes:
1. All other transitions have probability 0.
2. The goal state is $s 2$, and $s 3$ is a terminal state (similar to $\$$ in the grid-world question we have looked at).
3. Assume that if there are ties in the $Q$ function for actions $b$ and $c$ in a state, then we pick action $b$.
4. Assume the $Q$ function is initialized to 0 for every state-action pair and that, after every episode (sequence of actions) of length 10 , the agent is restarted in state $s 0$.
5. Assume a learning rate $(\alpha)$ of $0.5$.
6. Assume an $\epsilon$-greedy strategy with $\epsilon=0$.
7. Assume a discount factor of 1.
Note that we restart the agent in state $s 0$ after every 10 steps because otherwise it may reach $s 3$ and stay there forever.
In the goal-reward case, every action taken from the goal state $s 2$ gives an immediate positive reward of 1, and leads to a zero reward next state (in fact terminal state) $s 3$ that can never be escaped. Taking any action from any state other than the goal state provides zero reward. In other words, we have a reward function which outputs 0 for every state-action pair, except for $R(s 2, *)=1$.
What action will be selected the second time the agent encounters $s 0$ ? And why (explain why during the checkoff)? b or c?",b.,"We explore the Q-learning algorithm using a deterministic MDP with two possible actions $(b$ and $c)$ and four states $(s 0$, $s 1$, $s 2$, s3). The transition model is
$$
\begin{aligned}
& T(s 0, b, s 1)=1 \\
& T(s 0, c, s 2)=1 \\
& T(s 1, *, s 0)=1 \\
& T(s 2, *, s 3)=1 \\
& T(s 3, *, s 3)=1
\end{aligned}
where $*$ represents either $b$ or $c$.
Some notes:
1. All other transitions have probability 0.
2. The goal state is $s 2$, and $s 3$ is a terminal state (similar to $\$$ in the grid-world question we have looked at).
3. Assume that if there are ties in the $Q$ function for actions $b$ and $c$ in a state, then we pick action $b$.
4. Assume the $Q$ function is initialized to 0 for every state-action pair and that, after every episode (sequence of actions) of length 10 , the agent is restarted in state $s 0$.
5. Assume a learning rate $(\alpha)$ of $0.5$.
6. Assume an $\epsilon$-greedy strategy with $\epsilon=0$.
7. Assume a discount factor of 1.
Note that we restart the agent in state $s 0$ after every 10 steps because otherwise it may reach $s 3$ and stay there forever.
In the goal-reward case, every action taken from the goal state $s 2$ gives an immediate positive reward of 1, and leads to a zero reward next state (in fact terminal state) $s 3$ that can never be escaped. Taking any action from any state other than the goal state provides zero reward. In other words, we have a reward function which outputs 0 for every state-action pair, except for $R(s 2, *)=1$.
What action will be selected the hundredth time the agent encounters $s 0$ ? And why (explain why during the checkoff)? b or c?",b.,"We explore the Q-learning algorithm using a deterministic MDP with two possible actions $(b$ and $c)$ and four states $(s 0$, $s 1$, $s 2$, s3). The transition model is
$$
\begin{aligned}
& T(s 0, b, s 1)=1 \\
& T(s 0, c, s 2)=1 \\
& T(s 1, *, s 0)=1 \\
& T(s 2, *, s 3)=1 \\
& T(s 3, *, s 3)=1
\end{aligned}
where $*$ represents either $b$ or $c$.
Some notes:
1. All other transitions have probability 0.
2. The goal state is $s 2$, and $s 3$ is a terminal state (similar to $\$$ in the grid-world question we have looked at).
3. Assume that if there are ties in the $Q$ function for actions $b$ and $c$ in a state, then we pick action $b$.
4. Assume the $Q$ function is initialized to 0 for every state-action pair and that, after every episode (sequence of actions) of length 10 , the agent is restarted in state $s 0$.
5. Assume a learning rate $(\alpha)$ of $0.5$.
6. Assume an $\epsilon$-greedy strategy with $\epsilon=0$.
7. Assume a discount factor of 1.
Note that we restart the agent in state $s 0$ after every 10 steps because otherwise it may reach $s 3$ and stay there forever.
In the goal-reward case, every action taken from the goal state $s 2$ gives an immediate positive reward of 1, and leads to a zero reward next state (in fact terminal state) $s 3$ that can never be escaped. Taking any action from any state other than the goal state provides zero reward. In other words, we have a reward function which outputs 0 for every state-action pair, except for $R(s 2, *)=1$.
In the stochastic shortest path (SSP) case, we put zero reward on taking any action from the goal state. Every action taken from the goal state $s 2$ leads to a zero-reward terminal state $s 3$ that can never be escaped. We put $-1$ in rewards everywhere else. In other words, we have a reward function which outputs $-1$ for every state-action pair except $R(s 2, *)=R(s 3, *)=0$.
What action will be selected the first time the agent encounters $s 0$ ? And why (explain why during the checkoff)? b or c?",b.
12,Mathematics,18.03,Differential Equations,None,18.02,Problem Set 2,Complex Numbers,1,a,0.1608579088,Text,"Compute the real and imaginary parts of the following complex numbers. Simplify as much as possible.
$e^{\frac{5 \pi i}{3}}+e^{\frac{4 \pi i}{3}}$.",Numerical,"$$
\begin{gathered}
e^{\frac{5 \pi i}{3}}+e^{\frac{4 \pi i}{3}}=\cos \frac{5 \pi}{3}+i \sin \frac{5 \pi}{3}+\cos \frac{4 \pi}{3}+i \sin \frac{4 \pi}{3} \\
=\frac{1}{2}+i\left(-\frac{\sqrt{3}}{2}\right)-\frac{1}{2}+i\left(-\frac{\sqrt{3}}{2}\right)=i(-\sqrt{3}) \\
\operatorname{Re}\left(e^{\frac{5 \pi i}{3}}+e^{\frac{4 \pi i}{3}}\right)=0, \quad \operatorname{Im}\left(e^{\frac{5 \pi i}{3}}+e^{\frac{4 \pi i}{3}}\right)=-\sqrt{3}
\end{gathered}
$$","Compute the real and imaginary parts of the following complex numbers. Simplify as much as possible.
$1+e^{-\frac{\pi i}{6}}$.","$$
\begin{gathered}
1+e^{-\frac{\pi i}{6}}=1+\cos \left(-\frac{\pi}{6}\right)+i \sin \left(-\frac{\pi}{6}\right)=1+\frac{\sqrt{3}}{2}-i \frac{1}{2} \\
\operatorname{Re}\left(1+e^{-\frac{\pi i}{6}}\right)=1+\frac{\sqrt{3}}{2}, \quad \operatorname{Im}\left(1+e^{-\frac{\pi i}{6}}\right)=-\frac{1}{2}
\end{gathered}
$$","Compute the real and imaginary parts of the following complex numbers. Simplify as much as possible.
$i^{2022}$.","$$
\begin{gathered}
i^{4}=1 \Rightarrow i^{2022}=i^{2020} \cdot i^{2}=\left(i^{4}\right)^{505} \cdot i^{2}=1^{505} \cdot(-1)=-1 \\
\operatorname{Re}\left(i^{2022}\right)=-1, \quad \operatorname{Im}\left(i^{2022}\right)=0
\end{gathered}
$$","Answer the following questions without the use of a calculator or computer. Briefly explain your answers.
Determine the real and imaginary parts of $1 /\left(e^{j 3 \pi / 4}+\frac{1}{\sqrt{2}} e^{j \pi / 2}\right)$.","We can simplify the denominator by converting each of the complex exponentials to cartesian form:
$$
\frac{1}{e^{j 3 \pi / 4}+\frac{1}{\sqrt{2}} e^{j \pi / 2}}=\frac{1}{-\frac{1}{\sqrt{2}}+\frac{j}{\sqrt{2}}+\frac{j}{\sqrt{2}}}=\frac{1}{\frac{-1+2 j}{\sqrt{2}}}=\frac{\sqrt{2}}{-1+2 j} .
$$
Then multiply by $\frac{-1-2 j}{-1-2 j}$ to make the denominator real:
$$
\left(\frac{\sqrt{2}}{-1+2 j}\right)\left(\frac{-1-2 j}{-1-2 j}\right)=-\frac{\sqrt{2}}{5}(1+2 j)
$$
Thus the real part is $-\frac{\sqrt{2}}{5}$ and the imaginary part is $-\frac{2 \sqrt{2}}{5}$."
304,Mathematics,18.01,Calculus I,None,None,Problem Set 7,Differential Equations,5,d,0.03167898627,Text,"In this problem, we study a model of coffee cooling in a closed styrofoam cup. Our goal is to go through all the steps involved in starting with a real-world problem, modelling it with a differential equation, using the math you've learned to understand the differential equation, and then drawing conclusions about the original real-world problem.
If the coffee has temperature $T$, the thermal energy in it is
$$
E=C V T
$$
where $C$ is the volume heat capacity of water (energy per volume per temperature), and $V$ is the volume of the coffee. $\left(C\right.$ is about $4 \times 10^{6} \mathrm{~J} /\left(\mathrm{m}^{3}{ }^{\circ} C\right)$. Here $J$ stands for joule, a unit of energy, $m$ stands for meter, and ${ }^{\circ} C$ stands for a degree centigrade.)
To model heat leaving the coffee, we imagine that there is a lid on the cup, so that the coffee is insulated by styrofoam on all sides. If the lid was off the cup, it would be more complicated to model. The rate $R$ at which energy leaves the coffee is
$$
R=k \frac{T-T_{\text {room }}}{x} A
$$
where $k$ is the thermal conductivity of styrofoam, $T_{\text {room }}$ is room temperature, $x$ is the thickness of the styrofoam cup, and $A$ is the cup's outside surface area. 
If the coffee kept cooling at this rate, what would its temperature be at $t=\tau ?$ At $t=2 \tau$?",Expression,"It the function $\tilde{T}$ were linear in $t$ we would have
$$
\tilde{T}(\tau)=T_{0}-\tau \frac{T_{0}-T_{\text {room }}}{\tau}=T_{\text {room }} \quad \text { and } \quad \tilde{T}(2 \tau)=2 T_{\text {room }}-T_{0}=T_{\text {room }}-\left(T_{0}-T_{\text {room }}\right).
$$","In this problem, we study a model of coffee cooling in a closed styrofoam cup. Our goal is to go through all the steps involved in starting with a real-world problem, modelling it with a differential equation, using the math you've learned to understand the differential equation, and then drawing conclusions about the original real-world problem.
If the coffee has temperature $T$, the thermal energy in it is
$$
E=C V T
$$
where $C$ is the volume heat capacity of water (energy per volume per temperature), and $V$ is the volume of the coffee. $\left(C\right.$ is about $4 \times 10^{6} \mathrm{~J} /\left(\mathrm{m}^{3}{ }^{\circ} C\right)$. Here $J$ stands for joule, a unit of energy, $m$ stands for meter, and ${ }^{\circ} C$ stands for a degree centigrade.)
To model heat leaving the coffee, we imagine that there is a lid on the cup, so that the coffee is insulated by styrofoam on all sides. If the lid was off the cup, it would be more complicated to model. The rate $R$ at which energy leaves the coffee is
$$
R=k \frac{T-T_{\text {room }}}{x} A
$$
where $k$ is the thermal conductivity of styrofoam, $T_{\text {room }}$ is room temperature, $x$ is the thickness of the styrofoam cup, and $A$ is the cup's outside surface area. 
What is the actual temperature at $t=\tau ? \quad t=2 \tau$? ","$$
T(\tau)=T_{\text {room }}+e^{-1}\left(T_{0}-T_{\text {room }}\right), \quad \text { and } \quad T(2 \tau)=T_{\text {room }}+e^{-2}\left(T_{0}-T_{\text {room }}\right)
$$","In this problem, we study a model of coffee cooling in a closed styrofoam cup. Our goal is to go through all the steps involved in starting with a real-world problem, modelling it with a differential equation, using the math you've learned to understand the differential equation, and then drawing conclusions about the original real-world problem.
If the coffee has temperature $T$, the thermal energy in it is
$$
E=C V T
$$
where $C$ is the volume heat capacity of water (energy per volume per temperature), and $V$ is the volume of the coffee. $\left(C\right.$ is about $4 \times 10^{6} \mathrm{~J} /\left(\mathrm{m}^{3}{ }^{\circ} C\right)$. Here $J$ stands for joule, a unit of energy, $m$ stands for meter, and ${ }^{\circ} C$ stands for a degree centigrade.)
To model heat leaving the coffee, we imagine that there is a lid on the cup, so that the coffee is insulated by styrofoam on all sides. If the lid was off the cup, it would be more complicated to model. The rate $R$ at which energy leaves the coffee is
$$
R=k \frac{T-T_{\text {room }}}{x} A
$$
where $k$ is the thermal conductivity of styrofoam, $T_{\text {room }}$ is room temperature, $x$ is the thickness of the styrofoam cup, and $A$ is the cup's outside surface area. 
Sketch $T(t)$, labeling the $t$ axis in increments of $\tau$.",The sketch is below.,"In this problem, we study a model of coffee cooling in a closed styrofoam cup. Our goal is to go through all the steps involved in starting with a real-world problem, modelling it with a differential equation, using the math you've learned to understand the differential equation, and then drawing conclusions about the original real-world problem.
If the coffee has temperature $T$, the thermal energy in it is
$$
E=C V T
$$
where $C$ is the volume heat capacity of water (energy per volume per temperature), and $V$ is the volume of the coffee. $\left(C\right.$ is about $4 \times 10^{6} \mathrm{~J} /\left(\mathrm{m}^{3}{ }^{\circ} C\right)$. Here $J$ stands for joule, a unit of energy, $m$ stands for meter, and ${ }^{\circ} C$ stands for a degree centigrade.)
To model heat leaving the coffee, we imagine that there is a lid on the cup, so that the coffee is insulated by styrofoam on all sides. If the lid was off the cup, it would be more complicated to model. The rate $R$ at which energy leaves the coffee is
$$
R=k \frac{T-T_{\text {room }}}{x} A
$$
where $k$ is the thermal conductivity of styrofoam, $T_{\text {room }}$ is room temperature, $x$ is the thickness of the styrofoam cup, and $A$ is the cup's outside surface area. 
Let the coffee's initial temperature be $T_{0}$. What is its initial cooling rate $(|d T / d t|$ at $t=0)$ ? Give your answer in terms of $T_{0}, T_{\text {room }}$, and $\tau$.","$$
\left|\frac{d T}{d t}\right|=\frac{T_{0}-T_{\text {room }}}{\tau}
$$"
44,Mathematics,18.6,Probability and Random Variables,18.02,None,Problem Set 4,Cumulative Distribution Function,5,nan,0.5,Text,"Let $X$ be a continuous random variable have cumulative distribution function $F$. Define the random variable $Y$ by $Y = F(X)$. Show that $Y$ is uniformly distributed over $(0, 1)$.",Open,"Since $F_X$ is a cumulative distribution function of a continuous random variable, $0 \leq F_X \leq 1$ and $0 \leq Y \leq 1$. When $0 < x < 1$, $F_Y(x) = P\{Y \leq x\} = P\{F_X(X) \leq x\} = P\{X \leq F_X^{-1}(x)\} = F_X(F_X^{-1}(x)) = x$. Thus, $Y$ has the cumulative distribution function of a uniform random variable, so $Y$ is uniformly distributed over $(0, 1)$.","Let $X$ be a random variable with cumulative distribution function $F$.
What is the cumulative distribution function of $aX+b$, where $a$ and $b$ are constants and $a \neq 0$? (Remember that $a$ could be positive or negative.)","Let $Y = aX + b$.
\textbf{Case 1}: $a > 0$.
$F_Y(c) = P\{Y \leq c\} = P\{aX + b \leq c\} = P\{X \leq \frac{c - b}{a}\} = F_X(\frac{c - b}{a})$.
\textbf{Case 2}: $a < 0$.
$F_Y(c) = P\{Y \leq c\} = P\{aX + b \leq c\} = P\{X \geq \frac{c - b}{a}\} = 1 - P\{X < \frac{c - b}{a}\} = 1 - P\{X \leq \frac{c - b}{a}\} + P\{X = \frac{c - b}{a}\} = 1 - F_X(\frac{c - b}{a}) + p_X(\frac{c - b}{a})$.","Let $X$ be a random variable with cumulative distribution function $F$.
What is the cumulative distribution function of $e^X$?","Let $Y = e^X$.
\textbf{Case 1}: $c > 0$.
$F_Y(c) = P\{Y \leq c\} = P\{e^X \leq c\} = P\{X \leq ln$ $c)\} = F_X(ln$ $c)$.
\textbf{Case 2}: $c \leq 0$.
$F_Y(c) = 0$.","Let $X$ and $Y$ be independent random variables such that $X$ is uniformly distributed over $(0, 1)$ and $Y$ is exponentially distributed with parameter $\lambda = 1$.
Find the distribution of $Z = X + Y$.","For $k \geq 1$, $P\{Z \leq k\}$ is obtained as follows
$P\{X + Y \leq k\} = \iint_{X + Y \leq k} f_{X, Y}(x, y) \,dx\,dy = \int_{0}^{1} \int_{0}^{k-x} e^{-y} \,dy\,dx = \int_{0}^{1}(1 - e^{x - k}) dx = 1 - e^{1 - k} + e^{-k}$.
For $0 < k < 1$, $P\{Z \leq k\}$ is obtained as follows
$P\{X + Y \leq k\} = \iint_{X + Y \leq k} f_{X, Y}(x, y) \,dx\,dy = \int_{0}^{k} \int_{0}^{k-x} e^{-y} \,dy\,dx = \int_{0}^{k}(1 - e^{x - k})dx = k + e^{-k} - 1$.
Thus, the cumulative distribution of $Z$ is given by
\[
F_Z(k) = P\{Z \leq k\} = P\{X + Y \leq k\} = 
\begin{cases} 
1 - e^{1 - k} + e^{-k} & \mbox{if } k \geq 1\\
k + e^{-k} - 1 & \mbox{if } 0 < k < 1\\
0 & \mbox{otherwise}
\end{cases}
\]
By differentiation, the probability distribution of $Z$ is given by
\[
f_Z(k) = \frac{d}{dk}F_Z(k) = 
\begin{cases} 
e^{1 - k} - e^{-k} & \mbox{if } k \geq 1\\
1 - e^{-k} & \mbox{if } 0 < k < 1\\
0 & \mbox{otherwise}
\end{cases}
\]"
82,Mathematics,18.701,Algebra I,18.100B,None,Midterm Exam 3,The Class Equation,1,nan,5,Text,The class equation of a group $G$ is $12=1+3+4+4$. Let $x$ be an element in the conjugacy class of that contains three elements. What could the order of $x$ be?,Open,"The order must be 2 .
The conjugacy class $C(x)$ has order 3 . The counting formula tells us that the centralizer $Z(x)$ has order 4 , and $x$ is an element of $Z(x)$. Therefore the order of $x$ divides 4 . The possibilities are 2 and 4 (not 1).
If $x$ had order $4, x^{2}$ would have order 2 . The centralizer $Z\left(x^{2}\right)$ contains $x$, so its order would be divisible by 4 and its conjugacy class $C\left(x^{2}\right)$ would have order 3 or 1 . But $C\left(x^{2}\right)$ isn't $C(x)$ or $C(1)$ because $x^{2}$ doesn't have order 4 or 1 . Looking at the Class Equation, one sees that there is no such conjugacy class. So $x$ doesn't have order 4 .",Let $G$ denote the group $G L_{2}\left(\mathbb{F}_{3}\right)$ of invertible $2 \times 2$ matrices with entries modulo 3. Its order is 48. Determine the order of the conjugacy class of the element $A=\left(\begin{array}{ll}0 & 1 \\ 1 & 0\end{array}\right)$ of $G$.,"The centralizer of $A$ consists of the invertible matrices of the form $\left(\begin{array}{ll}a & b \\ b & a\end{array}\right)$. There are 4 such matrices, so the conjugacy class has order 12.
Some of you were careless when counting the elements of the centralizer. The matrix $\left(\begin{array}{ll}2 & 1 \\ 1 & 2\end{array}\right)$ has determinant 3, which is zero modulo 3.","Let $G$ be the group $G L_3\left(\mathbb{F}_2\right)$. Its Class Equation, which is $168=1+21+42+56+24+24$, was computed in the previous assignment.
Determine the orders of the elements of $G$ and the number of elements of each order.","Analogous reasoning shows that there are 28 Sylow 3-groups and that the elements of order 3 make up the class of order 56 . This leaves two classes, of orders 42 and 21.
The elements of a Sylow 2-group can have orders $1,2,4$, or 8 . If there were an element $x$ of order 8 , there would also be elements $\left(x^{2}\right.$ and $\left.x^{4}\right)$ of orders 4 and 2 . Then the elements of orders $2,4,8$ would form at least 3 conjugacy classes. This isn't possible, so the elements have orders 4 or 2 . Since $G$ contains $x=\left(\begin{array}{lll}1 & 1 & 0 \\ 0 & 1 & 1 \\ 0 & 0 & 1\end{array}\right)$ of order 4 , those orders do occur.
The elements of order 4 come in pairs $x, x^{-1}$, so there is an even number of them. (In a finite group, the number of elements of order $n$ with $n>2$ is even.) Therefore there are 42 elements of order 4 , and 21 elements of order 2.
Finally, the Third Sylow Theorem tells us that the number of Sylow 2-groups groups can be $1,3,7$, or 21 . If there were 7 or fewer groups, there wouldn't be enough elements to fill out the two conjugacy classes. Therefore $G$ contains 21 Sylow 2-groups.",Determine the possible Class Equations for a group $G$ of order 8.,"The class of the identity has order 1 . The order of any conjugacy class divides 8 , so it can be 1,2 or 4 . Since 8 is even, there must be at least one other 1 in the class equation. Therefore the center $Z$ of $G$ is a nontrivial subgroup of order $>1$. Since $G$ isn't abelian, $|Z|$ can be 2 or 4 .
Let $x$ be an element of $G$ not in the center. Its centralizer $Z(x)$ isn't the whole group, but it contains $x$ and it also contains the center $Z$. Therefore $|Z|$ is a proper divisor of $|Z(x)|$ and $|Z(x)|$ is a proper divisor of $|G|=8$. It follows that $|Z|=2$ and $|Z(x)|=4$. So $|C(x)|=2$. The Class Equation has two 1s and the other classes have order 2. It is $8=1+1+2+2+2$. "
36,EECS,6.102,Elements of Software Construction,6.101,None,Midterm Exam 2,Instance Method,1,b,0.8,Text,"In the provided code at the bottom, the type DNA represents a strand of DNA, which is a string of bases, where a base is represented by one of the letters A, C, G, or T.
/**
* Immutable type representing a strand of DNA.
*/
class DNA {
       /** omitted */
       public constructor(bases: string) {
       // omitted
}
       /**
        * @returns zero-based index of first occurence of `dna` as a substring of this strand,
        * or undefined if `dna` never occurs.
        */
       public find(dna: DNA): number|undefined {
             // omitted
       }
       /**
        * @returns true iff this and that are observationally equivalent
        */
       public equalValue(that: DNA): boolean {
              // omitted
       }
       // other code omitted
}
/**
* Immutable type representing a gene-editing process.
*/
interface Crispr {
      /**
       * Simulates this gene-editing process entirely in software, without using chemicals or a lab.
       * @returns DNA strand that would result from this process
       */
      simulate(): DNA;
     /**
      * Run this gene-editing process using the given `lab`.
      * @returns the tube of `lab` in which the final DNA from this process
      * can be found.
      */
      async fabricate(lab: Lab): Promise<Tube>;
      // other code omitted
}
/**
* Represents an already-existing DNA strand (a ""precursor"") in a gene-editing
* process. Precursors are bought premade from a supplier.
*/
class Precursor implements Crispr {
/**
* Make a gene-splicing step that results in the given `dna` strand.
*/
       public constructor(private readonly dna: DNA) {
       }
       // other code omitted
}
/**
* Represents a gene-splicing step in a gene-editing process,
* which replaces all instances of one gene with another.
*/
class Splice implements Crispr {
       /**
        * Make a gene-splicing step that finds all occurrences of
        * oldGene in target and substitutes newGene in place of each one.
        */
       public constructor(
       private readonly target: Crispr,
       private readonly oldGene: Crispr,
       private readonly newGene: Crispr
       ) {
       }
       // other code omitted
}
/**
* Mutable type controlling an automated gene-editing machine.
*/
class Lab {
/**
* Modifies the DNA in targetTube to replace all occurrences of the DNA from oldGeneTube with the
* DNA from newGeneTube.
* @returns a promise that fulfills with the same tube as targetTube, after the process is complet
*/
       public async splice(targetTube: Tube, oldGeneTube: Tube, newGeneTube: Tube): Promise<Tube> {
              // omitted
       }
       private tubeMap: Map<Tube, DNA> = new Map();
        /**
         * @returns a tube containing DNA strands corresponding to `dna`
         */
        public async get(dna: DNA): Promise<Tube> {
                for (const tube of this.tubeMap.keys()) {
                      if (this.tubeMap.get(tube).equalValue(dna)) {
                          return tube;
                      }
                 }
                 const tube = new Tube();
                 this.tubeMap.set(tube, dna);
                 await this.load(tube, dna); // ""line 6a"" is the load() call, ""line 6b"" is the await
                 return tube;
         }
         /**
          * Ask a human to order premade DNA from a supplier
          * and load it into the tube.
          * @returns a promise that fulfills once this tube contains `dna`.
          */
         private async load(tube: Tube, dna: DNA): Promise<void> {
               // omitted
         }
         // other code omitted
}
/**
* Mutable type representing a test tube containing DNA.
*/
class Tube {
       /** Make a new Tube. */
       public constructor() {
       }
       // other code omitted
}
One kind of DNA strand is a gene, which encodes the description of a protein. Genes can also occur as substrings in other DNA strands.
The provided type Crispr represents a gene-editing process. The process starts with precursors, with are premade DNA strands bought from a supplier. A typical step of a gene-editing process is a gene splice, which replaces a gene in a DNA strand with another gene.
A Crispr process can be simulated entirely in software. The result of simulation is a DNA value in memory.
A Crispr process can also be fabricated in the real world using a Lab, which programmatically controls a gene-editing machine with Tube elements in which gene-editing reactions occur. The result of fabrication is a Tube containing real DNA.
Note that this is an oversimplification of biology, gene-editing, and CRISPR technology. 
The government requires that gene-editing processes should never intentionally or accidentally produce DNA containing a dangerous substring (one that might, for example, be a dangerous virus). This requirement must be enforced not just on all precursors and final product of the process, but for intermediate products as well (the result of each completed gene-splicing step).
Alyssa Hacker recommends providing an operation ever0ccurs that takes a DNA strand and returns true if and only if the strand ever occurs as a substring of any DNA strand used or produced during the process.
Specify and implement ever0ccurs as an instance method of Crispr.",Programming,"interface Crispr {
       ...
       /**
        * @param dna strand to search for
        * @returns true if and only if dna ever occurs as a substring of any DNA strand
        * used or produced during this process
        */
        everOccurs(dna: DNA): boolean;
}
class Precursor implements Crispr {
        ...
   /** @inheritdoc */
   public everOccurs(dna: DNA) {
        return this.dna.find(dna) !== undefined;
   }
}
class Splice implements Crispr { 
       ...
   /** @inheritdoc */
   public everOccurs(dna: DNA) {
       return this.target.everOccurs(dna) || this.oldGene.everOccurs(dna) || this.newGene.everOccurs(dna) ||        this.simulate().find(dna) !== undefined;
    }
// other answers possible
}","In the provided code at the bottom, the type DNA represents a strand of DNA, which is a string of bases, where a base is represented by one of the letters A, C, G, or T.
/**
* Immutable type representing a strand of DNA.
*/
class DNA {
       /** omitted */
       public constructor(bases: string) {
       // omitted
}
       /**
        * @returns zero-based index of first occurence of `dna` as a substring of this strand,
        * or undefined if `dna` never occurs.
        */
       public find(dna: DNA): number|undefined {
             // omitted
       }
       /**
        * @returns true iff this and that are observationally equivalent
        */
       public equalValue(that: DNA): boolean {
              // omitted
       }
       // other code omitted
}
/**
* Immutable type representing a gene-editing process.
*/
interface Crispr {
      /**
       * Simulates this gene-editing process entirely in software, without using chemicals or a lab.
       * @returns DNA strand that would result from this process
       */
      simulate(): DNA;
     /**
      * Run this gene-editing process using the given `lab`.
      * @returns the tube of `lab` in which the final DNA from this process
      * can be found.
      */
      async fabricate(lab: Lab): Promise<Tube>;
      // other code omitted
}
/**
* Represents an already-existing DNA strand (a ""precursor"") in a gene-editing
* process. Precursors are bought premade from a supplier.
*/
class Precursor implements Crispr {
/**
* Make a gene-splicing step that results in the given `dna` strand.
*/
       public constructor(private readonly dna: DNA) {
       }
       // other code omitted
}
/**
* Represents a gene-splicing step in a gene-editing process,
* which replaces all instances of one gene with another.
*/
class Splice implements Crispr {
       /**
        * Make a gene-splicing step that finds all occurrences of
        * oldGene in target and substitutes newGene in place of each one.
        */
       public constructor(
       private readonly target: Crispr,
       private readonly oldGene: Crispr,
       private readonly newGene: Crispr
       ) {
       }
       // other code omitted
}
/**
* Mutable type controlling an automated gene-editing machine.
*/
class Lab {
/**
* Modifies the DNA in targetTube to replace all occurrences of the DNA from oldGeneTube with the
* DNA from newGeneTube.
* @returns a promise that fulfills with the same tube as targetTube, after the process is complet
*/
       public async splice(targetTube: Tube, oldGeneTube: Tube, newGeneTube: Tube): Promise<Tube> {
              // omitted
       }
       private tubeMap: Map<Tube, DNA> = new Map();
        /**
         * @returns a tube containing DNA strands corresponding to `dna`
         */
        public async get(dna: DNA): Promise<Tube> {
                for (const tube of this.tubeMap.keys()) {
                      if (this.tubeMap.get(tube).equalValue(dna)) {
                          return tube;
                      }
                 }
                 const tube = new Tube();
                 this.tubeMap.set(tube, dna);
                 await this.load(tube, dna); // ""line 6a"" is the load() call, ""line 6b"" is the await
                 return tube;
         }
         /**
          * Ask a human to order premade DNA from a supplier
          * and load it into the tube.
          * @returns a promise that fulfills once this tube contains `dna`.
          */
         private async load(tube: Tube, dna: DNA): Promise<void> {
               // omitted
         }
         // other code omitted
}
/**
* Mutable type representing a test tube containing DNA.
*/
class Tube {
       /** Make a new Tube. */
       public constructor() {
       }
       // other code omitted
}
One kind of DNA strand is a gene, which encodes the description of a protein. Genes can also occur as substrings in other DNA strands.
The provided type Crispr represents a gene-editing process. The process starts with precursors, with are premade DNA strands bought from a supplier. A typical step of a gene-editing process is a gene splice, which replaces a gene in a DNA strand with another gene.
A Crispr process can be simulated entirely in software. The result of simulation is a DNA value in memory.
A Crispr process can also be fabricated in the real world using a Lab, which programmatically controls a gene-editing machine with Tube elements in which gene-editing reactions occur. The result of fabrication is a Tube containing real DNA.
Note that this is an oversimplification of biology, gene-editing, and CRISPR technology. 
Write the data type definition for the provided Crispr type.","Crispr = Precursor(dna: DNA) + Splice(target: Crispr, oldGene: Crispr, newGene: Crispr).","/**
* Immutable type representing a strand of DNA.
*/
class DNA {
       /** omitted */
       public constructor(bases: string) {
       // omitted
}
       /**
        * @returns zero-based index of first occurence of `dna` as a substring of this strand,
        * or undefined if `dna` never occurs.
        */
       public find(dna: DNA): number|undefined {
             // omitted
       }
       /**
        * @returns true iff this and that are observationally equivalent
        */
       public equalValue(that: DNA): boolean {
              // omitted
       }
       // other code omitted
}
/**
* Immutable type representing a gene-editing process.
*/
interface Crispr {
      /**
       * Simulates this gene-editing process entirely in software, without using chemicals or a lab.
       * @returns DNA strand that would result from this process
       */
      simulate(): DNA;
     /**
      * Run this gene-editing process using the given `lab`.
      * @returns the tube of `lab` in which the final DNA from this process
      * can be found.
      */
      async fabricate(lab: Lab): Promise<Tube>;
      // other code omitted
}
/**
* Represents an already-existing DNA strand (a ""precursor"") in a gene-editing
* process. Precursors are bought premade from a supplier.
*/
class Precursor implements Crispr {
/**
* Make a gene-splicing step that results in the given `dna` strand.
*/
       public constructor(private readonly dna: DNA) {
       }
       // other code omitted
}
/**
* Represents a gene-splicing step in a gene-editing process,
* which replaces all instances of one gene with another.
*/
class Splice implements Crispr {
       /**
        * Make a gene-splicing step that finds all occurrences of
        * oldGene in target and substitutes newGene in place of each one.
        */
       public constructor(
       private readonly target: Crispr,
       private readonly oldGene: Crispr,
       private readonly newGene: Crispr
       ) {
       }
       // other code omitted
}
/**
* Mutable type controlling an automated gene-editing machine.
*/
class Lab {
/**
* Modifies the DNA in targetTube to replace all occurrences of the DNA from oldGeneTube with the
* DNA from newGeneTube.
* @returns a promise that fulfills with the same tube as targetTube, after the process is complet
*/
       public async splice(targetTube: Tube, oldGeneTube: Tube, newGeneTube: Tube): Promise<Tube> {
              // omitted
       }
       private tubeMap: Map<Tube, DNA> = new Map();
        /**
         * @returns a tube containing DNA strands corresponding to `dna`
         */
        public async get(dna: DNA): Promise<Tube> {
                for (const tube of this.tubeMap.keys()) {
                      if (this.tubeMap.get(tube).equalValue(dna)) {
                          return tube;
                      }
                 }
                 const tube = new Tube();
                 this.tubeMap.set(tube, dna);
                 await this.load(tube, dna); // ""line 6a"" is the load() call, ""line 6b"" is the await
                 return tube;
         }
         /**
          * Ask a human to order premade DNA from a supplier
          * and load it into the tube.
          * @returns a promise that fulfills once this tube contains `dna`.
          */
         private async load(tube: Tube, dna: DNA): Promise<void> {
               // omitted
         }
         // other code omitted
}
/**
* Mutable type representing a test tube containing DNA.
*/
class Tube {
       /** Make a new Tube. */
       public constructor() {
       }
       // other code omitted
}
Suppose that:
• two different gene-editing processes A and B are running asynchronously using the same Lab
• A and B both call lab.get(dnaX) for the same precursor dnaX
• no other asynchronous processes are using lab
For each of the following interleavings, referring to the line numbers 1-7 in get() in the provided code, decide whether the
interleaving is impossible, leads to a race condition or deadlock, or runs safely; then explain your answer in one sentence.
A runs lines 1, 4, 5, 6, 7, then B runs lines 1, 4, 5, 6, 7.","impossible; After A runs line 5, there will be at least one tube in tubeMap, so B must proceed from line 1 to line 2.","/**
* Immutable type representing a strand of DNA.
*/
class DNA {
       /** omitted */
       public constructor(bases: string) {
       // omitted
}
       /**
        * @returns zero-based index of first occurence of `dna` as a substring of this strand,
        * or undefined if `dna` never occurs.
        */
       public find(dna: DNA): number|undefined {
             // omitted
       }
       /**
        * @returns true iff this and that are observationally equivalent
        */
       public equalValue(that: DNA): boolean {
              // omitted
       }
       // other code omitted
}
/**
* Immutable type representing a gene-editing process.
*/
interface Crispr {
      /**
       * Simulates this gene-editing process entirely in software, without using chemicals or a lab.
       * @returns DNA strand that would result from this process
       */
      simulate(): DNA;
     /**
      * Run this gene-editing process using the given `lab`.
      * @returns the tube of `lab` in which the final DNA from this process
      * can be found.
      */
      async fabricate(lab: Lab): Promise<Tube>;
      // other code omitted
}
/**
* Represents an already-existing DNA strand (a ""precursor"") in a gene-editing
* process. Precursors are bought premade from a supplier.
*/
class Precursor implements Crispr {
/**
* Make a gene-splicing step that results in the given `dna` strand.
*/
       public constructor(private readonly dna: DNA) {
       }
       // other code omitted
}
/**
* Represents a gene-splicing step in a gene-editing process,
* which replaces all instances of one gene with another.
*/
class Splice implements Crispr {
       /**
        * Make a gene-splicing step that finds all occurrences of
        * oldGene in target and substitutes newGene in place of each one.
        */
       public constructor(
       private readonly target: Crispr,
       private readonly oldGene: Crispr,
       private readonly newGene: Crispr
       ) {
       }
       // other code omitted
}
/**
* Mutable type controlling an automated gene-editing machine.
*/
class Lab {
/**
* Modifies the DNA in targetTube to replace all occurrences of the DNA from oldGeneTube with the
* DNA from newGeneTube.
* @returns a promise that fulfills with the same tube as targetTube, after the process is complet
*/
       public async splice(targetTube: Tube, oldGeneTube: Tube, newGeneTube: Tube): Promise<Tube> {
              // omitted
       }
       private tubeMap: Map<Tube, DNA> = new Map();
        /**
         * @returns a tube containing DNA strands corresponding to `dna`
         */
        public async get(dna: DNA): Promise<Tube> {
                for (const tube of this.tubeMap.keys()) {
                      if (this.tubeMap.get(tube).equalValue(dna)) {
                          return tube;
                      }
                 }
                 const tube = new Tube();
                 this.tubeMap.set(tube, dna);
                 await this.load(tube, dna); // ""line 6a"" is the load() call, ""line 6b"" is the await
                 return tube;
         }
         /**
          * Ask a human to order premade DNA from a supplier
          * and load it into the tube.
          * @returns a promise that fulfills once this tube contains `dna`.
          */
         private async load(tube: Tube, dna: DNA): Promise<void> {
               // omitted
         }
         // other code omitted
}
/**
* Mutable type representing a test tube containing DNA.
*/
class Tube {
       /** Make a new Tube. */
       public constructor() {
       }
       // other code omitted
}
Suppose that:
• two different gene-editing processes A and B are running asynchronously using the same Lab
• A and B both call lab.get(dnaX) for the same precursor dnaX
• no other asynchronous processes are using lab
For each of the following interleavings, referring to the line numbers 1-7 in get() in the provided code, decide whether the
interleaving is impossible, leads to a race condition or deadlock, or runs safely; then explain your answer in one sentence.
A runs lines 1, 4, 5, 6a, then B runs lines 1, 2, 3, then A finishes lines 6b and 7.","race condition; B returns the tube that A is loading before the tube has finished loading, violating the postcondition of get()."
5,EECS,6.122,Design and Analysis of Algorithms,6.121,None,Problem Set 1,Probability,2,dii,0.07272727273,Text,"Asami and Bolin are playing a dice game in which a pair of dice is rolled repeatedly. Asami wins if a sum of 6 is rolled before any sum greater than or equal to 9, and Bolin wins if any sum greater than or equal to 9 is rolled first. We will find the probability that Asami wins the game.
Let $E_n$ denote the event that a 6 occurs on the $n^{\text {th }}$ roll and neither 6 nor any number greater than or equal to 9 occurs on any of the first $(n-1)$ rolls.
Now, suppose that in a run of this game, the dice are rolled ten times with neither a 6 nor any number greater than or equal to 9 appearing. Given this, let X be the sum of these ten rolls. We would now like to find an upper bound for the following probability $P[|X − \mathbb{E}[X]| \geq 10]$.
For these ten rolls, let $X_i$ be the sum of the numbers on the faces of the two dice for roll $i$. Compute the expected value of $X_i$.",Numerical,"The expected value of $X_i$ is given by
$$
\mathbb{E}\left[X_i\right]=\sum_j j \cdot P\left[X_i=j\right]=\frac{1}{21} \cdot 2+\frac{2}{21} \cdot 3+\frac{3}{21} \cdot 4+\frac{4}{21} \cdot 5+\frac{6}{21} \cdot 7+\frac{5}{21} \cdot 8=\frac{122}{21} .
$$
\begin{tabular}{|c|c|}
\hline Roll & Probability \\
\hline 2 & $1 / 21$ \\
\hline 3 & $2 / 21$ \\
\hline 4 & $3 / 21$ \\
\hline 5 & $4 / 21$ \\
\hline 7 & $6 / 21$ \\
\hline 8 & $5 / 21$ \\
\hline
\end{tabular}","Asami and Bolin are playing a dice game in which a pair of dice is rolled repeatedly. Asami wins if a sum of 6 is rolled before any sum greater than or equal to 9, and Bolin wins if any sum greater than or equal to 9 is rolled first. We will find the probability that Asami wins the game.
Let $E_n$ denote the event that a 6 occurs on the $n^{\text {th }}$ roll and neither 6 nor any number greater than or equal to 9 occurs on any of the first $(n-1)$ rolls.
Now, suppose that in a run of this game, the dice are rolled ten times with neither a 6 nor any number greater than or equal to 9 appearing. Given this, let X be the sum of these ten rolls. We would now like to find an upper bound for the following probability $P[|X − \mathbb{E}[X]| \geq 10]$.
Given that each of these ten rolls results in neither a 6 nor any number greater than or equal to 9, enumerate the possible totals for each roll and their respective probabilities.","Because we know that we roll neither a 6 nor any number greater than or equal to 9 , the only possible rolls are $2,3,4,5,7,8$. There are $36-5-10=21$ rolls that result in these totals, with counts $1,2,3,4$, 6, and 5, respectively. ","Asami and Bolin are playing a dice game in which a pair of dice is rolled repeatedly. Asami wins if a sum of 6 is rolled before any sum greater than or equal to 9, and Bolin wins if any sum greater than or equal to 9 is rolled first. We will find the probability that Asami wins the game.
Let $E_n$ denote the event that a 6 occurs on the $n^{\text {th }}$ roll and neither 6 nor any number greater than or equal to 9 occurs on any of the first $(n-1)$ rolls.
Now, suppose that in a run of this game, the dice are rolled ten times with neither a 6 nor any number greater than or equal to 9 appearing. Given this, let X be the sum of these ten rolls. We would now like to find an upper bound for the following probability $P[|X − \mathbb{E}[X]| \geq 10]$.
Compute the variance of $X$, where $X$ is again the sum of these ten dice rolls.","Because the dice rolls are pairwise independent, we have
$$
\operatorname{Var}[X]=\operatorname{Var}\left(\sum_{i=1}^{10} X_i\right)=\sum_{i=1}^{10} \operatorname{Var}\left(X_i\right) .
$$
To compute the variance of a single dice roll, we use $\operatorname{Var}\left(X_i\right)=\mathbb{E}\left[X_i^2\right]-$ $\mathbb{E}\left[X_i\right]^2$ To find $\mathbb{E}\left[X_i^2\right]$, we write:
$$
\mathbb{E}\left[X_i^2\right]=\sum_{j \in\{2,3,4,5,7,8\}} j^2 \cdot P\left[X_i=j\right]=\frac{1}{21} \cdot 2^2+\frac{2}{21} \cdot 3^2+\frac{3}{21} \cdot 4^2+\frac{4}{21} \cdot 5^2+\frac{6}{21} \cdot 7^2+\frac{5}{21} \cdot 8^2=\frac{784}{21} .
$$
The variance of $X_i$ is thus
$$
\operatorname{Var}\left(X_i\right)=\mathbb{E}\left[X_i^2\right]-\mathbb{E}\left[X_i\right]^2=\frac{784}{21}-\left(\frac{122}{21}\right)^2=\frac{1580}{441} .
$$
It follows that the variance of $X$ is given by
$$
\operatorname{Var}(X)=10 \cdot \frac{1580}{441}=\frac{15800}{441}
$$","Asami and Bolin are playing a dice game in which a pair of dice is rolled repeatedly. Asami wins if a sum of 6 is rolled before any sum greater than or equal to 9, and Bolin wins if any sum greater than or equal to 9 is rolled first. We will find the probability that Asami wins the game.
Let $E_n$ denote the event that a 6 occurs on the $n^{\text {th }}$ roll and neither 6 nor any number greater than or equal to 9 occurs on any of the first $(n-1)$ rolls.
Now, suppose that in a run of this game, the dice are rolled ten times with neither a 6 nor any number greater than or equal to 9 appearing. Given this, let X be the sum of these ten rolls. We would now like to find an upper bound for the following probability $P[|X − \mathbb{E}[X]| \geq 10]$.
Use Chebyshev's inequality to find an upper bound for $P[\mid X-$ $\mathbb{E}[X] \mid \geq 10]$.","Using Chebyshev's inequality and the values for the values for the expectation value and the variance of $X$ from the previous parts, we find
$$
P\left[\left|X-\frac{1220}{21}\right| \geq 10\right] \leq \frac{15800 / 441}{10^2}=\frac{158}{441} .
$$"
71,EECS,6.3,Signal Processing,"6.100A, 18.03",None,Problem Set 5,Fourier Transforms,6,c,0.15625,Text,What are important similarities and differences between $x_{1}(t)$ and $x_{2}(t)$ ? How do those similarities and differences manifest in their Fourier transforms?,Open,"Both $x_{1}(t)$ and $x_{2}(t)$ are real functions of time. However, $x_{1}(t)$ is an antisymmetric function of time and $x_{2}(t)$ is a symmetric function of time. Taken together, these features mean that $X_{1}(\omega)$ is an antisymmetric function of $\omega$ that is purely imaginary, and $X_{2}(\omega)$ is a symmetric function of $\omega$ that is purely real.
Both $X_{1}(\omega)$ and $X_{2}(\omega)$ are zero for $|\omega|>3 \pi$. Therefore, both $x_{1}(t)$ and $x_{2}(t)$ have infinite extents in time. ","Suppose that $x_{1}(t)$ obeys $x_{1}^{\prime}(t)=-x_{1}(t)$ and $x_{2}(t)$ obeys $x_{2}^{\prime}(t)=$ $-x_{2}(t)^{2}$. Suppose that $x_{1}(0)=x_{2}(0)=1$. Which one do we expect is bigger, $x_{1}(10)$ or $x_{2}(10)$ ? We will compute the answer below, but make an educated guess before you compute and explain your reasoning. If your educated guess is wrong, then you can come back and rethink this question.","In the first time step of an Euler approximation, both functions decrease by the same amount (their derivatives at zero are identical and negative). Thus, both are slightly smaller than 1 and roughly equal. However, in the second time step, the first function decreases more than the second does (because $-x$ is more negative than $-x^{2}$ when $x$ is slightly smaller than 1). Thus, the first function will be smaller.","Determine $x_{1}(t)$, whose Fourier transform $X_{1}(\omega)$ has the following magnitude and angle.
Express $x_{1}(t)$ as a closed-form function of time.","We can express $X_{1}(\omega)$ mathematically as $3 j \omega$ for $|\omega|<0$ and 0 for $|\omega|>0$.
Let $X_{1 a}(\omega)$ represent a rectangular pulse in frequency so that $X_{1 a}(\omega)=1$ if $|\omega|<3 \pi$ and 0 if $|\omega|>3 \pi$. Then
$$
X_{1}(\omega)=3 j \omega X_{1 a}(\omega)
$$
Thus $x_{1}(t)=3 \frac{d}{d t} x_{1 a}(t)$ where
$$
x_{1 a}(t)=\frac{\sin (3 \pi t)}{\pi t}
$$
Thus
$$
x_{1}(t)=\frac{3}{\pi t^{2}}(3 \pi t \cos 3 \pi t-\sin (3 \pi t))
$$","Determine $x_{2}(t)$, whose Fourier transform $X_{2}(\omega)$ has the following magnitude and angle.
Express $x_{2}(t)$ as a closed-form function of time.","Consider just the right-hand side of $X_{2}(\omega)$:
$$
\begin{aligned}
& X_{r}(\omega)= \begin{cases}3 \omega & \text { if } 0<\omega<3 \pi \\
0 & \text { otherwise }\end{cases} \\
& x_{r}(t)=\frac{1}{2 \pi} \int_{0}^{3 \pi} 3 \omega e^{j \omega t} d \omega
\end{aligned}
$$
We could integrate by parts, but it would be easier to think about $x_{r}(t)$ as the time derivative of some other function $y(t)$. Taking the time derivative introduces a factor of $j \omega$ in the Fourier domain, so we would like to express $x_{r}(t)$ in a form that has a factor of $j \omega$:
$$
\begin{aligned}
& x_{r}(t)=\frac{3}{j 2 \pi} \int_{0}^{3 \pi} j \omega e^{j \omega t} d \omega \\
& y(t)=\frac{3}{j 2 \pi} \int_{0}^{3 \pi} e^{j \omega t} d \omega=\frac{3}{j 2 \pi t}\left(1-e^{j 3 \pi t}\right)
\end{aligned}
$$
Using the product rule for derivatives, we have:
$$
\begin{aligned}
x_{r}(t) & =\dot{y}(t)=\frac{3}{2 \pi t}(-j 3 \pi) e^{j 3 \pi t}-\frac{3}{2 \pi t^{2}}\left(1-e^{j 3 \pi t}\right) \\
x(t) & =x_{r}(t)+x_{r}(-t) \\
& =-j \frac{9}{2 t} e^{j 3 \pi t}+j \frac{9}{2 t} e^{-j 3 \pi t}-\frac{3}{2 \pi t^{2}}\left(1-e^{j 3 \pi t}\right)-\frac{3}{2 \pi t^{2}}\left(1-e^{-j 3 \pi t}\right)
\end{aligned}
$$
Thus
$$
x(t)=\frac{9}{t} \sin (3 \pi t)-\frac{3}{\pi t^{2}}+\frac{3}{\pi t^{2}} \cos (3 \pi t)
$$"
79,Mathematics,18.404,Theory of Computation,6.1210/18.200,None,Final Exam,P and NP Classes,1,l,0.2083333333,Text,"For each of the following statements, answer True, $\underline{\text { False }}$ or Open question according to our current state of knowledge of complexity theory, as described in class. Do not give reasons for your answers.
$T Q B F$ is NP-hard (i.e., all problems in NP are polynomial-time reducible to $T Q B F$.)",Multiple Choice,"True, PSPACE-complete so also NP-hard.","For each of the following statements, answer True, $\underline{\text { False }}$ or Open question according to our current state of knowledge of complexity theory, as described in class. Do not give reasons for your answers.
$T Q B F$ is NP-complete.","Open, implies PSPACE = NP.","For each of the following statements, answer True, $\underline{\text { False }}$ or Open question according to our current state of knowledge of complexity theory, as described in class. Do not give reasons for your answers.
$T Q B F$ is EXPSPACE-complete.","False, implies PSPACE = EXPSPACE.","For each of the following statements, answer True, $\underline{\text { False }}$ or Open question according to our current state of knowledge of complexity theory, as described in class. Do not give reasons for your answers.
$T Q B F \leq_{\mathrm{L}} P A T H$.","False, implies PSPACE = NL."
281,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Final Exam,Hidden Markov Model,2,a,0.5,Text,"Imagine that $X_{1}$ is a binary random variable with two parent variables $X_{2}$ and $X_{3}$ that are not necessarily binary. Imagine that the first parent $X_{2}$ can assume three different values, and that the second parent $X_{3}$ can assume two values. How many parameters are needed to represent the conditional probability table $P\left(X_{1} \mid X_{2}, X_{3}\right)$?",Numerical,$3 \times 2 \times 2=12$ (or 6),"Let $X, Y$, and $Z$ be discrete random variables whose joint probability distribution is given by the following table:
\begin{tabular}{c|c|c|c}
$\mathrm{X}$ & $\mathrm{Y}$ & $\mathrm{Z}$ & Prob. \\
\hline \hline 0 & 1 & 3 & $0.2$ \\
\hline 1 & $-3$ & 2 & $0.1$ \\
\hline 1 & 2 & 2 & $0.2$ \\
\hline 1 & 4 & 1 & $0.1$ \\
\hline 2 & 0 & 0 & $0.3$ \\
\hline 3 & 1 & $-1$ & $0.1$ \\
\hline
\end{tabular}
(This means, for example, that $p_{X, Y, Z}(1,-3,2)=0.1$.) Remember that you don't need to compute everything out-an answer like ""(0.01+0.02)/(0.03+2)"" is fine.
What is the conditional probability $p_{Y \mid X}(2 \mid 1)$?","$$
p_{Y \mid X}(2 \mid 1)=\frac{P((Y=2) \cap(X=1))}{P(X=1)}=\frac{0.2}{0.1+0.2+0.1}=0.5.
$$","Suppose we have $n^{2}$ independent Bernoulli random variables $Z_{i j}$ for $1 \leq i \leq n, 1 \leq j \leq n$, each taking 1 with probability $1 / 2$ and 0 otherwise. You could view them as being on an $n \times n$ grid. Let $X_{i}$ (resp. $Y_{j}$ ) be the parity of the $i$ th row sum $\sum_{j=1}^{n} Z_{i j}$ (resp. $j$ th column sum $\sum_{i=1}^{n} Z_{i j}$ ). The parity of a number $k$ is 1 if $k$ is odd, and 0 if it is even; it can be written conveniently as $k(\bmod 2)$.
For $n=3$, show that $\operatorname{Pr}\left[X_{1}=a \wedge X_{2}=b \wedge Y_{1}=c\right]=\operatorname{Pr}\left[X_{1}=a\right] \operatorname{Pr}\left[X_{2}=b\right] \operatorname{Pr}\left[Y_{1}=c\right]$ for all $a, b, c \in\{0,1\}$.","We have
$$
\begin{aligned}
\mathbb{P}\left(X_{1}=a \wedge X_{2}=b \wedge Y_{1}=c\right) & =\sum_{\left(\alpha_{1}, \alpha_{2}\right) \in\{0,1\}^{2}}\left(\mathbb{P}\left(Z_{11}=\alpha_{1} \wedge Z_{21}=\alpha_{2}\right)\right. \\
& \left.\times \mathbb{P}\left(X_{1}=a \wedge X_{2}=b \wedge Y_{1}=c \mid Z_{11}=\alpha_{1} \wedge Z_{21}=\alpha_{2}\right)\right) .
\end{aligned}
$$
Since $Z_{11}$ and $Z_{21}$ are independent Bernoulli random variables with probability $1 / 2$, $\mathbb{P}\left(Z_{11}=\alpha_{1} \wedge Z_{21}=\alpha_{2}\right)=1 / 4$ regardless of what $\alpha_{1}$ and $\alpha_{2}$ are. To compute the second term in the product, we rewrite it as
$$
\begin{aligned}
& \left.\mathbb{P}\left(X_{1}=a \wedge X_{2}=b \wedge Y_{1}=c \mid Z_{11}=\alpha_{1} \wedge Z_{21}=\alpha_{2}\right)\right) \\
& =\mathbb{P}\left(Z_{12}+Z_{13} \equiv a-\alpha_{1} \quad \bmod 2 \wedge Z_{22}+Z_{23} \equiv b-\alpha_{2} \quad \bmod 2\right. \\
& \left.\wedge Z_{31} \equiv c-\alpha_{1}-\alpha_{2} \quad \bmod 2 \mid Z_{11}=\alpha_{1} \wedge Z_{21}=\alpha_{2}\right) .
\end{aligned}
$$
The random variables $Z_{12}+Z_{13}, Z_{22}+Z_{23}$, and $Z_{31}$ are Bernoulli random variables with probability $1 / 2$ from the previous subproblem, and the variables $Z_{11}, Z_{12}, Z_{12}+Z_{13}$, $Z_{22}+Z_{23}$, and $Z_{31}$ are jointly independent. Thus,
$$
\left.\mathbb{P}\left(X_{1}=a \wedge X_{2}=b \wedge Y_{1}=c \mid Z_{11}=\alpha_{1} \wedge Z_{21}=\alpha_{2}\right)\right)=\frac{1}{2^{3}} .
$$
Plugging this into our original equation, we gt
$$
\mathbb{P}\left(X_{1}=a \wedge X_{2}=b \wedge Y_{1}=c\right)=\sum_{\left(\alpha_{1}, \alpha_{2}\right) \in\{0,1\}^{2}} \frac{1}{4} \cdot \frac{1}{2^{3}}=\frac{1}{2^{3}} .
$$
Since $X_{1}, X_{2}$, and $Y_{1}$ are Bernoulli random variables with probability $1 / 2$, we see that
$$
\mathbb{P}\left(X_{1}=a \wedge X_{2}=b \wedge Y_{1}=c\right)=\mathbb{P}\left(X_{1}=a\right) \mathbb{P}\left(X_{2}=b\right) \mathbb{P}\left(Y_{1}=c\right)
$$
as desired.","Let's first look at how to go back and forth between Bayes nets and probability tables. Consider the following simple Bayes net, with three variables, $A$, $N$ and $S$. Note that we have only given the values for where the dependent variable is true.
How many rows are there in the probability table over the joint distribution of $A, N$, and $S$?
Enter an integer:",8
103,EECS,6.121,Introduction to Algorithms,"6.100A, 6.1200",6.101,Mini Quiz 7,Johnson's Algorithm,3,nan,0.2222222222,Text,"Asymptotically speaking, Johnson's algorithm is slower than Bellman-Ford.
$\mathrm{a}$ True.
$\mathrm{b}$ False.
$\mathrm{c}$ Depends on the graph.",Multiple Choice,"$\mathrm{c}$ Depends on the graph.
Johnson's algorithm is slower than Bellman-Ford for sparse graphs (for example when $|E|=$ $O(|V|)$ ). For dense graphs (when $|E|=\Omega\left(|V|^{2}\right)$ ), the two algorithms have similar asymptotic complexity.","If a graph has only positive weight edges, to compute All-Pairs-Shortest-Paths using Johnson's algorithm, it is not necessary to run Bellman-Ford prior to running Dijkstra from every node.
$\mathrm{a}$ True.
$\mathrm{b}$ False.
$\mathrm{c}$ Depends on the graph.","$\mathrm{a}$ True.
Bellman-Ford is run to get the potential function and transform the weight edges to positive weight edges without changing shortest paths.","For which graphs is the time of Floyd-Warshall the same as Johnson's Algorithm?
$\mathrm{a}$ For all graphs.
$\mathrm{b}$ For dense graphs, where $|E|=\Omega\left(|V|^{2}\right)$.
$\mathrm{c}$ For sparse graphs where $|E|=O(|V|)$.","$\mathrm{b}$ For dense graphs, where $|E|=\Omega\left(|V|^{2}\right)$.
FW has a runtime of $O\left(|V|^{3}\right)$ which matches Johnson's $O\left(|V|^{2} \log |V|+|V| \cdot|E|\right)$ only when $|E|=\Omega\left(|V|^{2}\right)$.","Which of the following statements are true about Bellman-Ford?
$\mathrm{a}$ Running Bellman-Ford on a DAG takes linear time.
$\mathrm{b}$ Bellman-Ford requires the graph to have no negative-weight cycles.
$\mathrm{c}$ Bellman-Ford returns the correct shortest paths to all vertices, or ""NEGATIVE CYCLE EXISTS"" on graphs with negative weight edges.","$\mathrm{a}$ Incorrect. Even if the graph is a DAG, BF still needs $|V|-1$ iterations, each of which takes $O(|E|+|V|)$ time.
$\mathrm{b}$ Incorrect. Bellman-Ford will detect whether the graph has a non-negative cycle.
$\mathrm{c}$ Correct."
90,EECS,6.122,Design and Analysis of Algorithms,6.121,None,Problem Set 10,Weighted Majority Algorithm,2,a,0.09090909091,Text,"Recall the Weighted Majority algorithm from the lecture. In that algorithm, in a given time step $t$, if the experts make predictions $\pi^{(t)}=\left(\pi_{1}^{(t)}, \ldots, \pi_{n}^{(t)}\right)\left(\right.$ each $\left.\pi_{i}^{(t)} \in\{0,1\}\right)$ and the current weight vector is $\mathbf{w}^{(t)}=\left(w_{1}^{(t)}, \ldots, w_{n}^{(t)}\right)$, the algorithm consolidates the predictions into a hard decision $d^{(t)} \in\{0,1\}$ which is the weighted majority of the expert's predictions. In other words, if the total weight predicting 1 is the dot product $T W_{1}=\pi^{(t)} \cdot w^{(t)}$, and the total weight predicting 0 is $T W_{0}=\sum_{i=1}^{n} w_{i}^{(t)}-T W_{1}$, then $d^{(t)}=1$ if $T W_{1} \geq T W_{0}$ and $d^{(t)}=0$ otherwise.
The Randomized Weighted Majority algorithm consolidates the predictions into a soft decision that is a random variable weighted by the same weight-vector $w^{(t)}$. That is, $d^{(t)}=1$ with probability $T W_{1} /\left(T W_{0}+T W_{1}\right)$, and 0 otherwise.
In this problem, you will show that the expected regret of Randomized Weighted Majority is approximately a factor of 2 better than the regret of Weighted Majority.
Consider a scenario with $n=5$ experts. At some given time steps $t$, let their predictions be $\pi^{(t))}=(1,0,0,1,1)$ and let their weights be $\mathbf{w}^{(t)}=$ $(1 / 2,1 / 4,1 / 8,1 / 16,1 / 32)$. What is the probability that the Randomized Weighted Majority algorithm sets its decision bit $d^{(t)}=0$ ?
A. $1 / 4$
B. $1 / 8$
C. $3 / 8$
D. $12 / 31$
E. $17 / 64$",Multiple Choice,D.,"Recall the Weighted Majority algorithm from the lecture. In that algorithm, in a given time step $t$, if the experts make predictions $\pi^{(t)}=\left(\pi_{1}^{(t)}, \ldots, \pi_{n}^{(t)}\right)\left(\right.$ each $\left.\pi_{i}^{(t)} \in\{0,1\}\right)$ and the current weight vector is $\mathbf{w}^{(t)}=\left(w_{1}^{(t)}, \ldots, w_{n}^{(t)}\right)$, the algorithm consolidates the predictions into a hard decision $d^{(t)} \in\{0,1\}$ which is the weighted majority of the expert's predictions. In other words, if the total weight predicting 1 is the dot product $T W_{1}=\pi^{(t)} \cdot w^{(t)}$, and the total weight predicting 0 is $T W_{0}=\sum_{i=1}^{n} w_{i}^{(t)}-T W_{1}$, then $d^{(t)}=1$ if $T W_{1} \geq T W_{0}$ and $d^{(t)}=0$ otherwise.
The Randomized Weighted Majority algorithm consolidates the predictions into a soft decision that is a random variable weighted by the same weight-vector $w^{(t)}$. That is, $d^{(t)}=1$ with probability $T W_{1} /\left(T W_{0}+T W_{1}\right)$, and 0 otherwise.
In this problem, you will show that the expected regret of Randomized Weighted Majority is approximately a factor of 2 better than the regret of Weighted Majority.
Let the random variable $m^{(T)}$ denote the total number of mistakes made by Randomized Weighted Majority algorithm until time $T$, and let $m_{*}^{(T)}$ be the fewest number of mistakes made by any expert until the same time $T$. Show that for $\epsilon \in[0,0.5]$ :
$$
\mathbb{E}\left[m^{(T)}\right] \leq(1+\epsilon) m_{*}^{(T)}+\frac{\ln n}{\epsilon}
$$
Hint: The approximation $\ln (1+x) \leq x$ may come in handy.","Let $\beta=(1-\epsilon)$. Furthermore, let $P^{(t)}$ denote the probability that a mistake is made by the algorithm in time step $t$, and let $W^{(t)}=\sum_{i=1}^{n} w_{i}^{(t)}$ be the total weight at time $t$. We know that the total weight is lower bounded by the individual weight of any expert, and we know that that the individual weight of the expert that makes the most mistakes by time $T$ is $\beta^{m_{*}^{(T)}}$. So, $W^{(t)} \geq \beta^{m_{*}^{(T)}}$.
Furthermore, the initial total weight $W^{(1)}=n$, and in each time step $W^{(t+1)}=$ $\left(1-(1-\beta) P^{(t)}\right) W^{(t)}$, since a mistake is made with probability $P^{(t)}$ and the weights of the mistaken experts are multiplied by $\beta$.
So, we get
$$
\begin{aligned}
\beta^{m_{*}^{(T)}} & \leq \mathbb{E}\left[m^{(T)}\right] \\
&=n \cdot \prod_{t=1}^{T-1}\left(1-(1-\beta) P^{(t)}\right)
\end{aligned}
$$
Taking logarithms on either side, we get
$$
\begin{aligned}
m_{*}^{(T)} \ln \beta & \leq \ln n+\sum_{t=1}^{T-1} \ln \left(1-(1-\beta) P^{(t)}\right) \\
&<\ln n+(\beta-1) \sum_{t=1}^{T-1} P^{(t)} \\
&=\ln n+(\beta-1) \mathbb{E}\left[m^{(T)}\right]
\end{aligned}
$$
Consequently
$$
\begin{aligned}
\mathbb{E}\left[m^{(T)}\right] & \leq \frac{1}{1-\beta}\left(m_{*}^{(T)} \ln \frac{1}{\beta}+\ln n\right) \\
&=\frac{1}{\epsilon}\left(m_{*}^{(T)} \ln \frac{1}{1-\epsilon}+\ln n\right) \\
& \leq(1+\epsilon) m_{*}^{(T)}+\frac{\ln n}{\epsilon}
\end{aligned}
$$
In the last inequality, we use the Taylor series bound of $\ln (1+x)$. ","Let us begin by recalling the randomized weighted majority (RWM) algorithm with $n$ experts. At the beginning of each time step $t \in\{1, \ldots, T\}$, the $n$ experts have weights $w_{1}^{(t)}, \ldots, w_{n}^{(t)}$. The algorithm works in three phases:
• Choice: Expert $i$ is picked with probability $p_{i}^{(t)}$ which is proportional to $w_{i}^{(t)}$.
• Revelation: The world reveals the binary cost $m_{i}^{(t)} \in\{0,1\}$ for each expert. The expected cost of the algorithm at time $t$ is $\sum_{i=1}^{n} p_{i}^{(t)} m_{i}^{(t)}$.
• Update: The weights are updated by a multiplicative rule that depends on $\epsilon$, a parameter of the algorithm.
We saw that the regret of this algorithm, namely, the difference between the total expected cost of the algorithm over $T$ time steps and the total cost of the best expert $i^{*}$ (in hindsight) is
$$
\operatorname{Regret}(T):=\sum_{t=1}^{T} \sum_{i=1}^{n} p_{i}^{(t)} m_{i}^{(t)}-\sum_{t=1}^{T} m_{i^{*}}^{(t)} \leq \epsilon T+\frac{\ln n}{\epsilon}
$$
Show that with probability at least a positive constant (over the random costs), there exists an expert who incurs a total cost of at most $\frac{T}{2}-\Omega(\sqrt{T \ln n})$ over the $T$ time steps, for large enough $T$. [Hint. You can use the following fact: in a sequence of $T$ tosses of a fair coin, the probability that at most $\frac{T}{2}-s \sqrt{T}$ heads appear is at least $\frac{c e^{-2 s^{2}}}{s}$ for some constant $c>0$. This holds as long as $s=o(\sqrt{T})$ is a small enough integer.]","For each expert $i$, and each time $t$, the probability that the cost is 1 is $1 / 2$. Furthermore, these probabilities are independent for all $i$ and $t$. Thus, from the hint, we know that the probability that expert $i$ incurs a total cost of at most $\frac{T}{2}-\sqrt{T \ln n}$ is at least $c \cdot e^{-2 \ln n} / \ln n=c / n^{2} \ln n \geq 1 / n$ for large enough $n$.
Since all events are independent, the probability that all experts have cost more than $\frac{T}{2}-$ $\sqrt{T \ln n}$ is at most $\left(1-\frac{1}{n}\right)^{n} \leq \frac{1}{e}$ and consequently, with probability at least $1-\frac{1}{e} \geq \frac{1}{2}$, at least one expert has cost less than $\frac{T}{2}-\sqrt{T \ln n}$. This finishes the proof.
For completeness, let's prove the statement in the hint (although the students do not have to do this). The probability that in a sequence of $n$ tosses of a fair coin, at most $k$ heads appear is $\frac{1}{2^{n}} \cdot \sum_{i=0}^{k}\left(\begin{array}{c}n \\ i\end{array}\right)$. We need the following facts, the first one about the sum of binomial coefficients: for any $n$ and $k \leq \frac{n}{2}-\sqrt{n}$,
$$
\sum_{i=1}^{k}\left(\begin{array}{l}
n \\
i
\end{array}\right)=\Theta\left(\frac{n}{n-2 k} \cdot\left(\begin{array}{l}
n \\
k
\end{array}\right)\right)
$$
Using Stirling's approximation, we have
$$
\left(\begin{array}{l}
n \\
k
\end{array}\right)=\Theta\left(\sqrt{\frac{n}{k(n-k)}} \cdot \frac{n^{n}}{k^{k}(n-k)^{n-k}}\right)
$$
Substituting $k=n / 2-s \sqrt{n}$ into equation 3, we get for some constants $c^{\prime}, c^{\prime \prime}>0$,
$$
\begin{aligned}
\left(\begin{array}{l}
n \\
k
\end{array}\right) & \geq \frac{c^{\prime}}{\sqrt{n}} \cdot \frac{n^{n}}{(n / 2-s \sqrt{n})^{n / 2-s \sqrt{n}} \cdot(n / 2+s \sqrt{n})^{n / 2+s \sqrt{n}}} \\
& \geq \frac{c^{\prime}}{\sqrt{n}} \cdot \frac{n^{n}}{\left(n^{2} / 4-s^{2} n\right)^{n / 2}} \cdot\left(\frac{n / 2-s \sqrt{n}}{n / 2+s \sqrt{n}}\right)^{s \sqrt{n}} \\
& \geq \frac{c^{\prime}}{\sqrt{n}} \cdot 2^{n} \cdot\left(1-\frac{2 s}{\sqrt{n}}\right)^{s \sqrt{n}} \\
& \geq \frac{c^{\prime \prime}}{\sqrt{n}} \cdot 2^{n} \cdot e^{-2 s^{2}}
\end{aligned}
$$
where the last inequality holds for large enough $n$. Combining with equation 2 , the required probability is
$$
c \cdot e^{-2 s^{2} / s}
$$
for some constant $c>0$.","Let us begin by recalling the randomized weighted majority (RWM) algorithm with $n$ experts. At the beginning of each time step $t \in\{1, \ldots, T\}$, the $n$ experts have weights $w_{1}^{(t)}, \ldots, w_{n}^{(t)}$. The algorithm works in three phases:
• Choice: Expert $i$ is picked with probability $p_{i}^{(t)}$ which is proportional to $w_{i}^{(t)}$.
• Revelation: The world reveals the binary cost $m_{i}^{(t)} \in\{0,1\}$ for each expert. The expected cost of the algorithm at time $t$ is $\sum_{i=1}^{n} p_{i}^{(t)} m_{i}^{(t)}$.
• Update: The weights are updated by a multiplicative rule that depends on $\epsilon$, a parameter of the algorithm.
We saw that the regret of this algorithm, namely, the difference between the total expected cost of the algorithm over $T$ time steps and the total cost of the best expert $i^{*}$ (in hindsight) is
$$
\operatorname{Regret}(T):=\sum_{t=1}^{T} \sum_{i=1}^{n} p_{i}^{(t)} m_{i}^{(t)}-\sum_{t=1}^{T} m_{i^{*}}^{(t)} \leq \epsilon T+\frac{\ln n}{\epsilon}
$$
In this part and the next, you will try to determine if there could possibly be an algorithm that performs better than RWM. Imagine that there is an algorithm that picks expert $i$ at time $t$ with probability $q_{i}^{(t)}$, computed as some complex clever function of whatever it has seen so far. Imagine that the costs $m_{i}^{(t)}$ for each expert $i$ and each time $t$ are uniform random numbers from $\{0,1\}$. What is the total expected cost of the algorithm over all $T$ time steps? Your answer should be a function of $T$ alone.","The expected cost at each step is
$$
\mathbb{E}\left[\sum_{i=1}^{n} q_{i}^{(t)} m_{i}^{(t)}\right]=\sum_{i=1}^{n} q_{i}^{(t)} \mathbb{E}\left[m_{i}^{(t)}\right]=\frac{1}{2} \cdot \sum_{i=1}^{n} q_{i}^{(t)}=\frac{1}{2}
$$
where the expectation is over $m_{i}^{(t)}$ randomly chosen from $\{0,1\}$. So, the total expected cost is $T / 2$. "
25,Mathematics,18.6,Probability and Random Variables,18.02,None,Problem Set 3,Expected Value,2,a,0.25,Text,"Suppose that two teams play a series of games that ends when one of them has won $i$ games. Suppose that each game played is, independently, won by team $A$ with probability $p$. Find the expected number of games that are played when $i = 2$. Also show that this number is maximized when $p = \frac{1}{2}$.",Open,"Let $A$ denote the first team, $B$ denote the second team, and the random variable $X$ denote the number of games played.
$p_X(2) = P\{X = 2\} = P(AA) + P(BB) = p^2 + (1-p)^2$.
$p_X(3) = P\{X = 3\} = P(ABA) + P(BAA) + P(ABB) + P(BAB) = 2p^2(1-p) + 2p(1-p)^2 = 2p(1-p)$.
$E[X] = 2p_X(2) + 3p_X(3) = 2 \cdot [p^2 + (1-p)^2] + 3 \cdot 2p(1-p) = 2p(1-p) + 2$.
Since $\frac{\partial}{\partial p}E[X] = 2 - 4p = 0$ and $\frac{\partial}{\partial p^{2}}E[X] = -4 < 0$ when $p = \frac{1}{2}$, the expected number of games is maximized when $p = \frac{1}{2}$.","Suppose that two teams play a series of games that ends when one of them has won $i$ games. Suppose that each game played is, independently, won by team $A$ with probability $p$. Find the expected number of games that are played when $i = 3$. Also show that this number is maximized when $p = \frac{1}{2}$.","Let $A$ denote the first team, $B$ denote the second team, and the random variable $X$ denote the number of games played.
$p_X(3) = P\{X = 3\} = P(AAA) + P(BBB) = p^3 + (1-p)^3$.
$p_X(4) = P\{X = 4\} = P(BAAA) + P(ABAA) + P(AABA) + P(ABBB) + P(BABB) + P(BBAB) = 3p^3(1-p) + 3p(1-p)^3 = 3p(1-p)[p^2+(1-p)^2]$.
$p_X(5) = P\{X = 5\} = P(AABBA) + P(ABABA) + P(ABBAA) + P(BBAAA) + P(BABAA) + P(BAABA) + P(BBAAB) + P(BABAB) + P(BAABB) + P(AABBB) + P(ABABB) + P(ABBAB) = 6p^3(1-p)^2 + 6p^2(1-p)^3 = 6p^2(1-p)^2$.
$E[X] = 3p_X(3) + 4p_X(4) + 5p_X(5) = 3 \cdot [p^3 + (1-p)^3] + 4 \cdot 3p(1-p)[p^2+(1-p)^2] + 5 \cdot 6p^2(1-p)^2= 6p^2(1-p)^2 + 3p(1-p) + 3$.
Since $\frac{\partial}{\partial p}E[X] = 24p^3 - 36p^2 + 6p + 3 = 0$ and $\frac{\partial}{\partial p^{2}}E[X] = 72p^2 - 72p + 6 = -12 < 0$ when $p = \frac{1}{2}$, the expected number of games is maximized when $p = \frac{1}{2}$.","Consider a fair spinner that gives a number between 0 and 2. Player One spins two times and gets $x$ and $y$. Player Two spins once and gets $z$. Player Two wins if $z$ is bigger than both $x$ and $y$. Otherwise, Player One wins. The goal of the problem is to find the probability that Player Two wins.
Find the probability that Player Two wins the game.","The probability that Player Two wins is
$$
\frac{\operatorname{Vol}(S)}{\operatorname{Vol}(\text { Cube })}=\frac{8 / 3}{8}=\frac{1}{3} \text {. }
$$
Note that $z$ being the maximum of $\{x, y, z\}$ has the same probability as $x$ (or $y$ ) being the maximum of $\{x, y, z\}$. The probability of at least two of $\{x, y, z\}$ attain the maximum of $\{x, y, z\}$ is 0 . Therefore, the event of $z$ being the maximum has probability $1 / 3$. ","Consider a fair spinner that gives a number between 0 and 2. Player One spins two times and gets $x$ and $y$. Player Two spins once and gets $z$. Player Two wins if $z$ is bigger than both $x$ and $y$. Otherwise, Player One wins. The goal of the problem is to find the probability that Player Two wins.
Instead of $z=1$, consider the slice with an arbitrary value of $z$. Draw the slice and find its area as a function of $z$.",The slice of $S$ with the plane $z$ (for $0 \leq z \leq 2$ ) is given by $\{x \leq z$ and $y \leq z\}$ which is the shaded area below. The area equals $z^{2}$.
78,EECS,6.122,Design and Analysis of Algorithms,6.121,None,Problem Set 8,Approximation Algorithms,2,e,0.1818181818,Text,"Alice has been working to organize a Halloween party for the creatures of Halloween City. Halloween is the only night the creatures of Halloween City can go unnoticed in the human world, so they decide to throw the party in there. However, to get everyone to the human world, Alice has to make sure that everyone can get to a portal and cross over. She only has enough time and power to open $k$ portals total. In order to decide where to put the portals, she gathers a table $D$ that contains the distance between the houses of each pair of creatures. It is guaranteed that the distances between houses are symmetric (i.e., $D[A, B]=D[B, A]$ ) and satisfy the triangle inequality (i.e., $D[A, C] \leq$ $D[A, B]+D[B, C])$. Alice wants to partition the creatures into $k$ clusters in a way that minimizes the maximum diameter of the cluster, where the diameter of a cluster is defined as the largest distance of any two houses in the cluster. She will then put a portal in each cluster so that all creatures living in that cluster can use it.
Based on your algorithm for part (d), devise a polynomial time 2-approximation algorithm to find the optimal clusters for the case where the optimal diameter is not known.
Hint: Argue that the optimum diameter is one of the $\left(\begin{array}{l}n \\ 2\end{array}\right)$ pairwise distances and use this fact to devise your algorithm.",Open,"As per the hint, we first argue that the diameter $d$ in the optimal solution is one of the $\left(\begin{array}{l}n \\ 2\end{array}\right)$ pairwise distances. This is clear from the definition as the diameter of a cluster is defined as maximum distance between any two points in it.
The 2-approximation algorithm is as follows. We find all pairwise distances and sort them in increasing value. This takes $O\left(n^2 \log n\right)$ time. In increasing order, we try the algorithm from part (a) and check whether it yields $k$ or fewer clusters. If it does, we stop. Otherwise, we move to the next candidate $d$.
It is not hard to argue that this is a 2-approximation algorithm. Assume that the optimal diameter is $d$. Then the algorithm will stop when trying distance $d$, or before. In any case, the algorithm will output at most $k$ clusters with diameter at most $2 d$.","Alice has been working to organize a Halloween party for the creatures of Halloween City. Halloween is the only night the creatures of Halloween City can go unnoticed in the human world, so they decide to throw the party in there. However, to get everyone to the human world, Alice has to make sure that everyone can get to a portal and cross over. She only has enough time and power to open $k$ portals total. In order to decide where to put the portals, she gathers a table $D$ that contains the distance between the houses of each pair of creatures. It is guaranteed that the distances between houses are symmetric (i.e., $D[A, B]=D[B, A]$ ) and satisfy the triangle inequality (i.e., $D[A, C] \leq$ $D[A, B]+D[B, C])$. Alice wants to partition the creatures into $k$ clusters in a way that minimizes the maximum diameter of the cluster, where the diameter of a cluster is defined as the largest distance of any two houses in the cluster. She will then put a portal in each cluster so that all creatures living in that cluster can use it.
At first, Alice was devastated to learn that HALLOWEEN is NPHard. However, she now realized that she might still be able to design an approximation algorithm! Devise a polynomial time 2-approximation algorithm to find the optimal clusters for a given $k$ and $D$, assuming that the optimal diameter, $d$, is known. In other words, this algorithm must partition the creatures into at most $k$ clusters that all have diameter at most $2 d$. Remember to analyze the runtime of your algorithm.
Hint: Consider any point and all points within radius $d$ of it.","As per the hint, we form clusters by picking points and all points within distance $d$. The 2-approximation algorithm follows from this idea. We pick an arbitrary point and form a cluster with all the points within distance $d$ of it. We repeat picking a yet uncovered point until covering all points.
We first show that the algorithm yields at most $k$ clusters. The main observation is that all of the ""centers"" picked in the different iterations are at distance greater than $d$ from each other. Therefore, not two of them can be in the same cluster in the optimal solution (as the clusters in the optimal solution have diameter $d$ ). As a result, we cannot have more than $k$ iterations.
Second, we prove that the algorithm gives a solution where each cluster has diameter at most $2 d$. But this is trivial as all points in each cluster are within distance $d$ of the center and therefore within distance $2 d$ of each other. The optimal diameter is $d$, so the approximation factor is 2. This algorithm runs in polynomial time-we can precompute pairwise distances between points to determine what points are within a distance $d$ of a cluster center.","Alice has been working to organize a Halloween party for the creatures of Halloween City. Halloween is the only night the creatures of Halloween City can go unnoticed in the human world, so they decide to throw the party in there. However, to get everyone to the human world, Alice has to make sure that everyone can get to a portal and cross over. She only has enough time and power to open $k$ portals total. In order to decide where to put the portals, she gathers a table $D$ that contains the distance between the houses of each pair of creatures. It is guaranteed that the distances between houses are symmetric (i.e., $D[A, B]=D[B, A]$ ) and satisfy the triangle inequality (i.e., $D[A, C] \leq$ $D[A, B]+D[B, C])$. Alice wants to partition the creatures into $k$ clusters in a way that minimizes the maximum diameter of the cluster, where the diameter of a cluster is defined as the largest distance of any two houses in the cluster. She will then put a portal in each cluster so that all creatures living in that cluster can use it.
Consider the decision problem for Alice's task:
HALLOWEEN $=\{\langle D, k, d\rangle \mid$ For the table of distances $D$, there is a way to partition with at most $k$ clusters that all have diameters at most $d\}$
Alice wants to show that HALLOWEEN is NP-Hard. Her friend suggests it may be helpful to reduce from the following decision problem that they claim is NP-Hard:
3-CLIQUE $=\{\langle G\rangle \mid$ For the graph $G$, there is a way to partition the graph into at most three cliques
Show $3-C L I Q U E \leq_p$ HALLOWEEN.","Our reduction from 3-CLIQUE to HALLOWEEN will be to take $G$ and create a $D$ where $D[i, i]=0$ for all $i$ and $D[i, j]=1$ if $(i, j) \in G$ and $D[i, j]=2$ otherwise. Now, we consider the problem HALLOWEEN with $D, k=3$, and $d=1$. Clearly, this reduction takes polynomial-time to run.
To show correctness, we first show that if the 3-CLIQUE instance is YES then the HALLOWEEN instance is YES. For each clique in the solution for the 3 CLIQUE instance, we will consider this a cluster in the HALLOWEEN instance. There are at most 3 clusters, and for every cluster the diameter is at most 1 because there is an edge between all the corresponding nodes in $G$ for any pair in a cluster, and thus their distance is 1 in the HALLOWEEN instance. Next, we show if the HALLOWEEN instance is YES then the 3-CLIQUE instance is YES. For each cluster in the solution to HALLOWEEN, consider this a clique in the instance of 3-CLIQUE. Clearly there are at most 3 resulting cliques because $k=3$. Moreover, all such cliques are valid cliques, because the distances were all at most 1 in the HALLOWEEN instance, meaning each pair of the nodes in the cluster had an edge between them in $G$.
As such, we have a complete reduction.","Alice has been working to organize a Halloween party for the creatures of Halloween City. Halloween is the only night the creatures of Halloween City can go unnoticed in the human world, so they decide to throw the party in there. However, to get everyone to the human world, Alice has to make sure that everyone can get to a portal and cross over. She only has enough time and power to open $k$ portals total. In order to decide where to put the portals, she gathers a table $D$ that contains the distance between the houses of each pair of creatures. It is guaranteed that the distances between houses are symmetric (i.e., $D[A, B]=D[B, A]$ ) and satisfy the triangle inequality (i.e., $D[A, C] \leq$ $D[A, B]+D[B, C])$. Alice wants to partition the creatures into $k$ clusters in a way that minimizes the maximum diameter of the cluster, where the diameter of a cluster is defined as the largest distance of any two houses in the cluster. She will then put a portal in each cluster so that all creatures living in that cluster can use it.
Alice knows the following distance table $D$ :
\begin{tabular}{ r|c|c|c|c|c|}
\multicolumn{1}{r}{}
 &  \multicolumn{1}{c}{Bob}
  &  \multicolumn{1}{c}{Carol} 
    &  \multicolumn{1}{c}{David}
      &  \multicolumn{1}{c}{Eve} 
 & \multicolumn{1}{c}{Frank} \\
\cline{2-6}
Bob & 0 & 2 & 6 & 3 & 6 \\
\cline{2-6}
Carol & 2 & 0 & 4 & 1 & 5\\
\cline{2-6}
David & 6 & 4 & 0 & 4 & 3 \\
\cline{2-6}
Eve & 3 & 1 & 4 & 0 & 5 \\
\cline{2-6}
Frank & 6 & 5 & 3 & 5 & 0 \\
\cline{2-6}
\end{tabular}
She only has time to make 2 portals. Which of the following pairs of clusters minimizes the maximum diameter?
A. (Bob, Carol, David, Frank) and (Eve)
B. (Bob, Carol, Eve) and (David, Frank)
C. () and (Bob, Carol, David, Eve, Frank)
D. (Bob) and (Carol, David, Eve, Frank)
E. (Bob, David, Frank) and (Carol, Eve)",B.
43,Mathematics,18.100B,Real Analysis,18.02,None,Problem Set 9,Continuity,1,nan,0.7142857143,Text,"Prove that $f$ is continuous at $x$ if and only if it satisfies the following property: for all $\epsilon>0$, there is a $\delta>0$ such that for all $y, z$ with $|x-y|<\delta$ and $|x-z|<\delta$, we have $|f(y)-f(z)|<\epsilon$. This is Lemma $6.12$ in the class notes (if you have the latest version, and I did not renumber it again... I did not prove exactly that statement is in class, but we discussed something equivalent); you can only use results that come before that statement in the notes.",Open,"Suppose that $f$ is continuous at $x$. By definition, given $\varepsilon>0$, there exists $\delta>0$ such that whenever $d(x, y)<\delta, d(f(x), f(y))<\varepsilon$. Let $\varepsilon>0$ be given. Let $\delta>0$ be chosen for $\varepsilon / 2$ in the definition of continuity. Then
$$
d(f(y), f(z)) \leq d(f(y), f(x))+d(f(z), f(x)) \leq \varepsilon.
$$
Conversely, taking $z=x$ in Lemma $6.12$, we recover the definition of continuity at $x$.","Prove the following: let $f:[a, b] \rightarrow \mathbb{R}$ be a continuous function. Then the set $\{y=f(x): x \in[a, b]\}$ is an interval $[c, d]$. This is Corollary $6.27$ in the class notes (if you have the latest version, and unless I renumbered them again in the meantime); you can only use results that come before that in your proof.","By Corollary $6.26, f$ has an absolute minimum $c=f\left(a^{\prime}\right)$ and and absolute maximum $d=f\left(b^{\prime}\right)$, with $a^{\prime}, b^{\prime} \in[a, b]$. Without loss of generality, $a^{\prime} \leq b^{\prime}$ (otherwise we can apply the following argument to $-f)$.
Let $y \in[c, d]$. Applying Theorem $6.24$ to $g(x)=f(x)-y$ on the interval $\left[a^{\prime}, b^{\prime}\right]$, there exists $z \in\left[a^{\prime}, b^{\prime}\right] \subset[a, b]$ such that $g(z)=0$, i.e. $f(z)=y$. This shows that $f([a, b]) \supset[c, d]$, so we must have $f([a, b])=[c, d]$.","If $f:[0,2] \longrightarrow \mathbb{R}$ is a continuous function, state a theorem which shows that $F(x)=\int_{0}^{x} f(s) d s$ is differentiable on $[0,2]$ (or prove it directly) and show that there exists $c \in(0,2)$ such that $\int_{0}^{2} f(x) d x=2 f(c)$.","The Fundamental Theorem of Calculus states that the integral of a Riemann integrable function $F(x)=\int_{0}^{x} f(s) d s$ is differentiable at each point of continuity of $f$ with derivative there $F^{\prime}(x)=f(x)$. Since $f$ is continuous everywhere on $[0,2], F$ is differentiable on [0,2] and by the Mean Value Theorem there exists $c \in(0,2)$ such that
$$
F(2)-F(0)=\int_{0}^{2} f(s) d s=f(c)(2-0)=2 f(c).
$$","Let $f: \mathbb{R} \longrightarrow \mathbb{R}$ be twice differentiable and suppose that 0 is a local minimum of $f$, i.e. for some $\epsilon>0 f(x) \geq f(0)$ for all $x \in(-\epsilon, \epsilon)$. Show that if $f^{\prime \prime}(0)>0$ then 0 is a strict local minimum in the sense that there exists $\epsilon>0$ such that $f(x)>f(0)$ for $0 \neq x \in(-\epsilon, \epsilon)$.","By the definition of (second) derivative, $f^{\prime \prime}(0)$ is the limit as $x \rightarrow 0$ of the difference quotient $\left(f^{\prime}(x)-f^{\prime}(0)\right) / x$. Since 0 is given to be an interior local minimum of $f, f^{\prime}(0)=0$ by a Theorem stating precisely this in Rudin's book. Thus if $f^{\prime \prime}(0)=>0$ then $f^{\prime}(x) / x>0$ in $(-\delta, \delta) \backslash\{0\}$ for some $\delta>0$. Now, applying the mean value theorem if $x \in(-\delta, 0)$,
$$
f(0)-f(x)=x f^{\prime}(c)<0
$$
and similarly, if $x \in(0, \delta)$ then $f(x)-f(0)=x f^{\prime}(c)>0$ for some $c \in(0, \delta)$. Finally then $f(x)>f(0)$ so $f$ has a strict local minimum at 0.
There are probably other ways to see this."
150,Mathematics,18.03,Differential Equations,None,18.02,Final Exam,Linear Algebra,6,a,2.168674699,Text,"Consider the matrix
$$
A=\left(\begin{array}{cccc}
1 & 2 & 4 & 5 \\
2 & 4 & 9 & 16 \\
1 & 2 & 3 & -1
\end{array}\right).
$$
Find a basis for $\operatorname{Ker}(A)=\operatorname{NullSpace}(A)$.",Expression,"We put $A$ is RREF. We start by removing twice the first row from the second, and removing the first row to the third:
$$
\left(\begin{array}{cccc}
1 & 2 & 4 & 5 \\
0 & 0 & 1 & 6 \\
0 & 0 & -1 & -6
\end{array}\right)
$$
Then, we add the second row to the third:
$$
\left(\begin{array}{llll}
1 & 2 & 4 & 5 \\
0 & 0 & 1 & 6 \\
0 & 0 & 0 & 0
\end{array}\right) .
$$
Finally, we remove four times the second row from the first:
$$
\left(\begin{array}{cccc}
1 & 2 & 0 & -19 \\
0 & 0 & 1 & 6 \\
0 & 0 & 0 & 0
\end{array}\right) \text {. }
$$
Consequently, a vector $\left(\begin{array}{l}x_{1} \\ x_{2} \\ x_{3} \\ x_{4}\end{array}\right)$ in the kernel of $A$ must satisfy $x_{1}+2 x_{2}-19 x_{4}=0$ and $x_{3}+6 x_{4}=0$. Consequently,
$$
\left(\begin{array}{c}
-2 \\
1 \\
0 \\
0
\end{array}\right) \text { and }\left(\begin{array}{c}
19 \\
0 \\
-6 \\
1
\end{array}\right)
$$
form a basis of the null space of $A$ (remember that the dimension of the null space is the number of non-pivot columns in the RREF for $A$ ).","Consider the $3 \times 3$ matrix
$$
A=\left(\begin{array}{ccc}
1 & 0 & -1 \\
-1 & 1 & 2 \\
0 & 1 & 1
\end{array}\right).
$$
Find a basis for $\operatorname{Ker}(A)=N S(A)$.","We need to row reduce $A$.
$$
\left(\begin{array}{ccc}
1 & 0 & -1 \\
-1 & 1 & 2 \\
0 & 1 & 1
\end{array}\right)_{R_{2} \rightarrow R_{2}+R_{1}} \rightarrow\left(\begin{array}{ccc}
1 & 0 & -1 \\
0 & 1 & 1 \\
0 & 1 & 1
\end{array}\right)_{R_{3} \rightarrow R_{3}-R_{2}} \rightarrow\left(\begin{array}{ccc}
1 & 0 & -1 \\
0 & 1 & 1 \\
0 & 0 & 0
\end{array}\right)
$$
We can check the row reduction by verifying that the third column is indeed the second column minus the first column. A general vector in $\operatorname{Ker}(A)$ satisfies
$$
\left(\begin{array}{ccc}
1 & 0 & -1 \\
0 & 1 & 1 \\
0 & 0 & 0
\end{array}\right)\left(\begin{array}{l}
x_{1} \\
x_{2} \\
x_{3}
\end{array}\right)=\left(\begin{array}{l}
0 \\
0 \\
0
\end{array}\right)
$$
As we have two linearly independent rows and three variables, we need one parameter, and the kernel is thus a one-dimensional vector space. Setting $x_{3}=t$, find
$$
\left(\begin{array}{l}
x_{1} \\
x_{2} \\
x_{3}
\end{array}\right)=t\left(\begin{array}{c}
1 \\
-1 \\
1
\end{array}\right)
$$
and so the kernel is spanned by $\left\{\left(\begin{array}{c}1 \\ -1 \\ 1\end{array}\right)\right\}$.","Consider the matrix
$$
A=\left(\begin{array}{cccc}
1 & 2 & 4 & 5 \\
2 & 4 & 9 & 16 \\
1 & 2 & 3 & -1
\end{array}\right).
$$
Find a basis for $\operatorname{Im}(A)=\operatorname{ColumnSpace}(A)$.","A basis for the column space for $A$ is given by the columns of $A$ that correspond to pivot columns in the RREF for $A$. Here, we see that
$$
\left(\begin{array}{l}
1 \\
2 \\
1
\end{array}\right) \text { and }\left(\begin{array}{l}
4 \\
9 \\
3
\end{array}\right)
$$
is a basis for the range of $A$. ","Consider the following matrix.
$$
A=\left[\begin{array}{ccccc}
0 & 2 & 4 & 5 & 6 \\
0 & 1 & 2 & 5 & 8 \\
0 & 0 & 0 & -3 & -6
\end{array}\right].
$$
Give a basis for $C(A)$, and also state the dimension of $C(A)$.","We have
$$
C(A)=\operatorname{span}\left\{\left[\begin{array}{l}
2 \\
1 \\
0
\end{array}\right],\left[\begin{array}{l}
5 \\
0 \\
3
\end{array}\right]\right\}
$$
(other bases are of course possible). This subspace has dimension 2."
31,Mathematics,18.701,Algebra I,18.100B,None,Problem Set 4,The Matrix of a Linear Transformation,3,nan,0.5,Text,"Let $A$ be an $m \times n$ matrix of $\operatorname{rank} r$, let $I$ be a set of $r$ row indices such that the corresponding rows of $A$ are independent, and let $J$ be a set of $r$ column indices such that the corresponding columns of $A$ are independent. Let $M$ denote the $r \times r$ submatrix of $A$ obtained by taking rows from $I$ and columns from $J$. Prove that $M$ is invertible.",Open,Let's permute rows and columns to make $M$ into the upper left $r \times r$ submatrix of $A$. We can make row operations using the $r$ rows at the top to clear out the rows with indices $>r$. The $r$ rows of $A$ at the top and the $r$ columns on the left of $A$ remain independent. Then we use column operations to clear out the columns with indices $>r$. etc...,"Let $A$ be an $n \times n$ matrix with integer entries $a_{i j}$. Prove that $A$ is invertible, and that its inverse $A^{-1}$ has integer entries, if and only if $\operatorname{det} A=\pm 1$.","The proofs of the two directions are different.
The determinant of an integer matrix is an integer. If $A$ has an integer inverse, the formula $(\operatorname{det} A)\left(\operatorname{det} A^{-1}\right)=\operatorname{det}\left(A A^{-1}\right)=\operatorname{det} I=1$ shows that $\operatorname{det} A$ divides 1 , and therefore is equal to $\pm 1$.
To show that an integer matrix with determinant 1 has an integer inverse, the simplest thing is to use the formula for the inverse in terms of the cofactor matrix. The cofactors will be integers. Another way would be to reduce $A$ to the identity using invertible integer row operations.",Let $M$ be a square matrix and suppose that none of the rows or columns are the zero vector. Furthermore suppose no row or column is a scalar multiple of another. Then $M$ is invertible.,"False. Consider for example
$$
\left[\begin{array}{lll}
1 & 0 & 1 \\
0 & 1 & 1 \\
1 & 1 & 2
\end{array}\right]
$$
We can check that none of the rows or columns are the zero vector. Moreover no row or column is a scalar multiple of another. And yet the rank of the matrix is at most two, because we the third column is the sum of the first and second columns.",Let $A$ be an $m \times n$ matrix and let $A^{+}$be its pseudoinverse. Then $N\left(A^{+}\right)=C(A)^{\perp}$.,"True. Suppose $A$ has rank $r$ and left singular vectors $u_{1}, \ldots, u_{n}$. Recall that $u_{1}, \ldots, u_{r}$ is a basis for $C(A)$. Thus $u_{r+1}, \ldots, u_{n}$ is a basis for $C(A)^{\perp}$. Also $u_{1}, \ldots, u_{n}$ are the right singular vectors of $A^{+}$and since its rank is also $r$ we have that $u_{r+1}, \ldots, u_{n}$ is a basis for $N\left(A^{+}\right)$as desired. "
64,Mathematics,18.100B,Real Analysis,18.02,None,Final Exam,Convergence,9,nan,3,Text,"If $a_{n}>0, n \in \mathbb{N}$, is a sequence of real numbers such that the sequence $b_{N}=$ $\sum_{n=1}^{N} a_{n}$ is a bounded, show that $\sum_{n} a_{n}^{\frac{1}{2}} a_{n+1}^{\frac{1}{2}}$ converges.",Open,"Since $2 a_{n} a_{n+1} \leq a_{n}^{2}+a_{n+1}^{2}$ taking square-roots shows that the increasins sequence $b_{N}$ is bounded above by a multiple of the limit if the series, so is itself convergent. Hence the series converges.","Take a sequence $\left(x_{n}\right)$ with the following property: it has a subsequence which converges to 1 ; a subsequence which converges to $1 / 2$; and so on ... (a subsequence which converges to $1 / k$ for any natural number $k)$. Show that then, the same $\left(x_{n}\right)$ also must have a subsequence which converges to 0.","The plan is to use Problem 1b. Let $\varepsilon>0, N \in \mathbb{N}$ be given. Let $M \in \mathbb{N}$ be such that $M>\frac{2}{\varepsilon}$. By Problem 1b, it is enough to exhibit $n \geq N$ such that $\left|x_{n}\right|<\varepsilon$. By Problem 1b again, there exists $n \geq N$ such that $\left|x_{n}-\frac{1}{M}\right|<\frac{\varepsilon}{2}$. But for such $x_{n}$,
$$
-\varepsilon<\frac{1}{M}-\frac{\varepsilon}{2}<x_{n}<\frac{\varepsilon}{2}+\frac{1}{M}<\varepsilon,
$$
i.e. $\left|x_{n}\right|<\varepsilon$ as desired.","Suppose that $\sum_{i \geq 1} a_{i}$ is absolutely convergent. Show that then, $\sum_{i \geq 1} a_{2 i}$ and $\sum_{i \geq 1} a_{2 i-1}$ are absolutely convergent, and that
$$
\sum_{i \geq 1} a_{i}=\sum_{i \geq 1} a_{2 i}+\sum_{i \geq 1} a_{2 i-1} .
$$
Does the same hold for conditional convergence (proof or counterexample)?","Absolute convergence means that the partial sums of the $\left|a_{i}\right|$ are bounded. The same then holds for the partial sums of the $\left|a_{2 i}\right|$ or $\left|a_{2 i-1}\right|$, since
$$
\sum_{i=1}^{n}\left|a_{2 i}\right|+\sum_{i=1}^{n}\left|a_{2 i-1}\right|=\sum_{i=1}^{2 n}\left|a_{i}\right|.
$$
Having now established absolute convergence, we have
$$
\sum_{i=1}^{n} a_{2 i}+\sum_{i=1}^{n} a_{2 i-1}=\sum_{i=1}^{2 n} a_{i} .
$$
If the first partial sum converges to $x$, and the second to $y$, then the third must converge to $x+y$. Similarly, one can write
$$
\sum_{i=1}^{n} a_{2 i}+\sum_{i=1}^{n+1} a_{2 i-1}=\sum_{i=1}^{2 n+1} a_{i}
$$
with the result that the partial sums on the right hand again converge to $x+y$. Since both the even and odd partial sums of $\sum_{i \geq 1} a_{i}$ converge to $x+y$, so does the entire sequence of partial sums.
For conditional convergence, this is false, an example being $1-1+1 / 2-1 / 2+1 / 3-1 / 3+\cdots$, where both the odd and even terms give sums that grow unboundedly (as explained in class).","Suppose $u_{n} \in \mathcal{C}_{\mathrm{c}}(\mathbb{R})$ form an absolutely summable series with respect to the $L^{1}$ norm and set
$$
E=\left\{x \in \mathbb{R} ; \sum_{n}\left|u_{n}(x)\right|=\infty\right\}
$$
Show that if $a>0$ then the set
$$
\left\{x \in \mathbb{R} ; \sum_{n}\left|u_{n}(x)\right| \leq a\right\}
$$
is closed.","We need to check that if $\sum_{n}\left|u_{n}\left(x_{0}\right)\right|>a$ for some $x_{0}$ then the same holds in some neighbourhood of $x_{0}$. In this case $\sum_{n=1}^{N}\left|u_{n}\left(x_{0}\right)\right|>a$ for some $N$. But $\sum_{n=1}^{N}\left|u_{n}\left(x_{0}\right)\right|$ is a continuous functions. Thus, in some neighbourhood of $x_{0}$ we have $\sum_{n=1}^{N}\left|u_{n}(x)\right|>a$ and since $\sum_{n}\left|u_{n}\left(x_{0}\right)\right| \geq \sum_{n=1}^{N}\left|u_{n}(x)\right|$ the statement follows."
352,Mathematics,18.01,Calculus I,None,None,Problem Set 7,Probability,19,c,0.06335797254,Text,"Now suppose we start to gamble with this spinner. If I spin $x$, I win $x^{2}-4$ dollars. Notice that $x^{2}-4$ could be negative, and then I lose money. For instance, if I spin the number 1 , then I lose 3 dollars.
Estimate the probability that I win at least 4 dollars. Is it closest to $1 / 6$ or $1 / 9$ or $1 / 18 ?$ Explain your reasoning.",Open,"Since $\left[\frac{d}{d x} x^{2}-4\right]_{x=3}=[2 x]_{x=3}=6$, near the top payoff of 5 we have that a range of outcomes $3-\Delta \leq x \leq 3$ of the spin corresponds to a range of payoffs from approximately $5-6 \Delta x$ to 5 . We want this range to be from 4 to 5 , so pick $\Delta x=1 / 6$. The range of spin outcomes from $3-1 / 6$ to 3 has probability $\frac{1 / 6}{3}=\frac{1}{18}$.","Now suppose we start to gamble with this spinner. If I spin $x$, I win $x^{2}-4$ dollars. Notice that $x^{2}-4$ could be negative, and then I lose money. For instance, if I spin the number 1 , then I lose 3 dollars.
If I spin once, what is the probability that I lose money?",$\operatorname{Prob}\left(x^{2}-4<0\right)=\operatorname{Prob}(x<2)=2 / 3$.,"Now suppose we start to gamble with this spinner. If I spin $x$, I win $x^{2}-4$ dollars. Notice that $x^{2}-4$ could be negative, and then I lose money. For instance, if I spin the number 1 , then I lose 3 dollars.
What is the most I could win on one spin? What is the most I could lose on one spin?",The payoff is between $-4$ and $3^{2}-4=5$.,"Consider the following game. You spin a fair spinner that gives a number $x$ between 0 and 3. If $x<2$, then you win 10 dollars. But if $x>2$, then you lose $10 x$ dollars. For instance, if you spin 2.5, then you would lose 25 dollars.
If you played this game 1000 times, how much money would you expect to win or lose?","The probability density of $x$ is
$$
f(x)= \begin{cases}1 / 3, & 0 \leq x \leq 3 \\ 0, & \text { otherwise }\end{cases}
$$
The winning function is
$$
W(x)= \begin{cases}10, & x<2 \\ -10 x, & x>2\end{cases}
$$
The expected winning of one spin is
$$
\begin{aligned}
E(W(x)) & =\int_{0}^{3} f(x) W(x) d x=\frac{1}{3} \int_{0}^{2} 10 d x+\frac{1}{3} \int_{2}^{3}-10 x d x \\
& =\frac{20}{3}-\frac{10}{3}\left[\frac{x^{2}}{2}\right]_{2}^{3}=-\frac{5}{3} .
\end{aligned}
$$
If we play 1000 times, then we expect to lose $5000 / 3$ dollars. "
18,EECS,6.122,Design and Analysis of Algorithms,6.121,None,Problem Set 2,Freivalds' Algorithm,1,e,0.2727272727,Text,"The year is 2042. Matrix Inc is the hottest new startup on the tech scene. Their key product is a matrix multiplication engine called $\mathrm{Dijkstra}^{\mathrm{TM}}$ which multiples two given $n$-by-$n$ binary matrices $A$ and $B\left(\right.$ in $\mathbb{Z}_2^{n \times n}$ ) blazingly fast. Alice and Bob, who run HardBank Group, a VC firm, are trying to decide whether to fund Matrix Inc. 
In the course of their due diligence, Alice and Bob find that $\mathrm{Dijkstra}^{\mathrm{TM}}$  does occasionally make mistakes. They are unfazed, though. They harken back to the time when they TA'ed $6.046$ and taught Freivalds' algorithm, which gives a super fast way to take three matrices $A, B, C \in \mathbb{Z}_2^{n \times n}$, and with high probability verify whether $A B=C(\bmod 2)$. They reckon that Freivalds' test can be used to quickly check the correctness of $\mathrm{Dijkstra's}$ output. Your job in this problem is to help them figure this out.
Alice and Bob remember that (a single iteration of) Freivalds' test picks a random binary vector $r \in \mathbb{Z}_2^n$ and computes $A B r$ and $C r$. The test passes if $A B r=C r(\bmod 2)$ and fails otherwise. They remember that if $A B \neq C(\bmod 2)$, Freivalds' test catches the mistake (i.e. it fails) with probability at least $\frac{1}{2}$. By repeating the test $k$ times, they can catch any mistake in $\mathrm{Dijkstra's}$ output with probability at least $1-2^{-k}$; however, Alice and Bob are also keenly aware that doing so will make checking $k$ times slower.
Alice and Bob are on a roll. They show not just how to detect mistakes, but also correct them, again without using any randomness, in $O\left(n^2 t\right)$ time. How did they do it?",Open,"Note that by running the algorithm from part (d), we can figure out which $t$ rows contain the $t$ mistakes by simply observing the elements which differ. Then, for each row-index $i$, modify Freivalds' test to left multiply with a unit vector with 1 in the $i^{\text {th }}$ entry and 0 elsewhere, to figure out which entry $(i, j)$ is erroneous. This takes $O\left(n^2\right)$ for each of the $t$ incorrect entries, so it is $O\left(n^2 t\right)$ overall. Alternatively, for every row in $C$ that contains a mistake, simply compute the entire corresponding row of $A B$ by brute force in $O\left(n^2\right)$ time. There are $t$ rows with mistakes, so this is $O\left(n^2 t\right)$ overall.","The year is 2042. Matrix Inc is the hottest new startup on the tech scene. Their key product is a matrix multiplication engine called $\mathrm{Dijkstra}^{\mathrm{TM}}$ which multiples two given $n$-by-$n$ binary matrices $A$ and $B\left(\right.$ in $\mathbb{Z}_2^{n \times n}$ ) blazingly fast. Alice and Bob, who run HardBank Group, a VC firm, are trying to decide whether to fund Matrix Inc. 
In the course of their due diligence, Alice and Bob find that $\mathrm{Dijkstra}^{\mathrm{TM}}$  does occasionally make mistakes. They are unfazed, though. They harken back to the time when they TA'ed $6.046$ and taught Freivalds' algorithm, which gives a super fast way to take three matrices $A, B, C \in \mathbb{Z}_2^{n \times n}$, and with high probability verify whether $A B=C(\bmod 2)$. They reckon that Freivalds' test can be used to quickly check the correctness of $\mathrm{Dijkstra's}$ output. Your job in this problem is to help them figure this out.
Alice and Bob remember that (a single iteration of) Freivalds' test picks a random binary vector $r \in \mathbb{Z}_2^n$ and computes $A B r$ and $C r$. The test passes if $A B r=C r(\bmod 2)$ and fails otherwise. They remember that if $A B \neq C(\bmod 2)$, Freivalds' test catches the mistake (i.e. it fails) with probability at least $\frac{1}{2}$. By repeating the test $k$ times, they can catch any mistake in $\mathrm{Dijkstra's}$ output with probability at least $1-2^{-k}$; however, Alice and Bob are also keenly aware that doing so will make checking $k$ times slower.
The next morning, Alice and Bob figure out something amazing. Using their observation about the pattern of errors in $\mathrm{Dijkstra's}$ from part (c), they figure out how to detect if there is a mistake without using any randomness in $O\left(n^2\right)$ time. How did they do it?","Run Freivalds' algorithm using $r=\left(\begin{array}{llll}1 & 1 & \ldots & 1\end{array}\right)^T$. As shown above, for all $i, k$, if $(A B)_{i, k} \neq(C)_{i, k}$, we have $r_k=1 \Longrightarrow(A B r)_i \neq(C r)_i$. Thus, if $\mathrm{Dijkstra's}$ makes a mistake in the specified pattern, they will always find that $A B r \neq C r$.","The year is 2042. Matrix Inc is the hottest new startup on the tech scene. Their key product is a matrix multiplication engine called $\mathrm{Dijkstra}^{\mathrm{TM}}$ which multiples two given $n$-by-$n$ binary matrices $A$ and $B\left(\right.$ in $\mathbb{Z}_2^{n \times n}$ ) blazingly fast. Alice and Bob, who run HardBank Group, a VC firm, are trying to decide whether to fund Matrix Inc. 
In the course of their due diligence, Alice and Bob find that $\mathrm{Dijkstra}^{\mathrm{TM}}$  does occasionally make mistakes. They are unfazed, though. They harken back to the time when they TA'ed $6.046$ and taught Freivalds' algorithm, which gives a super fast way to take three matrices $A, B, C \in \mathbb{Z}_2^{n \times n}$, and with high probability verify whether $A B=C(\bmod 2)$. They reckon that Freivalds' test can be used to quickly check the correctness of $\mathrm{Dijkstra's}$ output. Your job in this problem is to help them figure this out.
Alice and Bob remember that (a single iteration of) Freivalds' test picks a random binary vector $r \in \mathbb{Z}_2^n$ and computes $A B r$ and $C r$. The test passes if $A B r=C r(\bmod 2)$ and fails otherwise. They remember that if $A B \neq C(\bmod 2)$, Freivalds' test catches the mistake (i.e. it fails) with probability at least $\frac{1}{2}$. By repeating the test $k$ times, they can catch any mistake in $\mathrm{Dijkstra's}$ output with probability at least $1-2^{-k}$; however, Alice and Bob are also keenly aware that doing so will make checking $k$ times slower.
Alice and Bob dig into $\mathrm{Dijkstra's}$ internals and figure out that it always makes mistakes in a curious pattern. When it makes a mistake, it makes exactly $t$ of them (for some $1 \leq t \leq n$ ). Furthermore, any particular row or column of $C$ has at most one incorrect element. What is the probability that a single iteration of Freivalds' test fails (catches the mistake)?","Since every row of $C$ has at most one incorrect element, if $C_{i, k} \neq$ $(A B)_{i, k}$ then we have $C_{i, j}=(A B)_{i, j}$ for all $k \neq j$. Also, we know $(C r)_i=$ $\sum_{j=1}^n C_{i, j} r_j$, and similarly $(A B r)_i=\sum_{j=1}^n(A B)_{i, j} r_j$. Thus if there is an incorrect element such that $C_{i, k} \neq(A B)_{i, k}$ then we have $(C r)_i \neq(A B r)_i \Longleftrightarrow C_{i, k} r_k \neq$ $(A B)_{i, k} r_k \Longleftrightarrow r_k=1$. So for $C$ to (incorrectly) pass, we must have $r_k=0$ for all $i, k$ such that $C_{i, k} \neq(A B)_{i, k}$.
All values of $k$ are distinct since every column of $C$ has at most one incorrect element, and each element of $r$ has independent probability $\frac{1}{2}$ of being 0, so the probability that a single iteration of Freivalds' algorithm fails (catches the mistake) is $1-2^{-t}$.","The year is 2042. Matrix Inc is the hottest new startup on the tech scene. Their key product is a matrix multiplication engine called $\mathrm{Dijkstra}^{\mathrm{TM}}$ which multiples two given $n$-by-$n$ binary matrices $A$ and $B\left(\right.$ in $\mathbb{Z}_2^{n \times n}$ ) blazingly fast. Alice and Bob, who run HardBank Group, a VC firm, are trying to decide whether to fund Matrix Inc. 
In the course of their due diligence, Alice and Bob find that $\mathrm{Dijkstra}^{\mathrm{TM}}$  does occasionally make mistakes. They are unfazed, though. They harken back to the time when they TA'ed $6.046$ and taught Freivalds' algorithm, which gives a super fast way to take three matrices $A, B, C \in \mathbb{Z}_2^{n \times n}$, and with high probability verify whether $A B=C(\bmod 2)$. They reckon that Freivalds' test can be used to quickly check the correctness of $\mathrm{Dijkstra's}$ output. Your job in this problem is to help them figure this out.
Alice and Bob remember that (a single iteration of) Freivalds' test picks a random binary vector $r \in \mathbb{Z}_2^n$ and computes $A B r$ and $C r$. The test passes if $A B r=C r(\bmod 2)$ and fails otherwise. They remember that if $A B \neq C(\bmod 2)$, Freivalds' test catches the mistake (i.e. it fails) with probability at least $\frac{1}{2}$. By repeating the test $k$ times, they can catch any mistake in $\mathrm{Dijkstra's}$ output with probability at least $1-2^{-k}$; however, Alice and Bob are also keenly aware that doing so will make checking $k$ times slower.
Suppose that $A, B, C \in \mathbb{Z}_2^{n \times n}$. Krievald, an advisor to HardBank, claims that the more mistakes Dijkstra makes, the higher the probability that Freivalds' will catch it. Alice, however, is skeptical of this claim.
Construct a worst-case example of matrices $A, B$ and $C$ where $C$ and $A B$ differ in $\Omega\left(n^2\right)$ entries, yet Freivalds' fails (i.e. catches the error) with probability at most $\frac{1}{2}$. (Remember, we assume that all computations are mod 2.)","Consider $C$ where every entry is incorrect: explicitly, we can take $A$ and $B$ to be zero matrices, such that $A B$ is also a zero matrix, and $C$ to contain only 1s. Thus, there are $n^2=\Omega\left(n^2\right)$ errors, but a single iteration of Freivalds' algorithm will pass (i.e. fail to catch the error) as long as $r$ contains an even number of 1s, which occurs with probability $\frac{1}{2}$."
129,Mathematics,18.01,Calculus I,None,None,Problem Set 3,Chain Rule,14,a,0.07919746568,Text,Which of the following is equal to $2^{x}: e^{x / 2}$ or $e^{\left(\log _{2} e\right) x}$ or $e^{(\ln 2) x}$ or $e^{\ln (2 x)} ?$,Multiple Choice,$2^{x}=e^{(\ln 2) x}$.,"If $2^{100}=10^{t}$, which of the following is the best approximation of $t: 10$ or 20 or 30 or 40 or $50 ?$ (If you want, you can use that $\log _{2} 10=3.32 \ldots$)","In words, $\log _{2} 10 \approx 3.32$ means that there are approximately $3.32$ factors of 2 in a factor of 10 . Thus, 100 factors of 2 are, approximately, 100/3.32 $\approx 30$ factors of 10.
$$
2^{100} \approx 10^{30} .
$$","Recall that $e$ is the number 2.71... It plays a special role in calculus because $\frac{d}{d x} e^{x}=e^{x}$.
Using the linear approximation of $e^{x}$ around $x=0$, approximate $e^{\cdot 1}$.","The linear approximation for $f(x)$ around $x=0$ is
$$
L(x)=f(0)+f^{\prime}(0) x.
$$
Here, with $f(x)=e^{x}, f(0)=1$. Because $f^{\prime}(x)=e^{x}, f^{\prime}(0)$ is also 1. Thus,
$$
L(x)=1+x.
$$
So, $e^{0.1} \approx 1.1$.","Using that expression and the chain rule, find the derivative of $2^{x}$.","Using that expression and the chain rule, find the derivative of $2^{x}$. $\frac{d}{d x} e^{(\ln 2) x}=e^{(\ln 2) x}(\ln 2)=(\ln 2) 2^{x}$."
24,Mathematics,18.3,Principles of Continuum Applied Mathematics,"18.02, 18.03",None,Problem Set 1,Direct Taylor Expansions,10,c,0.1822916667,Text,"For the examples below, calculate the Taylor expansion up to the order indicated (e.g.: $\left.\cos (x)=1-\frac{1}{2} x^{2}+O\left(x^{4}\right)\right)$. Do not use a calculator to evaluate constants that appear in the expansions - e.g., $\sqrt{2} / \pi$ or $\cos (3)$. On the other hand, do simplify when possible $-$ e.g., $\tan (\pi / 4)=1$ or $2 / \sqrt{2}=\sqrt{2}$.
Expand, up to $O\left(x^{5}\right), f(x)=\sin \left(1+x+x^{3}\right)$.",Expression,"Using the answer to part 2, we get
$$
\begin{aligned}
f(x)= & \sin (1)+\cos (1)\left(x+x^{3}\right)-\frac{1}{2} \sin (1)\left(x^{2}+2 x^{4}+O\left(x^{6}\right)\right)- \\
& \frac{1}{6} \cos (1)\left(x^{3}+O\left(x^{5}\right)\right)+\frac{1}{24} \sin (1)\left(x^{4}+O\left(x^{6}\right)\right)+O\left(x^{5}\right) \\
= & \sin (1)+\cos (1) x-\frac{1}{2} \sin (1) x^{2}+\frac{5}{6} \cos (1) x^{3}-\frac{23}{24} \sin (1) x^{4}+O\left(x^{5}\right) .
\end{aligned}
$$","For the examples below, calculate the Taylor expansion up to the order indicated (e.g.: $\left.\cos (x)=1-\frac{1}{2} x^{2}+O\left(x^{4}\right)\right)$. Do not use a calculator to evaluate constants that appear in the expansions - e.g., $\sqrt{2} / \pi$ or $\cos (3)$. On the other hand, do simplify when possible $-$ e.g., $\tan (\pi / 4)=1$ or $2 / \sqrt{2}=\sqrt{2}$.
Expand, up to $O\left(x^{5}\right), f(x)=\sin (1+x)$.",$f(x)=\sin (1)+\cos (1) x-\frac{1}{2} \sin (1) x^{2}-\frac{1}{6} \cos (1) x^{3}+\frac{1}{24} \sin (1) x^{4}+O\left(x^{5}\right)$.,"For the examples below, calculate the Taylor expansion up to the order indicated (e.g.: $\left.\cos (x)=1-\frac{1}{2} x^{2}+O\left(x^{4}\right)\right)$. Do not use a calculator to evaluate constants that appear in the expansions - e.g., $\sqrt{2} / \pi$ or $\cos (3)$. On the other hand, do simplify when possible $-$ e.g., $\tan (\pi / 4)=1$ or $2 / \sqrt{2}=\sqrt{2}$.
Expand, up to $O\left(x^{4}\right), f(x)=\sin (x) \cos (\sqrt{x})$.",$f(x)=\left(x-\frac{1}{6} x^{3}+O\left(x^{5}\right)\right)\left(1-\frac{1}{2} x+\frac{1}{24} x^{2}+O\left(x^{3}\right)\right)=x-\frac{1}{2} x^{2}-\frac{1}{8} x^{3}+O\left(x^{4}\right)$.,"For the examples below, calculate the Taylor expansion up to the order indicated (e.g.: $\left.\cos (x)=1-\frac{1}{2} x^{2}+O\left(x^{4}\right)\right)$. Do not use a calculator to evaluate constants that appear in the expansions - e.g., $\sqrt{2} / \pi$ or $\cos (3)$. On the other hand, do simplify when possible $-$ e.g., $\tan (\pi / 4)=1$ or $2 / \sqrt{2}=\sqrt{2}$.
Let $G=G(x, y)$ be some $\operatorname{smooth}^{7}$ function of two variables. For $z \geq 0$, expand up to $O\left(z^{3}\right), f(z)=G\left(z, z^{1.5}\right)$. Express the expansion coefficients in terms of partial derivatives of $G$.","We have $G(x, y)=G^{0}+G_{x}^{0} x+G_{y}^{0} y+\frac{1}{2} G_{x x}^{0} x^{2}+G_{x y}^{0} x y+\frac{1}{2} G_{y y}^{0} y^{2}+O\left(\left(x^{2}+y^{2}\right)^{1.5}\right)$, where: The superscript 0 denotes evaluation at $(0,0)-$ e.g., $G^{0}=G(0,0)$, etc.
The subscripts denote partial derivatives - e.g., $G_{x}=\frac{\partial G}{\partial x}$, etc.
Thus $f(z)=G^{0}+G_{x}^{0} z+G_{y}^{0} z^{1.5}+\frac{1}{2} G_{x x}^{0} z^{2}+G_{x y}^{0} z^{2.5}+O\left(z^{3}\right)$."
1,Mathematics,18.100B,Real Analysis,18.02,None,Problem Set 1,Axioms of Arithmetic,2,nan,0.7142857143,Text,"Suppose that from the axioms of arithmetic, we remove the piece that says $1 \neq 0$. Is it true that then, there is a notion of ""number"" where only one number exists, and which satisfies the rest of the axioms of arithmetic? Explain your reasoning. [The axioms of arithmetic are those from the first lecture. Do not use the axioms introduced in later lectures.]",Open,"The answer is yes. The associative, commutative, and distributive laws are satisfied: both sides of the equalities in those laws describe a number, and in our context, equality between numbers is always true, because there's only one number. That number is also an additive neutral element (it automatically satisfies $0+0=0$ ) and is its own additive inverse (for the same reason). The number 0 is also a multiplicative neutral element, since we have $0 \cdot 0=0$. The last axiom (multiplicative inverse) is a statement about ""all numbers $\neq 0$ "", and since there is no such number, the statement is true (along the same lines as ""all oxygen-breathing rocks are pink"" is a logically true statement). ","Suppose that we have any notion of number, satisfying the axioms of arithmetic. Let's change the operations as follows: we keep addition, $x+y=x+y$, but change multiplication to $x \cdot y=-(x \cdot y)$, where $-(\cdots)$ is the additive inverse for the old operation $+$. Do our new operations satisfy the axioms of arithmetic? Explain your answer.","During these computations, we will use $-(a \cdot b)=(-a) \cdot b=a \cdot(-b)$ many times. (Axiomatically, this follows from the distributive axiom, which shows that $(-a) \cdot b$ is an additive inverse to $a \cdot b$.)
Addition did not change, so we don't have to check any of its properties.
When we spell out axioms for $\cdot \cdot$ in terms of the old operations, we get:
$$
\begin{array}{ll}
-(x \cdot y)=-(y \cdot x) & \text { commutativity } \\
-(x \cdot(-(y \cdot z)))=-((-(x \cdot y)) \cdot z) & \text { associativity } \\
-(x \cdot(y+z))=(-(x \cdot y))+(-(x \cdot z)) & \text { distributivity. }
\end{array}
$$
The first line, commutativity, is obviously true. For the second line, we see that (using the fact mentioned at the beginning $)-(x \cdot(-(y \cdot z)))=x \cdot y \cdot z$, and the same applies to $-((-(x \cdot y)) \cdot z)$. Distributivity uses the same strategy, $-(x \cdot(y+z))=(-x) \cdot(y+z)=(-x) \cdot y+(-x) \cdot z=$ $(-(x \cdot y))+(-(x \cdot z))$
The final step is multiplicative neutral element and inverses. One has $-((-1) \cdot x)=1 \cdot x=x$, so $(-1)$ is a multiplicative neutral element for $\cdot \cdot$. One also has $-\left(\left(-x^{-1}\right) \cdot x\right)=x^{-1} \cdot x=1$, so $-x^{-1}$ is a multiplicative inverse with respect to $\cdot$.","Prove that the commutativity and associativity axioms for addition, together with the axiom of the existence of a neutral element for addition, imply that each $x$ can have at most one additive inverse. [This is Lemma 1.2 from the class summaries; obviously, you can't use either that Lemma, or anything that came after that. Argue strictly axiomatically.]","Suppose that $y$ and $z$ are both additive inverses of $x$, so $x+y=0$ and $x+z=0$. Then,
$$
y=y+0=y+(x+z).
$$
Here, we have used the defining property of the neutral element 0 , as well as the fact that $z$ is an inverse of $x$. Now we use associativity and commutativity:
$$
y+(x+z)=(y+x)+z=(x+y)+z .
$$
Now we use that $y$ is an inverse, and the defining property of the neutral element 0:
$$
(x+y)+z=0+z=z .
$$
Taking all that together, we have shown that $y=z$: any two additive inverses of $x$ must be equal, so there is at most one.","Continuing the previous problem, suppose that our originally given numbers had a subset $P$ which satisfies the axioms of ordering (with respect to $+$ and $\cdot$ ). Is there a subset which does the same for our new $+$, . . operations? [Note that the axiom of completeness is not part of the axioms of ordering.]","We use $P=-P=\{-x \quad: \quad x \in P\}$ as subset of positive numbers for our new operations. Trichotomy for this $P$ says that for each $x$, either $x=0$, or $-x \in P$, or $-(-x) \in P$. But $-(-x)=x$, because both those numbers are the additive inverse of $-x$, and additive inverses are unique. So this statement is the same as trichotomy for $P$, which we know.
Suppose $x, y \in P$, so $-x \in P$ and $-y \in P$. Now $(-x)+(-y)$ is the additive inverse of $x+y$, because $(-x)+(-y)+x+y=((-x)+x)+((-y)+y)=0+0=0$. Therefore, it follows from the axioms of ordering for $P$ that $(-x)+(-y)=-(x+y) \in P$, which shows that $x+y \in P$.
Suppose $x, y \in P$, so $-x \in P$ and $-y \in P$. The statement that $x \cdot y \in P$ means that $-(-(x \cdot y)) \in P$, or equivalently (by what I've observed above) that $x \cdot y \in P$. But we know that to be true, because (as proved in lecture) $x \cdot y=(-x) \cdot(-y)$, where the right hand side lies in $P$ because of the axiom of ordering for $\cdot$."
110,Mathematics,18.01,Calculus I,None,None,Problem Set 3,Product Rule and Quotient Rule,8,a,0.07919746568,Text,"In this problem, we work out the derivative of $f(x)=\frac{1}{x}$ by finding a nice approximation of $f(x+\Delta x)$. We know that
$$
f(x+\Delta x)=\frac{1}{x+\Delta x} .
$$
Because $\Delta x$ is in the denominator, this expression is a little complicated. There's a trick that makes it easier to approximate: multiply top and bottom by $x-\Delta x$.
$$
\frac{1}{x+\Delta x}=\frac{1}{x+\Delta x} \cdot \frac{x-\Delta x}{x-\Delta x}=\frac{x-\Delta x}{x^{2}-(\Delta x)^{2}} .
$$
Which of the following is a better approximation of $\frac{x-\Delta x}{x^{2}-(\Delta x)^{2}}$ when $\Delta x$ is really small? Briefly explain your reasoning.
$$
\frac{x-\Delta x}{x^{2}} \text { or } \frac{x}{x^{2}-(\Delta x)^{2}} .
$$",Open,$\frac{x-\Delta x}{x^{2}}$ is the better approximation because $x-\Delta x$ is further from $x$ than $x^{2}-(\Delta x)^{2}$ is from $x^{2}$.,"In this problem, we work out the derivative of $f(x)=\frac{1}{x}$ by finding a nice approximation of $f(x+\Delta x)$. We know that
$$
f(x+\Delta x)=\frac{1}{x+\Delta x} .
$$
Because $\Delta x$ is in the denominator, this expression is a little complicated. There's a trick that makes it easier to approximate: multiply top and bottom by $x-\Delta x$.
$$
\frac{1}{x+\Delta x}=\frac{1}{x+\Delta x} \cdot \frac{x-\Delta x}{x-\Delta x}=\frac{x-\Delta x}{x^{2}-(\Delta x)^{2}} .
$$
Use this approximation to find $f^{\prime}(x)$. Remember $f(x+\Delta x) \approx f(x)+f^{\prime}(x) \Delta x$, so try to write your answer to part a. in this form.","We have $f^{\prime}(x) \approx \frac{x-\Delta x}{x^{2}}=\frac{1}{x}-\frac{1}{x^{2}} \Delta x$, so $f^{\prime}(x)=\frac{-1}{x^{2}}$.","In class we used difference quotients to figure out the derivative of the function $x^{2}$. Using the same method, find the derivative of $f(x)=2 x^{2}+3 x+2$.
Recall that
$$
f^{\prime}(x)=\lim _{\Delta x \rightarrow 0} \frac{f(x+\Delta x)-f(x)}{\Delta x} .
$$
Quick review. There are two ways to write the derivative of a function $f(x)$. One way is to write $f^{\prime}(x)$. The other way is to write $\frac{d f}{d x}$. For instance, if we want to write the derivative of the function $x^{2}+2 x$, then we can write $\frac{d}{d x}\left(x^{2}+2 x\right)$. In recitation, you worked out the derivative of $x^{3}$ and the same idea works for any polynomial. For any exponent $n, \frac{d}{d x} x^{n}=n x^{n-1}$. Here is an example of how to differentiate a more complicated polynomial:
$$
\frac{d}{d x}\left(3 x^{5}-6 x^{2}\right)=3 \cdot 5 x^{4}-6 \cdot 2 x=15 x^{4}-12 x .
$$","Using the definition of derivative,
$$
\begin{aligned}
& f^{\prime}(x)=\frac{d}{d x}\left(2 x^{2}+3 x+2\right) \\
& \equiv \lim _{\Delta x \rightarrow 0} \frac{\frac{\text { horrible! }}{\left[2(x+\Delta x)^{2}+3(x+\Delta x)+2\right]-\left[2 x^{2}+3 x+2\right]}}{\Delta x} .
\end{aligned}
$$
(The triple-equals sign means ""is defined to be."")
Next, regroup and civilize the horrible numerator by placing related terms near one another.
$$
\begin{aligned}
& \left[2(x+\Delta x)^{2}+3(x+\Delta x)+2\right]-\left[2 x^{2}+3 x+2\right]= \\
& \frac{\left[2(x+\Delta x)^{2}-2 x^{2}\right]}{\text { term A }}+\underbrace{[3(x+\Delta x)-3 x]}_{\operatorname{term~B}}+\underbrace{[2-2]}_{\text {term C }} \text {. }
\end{aligned}
$$
Simplifying term A:
$$
2(x+\Delta x)^{2}-2 x^{2}=2\left[(x+\Delta x)^{2}-x^{2}\right]=2\left[2 x \Delta x+(\Delta x)^{2}\right]=4 x \Delta x+2(\Delta x)^{2} .
$$
Simplifying term B:
$$
3(x+\Delta x)-3 x=3 \Delta x.
$$
And simplifying term C:
$$
2-2=0 \text {. }
$$
Combining these simplifications, the numerator becomes
$$
\left[4 x \Delta x+2(\Delta x)^{2}\right]+[3 \Delta x]+[0] .
$$
Thus,
$$
f^{\prime}(x)=\lim _{\Delta x \rightarrow 0} \frac{\left[4 x \Delta x+2(\Delta x)^{2}\right]+[3 \Delta x]+[0]}{\Delta x} .
$$
Dividing by $\Delta x$ (leaving in the technically superfluous inner brackets because they help show where the terms originate),
$$
f^{\prime}(x)=\lim _{\Delta x \rightarrow 0}[[4 x+2 \Delta x]+[3]] .
$$
In the limit, the $2 \Delta x$ term vanishes, so
$$
f^{\prime}(x)=4 x+3 .
$$","Now we take a more quantitative approach using Taylor series. Let $f(x)$ be any function. Let $T_{2}(x)$ be the second order Taylor series of $f(x)$ around $x=a$.
Show that 
$$
T_{2}(a+\Delta x)-\frac{T_{2}(a)+T_{2}(a+2 \Delta x)}{2}=-(1 / 2) f^{\prime \prime}(a)(\Delta x)^{2} .
$$
If $\Delta x$ is small enough, then this should be a good approximation of $f(a+\Delta x)-$ $\frac{f(a)+f(a+2 \Delta x)}{2}$.","Let $c_{0}=f(a), c_{1}=f^{\prime}(a)$, and $c_{2}=\frac{1}{2} f^{\prime \prime}(a)$. Then,
$$
\begin{aligned}
T_{2}(a) & =c_{0} \\
T_{2}(a+\Delta x) & =c_{0}+c_{1} \Delta x+c_{2} \Delta x^{2} \\
T_{2}(a+2 \Delta x) & =c_{0}+2 c_{1} \Delta x+4 c_{2} \Delta x^{2}
\end{aligned}
$$
Take the average of the first and last equations,
$$
\frac{T_{2}(a)+T_{2}(a+2 \Delta x)}{2}=c_{0}+c_{1} \Delta x+2 c_{2} \Delta x^{2},
$$
and subtract the result from (3):
$$
T_{2}(a+2 \Delta x)-\frac{T_{2}(a)+T_{2}(a+2 \Delta x)}{2}=-c_{2} \Delta x^{2}=-\frac{1}{2} f^{\prime \prime}(a) \Delta x^{2} .
$$"
237,EECS,6.3,Signal Processing,"6.100A, 18.03",None,Final Exam,Discrete-Time Fourier Transforms,1,c,1,Text,"Each part of this problem describes a different discrete-time signal $f_{i}[n]$ and then asks you to determine the $k=3$ component of the DFT of that signal, where the DFT is computed with analysis window $N=16$:
$$
F_{i}[3]=\frac{1}{16} \sum_{n=0}^{15} f_{i}[n] e^{-j 2 \pi 3 n / 16}
$$
Let $f_{3}[n]=\cos (3 \pi n / 8-9 \pi / 8)$. Enter a closed form expression for $F_{3}[3]$ below.",Expression,"$$
\mathrm{F}_{3}[3]=\overline{\frac{1}{2} e^{-j 2 \pi 9 / 16}}
$$
Since
$$
f_{3}[n]=f_{2}[n-3]
$$
it follows that
$$
\mathrm{F}_{3}[\mathrm{k}]=\mathrm{e}^{-\mathrm{j} 2 \pi \mathrm{k} 3 / 16} \mathrm{~F}_{2}[\mathrm{k}]
$$
Therefore $F_{3}[3]=\frac{1}{2} e^{-j 2 \pi 9 / 16}$.","Each part of this problem describes a different discrete-time signal $f_{i}[n]$ and then asks you to determine the $k=3$ component of the DFT of that signal, where the DFT is computed with analysis window $N=16$:
$$
F_{i}[3]=\frac{1}{16} \sum_{n=0}^{15} f_{i}[n] e^{-j 2 \pi 3 n / 16}
$$
Let $f_{2}[n]=\cos (3 \pi n / 8)$. Enter a closed form expression for $F_{2}[3]$ below.","$F_{2}[3] = \frac{1}{2}$.
$$
\begin{gathered}
f_{2}[n]=\cos (3 \pi n / 8)=\frac{e^{j 6 \pi n / 16}+e^{-j 6 \pi n / 16}}{2}=\sum_{k=0}^{15} F_{2}[k] e^{j 2 \pi k n / 16}
\end{gathered}
$$
Since the basis functions for the DFT are orthogonal, it follows that
$$
F_{2}[k]= \begin{cases}\frac{1}{2} & \text { if } k=3 \text { or } k=13 \\ 0 & \text { otherwise }\end{cases}
$$","Each part of this problem describes a different discrete-time signal $f_{i}[n]$ and then asks you to determine the $k=3$ component of the DFT of that signal, where the DFT is computed with analysis window $N=16$:
$$
F_{i}[3]=\frac{1}{16} \sum_{n=0}^{15} f_{i}[n] e^{-j 2 \pi 3 n / 16}
$$
Let $f_{1}[n]=(-1)^{n}$ Enter a closed form expression for $F_{1}[3]$ below.","$F_{1}[3] = 0$.
The basis functions for DFTs of length $N=16$ are of the form $e^{-j 2 \pi k n / 16}$. Therefore $f_{1}[n]=(-1)^{n}=e^{-j 2 \pi 8 n / 16}$ contains a single basis function, and that basis function is at index $k=8$. Since the $k=8$ and $k=3$ basis functions are orthogonal, $F_{1}$[3] must be zero.
Mathematically:
$$
\begin{aligned}
F_{1}[k] & =\frac{1}{N} \sum_{n=0}^{N-1} f_{1}[n] e^{-j 2 \pi k n / N}=\frac{1}{N} \sum_{n=0}^{N-1}(-1)^{n} e^{-j 2 \pi k n / N}=\frac{1}{N} \sum_{n=0}^{N-1} e^{-j \pi n} e^{-j 2 \pi k n / N} \\
& =\frac{1}{N} \sum_{n=0}^{N-1} e^{-j \pi N n / N} e^{-j 2 \pi k n / N}=\frac{1}{N} \sum_{n=0}^{N-1} e^{-j \pi(2 k+N) n / N}=\frac{1}{16}\left(\frac{1-e^{-j \pi 22}}{1-e^{-j \pi 22 / 16}}\right)=0
\end{aligned}
$$","Each part of this problem describes a different discrete-time signal $f_{i}[n]$ and then asks you to determine the $k=3$ component of the DFT of that signal, where the DFT is computed with analysis window $N=16$:
$$
F_{i}[3]=\frac{1}{16} \sum_{n=0}^{15} f_{i}[n] e^{-j 2 \pi 3 n / 16}
$$
Determine a closed form expression for $F_{5}[3]$ where
$$
\begin{aligned}
& f_{5}[n]=\left(\frac{1}{2}\right)^{n} u[n] \\
\end{aligned}
$$","$$
F_{5}[3]=\frac{1}{16}\left(\frac{1-\left(\frac{1}{2}\right)^{16}}{1-\frac{1}{2} e^{-j 2 \pi 3 / 16}}\right)
$$
$$
\begin{aligned}
& F_{5}[k]=\frac{1}{N} \sum_{n=0}^{N-1}\left(\frac{1}{2}\right)^{n} e^{-j 2 \pi k n / N}=\frac{1}{N}\left(\frac{1-\left(\frac{1}{2}\right)^{N} e^{-j 2 \pi k N / N}}{1-\frac{1}{2} e^{-j 2 \pi k / N}}\right)=\frac{1}{N}\left(\frac{1-\left(\frac{1}{2}\right)^{N}}{1-\frac{1}{2} e^{-j 2 \pi k / N}}\right)
\end{aligned}
$$
Substituting $k=3$ and $\mathrm{N}=16$ yields
$$
F_{5}[3]=\frac{1}{16}\left(\frac{1-\left(\frac{1}{2}\right)^{16}}{1-\frac{1}{2} e^{-j 2 \pi 3 / 16}}\right)
$$"
0,Mathematics,18.704,Seminar in Algebra,18.701,None,Problem Set 1,Group,1,a,0.75,Text,"Consider the subgroup $G$ of $S_{4}$ generated by the 4-cycle (1234) and the transposition (13). Let $G$ act on $\mathbb{C}^{4}$ by permuting coordinates; that is, (1234) acts by cycling the coordinates, and (13) acts by swapping the first and third coordinates.
Prove that $G \cong D_{2 n}$ for $n=4$ (see Example $1.4$ of James-Liebeck for the definition of $D_{2 n}$).",Open,"We use the presentation
$$
D_{8}=\left\langle a, b: a^{4}=b^{2}=1, b^{-1} a b=a^{-1}\right\rangle
$$
for the dihedral group of order 8 from page 3 of James and Liebeck. We can see that the generators (1234) and (13) of $G$ have orders 4 and 2, respectively. Then, the mapping $\varphi: D_{8} \rightarrow G$ defined on the generators by
$$
\begin{aligned}
a & \mapsto(1234) \\
b & \mapsto(13)
\end{aligned}
$$
must be a surjective homomorphism, implying that $\left|D_{8}\right| \geq|G|$. The homomorphism $\varphi$ is an isomorphism as long as the orders of the two groups equal, so it just remains to show that $8=\left|D_{8}\right| \leq|G|$ in order to prove that $\varphi$ is an isomorphism. The elements in $G$ generated by (1234) are
$$
1,(12)(23)(34),(13)(24),(14)(43)(32) \text {. }
$$
Furthermore, multiplying each of the above by (13) on the right, we get more elements of $G$:
$$
(13),(12)(34),(24),(14)(23) \text {. }
$$
Each of these 8 elements are distinct since permutations can be uniquely decomposed into transpositions. Thus, $|G| \geq 8$ and we are done. ","Consider the subgroup $G$ of $S_{4}$ generated by the 4-cycle (1234) and the transposition (13). Let $G$ act on $\mathbb{C}^{4}$ by permuting coordinates; that is, (1234) acts by cycling the coordinates, and (13) acts by swapping the first and third coordinates.
There are exactly six nontrivial $G$-stable subspaces of $\mathbb{C}^{4}$. Find them all. (Remember that a $G$-stable subspace is sub-vector-space $W$ such that $g * w \in W$ for any $g \in G$ and any $w \in W$.)","Any one-dimensional G-stable subspace of $\mathbb{C}^{4}$ must be stable on (1234) - this implies that for any $\left(x_{1}, x_{2}, x_{3}, x_{4}\right) \in \mathbb{C}^{4}$, we have $\left[x_{1}, x_{2}, x_{3}, x_{4}\right]=\lambda\left[x_{2}, x_{3}, x_{4}, x_{1}\right]$ for some $\lambda \in \mathbb{C}$. This means that $\lambda$ is a fourth root of unity, and in fact must have $\lambda=\pm 1$ by checking that it's stable under (13) as well. That is, our spaces are $V_{1}$ (spanned by $(1,1,1,1)$ ) and $V_{2}$ (spanned by $(1,-1,1,-1)$ ). The cases when $\lambda=\pm i$ can be combined into an irreducible two-dimensional subspace since (13) swaps the two one-dimensional spaces - this is more easily described as the space $V_{3}$, spanned by $(1,0,1,0)$ and $(0,1,0,1)$ (Rather than $(1, i,-1,-i)$ and $(1,-i,-1, i))$. Our six nontrivial $G$-stable subspaces are then $V_{1}, V_{2}, V_{3}, V_{1} \oplus V_{2}, V_{1} \oplus V_{3}, V_{2} \oplus V_{3}$, which respectively have dimensions $1,2,2,2,3,3$.",Recall that the group $S_{n}$ is generated by transpositions. Prove that all transpositions are conjugate.,"Given some transposition $\sigma_{1}=(i j) \in S_{n}$, we want to show that all other transpositions in $\sigma_{2} \in S_{n}$ are conjugate via casework analysis. We are looking for elements $\sigma$ in $S_{n}$ such that $\sigma_{2}=\sigma^{-1} \sigma_{1} \sigma$.
The first and easiest case is when $\sigma_{2}=(i j)$. Then $\sigma_{2}=e^{-1} \sigma_{1} e$.
The second case is when one index matches but the other doesn't. Without lost of generality, assume $\sigma_{2}=(j k)$, where $i \neq k$. Then
$$
(j k)=(i j k)^{-1}(i j)(i j k).
$$
The third and final case is when neither index matches; i.e., $\sigma_{2}=(k l)$ for distinct $i, j, k, \ell$. Then observe that
$$
(k \ell)=(i k j \ell)^{-1}(i j)(i k j \ell).
$$","The set of $n \times n$ matrices can be identified with the space $\mathbb{R}^{n \times n}$. Let $G$ be a subgroup of $G L_n(\mathbb{R})$. With the notation of the previous problem, prove:
If $A, B, C, D$ are in $G$, and if there are paths in $G$ from $A$ to $B$ and from $C$ to $D$, then there is a path in $G$ from $A C$ to $B D$.","If $X(t)$ is a path from $A$ to $B$ in $G L_{n}$ and $Y(t)$ is a path from $C$ to $D$, then the matrix product $X(t) Y(t)$ defines a path from $A B$ to $C D$. It is continuous because matrix multiplication is continuous."
11,Mathematics,18.404,Theory of Computation,6.1210/18.200,None,Problem Set 2,Context-Free Language,1,b,0.5555555556,Text,"Let $C=\set{zuz} z\in\st0^*$ and $u\in\st0^*\st1\st0^*$
where $|u|=|z|\setend$.  Show that $C$ is a \cfl\ by giving a \pda\ that recognizes $C$.",Open,"$\quad C$ is the language of all strings $s$ whose length is a multiple of 3 and where $s$ contains a single 1 in the middle third and os everywhere else.
The PDA for $C$ operates by using the same idea. It begins by reading 0 s and pushing them on the stack. At any point it nondeterministically reads 010. From that point on it reads either 0 and pops 00 , or reads 00 and pops 0 , and continues by repeating this process. If the stack is ever empty at the end of the input, it accepts.","Let $C=\set{zuz} z\in\st0^*$ and $u\in\st0^*\st1\st0^*$
where $|u|=|z|\setend$.  Show that $C$ is a \cfl\ by giving a \cfg\ that generates $C$.","$\quad C$ is the language of all strings $s$ whose length is a multiple of 3 and where $s$ contains a single 1 in the middle third and os everywhere else.
$S \rightarrow 0 S 00|00 S 0| 010$. The CFG works because it directly generates 010, the shortest string in $C$, and it generates additional strings by adding 0s in a way that keeps the 1 in the middle third while allowing the 1 to be in any location in the middle third. A proof of correctness isn't necessary, but it could be accomplished by using induction.","Let $D = \set{ztz}z\in\st0^*$
and $t\in\st0^*\st1\st0^*\st1\st0^*$ where $|t|=|z|\setend$.
Show that $D$ is not a \cfl.","Assume (for contradiction) that $D$ is a CFG and apply the pumping lemma to obtain the pumping length $p$. Let $s=0^{p+2} 10^{p} 10^{p+2}$. Because $s \in D$ and $|s| \geq p$ the pumping lemma says that we may write $s=u v x y z$ satisfying the lemma's three conditions. If either $v$ or $y$ contains a 1, then the string $u x z$ contains fewer than two $1 \mathrm{~s}$ and thus it cannot be a member of $D$. By condition three of the pumping lemma, parts $v$ and $y$ cannot together contain 0s from both of the two outer runs of 0s. Hence in the string $u v^{2} x y^{2} z$ the 1s cannot both remain in the middle third and so $u v^{2} x y^{2} z$ is not in $D$.","Let $D = \set{ztz}z\in\st0^*$
and $t\in\st0^*\st1\st0^*\st1\st0^*$ where $|t|=|z|\setend$.
Is $D \union \SS(\SS\SS\SS)^*$ a \cfl?  Why or why not?","If $D \cup \Sigma(\Sigma \Sigma \Sigma)^{*}$ were a CFL, then its intersection with the regular language $(\Sigma \Sigma \Sigma)^{*}$ would also be a CFL. However that intersection equals $D$ which we've shown isn't a CFL, and thus $D \cup \Sigma(\Sigma \Sigma \Sigma)^{*}$ isn't a CFL."
43,Mathematics,18.03,Differential Equations,None,18.02,Problem Set 4,Exponential Response Formula,1,e,0.08042895442,Text,"Consider the polynomial $P(x)=\left(x^{2}+4\right)(x-2)$, find the general solution of the inhomogeneous ODE
$$
P(D) y=f(t),
$$
where $f(t)$ is the specified function.
$f(t)=2 e^{t}-3 e^{2 t}+(1+i) e^{2 i t}$.",Expression,"By superposition and applying b), c), d), we have
$$
y_{p}=-\frac{2 e^{t}}{5}+\frac{3 t e^{2 t}}{8}-\frac{t e^{2 i t}}{8} \text {. }
$$
Thus, the general solution is given by,
$$
y=c_{1} e^{2 t}+c_{2} \cos (2 t)+c_{3} \sin (2 t)-\frac{2 e^{t}}{5}-\frac{3 t e^{2 t}}{8}-\frac{t e^{2 i t}}{8} .
$$","Consider the polynomial $P(x)=\left(x^{2}+4\right)(x-2)$, find the general solution of the inhomogeneous ODE
$$
P(D) y=f(t),
$$
where $f(t)$ is the specified function.
$f(t)=e^{2 i t}$.","As $2 i$ is a root of $P$ with multiplicity 1 , by exponential response formula, we have
$$
y_{p}=\frac{t e^{2 i t}}{P^{\prime}(2 i)}=\frac{-1+i}{16} t e^{2 i t} .
$$
Thus, the general solution is given by,
$$
y=y_{h}+y_{p}=c_{1} e^{2 t}+c_{2} \cos (2 t)+c_{3} \sin (2 t)+\frac{-1+i}{16} t e^{2 i t} .
$$","Consider the polynomial $P(x)=\left(x^{2}+4\right)(x-2)$, find the general solution of the inhomogeneous ODE
$$
P(D) y=f(t),
$$
where $f(t)$ is the specified function.
$f(t)=e^{2 t}$.","As 2 is a root of $P$ with multiplicity 1 , by exponential response formula, we have
$$
y_{p}=\frac{t e^{2 t}}{P^{\prime}(2)}=\frac{t e^{2 t}}{8} \text {. }
$$
Thus, the general solution is given by,
$$
y=y_{h}+y_{p}=c_{1} e^{2 t}+c_{2} \cos (2 t)+c_{3} \sin (2 t)+\frac{t e^{2 t}}{8} .
$$","Consider the polynomial $P(x)=\left(x^{2}+4\right)(x-2)$, find the general solution of the inhomogeneous ODE
$$
P(D) y=f(t),
$$
where $f(t)$ is the specified function.
$f(t)=e^{t}$.","As 1 is not root of $P$, by exponential response formula, we have
$$
y_{p}=\frac{e^{t}}{P(1)}=-\frac{e^{t}}{5} \text {. }
$$
Thus, the general solution is given by,
$$
y=y_{h}+y_{p}=c_{1} e^{2 t}+c_{2} \cos (2 t)+c_{3} \sin (2 t)-\frac{e^{t}}{5} .
$$"
27,Mathematics,18.03,Differential Equations,None,18.02,Problem Set 3,Second-Order Differential Equations,1,b,0.2412868633,Text,"Find the general, real solution to each of the following ODEs.
$y^{\prime \prime}+3 y^{\prime}-4 y=0$.",Expression,"The characteristic equation is $r^{2}+3 r-4=0$, or $(r+4)(r-1)=0$, which has two solutions $r=-4,1$. Hence the general solution is
$$
C_{1} e^{-4 t}+C_{2} e^{t}.
$$","Find the general, real solution to each of the following ODEs.
$y^{\prime \prime}+4 y^{\prime}+4 y=0$.","The characteristic equation is $r^{2}+4 r+4=0$, which has the repeated real root $r=-2$. Hence the general solution is
$$
C_{1} e^{-2 t}+C_{2} t e^{-2 t}.
$$","Find the general, real solution to each of the following ODEs.
$y^{\prime \prime}+\sqrt{7} y^{\prime}+4 y=0$.","The characteristic equation is $r^{2}+\sqrt{7} r+4=0$. By the quadratic formula, the two solutions are
$$
r=\frac{-\sqrt{7} \pm \sqrt{7-4 \times 4}}{2}=\frac{-\sqrt{7} \pm 3 i}{2} .
$$
These solutions are complex conjugates of one another, so we know that the solutions are the imaginary and real parts of $e^{\left(\frac{-\sqrt{7}+3 i}{2}\right) t}$. Hence the general solution is
$$
C_{1} e^{-\sqrt{7} t / 2} \cos \left(\frac{3 t}{2}\right)+C_{2} e^{-\sqrt{7} t / 2} \sin \left(\frac{3 t}{2}\right)
$$
or equivalently $A e^{-\sqrt{7} t / 2} \cos \left(\frac{3 t}{2}-\phi\right)$ in phase-lag form.","Find the general, real solution to each of the following ODEs.
$y^{\prime \prime}+9 y=0$.","The characteristic equation is $r^{2}+9=0$, which has two solutions $r=\pm 3 i$. Hence the general solution is
$$
C_{1} \cos (3 t)+C_{2} \sin (3 t) .
$$"
35,Mathematics,18.100B,Real Analysis,18.02,None,Problem Set 7,Open Subsets,1,nan,1.428571429,Text,"In RR\mathbb{R}, which of the following subsets is open? Which of the following is closed? With explanation please (does not need to amount to full proof).
(a) [0,∞)[0,∞)[0, \infty);
(b) ⋃x∈Z(x−14,x+14)⋃x∈Z(x−14,x+14)\bigcup_{x \in \mathbb{Z}}\left(x-\frac{1}{4}, x+\frac{1}{4}\right);
(c) {x∈R:x2≥2}{x∈R:x2≥2}\left\{x \in \mathbb{R}: x^{2} \geq 2\right\};
(d) ⋃p∈Z,q∈N(pq−14q,pq+14q)⋃p∈Z,q∈N(pq−14q,pq+14q)\bigcup_{p \in \mathbb{Z}, q \in \mathbb{N}}\left(\frac{p}{q}-\frac{1}{4 q}, \frac{p}{q}+\frac{1}{4 q}\right).",Open,"a) This set is closed and not open. Indeed, it does not contain any open ball centered at 0 , so it cannot be open. On the other hand, its complement is $(-\infty, 0)$ which is open, so $[0, \infty)$ is closed.
b) This set is open and not closed. Indeed, it is a union of open intervals which must be open. It is not closed because it contains a sequence $\left(x_{n}\right)=\left(\frac{1}{4}-\frac{1}{n+1}\right)$ converging to $\frac{1}{4}$, but does not contain $\frac{1}{4}$.
c) This set is closed and not open. This set is the same as $(-\infty,-\sqrt{2}] \cup[\sqrt{2}, \infty)$. It is the union of two closed sets (same reasoning as part (a)) hence is closed. On the other hand, it does not contain any open ball centered at $\sqrt{2}$, hence is not open.
d) This set is both closed and open. Let
$$
S=\bigcup_{p \in \mathbb{Z}, q \in \mathbb{N}}\left(\frac{p}{q}-\frac{1}{4 q}, \frac{p}{q}+\frac{1}{4 q}\right)
$$
We claim that $S=\mathbb{R}$. First, note that for $\alpha \in \mathbb{R}$, if
$$
\frac{p}{q}-\frac{1}{4 q}<\alpha<\frac{p}{q}+\frac{1}{4 q}
$$
then for any $n \in \mathbb{Z}$,
$$
\frac{p+q n}{q}-\frac{1}{4 q}<\alpha+n<\frac{p+q n}{q}+\frac{1}{4 q} .
$$
Hence it suffices to show that $S \supset[0,1]$.
Taking $p=0,1$ and $q=1$, we see that $S \supset[0,1 / 4) \cup(3 / 4,1]$.
Taking $q=2, p=1, S \supset(3 / 8,5 / 8)$. Taking $q=3, p=0,1$, we see that $S$ contains $(1 / 4,5 / 12) \cup(7 / 12,3 / 4)$. Since $5 / 12>3 / 8$ and $5 / 8>7 / 12, S \supset(1 / 4,3 / 4)$.
Taking $q=4, p=0,1$, we see that $S$ contains $\frac{1}{4}$ and $\frac{3}{4}$, so we have finally shown that $S \supset[0,1]$.","Show that every open interval (a,b)⊂(0,1)(a,b)⊂(0,1)(a, b) \subset(0,1) contains a number xxx such that: neither xxx nor any of its powers xm(m=2,3,…)xm(m=2,3,…)x^{m}(m=2,3, \ldots) lies in the Cantor set. In your argument, you may use freely the fact that every number in (am,bm)(am,bm)\left(a^{m}, b^{m}\right) has an mmm-th root in (a,b)(a,b)(a, b). (This is the nastiest problem I've put on a pset so far; among other things, it uses Baire's theorem.)","Let $C$ denote the Cantor set. We have seen that $C$ is closed and contains no open interval. For any $m \in \mathbb{N}$, define
$$
C_{m}:=\left\{x \in[0,1] \mid x^{m} \in C\right\} .
$$
We claim that $C_{m}$ is closed. Indeed, if $x_{n} \in C_{m}$ form a sequence $\left(x_{n}\right)$ converging to some $l, x_{n}^{m}$ converges to $l^{m}$ (Lemma 2.8). But $C$ is closed, so $l^{m} \in C$. Since $0 \leq x_{n} \leq 1$ for all $n, l \in[0,1]$. By definition, $l \in C_{m}$. Suppose that $C_{m}$ contained an open interval $(a, b) \subset(0,1)$. Let $x \in\left(a^{m}, b^{m}\right)$. Then $x$ has an $m$ th root $y \in(a, b)$. By definition of $C_{m}, y^{m}=x \in C$. So $C$ would contain the open interval $\left(a^{m}, b^{m}\right)$, which is a contradiction. Therefore, $C_{m}$ contains no open interval.
By Theorem 4.21, $\bigcup_{m \geq 1} C_{m}$ contains no open interval. Therefore, given any interval $(a, b) \subset(0,1)$, there exists $x$ such that $x \notin \bigcup_{m \geq 1} C_{m}$. This means that no powers of $x$ lie in $C$.",Prove Lemma 4.26 from the lecture summaries: the intersection of finitely many open subsets of $\mathbb{R}$ is open.,"Let $U_{i}, i=1, \ldots, n$, be open sets. Let $x \in \bigcap_{i=1}^{n} U_{i}$. Since each $U_{i}$ is open, for each $i$, there exists $\varepsilon_{i}>0$ such that $\left(x-\varepsilon_{i}, x+\varepsilon_{i}\right) \in U_{i}$. Let $\varepsilon:=\min _{i}\left(\varepsilon_{i}\right)$. Then $(x-\varepsilon, x+\varepsilon) \subset \bigcap_{i=1}^{n} U_{i}$. It follows that $\bigcap_{i=1}^{n} U_{i}$ is open.","For any sequence $\left(x_{n}\right)$ of real numbers, show that: the set $A \subset \mathbb{R}$ of numbers that are limits of a subsequence of $\left(x_{n}\right)$ is closed.","Let $y \in \bar{A}$. We wish to show that $y \in A$, i.e. to show that $\left(x_{n}\right)$ has a subsequence converging to $y$. By Lemma 2.14, it is enough to show that there are infinitely many $n$ such that $\left|x_{n}-y\right|<\varepsilon$ for any given $\varepsilon>0$.
Let $\varepsilon>0$ be given. By Lemma 4.12, there exists $z \in A$ such that $|z-y|<\varepsilon / 2$. By Lemma 2.14, there are infinitely many $n$ such that $\left|z-x_{n}\right|<\varepsilon / 2$. For any such $n$,
$$
\left|x_{n}-y\right| \leq|z-y|+\left|z-x_{n}\right|<\varepsilon
$$
which was what we needed."
89,Mathematics,18.6,Probability and Random Variables,18.02,None,Problem Set 7,Geometric Random Variable,5,a,0.2,Text,"Let $X_1,...,X_N$ be independent random variables with the common distribution function $F$, and suppose they are independent of $N$, a geometric random variable with parameter $p$. Let $M = \mbox{max}(X_1,...,X_N)$.
Find $P\{M \leq x\}$ by conditioning on $N$.",Expression,"$P\{M \leq x\} = \mathlarger{\sum\limits^{\infty}_{n = 1}} P\{N = n\}P\{M \leq x | N = n\} = \mathlarger{\sum\limits^{\infty}_{n = 1}} p(1 - p)^{n - 1}P\{\mbox{max}(X_1,...,X_N) \leq x\} = \mathlarger{\sum\limits^{\infty}_{n = 1}}p(1 - p)^{n - 1}P\{X_1 \leq x \cap X_2 \leq x \cap ... \cap X_n \leq x\} = \mathlarger{\sum\limits^{\infty}_{n = 1}}p(1 - p)^{n - 1}\mathlarger{\prod\limits^{n}_{i = 1}} P\{X_i \leq x\} = \mathlarger{\sum\limits^{\infty}_{n = 1}}p(1 - p)^{n - 1}F(x)^n$. 
This is an infinite geometric series which can be evaluated as follows
\begin{center}
$P\{M \leq x\} = \dfrac{pF(x)}{1 - (1 - p)F(x)}$.
\end{center}","Let $X_1,...,X_N$ be independent random variables with the common distribution function $F$, and suppose they are independent of $N$, a geometric random variable with parameter $p$. Let $M = \mbox{max}(X_1,...,X_N)$.
Find $P\{M \leq x|N = 1\}$.",$P\{M \leq x|N = 1\} = P\{X_1 \leq x\} = F(x)$.,"Let $X_1,...,X_N$ be independent random variables with the common distribution function $F$, and suppose they are independent of $N$, a geometric random variable with parameter $p$. Let $M = \mbox{max}(X_1,...,X_N)$.
Find $P\{M \leq x|N > 1\}$. ","$P\{M \leq x|N > 1\} = P\{X_1 \leq x | N > 1\} P\{\mbox{max}(X_2,...,X_n) \leq x | N > 1\} = F(x)P\{M \leq x\}$.","Let $X_1,...,X_N$ be independent random variables with the common distribution function $F$, and suppose they are independent of $N$, a geometric random variable with parameter $p$. Let $M = \mbox{max}(X_1,...,X_N)$.
Use $(b)$ and $(c)$ to rederive the probability you found in $(a)$.","$P\{M \leq x\} = P\{N = 1\}P\{M \leq x|N = 1\} + P\{N > 1\}P\{M \leq x|N > 1\} = pF(x) + (1 - p)F(x)P\{M \leq x\}$.
Thus,  $P\{M \leq x\} = \dfrac{pF(x)}{1 - (1 - p)F(x)}$.
"
19,Mathematics,18.2,Principles of Discrete Applied Mathematics,None,18.C06,Problem Set 4,Chernoff's Bound,2,a,1.018518519,Text,"Consider a set $T$, and $n$ subsets $F_{1}, F_{2}, \cdots, F_{n} \subset T$ each having size exactly $n$, where $n \geq$ 2. We would like to assign each element of $T$ the value $+1$ or $-1$ such that each set has approximately the same number of positive and negative elements. More precisely, given a coloring function $f: T \rightarrow\{-1,+1\}$, we define its imbalance to be
$$
I(f)=\max _{i}\left|\sum_{j \in F_{i}} f(j)\right| .
$$
Notice that the imbalance is always at most $n$, and we would like it to be much smaller; if it is 0, every set has the same number of elements of each color.
Let $Y=\sum_{i=1}^{n} Y_{i}$ where the $Y_{i}$ 's are independent and $Y_{i} \in\{-1,1\}$ with equal probability. Use the Chernoff bound to prove that $\mathbb{P}(|Y| \geq c \sqrt{n \log n}) \leq 2 n^{-c^{2} / 6}$.",Open,"We would like to transform $Y$ to a random variable which is a sum of independent Bernoulli trials. For, let $Z_{i}=\left(Y_{i}+1\right) / 2$ for each $i=1, \ldots, n$ and let $Z=\sum_{i=1}^{n} Z_{i}$. Note that $Z_{i}=1$ with probability $1 / 2$ and $Z_{i}=0$ with probability $1 / 2$, and all $Z_{i}$ are independent. Chernoff's bound implies that for all $0<\delta<1$ we have
$$
\mathbb{P}(|Z-\mu| \geq \delta \mu) \leq 2 e^{-\delta^{2} \mu / 3}
$$
where $\mu=\mathbb{E}(Z)=n / 2$. On the other hand,
$$
\begin{aligned}
\mathbb{P}(|Y| \geq c \sqrt{n \log n}) & =\mathbb{P}\left(\left|\sum_{i=1}^{n} Y_{i}\right| \geq c \sqrt{n \log n}\right) \\
& =\mathbb{P}\left(\left|\sum_{i=1}^{n}\left(2 Z_{i}-1\right)\right| \geq c \sqrt{n \log n}\right) \\
& =\mathbb{P}(|2 Z-n| \geq c \sqrt{n \log n}) \\
& =\mathbb{P}(|Z-\mu| \geq c \sqrt{n \log n} / 2)
\end{aligned}
$$
Let $\delta=\frac{c \sqrt{n \log n} / 2}{\mu}=c \sqrt{\frac{\log n}{n}}$. Observe that $\delta \leq 1$ for large enough $n$. By substituting $\delta$ into the inequality (1), we get
$$
\begin{aligned}
\mathbb{P}(|Z-\mu| \geq c \sqrt{n \log n} / 2)=\mathbb{P}(|Z-\mu| \geq \delta \mu) & \leq 2 e^{-\delta^{2} \mu / 3} \\
& =2 \exp \left(-\frac{c^{2} \frac{\log n}{n} \cdot \frac{n}{2}}{3}\right) \\
& =2 e^{-\left(c^{2} / 6\right) \log n}=2 n^{-c^{2} / 6} .
\end{aligned}
$$
Hence, $\mathbb{P}(|Y| \geq c \sqrt{n \log n}) \leq 2 n^{-c^{2} / 6}$.","Consider a set $T$, and $n$ subsets $F_{1}, F_{2}, \cdots, F_{n} \subset T$ each having size exactly $n$, where $n \geq$ 2. We would like to assign each element of $T$ the value $+1$ or $-1$ such that each set has approximately the same number of positive and negative elements. More precisely, given a coloring function $f: T \rightarrow\{-1,+1\}$, we define its imbalance to be
$$
I(f)=\max _{i}\left|\sum_{j \in F_{i}} f(j)\right| .
$$
Notice that the imbalance is always at most $n$, and we would like it to be much smaller; if it is 0, every set has the same number of elements of each color.
Prove that, for any collection of $n$ sets of size $n$, there always exists a coloring $f$ with $I(f) \leq c \sqrt{n \log n}$ where $c$ is a small constant (for example $c=3$ works). ","If we aim to prove this with a constant $c \geq 3$, we can assume that $n \geq 31$ since $3 \sqrt{n \log (n)} \geq n$ for $n \leq 30$.
Let $f: T \rightarrow\{-1,+1\}$ be a coloring chosen uniformly at random. Precisely, we assign a color $f(j)=X_{j}$ to each element $j \in T$, where $X_{j}$ are independent and $X_{j} \in\{-1,+1\}$ with equal probability. Let $Y_{i}=\sum_{j \in F_{i}} X_{j}$ for $i=1, \ldots, n$. Then, the imbalance of $f$ is equal to $\max _{i}\left|Y_{i}\right|$ by definition.
We would like to show that $\max _{i}\left|Y_{i}\right|$ is at most $c \sqrt{n \log n}$ with nonzero probability for some constant $c>0$. For, let us first consider the probability $\mathbb{P}\left(\left|Y_{i}\right| \geq c \sqrt{n \log n}\right)$ for a fixed $i$. Note that
$$
Y_{i}=\sum_{j \in F_{i}} X_{j},
$$
which is the sum of $n$ independent random variables $\left\{X_{j}: j \in F_{i}\right\}$, and $X_{j} \in\{-1,+1\}$ with equal probability. Hence, we have
$$
\mathbb{P}\left(\left|Y_{i}\right| \geq c \sqrt{n \log n}\right) \geq 2 n^{-c^{2} / 6}
$$
by using the lemma. We get
$$
\begin{aligned}
\mathbb{P}\left(\max _{i}\left|Y_{i}\right|<c \sqrt{n \log n}\right) & =1-\mathbb{P}\left(\left|Y_{i}\right| \geq c \sqrt{n \log n} \text { for some } i \in\{1, \ldots, n\}\right) \\
& \geq 1-\sum_{i=1}^{n} \mathbb{P}\left(\left|Y_{i}\right| \geq c \sqrt{n \log n}\right) \\
& \geq 1-n \cdot\left(2 n^{-c^{2} / 6}\right) \\
& =1-2 n^{1-c^{2} / 6}
\end{aligned}
$$
where the second inequality follows from the union bound. For $c=3$ and $n \geq 31$, the value (from the previous exercise) of $\delta=3 \sqrt{\frac{\ln n}{n}} \leq 3 \sqrt{\frac{\ln 31}{31}}<1$ (so that we can use the previous exercise) and also $2 n^{1-c^{2} / 6}$ is strictly less than 1 . Hence, for any $c \geq 3$ and $n \geq 31$ we have
$$
\mathbb{P}\left(\max _{i}\left|Y_{i}\right|<c \sqrt{n \log n}\right)>0
$$
and it implies that there exists a coloring $f: T \rightarrow\{-1,+1\}$ such that $I(f)<c \sqrt{n \log n}$, and this is irrespective of the value of $n$.","Let $A_{1}, A_{2}, \ldots, A_{m}$ be subsets of the integers from 1 to $n$. Suppose that each set $A_{i}$ has size $k$. Consider coloring the integers with one of three colors red, blue and green. We will say that a set $A_{i}$ is rainbow colored if each color appears at least once.
Give an expression for the probability $p_{k}$ that a random coloring of a set of size $k$ is rainbow, for general $k \geq 3$. Check your answer against what you computed in part $(a)$ and $(b)$.","We can compute the expression using the inclusion-exclusion formula. Let $T_{1}$ be the event that the color blue does not appear (only the colors red and green may appear). Similarly let $T_{2}$ denote the event that no green appears, and let $T_{3}$ denote the event that no red appears. Now we have $\mathbb{P}\left[T_{i}\right]=\left(\frac{2}{3}\right)^{k}$. Moreover $\mathbb{P}\left[T_{i}\right.$ and $\left.T_{j}\right]=\frac{1}{3^{k}}$ and the probability that all three events occur is zero. Let $p$ be the probability of a rainbow coloring. Then
$$
p_{k}=1-\operatorname{Pr}\left[T_{1}\right]-\operatorname{Pr}\left[T_{2}\right]-\operatorname{Pr}\left[T_{3}\right]+\operatorname{Pr}\left[T_{1} \text { and } T_{2}\right]+\operatorname{Pr}\left[T_{1} \text { and } T_{3}\right]+\operatorname{Pr}\left[T_{2} \text { and } T_{3}\right]
$$
And thus
$$
p_{k}=1-\frac{2^{k}-1}{3^{k-1}}
$$","Suppose $A_{1}, A_{2}, \cdots, A_{k}$ are subsets of size $n$ of a finite set $X$. We would like to color the elements of $X$ red or blue in such a way that in every $A_{i}$ for $i=1, \ldots, k$, there exists at least one red element and at least one blue element. Show that this is always possible when $k<2^{n-1}$.
By the way, this bound is not best possible (some larger values of $k$ are possible). For $n=2$, what is the largest $k$ for which it is possible?","Suppose we color each element of $X$ blue or red independently and uniformly at random. Then the probability that a subset $A_{k}$ is monochromatic (i.e. has all its elements of the same color) is equal to $\frac{1}{2^{n-1}}$, since it is the probability that all of its elements are red plus the probability that all its elements are blue, and each of these probabilities is $1 / 2^{n}$. Furthermore, the probability that some set $A_{k}$ is monochromatic is then upper bounded (by the union bound) by $\frac{k}{2^{n-1}}$ which is strictly less than one by our hypothesis. This implies that the probability that none of the sets is monochromatic is at least $1-\frac{k}{2^{n-1}}$, which is strictly greater than zero. In other words, there is a realization of our random experiment for which none of the sets is monochromatic.
For $n=2$, we have that $k=2$ works, but $n=3$ is not necessarily possible as seen from the sets $\{1,2\},\{1,3\}$ and $\{2,3\}$."
109,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Problem Set 5,Sequential Logic,4,nan,0.6,Text,"Implement a pipeline to calculate the expression ((|a| ÷ 3) + 10)×7 by completing the rule pipeline in PipelineMath.ms using the components provided in MathFunctions.ms. Your implementation should use at most three registers and achieve a critical-path delay ≤ 500ps.

import MathFunctions;

// Exercise 4:
// Complete the module below to calculate the mathematical function
// ((abs(in)/3)+10)*7) by calling functions from MathFunction.ms.

module PipelineMath;
  // Pipeline registers (to pass partial results from one stage to the next)
  Reg#(Maybe#(Bit#(16))) stage1(Invalid);
  Reg#(Maybe#(Bit#(16))) stage2(Invalid);
  Reg#(Maybe#(Bit#(16))) result(Invalid);

  input Maybe#(Bit#(16))
    in default = Invalid;

  rule pipeline;
    // TODO: Implement this in Exercise 4
    result <= Invalid;
  endrule

  method Maybe#(Bit#(16)) out = result; // Do not change this line
endmodule",Programming,"import MathFunctions;

// Exercise 4:
// Complete the module below to calculate the mathematical function
// ((abs(in)/3)+10)*7 by calling functions from MathFunction.ms.

module PipelineMath;
  // Pipeline registers (to pass partial results from one stage to the next)
  Reg#(Maybe#(Bit#(16))) stage1(Invalid);
  Reg#(Maybe#(Bit#(16))) stage2(Invalid);
  Reg#(Maybe#(Bit#(16))) result(Invalid);

  input Maybe#(Bit#(16))
    in default = Invalid;

  rule pipeline;
    // TODO: Implement this in Exercise 4
    if (isValid(in)) begin
       stage1 <= Valid(abs(fromMaybe(?, in)));
    end else stage1 <= Invalid;
    if (isValid(stage1)) begin
       stage2 <= Valid(divide3(fromMaybe(?, stage1)));
    end else stage2 <= Invalid;
    if (isValid(stage2)) begin
       result <= Valid(multiply7(add10(fromMaybe(?, stage2))));
    end else result <= Invalid;
  endrule

  method Maybe#(Bit#(16)) out = result; // Do not change this line
endmodule","Fill in the skeleton code for the module FastFoldedMultiplier in Multipliers.ms, such that your 32-bit sequential multiplier achieves a critical-path delay ≤ 280ps.
Hint: There are at least two ways to speed up your multiplier. First, you can use a faster adder (e.g., the one from Lab 4). Second, you can try a multiplier algorithm that avoids dynamic bit selection and shifting by a variable number of bits. For example, you may have used an algorithm in the folded multiplier exercise that required the number to be added in the ith step to depend upon the ith bit of operand a. If you implemented this using dynamic bit selection (a[i]), it would require a signicant number of gates (it requires an n-input multiplexer). It is possible to replace this dynamic selection by a simpler one-bit shift at each step.

// Fast folded multiplier by repeated addition
module FastFoldedMultiplier#( Integer n );
    // You can use these registers or create your own if you want
    RegU#(Bit#(n)) a;
    RegU#(Bit#(n)) b;
    RegU#(Bit#(n)) prod;
    RegU#(Bit#(n)) tp;
    Reg#(Maybe#(Bit#(log2(n)+1))) i(Invalid); // This is a Maybe type

    // When there is a new pair of numbers to multiply, they
    // will be passed in as a valid MultiplierInput.
    input Maybe#(MultiplierInput#(n))
        in default = Invalid;

    rule mulStep;
        // TODO: Implement this in Exercise 3
        // NOTE: This rule can be implemented in about 15 lines of code
    endrule

    // getResult should return the most recent multiplication result,
    // or Invalid if the multiplier is calculating the next result.
    // If no input has been given yet, the result should be Invalid.
    method Maybe#(Bit#(2*n)) getResult;
        // TODO: Implement this in Exercise 3
        // NOTE: This method can be implemented in about 1 line of code
        return Invalid;
    endmethod
endmodule","function Bit#(2) fullAdder(Bit#(1) a, Bit#(1) b, Bit#(1) carryIn);
    Bit #(2) ret = 0;
    Bit #(1) sum = a ^ b ^ carryIn;
    Bit #(1) carryOut = a & b | a & carryIn | b & carryIn;
    ret = {carryOut, sum};
    return ret;
endfunction

function Bit#(2) csa#(1)(Bit#(1) a, Bit#(1) b, Bit#(1) carryIn);
    return fullAdder(a, b, carryIn);
endfunction

function Bit#(n + 1) csa#(Integer n)(Bit#(n) a, Bit#(n) b, Bit#(1) carryIn);
    Bit #(n + 1) ret = 0;
    Bit #(n / 2 + 1) upper_0 = csa#(n / 2)(a[n - 1:n / 2], b[n - 1:n / 2], 0);
    Bit #(n / 2 + 1) upper_1 = csa#(n / 2)(a[n - 1:n / 2], b[n - 1:n / 2], 1);
    Bit #(n / 2 + 1) lower = csa#(n / 2)(a[n / 2 - 1:0], b[n / 2 - 1:0], carryIn);
    Bit #(n / 2 + 1) upper = (lower[n / 2] == 0) ? upper_0 : upper_1;
    ret = {upper, lower[n / 2 - 1:0]};
    return ret;
endfunction

function Bit#(n) fastAdd#(Integer n)(Bit#(n) a, Bit#(n) b, Bit#(1) carryIn);
    Bit #(n) ret = 0;
    Bit #(n / 2 + 1) upper_0 = csa#(n / 2)(a[n - 1:n / 2], b[n - 1:n / 2], 0);
    Bit #(n / 2 + 1) upper_1 = csa#(n / 2)(a[n - 1:n / 2], b[n - 1:n / 2], 1);
    Bit #(n / 2 + 1) lower = csa#(n / 2)(a[n / 2 - 1:0], b[n / 2 - 1:0], carryIn);
    Bit #(n / 2 + 1) upper = (lower[n / 2] == 0) ? upper_0 : upper_1;
    ret = {upper[n / 2 - 1:0], lower[n / 2 - 1:0]};
    return ret;
endfunction

// Fast folded multiplier by repeated addition
module FastFoldedMultiplier#( Integer n );
    // You can use these registers or create your own if you want
    RegU#(Bit#(n)) a;
    RegU#(Bit#(2*n)) b;
    RegU#(Bit#(2*n)) tp;
    Reg#(Maybe#(Bit#(log2(n)+1))) i(Invalid); // This is a Maybe type

    // When there is a new pair of numbers to multiply, they
    // will be passed in as a valid MultiplierInput.
    input Maybe#(MultiplierInput#(n))
        in default = Invalid;

    rule mulStep;
        // TODO: Implement this in Exercise 3
        // NOTE: This rule can be implemented in about 15 lines of code
        if (isValid(in)) begin
           let args = fromMaybe(?, in);
           a <= args.a;
           b <= zeroExtend(args.b);
           tp <= 0;
           i <= Valid(0);
        end else if (fromMaybe(?, i) < n) begin
           tp <= fastAdd#(2*n)(tp, (a[0] == 1 ? b : 0), 0);
           a <= a >> 1;
           b <= b << 1;
           i <= Valid(fromMaybe(?, i) + 1);
        end    
    endrule

    // getResult should return the most recent multiplication result,
    // or Invalid if the multiplier is calculating the next result.
    // If no input has been given yet, the result should be Invalid.
    method Maybe#(Bit#(2*n)) getResult;
        // TODO: Implement this in Exercise 3
        // NOTE: This method can be implemented in about 1 line of code
        if (isValid(i)) begin
           return (fromMaybe(?, i) == n) ? Valid(tp) : Invalid;
        end else return Invalid;
    endmethod
endmodule","Implement a folded multiplier by completing the FoldedMultiplier module in Multipliers.ms. This includes dening any internal state, implementing the getResult method, and implementing a rule that updates the circuit's state.

// Folded multiplier by repeated addition
module FoldedMultiplier#(Integer n);
    // You can use these registers or create your own if you want
    RegU#(Bit#(n)) a;
    RegU#(Bit#(n)) b;
    RegU#(Bit#(n)) prod;
    RegU#(Bit#(n)) tp;
    Reg#(Maybe#(Bit#(log2(n)+1))) i(Invalid); // This is a Maybe type

    // When there is a new pair of numbers to multiply, they
    // will be passed in as a valid MultiplierInput.
    input Maybe#(MultiplierInput#(n))
        in default = Invalid;

    rule mulStep;
        // TODO: Implement this in Exercise 2
        // NOTE: This rule can be implemented in about 15 lines of code
    endrule

    // getResult should return the most recent multiplication result,
    // or Invalid if the multiplier is calculating the next result.
    // If no input has been given yet, the result should be Invalid.
    method Maybe#(Bit#(2*n)) getResult;
        // TODO: Implement this in Exercise 2
        // NOTE: This method can be implemented in about 1 line of code
        return Invalid;
    endmethod
endmodule","// Folded multiplier by repeated addition
module FoldedMultiplier#(Integer n);
    // You can use these registers or create your own if you want
    RegU#(Bit#(n)) a;
    RegU#(Bit#(2*n)) b;
    RegU#(Bit#(2*n)) tp;
    Reg#(Maybe#(Bit#(log2(n)+1))) i(Invalid); // This is a Maybe type

    // When there is a new pair of numbers to multiply, they
    // will be passed in as a valid MultiplierInput.
    input Maybe#(MultiplierInput#(n))
        in default = Invalid;

    rule mulStep;
        // TODO: Implement this in Exercise 2
        // NOTE: This rule can be implemented in about 15 lines of code
        if (isValid(in)) begin
           let args = fromMaybe(?, in);
           a <= args.a;
           b <= zeroExtend(args.b);
           tp <= 0;
           i <= Valid(0);
        end else if (fromMaybe(?, i) < n) begin
           tp <= tp + (a[0] == 1 ? b : 0);
           a <= a >> 1;
            b <= b << 1;
           i <= Valid(fromMaybe(?, i) + 1);
        end
    endrule

    // getResult should return the most recent multiplication result,
    // or Invalid if the multiplier is calculating the next result.
    // If no input has been given yet, the result should be Invalid.
    method Maybe#(Bit#(2*n)) getResult;
        // TODO: Implement this in Exercise 2
        // NOTE: This method can be implemented in about 1 line of code
        if (isValid(i)) begin
           return (fromMaybe(?, i) == n) ? Valid(tp) : Invalid;
        end else return Invalid;
    endmethod
endmodule","You are given a module, named “F.” This module has two inputs, X and Y, and two outputs, A and B. You are told that the circuit functions, but its throughput is too low. You decide to take a look and try to pipeline the circuit.
For each of the questions below, please create a valid K-stage pipeline of the given circuit. Each component in the circuit is annotated with its propagation delay in nanoseconds. Show your pipelining contours and place large black circles (●) on the signal arrows to indicate the placement of pipeline registers. Give the latency and throughput of each design, assuming ideal registers (tPD=0, tSETUP=0). Remember that our convention is to place a pipeline register on each output.
Show the maximum-throughput 3-stage pipeline using a minimal number of registers. What are the latency and throughput of the resulting circuit? Pay close attention to the direction of each arrow.","The maximum-throughput 3-stage pipeline is below.
Latency (ns): ____33____
Throughput ($\text{ns}^{-1}$): ___1/11____"
9,EECS,6.3,Signal Processing,"6.100A, 18.03",None,Problem Set 2,Trigonometric Expansions,1,b,0.1875,Text,"In this problem, we compare two methods for expanding a function $f(\theta)$ as a series of the form
$$
f(\theta)=c_{0}+\sum_{k=1}^{\infty} c_{k} \cos (k \theta)+\sum_{k=1}^{\infty} d_{k} \sin (k \theta).
$$
An alternative to trigonometric identities is to use complex exponentials. Determine the non-zero coefficients $c_{k}$ and $d_{k}$ as in the previous part - but this time use Euler's formula and complex numbers, but no trigonometric identities.",Numerical,"We can use Euler's formula to rewrite the target function as
$$
f_{1}(\theta)=\left(\frac{e^{j \theta}+e^{-j \theta}}{2}\right)^{5} .
$$
Then we can expand the fifth power by repeated multiplication (or by using the binomial equation) to get 
$$
f_{1}(\theta)=\frac{1}{32}\left(e^{j 5 \theta}+5 e^{j 3 \theta}+10 e^{j \theta}+10 e^{-j \theta}+5 e^{-3 j \theta}+e^{-5 j \theta}\right).
$$
Finally, we can pair complex exponentials with their negative partners and use Euler's formula to obtain
$$
f_{1}(\theta)=\frac{5}{8} \cos (\theta)+\frac{5}{16} \cos (3 \theta)+\frac{1}{16} \cos (5 \theta).
$$
As before, the coefficient $c_{1}=5 / 8, c_{3}=5 / 16$, and $c_{5}=1 / 16$. The others are zero.","In this problem, we compare two methods for expanding a function $f(\theta)$ as a series of the form
$$
f(\theta)=c_{0}+\sum_{k=1}^{\infty} c_{k} \cos (k \theta)+\sum_{k=1}^{\infty} d_{k} \sin (k \theta).
$$
Determine the non-zero coefficients $c_{k}$ and $d_{k}$ as in the previous part - but this time use Euler's formula and complex numbers, but no trigonometric identities.","Use Euler's formula to rewrite the target function as
$$
f_{2}(\theta)=\left(\frac{e^{j \theta}-e^{-j \theta}}{2 j}\right)^{5} \text {. }
$$
Then expand the fifth power by repeated multiplication (or by using the binomial formula) to obtain
$$
f_{2}(\theta)=\frac{1}{32 j}\left(e^{j 5 \theta}-5 e^{j 3 \theta}+10 e^{j \theta}-10 e^{-j \theta}+5 e^{-3 j \theta}-e^{-5 j \theta}\right).
$$
Then pair the complex exponentials with their negative partners and use Euler's formula to obtain
$$
f_{2}(\theta)=\frac{5}{8} \sin (\theta)-\frac{5}{16} \sin (3 \theta)+\frac{1}{16} \sin (5 \theta).
$$
As before, the coefficient $d_{1}=5 / 8, d_{3}=-5 / 16$, and $d_{5}=1 / 16$. The others are zero.","In this problem, we compare two methods for expanding a function $f(\theta)$ as a series of the form
$$
f(\theta)=c_{0}+\sum_{k=1}^{\infty} c_{k} \cos (k \theta)+\sum_{k=1}^{\infty} d_{k} \sin (k \theta).
$$
Use the trigonometric identities provided on the last page of this homework assignment plus the rules of ordinary algebra to determine the values of the non-zero coefficients $c_{k}$ and $d_{k}$ needed to expand the function
$$
f_{1}(\theta)=\cos ^{5}(\theta).
$$","$$
\begin{aligned}
f_{1}(\theta) &=\cos ^{5}(\theta)=\cos ^{2}(\theta) \cos ^{2}(\theta) \cos (\theta) \\
&=\left(\frac{1+\cos (2 \theta)}{2}\right) \times\left(\frac{1+\cos (2 \theta)}{2}\right) \times \cos (\theta) \\
&=\left(\frac{1+2 \cos (2 \theta)+\cos ^{2}(2 \theta)}{4}\right) \times \cos (\theta) \\
&=\left(\frac{1+2 \cos (2 \theta)+\frac{1+\cos (4 \theta)}{2}}{4}\right) \times \cos (\theta) \\
&=\left(\frac{3}{8}+\frac{1}{2} \cos (2 \theta)+\frac{1}{8} \cos (4 \theta)\right) \cos (\theta) \\
&=\frac{3}{8} \cos (\theta)+\frac{1}{2} \cos (2 \theta) \cos (\theta)+\frac{1}{8} \cos (4 \theta) \cos (\theta) \\
&=\frac{3}{8} \cos (\theta)+\frac{1}{4} \cos (\theta)+\frac{1}{4} \cos (3 \theta)+\frac{1}{16} \cos (3 \theta)+\frac{1}{16} \cos (5 \theta) \\
&=\frac{5}{8} \cos (\theta)+\frac{5}{16} \cos (3 \theta)+\frac{1}{16} \cos (5 \theta)
\end{aligned}
$$
The coefficient $c_{1}=5 / 8, c_{3}=5 / 16$, and $c_{5}=1 / 16$. The other coefficients are zero.","In this problem, we compare two methods for expanding a function $f(\theta)$ as a series of the form
$$
f(\theta)=c_{0}+\sum_{k=1}^{\infty} c_{k} \cos (k \theta)+\sum_{k=1}^{\infty} d_{k} \sin (k \theta).
$$
Use the trigonometric identities provided on the last page of this homework assignment plus the rules of ordinary algebra to determine the values of the non-zero coefficients $c_{k}$ and $d_{k}$ needed to expand the function
$$
f_{2}(\theta)=\sin ^{5}(\theta) .
$$","$$
\begin{aligned}
f_{2}(\theta) &=\sin ^{5}(\theta)=\sin ^{2}(\theta) \sin ^{2}(\theta) \sin (\theta) \\
&=\left(\frac{1-\cos (2 \theta)}{2}\right) \times\left(\frac{1-\cos (2 \theta)}{2}\right) \times \sin (\theta) \\
&=\left(\frac{1-2 \cos (2 \theta)+\cos ^{2}(2 \theta)}{4}\right) \times \sin (\theta) \\
&=\left(\frac{1-2 \cos (2 \theta)+\frac{1+\cos (4 \theta)}{2}}{4}\right) \times \sin (\theta) \\
&=\left(\frac{3}{8}-\frac{1}{2} \cos (2 \theta)+\frac{1}{8} \cos (4 \theta)\right) \sin (\theta) \\
&=\frac{3}{8} \sin (\theta)-\frac{1}{2} \cos (2 \theta) \sin (\theta)+\frac{1}{8} \cos (4 \theta) \sin (\theta) \\
&=\frac{3}{8} \sin (\theta)-\frac{1}{4} \sin (3 \theta)+\frac{1}{4} \sin (\theta)+\frac{1}{16} \sin (5 \theta)-\frac{1}{16} \sin (3 \theta) \\
&=\frac{5}{8} \sin (\theta)-\frac{5}{16} \sin (3 \theta)+\frac{1}{16} \sin (5 \theta)
\end{aligned}
$$
The coefficient $d_{1}=5 / 8, d_{3}=-5 / 16$, and $d_{5}=1 / 16$. The other coefficients are zero."
109,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 3,Propositional Proof,4,aiii,0.1116071429,Text,"There are three suspects for a murder: Adams, Brown, and Clark.
1. Adams says ""I didn't do it. The victim was an old acquaintance of Brown's. But Clark hated him.""
2. Brown states ""I didn't do it. I didn't know the guy. Besides I was out of town all week.""
3. Clark says ""I didn't do it. I saw both Adams and Brown in town around the victim that day; one of them must have done it.""
4. We know that exactly one of the suspects is guilty.
Assume that the two innocent people are telling the truth, but that the guilty people might not be. So, the statements from the suspects can be encoded as ""If suspect_is_innocent, then some other facts are true"".
Let the propositional variables have the following definitions:
\begin{itemize}
\item $A=$ Adams is innocent
\item $B=$ Brown is innocent
\item $C=$ Clark is innocent
\item $X=$ Brown knew the victim
\item $Y=$ Brown was out of town
\item $Z=$ Adams was out of town
\item $W=$ Clark hated the victim
\end{itemize}
We can write down propositional logic axioms for each of the four statements defining this problem. For propositional resolution, we need to convert these sentences to CNF. We will ask you to convert one sentence at a time. Enter one CNF formula corresponding to the specified sentence in each of the answer spaces below.
Enter each CNF formula as a list of lists of literal strings. A literal string is either a propositional symbol, e.g. 'A' or the negation of a propositional symbol, e.g. ' $A$ '. A typical clause will look like: $\left[{ }^{\prime} A ', ' \sim B\right.$ ', ' $\left.\sim C '\right]$. And a CNF formula is a list of clauses. Do not include any spaces in the strings. 
The third axiom is: $C \Rightarrow(\neg Y \wedge \neg Z \wedge(\neg A \vee \neg B))$
Enter the CNF as a formula following the syntax described above.",Expression,"[['~C', '~Y'], ['~C', '~Z'], ['~C', '~A', '~B']]","There are three suspects for a murder: Adams, Brown, and Clark.
1. Adams says ""I didn't do it. The victim was an old acquaintance of Brown's. But Clark hated him.""
2. Brown states ""I didn't do it. I didn't know the guy. Besides I was out of town all week.""
3. Clark says ""I didn't do it. I saw both Adams and Brown in town around the victim that day; one of them must have done it.""
4. We know that exactly one of the suspects is guilty.
Assume that the two innocent people are telling the truth, but that the guilty people might not be. So, the statements from the suspects can be encoded as ""If suspect_is_innocent, then some other facts are true"".
Let the propositional variables have the following definitions:
\begin{itemize}
\item $A=$ Adams is innocent
\item $B=$ Brown is innocent
\item $C=$ Clark is innocent
\item $X=$ Brown knew the victim
\item $Y=$ Brown was out of town
\item $Z=$ Adams was out of town
\item $W=$ Clark hated the victim
\end{itemize}
We can write down propositional logic axioms for each of the four statements defining this problem. For propositional resolution, we need to convert these sentences to CNF. We will ask you to convert one sentence at a time. Enter one CNF formula corresponding to the specified sentence in each of the answer spaces below.
Enter each CNF formula as a list of lists of literal strings. A literal string is either a propositional symbol, e.g. 'A' or the negation of a propositional symbol, e.g. ' $A$ '. A typical clause will look like: $\left[{ }^{\prime} A ', ' \sim B\right.$ ', ' $\left.\sim C '\right]$. And a CNF formula is a list of clauses. Do not include any spaces in the strings. 
The fourth axiom is: $(\neg A \vee \neg B \vee \neg C) \wedge((A \wedge B) \vee(A \wedge C) \vee(B \wedge C))$
Enter the CNF as a formula following the syntax described above.","[['~C', '~A', '~B'], ['A', 'C'], ['A', 'B'], ['B', 'C'], ['A', 'B', 'C']]","There are three suspects for a murder: Adams, Brown, and Clark.
1. Adams says ""I didn't do it. The victim was an old acquaintance of Brown's. But Clark hated him.""
2. Brown states ""I didn't do it. I didn't know the guy. Besides I was out of town all week.""
3. Clark says ""I didn't do it. I saw both Adams and Brown in town around the victim that day; one of them must have done it.""
4. We know that exactly one of the suspects is guilty.
Assume that the two innocent people are telling the truth, but that the guilty people might not be. So, the statements from the suspects can be encoded as ""If suspect_is_innocent, then some other facts are true"".
Let the propositional variables have the following definitions:
\begin{itemize}
\item $A=$ Adams is innocent
\item $B=$ Brown is innocent
\item $C=$ Clark is innocent
\item $X=$ Brown knew the victim
\item $Y=$ Brown was out of town
\item $Z=$ Adams was out of town
\item $W=$ Clark hated the victim
\end{itemize}
We can write down propositional logic axioms for each of the four statements defining this problem. For propositional resolution, we need to convert these sentences to CNF. We will ask you to convert one sentence at a time. Enter one CNF formula corresponding to the specified sentence in each of the answer spaces below.
Enter each CNF formula as a list of lists of literal strings. A literal string is either a propositional symbol, e.g. 'A' or the negation of a propositional symbol, e.g. ' $A$ '. A typical clause will look like: $\left[{ }^{\prime} A ', ' \sim B\right.$ ', ' $\left.\sim C '\right]$. And a CNF formula is a list of clauses. Do not include any spaces in the strings. 
The second axiom is: $B \Rightarrow(\neg X \wedge Y)$
Enter the CNF as a formula following the syntax described above.","[['~B', '~X'], ['~B', 'Y']]","There are three suspects for a murder: Adams, Brown, and Clark.
1. Adams says ""I didn't do it. The victim was an old acquaintance of Brown's. But Clark hated him.""
2. Brown states ""I didn't do it. I didn't know the guy. Besides I was out of town all week.""
3. Clark says ""I didn't do it. I saw both Adams and Brown in town around the victim that day; one of them must have done it.""
4. We know that exactly one of the suspects is guilty.
Assume that the two innocent people are telling the truth, but that the guilty people might not be. So, the statements from the suspects can be encoded as ""If suspect_is_innocent, then some other facts are true"".
Let the propositional variables have the following definitions:
\begin{itemize}
\item $A=$ Adams is innocent
\item $B=$ Brown is innocent
\item $C=$ Clark is innocent
\item $X=$ Brown knew the victim
\item $Y=$ Brown was out of town
\item $Z=$ Adams was out of town
\item $W=$ Clark hated the victim
\end{itemize}
We can write down propositional logic axioms for each of the four statements defining this problem. For propositional resolution, we need to convert these sentences to CNF. We will ask you to convert one sentence at a time. Enter one CNF formula corresponding to the specified sentence in each of the answer spaces below.
Enter each CNF formula as a list of lists of literal strings. A literal string is either a propositional symbol, e.g. 'A' or the negation of a propositional symbol, e.g. ' $A$ '. A typical clause will look like: $\left[{ }^{\prime} A ', ' \sim B\right.$ ', ' $\left.\sim C '\right]$. And a CNF formula is a list of clauses. Do not include any spaces in the strings. 
The first axiom is: $A \Rightarrow(X \wedge W)$
Enter the CNF as a formula following the syntax described above.","[['~A', 'X'], ['~A', 'W']]"
112,Mathematics,18.02,Calculus II,18.01,None,Midterm Exam 4,Divergence,3,a,1.125,Text,"Let $\vec{F}=x z \hat{i}+y z \hat{j}-\left(z^2+1\right) \hat{k}$. Let $H$ be the solid hemisphere of radius 1 , consisting of the half of the solid sphere of radius 1 centered at the origin and above the $x y$-plane. Let $S$ be the surface of $H$. So $S$ includes the curved top surface $T$ and the flat bottom surface $B$. 
Compute the divergence $\vec{\nabla} \cdot \vec{F}$.",Numerical,"$$
\vec{\nabla} \cdot \vec{F}=\partial_x(x z)+\partial_y(y z)+\partial_z\left(-\left(z^2+1\right)\right)=z+z-2 z=0 .
$$","Let $\vec{F}=x z \hat{i}+y z \hat{j}-\left(z^2+1\right) \hat{k}$. Let $H$ be the solid hemisphere of radius 1 , consisting of the half of the solid sphere of radius 1 centered at the origin and above the $x y$-plane. Let $S$ be the surface of $H$. So $S$ includes the curved top surface $T$ and the flat bottom surface $B$. 
Calculate the flux of $\vec{F}$ through $S$ using the divergence theorem, by evaluating the triple integral (not the surface integral). Assume $S$ is oriented outward.","$$
\oiint_S \vec{F} \cdot d \vec{S}=\iiint_S \vec{\nabla} \cdot \vec{F} d V=0 .
$$","Let $\vec{F}=x z \hat{i}+y z \hat{j}-\left(z^2+1\right) \hat{k}$. Let $H$ be the solid hemisphere of radius 1 , consisting of the half of the solid sphere of radius 1 centered at the origin and above the $x y$-plane. Let $S$ be the surface of $H$. So $S$ includes the curved top surface $T$ and the flat bottom surface $B$. 
Use the results to calculate the flux of $\vec{F}$ through $T$ (not by evaluating the surface integral directly). Assume that $T$ is oriented upward.",$0-\pi=-\pi$.,"Let $\vec{F}=x z \hat{i}+y z \hat{j}-\left(z^2+1\right) \hat{k}$. Let $H$ be the solid hemisphere of radius 1 , consisting of the half of the solid sphere of radius 1 centered at the origin and above the $x y$-plane. Let $S$ be the surface of $H$. So $S$ includes the curved top surface $T$ and the flat bottom surface $B$. 
Calculate the flux of $\vec{F}$ through $B$ by any method. Assume $B$ is oriented downward.",$\oiint_B \vec{F} \cdot \vec{n} d S=1 \cdot \operatorname{Area}(B)=\pi$.
6,EECS,18.C06,Linear Algebra and Optimization,18.02,None,Problem Set 1,Linear Maps,3,a,0.2469135802,Text,"Let $x \in \mathbb{R}^{5}$, and consider the linear map $f(x)$ defined by
$$
\left[\begin{array}{c}
x_{1} \\
x_{2} \\
\vdots \\
x_{5}
\end{array}\right] \mapsto\left[\begin{array}{c}
x_{1} \\
x_{1}+x_{2} \\
\vdots \\
x_{1}+x_{2}+\cdots+x_{5}
\end{array}\right]
$$
Compute a matrix representing this linear map-i.e. find a matrix $A$ so that $f(x)=A x$.",Expression,"Consider
$$
\begin{aligned}
{\left[\begin{array}{l}
x_{1} \\
x_{2} \\
x_{3} \\
x_{4} \\
x_{5}
\end{array}\right] \mapsto\left[\begin{array}{c}
x_{1} \\
x_{1}+x_{2} \\
x_{1}+x_{2}+x_{3} \\
x_{1}+x_{2}+x_{3}+x_{4} \\
x_{1}+x_{2}+x_{3}+x_{4}+x_{5}
\end{array}\right] } \\
=& x_{1}\left[\begin{array}{l}
1 \\
1 \\
1 \\
1 \\
1
\end{array}\right]+x_{2}\left[\begin{array}{l}
0 \\
1 \\
1 \\
1 \\
1
\end{array}\right]+x_{3}\left[\begin{array}{l}
0 \\
0 \\
1 \\
1 \\
1
\end{array}\right]+x_{4}\left[\begin{array}{l}
0 \\
0 \\
0 \\
1 \\
1
\end{array}\right]+x_{5}\left[\begin{array}{l}
0 \\
0 \\
0 \\
0 \\
0
\end{array}\right] \\
=& {\left[\begin{array}{lllll}
1 & 0 & 0 & 0 & 0 \\
1 & 1 & 0 & 0 & 0 \\
1 & 1 & 1 & 0 & 0 \\
1 & 1 & 1 & 1 & 0 \\
1 & 1 & 1 & 1 & 1
\end{array}\right]\left[\begin{array}{l}
x_{1} \\
x_{2} \\
x_{3} \\
x_{4} \\
x_{5}
\end{array}\right] . }
\end{aligned}
$$
This implies that the linear map $f$ corresponds to $A=\left[\begin{array}{lllll}1 & 0 & 0 & 0 & 0 \\ 1 & 1 & 0 & 0 & 0 \\ 1 & 1 & 1 & 0 & 0 \\ 1 & 1 & 1 & 1 & 0 \\ 1 & 1 & 1 & 1 & 1\end{array}\right]$.","Let $x \in \mathbb{R}^{5}$, and consider the linear map $f(x)$ defined by
$$
\left[\begin{array}{c}
x_{1} \\
x_{2} \\
\vdots \\
x_{5}
\end{array}\right] \mapsto\left[\begin{array}{c}
x_{1} \\
x_{1}+x_{2} \\
\vdots \\
x_{1}+x_{2}+\cdots+x_{5}
\end{array}\right]
$$
Find a vector $x \in \mathbb{R}^{5}$ (if it exists) such that
$$
A x=\left[\begin{array}{l}
3 \\
1 \\
4 \\
1 \\
5
\end{array}\right] .
$$","Set $v=\left[\begin{array}{l}3 \\ 1 \\ 4 \\ 1 \\ 5\end{array}\right]$ in part $b$. We then can solve
$$
x=\left[\begin{array}{c}
3 \\
1-3 \\
4-1 \\
1-4 \\
5-1
\end{array}\right]=\left[\begin{array}{c}
3 \\
-2 \\
3 \\
-3 \\
4
\end{array}\right].
$$","Let $x \in \mathbb{R}^{5}$, and consider the linear map $f(x)$ defined by
$$
\left[\begin{array}{c}
x_{1} \\
x_{2} \\
\vdots \\
x_{5}
\end{array}\right] \mapsto\left[\begin{array}{c}
x_{1} \\
x_{1}+x_{2} \\
\vdots \\
x_{1}+x_{2}+\cdots+x_{5}
\end{array}\right]
$$
Is the span of the columns of $A$ all of $\mathbb{R}^{5}$? Justify your answer.","For any 5 -dimensional vector $v=\left[\begin{array}{l}v_{1} \\ v_{2} \\ v_{3} \\ v_{4} \\ v_{5}\end{array}\right]$, we can backsolve $x \in \mathbb{R}^{5}$ that $A x=v$ by comparing
$$
\left[\begin{array}{c}
x_{1} \\
x_{1}+x_{2} \\
x_{1}+x_{2}+x_{3} \\
x_{1}+x_{2}+x_{3}+x_{4} \\
x_{1}+x_{2}+x_{3}+x_{4}+x_{5}
\end{array}\right]=\left[\begin{array}{l}
v_{1} \\
v_{2} \\
v_{3} \\
v_{4} \\
v_{5}
\end{array}\right]
$$
which yields $x_{1}=v_{1}, x_{2}=v_{2}-v_{1}, x_{3}=v_{3}-v_{2}, x_{4}=v_{4}-v_{3}$, and $x_{5}=v_{5}-v_{4}$. In other words, for any $v \in \mathbb{R}^{5}$, we can find $x \in \mathbb{R}^{5}$ that $A x=v$. This means that the columns of $A$ span over all of $\mathbb{R}^{5}$.","Let $f: \mathbb{R}^2 \rightarrow \mathbb{R}^2$ be the linear transformation that projects each point vertically to a point on the $x$-axis. For example $f\left(\begin{array}{l}2 \\ 1\end{array}\right)=\left(\begin{array}{l}2 \\ 0\end{array}\right)$ and $f\left(\begin{array}{l}-2 \\ -3\end{array}\right)=\left(\begin{array}{c}-2 \\ 0\end{array}\right)$, see picture. Find the associated $2 \times 2$ matrix $A$.","$$
A=\left(\begin{array}{ll}
1 & 0 \\
0 & 0
\end{array}\right) .
$$"
164,Mathematics,18.01,Calculus I,None,None,Problem Set 4,Integrals,17,b,0.07919746568,Text,"Suppose we have an integral $\int_{0}^{B} f(x) d x$. As $B$ gets larger and larger and goes to infinity, then how does this expression behave? It depends on $f(x)$. Here's an example where it behaves nicely: 
$$
\int_{0}^{B} e^{-x} d x=-\left.e^{-x}\right|_{0} ^{B}=-e^{-B}+1
$$
So as $B$ goes to infinity, $\int_{0}^{B} e^{-x} d x$ goes to 1 . We write this as
$$
\int_{0}^{\infty} e^{-x} d x=1
$$
It means that the total area under the graph of $e^{x}$, for all $x \geq 0$, is equal to 1 .
Here's an example that behaves not nicely. $\int_{0}^{B} \sin x d x=-\left.\cos x\right|_{0} ^{B}=-\cos (B)+1$. As $B$ gets larger and larger, the expression $-\cos (B)+1$ keeps going back and forth between 0 and 2, and never approaches any particular number. In this situation, $\int_{0}^{\infty} \sin x d x$ doesn't make sense.
In general $\int_{0}^{\infty} f(x) d x$ means the limit as $B$ goes to infinity of $\int_{0}^{B} f(x) d x$.
Find $\int_{0}^{\infty} 2^{-x} d x$. Hint: write $2^{-x}$ as $e$ to a power.",Numerical,"$$
\int_{0}^{B} 2^{-x} d x=\int_{0}^{B} e^{-\ln (2) \cdot x} d x=\int_{0}^{B}=\frac{1}{\ln 2} \int_{0}^{\ln (2) \cdot B} e^{-u} d u=\frac{1}{\ln 2}\left(1-2^{-B}\right)
$$
Letting $B \rightarrow \infty$,
$$
\int_{0}^{\infty} 2^{-x} d x=\frac{1}{\ln 2}
$$","Suppose we have an integral $\int_{0}^{B} f(x) d x$. As $B$ gets larger and larger and goes to infinity, then how does this expression behave? It depends on $f(x)$. Here's an example where it behaves nicely: 
$$
\int_{0}^{B} e^{-x} d x=-\left.e^{-x}\right|_{0} ^{B}=-e^{-B}+1
$$
So as $B$ goes to infinity, $\int_{0}^{B} e^{-x} d x$ goes to 1 . We write this as
$$
\int_{0}^{\infty} e^{-x} d x=1
$$
It means that the total area under the graph of $e^{x}$, for all $x \geq 0$, is equal to 1 .
Here's an example that behaves not nicely. $\int_{0}^{B} \sin x d x=-\left.\cos x\right|_{0} ^{B}=-\cos (B)+1$. As $B$ gets larger and larger, the expression $-\cos (B)+1$ keeps going back and forth between 0 and 2, and never approaches any particular number. In this situation, $\int_{0}^{\infty} \sin x d x$ doesn't make sense.
In general $\int_{0}^{\infty} f(x) d x$ means the limit as $B$ goes to infinity of $\int_{0}^{B} f(x) d x$.
Find $\int_{0}^{\infty} e^{-x / 100} d x$.","Substituting $u(x)=x / 100$, we have
$$
\begin{aligned}
& \int_{0}^{B} e^{-x / 100} d x=100 \int_{0}^{B} e^{-\frac{x}{100}} \frac{1}{100} d x=100 \int_{0}^{\frac{B}{100}} e^{-u} d u=100\left(1-e^{-B / 100}\right) . \\
& \text { Letting } B \rightarrow \infty, \\
& \qquad \int_{0}^{\infty} e^{-x / 100} d x=\lim _{B \rightarrow \infty} 100\left(1-e^{-B / 100}\right)=100 .
\end{aligned}
$$","Sometimes we will encounter a trickier limit when we try to understand the limiting
behavior of $\int_{0}^{B} f(x) d x$. For instance, we may meet something like $\lim _{B \rightarrow \infty} B e^{-B / 100}$. In this situation, the exponential term always wins out over a polynomial term like $B$ or $B^{2}$. Roughly speaking, the reason is that exponentials grow so fast that they dominate polynomials.
Give a convincing argument that when $B>10^{4}, B e^{-B / 100}$ is smaller than .001. If you can do this, then you basically understand that $\lim _{B \rightarrow \infty} B e^{-B / 100}=$ 0.","By taking the logarithm, $B e^{-B / 100}<0.001$ is equivalent with
$$
-\frac{B}{100}+\ln B<\ln \left(10^{-3}\right)=-3 \ln (10)
$$
or equivalently
$$
\frac{B}{100}-\ln B>3 \ln (10) .
$$
This is true for $B=10^{4}$ since
$$
100-4 \ln 10>90>3 \ln 10
$$
Furthermore, the left-hand side of (1) stays larger than $2 \ln (10)$ because is is increasing from $B \geq 10^{4}$. Indeed, the derivative of the left-hand side of (1) is
$$
\frac{1}{100}-\frac{1}{B}>0.
$$","Consider the integral $\int_{1}^{1.01} e^{x^{3}} d x$. Let $u=x^{3}$. As $x$ goes from 1 to $1.01, x^{3}$ goes from 1 to $1.01^{3}$. So let's also consider the integral $\int_{1}^{1.01^{3}} e^{u} d u$. The problem is to understand how these integrals are related to each other.
$$
\int_{1}^{1.01^{3}} e^{u} d u=A \int_{1}^{1.01} e^{x^{3}} d x
$$
Is $A$ closest to 1 or 2 or 3 or $(1 / 2)$ or (1/3)? Explain your reasoning.
Hint: Make a sketch of the graph of $e^{x^{3}}$ for $1 \leq x \leq 1.01$ and the graph of $e^{u}$ for $1 \leq u \leq 1.01^{3}$. Compare the geometric features of the two graphs.
Suppose that $u(x)$ is a function of $x$. Substitution says that
$$
\int_{a}^{b} f(u(x)) \frac{d u}{d x} d x=\int_{u(a)}^{u(b)} f(u) d u
$$
In the last problem, $u(x)=x^{3}, f(y)=e^{y}, a=1$ and $b=1.01$. In this situation, the interval from $a$ to $b$ is so short that $\frac{d u}{d x}$ is almost constant on this interval, and the factor $A$ in the last problem corresponds to $\frac{d u}{d x}$. (You can use this to check the last problem if you want.) The geometric reasoning you did in the last problem is supposed to give intuition about why substitution works.
To use substitution, we start with an integral in terms of $x$. Then we try to pick a good function $u(x)$ so that we can write the integral in the form $\int_{a}^{b} f(u(x)) \frac{d u}{d x} d x$.
Example.
$$
\int_{0}^{2} \frac{1}{1+2 x} d x
$$
Here it looks reasonable to choose $u(x)=1+2 x$, because then the complicated expression $\frac{1}{1+2 x}$ becomes the simpler expression $\frac{1}{u}$. If we do that, we find $\frac{d u}{d x}=2$. So
$$
\frac{1}{1+2 x}=\frac{1}{u}=\frac{1}{2} \cdot \frac{1}{u} \cdot 2=\frac{1}{2} \cdot \frac{1}{u} \cdot \frac{d u}{d x} .
$$
So
$$
\int_{0}^{2} \frac{1}{1+2 x} d x=\int_{0}^{2} \frac{1}{2} \cdot \frac{1}{u} \cdot \frac{d u}{d x} d x=\int_{1}^{5} \frac{1}{2} \cdot \frac{1}{u} d u
$$
In the last step, $u$ goes from 1 to 5 , because $u=1+2 x$ and $x$ goes from 0 to 2 . Now we can evaluate the integral 
$$
\int_{1}^{5} \frac{1}{2} \cdot \frac{1}{u} d u=\frac{1}{2} \int_{1}^{5} \frac{1}{u} d u=\left.\frac{1}{2} \ln u\right|_{1} ^{5}=\frac{1}{2} \ln 5
$$","We have $e^{u} \approx e^{\left(1^{3}\right)}=e$ for $1 \leq u \leq 1.01^{3}$ and $e^{x^{3}} \approx e^{1^{3}}=1$ for $1 \leq x \leq 1.01$, so
$$
\int_{1}^{1.01^{3}} e^{u} d u \approx \underbrace{\left((1.01)^{3}-1\right)}_{\text {length of interval }} e^{1} \approx 0.03 e \quad \text { and } \quad \int_{1}^{1.01} e^{x^{3}} d x \approx \underbrace{0.01}_{\text {length of interval }} e .
$$
Thus, $A \approx 3$ :
$$
\int_{1}^{1.01^{3}} e^{u} d u \approx 3 \int_{1}^{1.01} e^{x^{3}} d x .
$$"
88,Mathematics,18.102,Introduction to Functional Analysis,"18.C06, 18.100B",None,Final Exam,Hölder Condition,2,b,2.25,Text,"Let $f \in L^{q}(0,1)$ for some $q>1$ and
$$
h(x):=\int_{[0, x]} f, x \in[0,1].
$$
Let $\frac{1}{p}+\frac{1}{q}=1$.
Let $1 \leq r<p$. Must $h$ satisfy the Hölder condition with parameter $\frac{1}{r}$?",Open,"No. Let $r<s<p$ and $f=x^{\frac{1}{s}-1}$. Then $h=s x^{\frac{1}{s}}$, so it does not satisfy the Hölder condition with parameter $\frac{1}{r}$ (for $y=0$ ). But $f \in L^{q}(0,1)$ since
$$
q\left(1-\frac{1}{s}\right)<q\left(1-\frac{1}{p}\right)=1.
$$","Let $f \in L^{q}(0,1)$ for some $q>1$ and
$$
h(x):=\int_{[0, x]} f, x \in[0,1].
$$
Let $\frac{1}{p}+\frac{1}{q}=1$.
Show that $h$ satisfies the Hölder condition with parameter $\frac{1}{p}$ : there exists $C>0$ such that
$$
|h(x)-h(y)| \leq C|x-y|^{\frac{1}{p}}, 0 \leq x, y \leq 1.
$$","Let $y<x$ and $C=\|f\|_{q}$. By the Hölder inequality
$$
|h(x)-h(y)|=\left|\int_{y}^{x} f(t) d t\right| \leq\left(\int_{y}^{x} 1^{p} d t\right)^{\frac{1}{p}}\left(\int_{y}^{x}|f(t)|^{q} d t\right)^{\frac{1}{q}}=C|x-y|^{\frac{1}{p}}.
$$","If $U \subset \mathbb{R}$ is measureable and $f \in \mathcal{L}^{1}(\mathbb{R})$ show that
$$
\int_{U} f=\int \chi_{U} f \in \mathbb{C}
$$
is well-defined. Prove that if $f \in \mathcal{L}^{1}(\mathbb{R})$ then
$$
I_{f}(x)= \begin{cases}\int_{(0, x)} f & x \geq 0 \\ -\int_{(x, 0)} f & x<0\end{cases}
$$
is a bounded continuous function on $\mathbb{R}$.","The integral is well-defined by Problem 4.3.3. The function $I_{f}(x)$ is well defined and bounded since $I_{|f|}(x)$ is bounded by $\int|f|<\infty$.
To prove continuity it is sufficient to check that the sequence $\int_{\left(x, x_{n}\right)} f$ for $x_{n}<x$ and $\int_{\left(x_{n}, x\right)} f$ for $x \leq x_{n}$ tends to 0 as $x_{n}$ tends to $x$. The sequence $\chi_{\left(x, x_{n}\right)} f$ (resp. $\chi_{\left(x_{n}, x\right)} f$ ) is dominated by $|f| \in \mathcal{L}^{1}(\mathbb{R})$ and its limit is 0 a.e. The statement now follows from dominated convergence theorem.","Suppose that $f \in L^{2}(\mathbb{R})$ is such that there exists a function $v \in L^{2}(\mathbb{R})$ satisfying
$$
\int_{\mathbb{R}} f \phi^{\prime}=\int_{\mathbb{R}} v \widehat{\phi} \quad \forall \phi \in \mathcal{S}(\mathbb{R})
$$
where $\widehat{\phi}$ is the Fourier transform of $\phi$. Show that $f \in C_{0}(\mathbb{R}) \subset L^{2}(\mathbb{R})$, where $C_{0}(\mathbb{R})$ is the space of continuous functions on $\mathbb{R}$ with zero limit at $\pm \infty$.
You may use that if $h$ is a locally $L^{2}$ function on $\mathbb{R}$ such that $\int h \phi=0$ for every $\phi \in C_{c}^{\infty}(\mathbb{R})$ then $h=0$ a.e. (as $C_{c}^{\infty}(I)$ is dense in $L^{2}(I)$ for every interval $I$).","Let $\psi:=\widehat{\phi}$. Then $\phi(x)=\frac{1}{2 \pi} \widehat{\psi}(-x)$, so
$$
\int_{\mathbb{R}} f(-x) \widehat{i \xi \psi}(x)=\int v \psi \quad \forall \psi \in \mathcal{S}(\mathbb{R}).
$$
So
$$
\int_{\mathbb{R}} \widehat{f}(-\xi) i \xi \psi(\xi)=\int v \psi
$$
from which it follows that the locally $L^{2}$-function $h(\xi):=i \xi \widehat{f}(-\xi)-v(\xi)$ is orthogonal to $\mathcal{S}(\mathbb{R})$, hence to its subspace $C_{c}^{\infty}(\mathbb{R})$. Thus $h=0$ a.e., i.e., $\xi \widehat{f} \in L^{2}(\mathbb{R})$. This means $\widehat{f} \in L^{1}(\mathbb{R})$, since
$$
\left(\int|\widehat{f}|\right)^{2} \leq \int \frac{1}{1+\xi^{2}} \cdot \int\left(1+\xi^{2}\right)|\widehat{f}|^{2}=\pi \int\left(1+\xi^{2}\right)|\widehat{f}|^{2}<\infty.
$$
so $f$ is continuous and goes to zero at infinity."
9,Mathematics,18.2,Principles of Discrete Applied Mathematics,None,18.C06,Problem Set 3,Combinatorial Identities,1,b,0.3819444444,Text,"Prove the following combinatorial identities, where $n, k, a$ are non-negative integers, using the ""counting two ways"" technique.
$\sum_{k=0}^{n}\left(\begin{array}{c}a+k \\ k\end{array}\right)=\left(\begin{array}{c}a+n+1 \\ n\end{array}\right)$",Open,"Let's rewrite both sides using the fact that $\left(\begin{array}{l}n \\ k\end{array}\right)=\left(\begin{array}{c}n \\ n-k\end{array}\right)$. The LHS is equal to
$$
\sum_{k=0}^{n}\left(\begin{array}{c}
a+k \\
a
\end{array}\right)
$$
and the RHS to
$$
\left(\begin{array}{c}
a+n+1 \\
a+1
\end{array}\right)
$$
Both of these expressions count the ways to choose $a+1$ elements out of $a+n+1$ : the RHS is the usual binomial formula; the LHS chooses the largest element to be included and sets it to $a+k+1$, subsequently it chooses $a$ elements out of $\{1,2, \ldots, a+k\}$.","Prove the following combinatorial identities, where $n, k, a$ are non-negative integers, using the ""counting two ways"" technique.
$\sum_{k=0}^{n} k\left(\begin{array}{l}n \\ k\end{array}\right)=n 2^{n-1}$","Rearranging terms, what we want to prove is equivalent to $\sum_{k=0}^{n} k \frac{(\substack{n \\ k}}{2^{n}}=\frac{n}{2}$ Both sides are the expected size of a randomly chosen subset of $[n]$ elements. On the LHS, the expectation is calculated by choosing the size of the set first, then a random set of that size. On the RHS, this expectation is calculated by linearity of expectation as $\mathbb{E}\left(\sum_{i=1}^{n} X_{i}\right)$, where $X_{i}$ is a 0-1 random variable, which is 1 with probability $1 / 2$.","Prove the following combinatorial identities, where $n, k, a$ are non-negative integers, using the ""counting two ways"" technique.
$\left(\begin{array}{c}2 n \\ n\end{array}\right)=\sum_{k=0}^{n}\left(\begin{array}{c}n \\ k\end{array}\right)^{2}$","$\left(\begin{array}{c}2 n \\ n\end{array}\right)$ is the number of ways that $n$ red balls and $n$ green balls can be arranged in a row. Another way of counting this is as follows. Split the row into a left and a right half. For each $k$, you can place $k$ greens on the left (which can be done in $\left(\begin{array}{l}n \\ k\end{array}\right)$ ways), you have to place and the remaining $n-k$ greens on the right (or equivalently $k$ reds on the right), which can also be done in $\left(\begin{array}{c}n \\ n-k\end{array}\right)=\left(\begin{array}{l}n \\ k\end{array}\right)$ ways. This gives the expression $\sum_{k=0}^{n}\left(\begin{array}{l}n \\ k\end{array}\right)^{2}$.","Prove the following combinatorial identities, where $n, k, a$ are non-negative integers, using the ""counting two ways"" technique.
$\left(\begin{array}{c}3 n \\ 3\end{array}\right)=3\left(\begin{array}{l}n \\ 3\end{array}\right)+6 n\left(\begin{array}{c}n \\ 2\end{array}\right)+n^{3}$","$\left(\begin{array}{c}3 n \\ 3\end{array}\right)$ is the number of ways of ticking 3 boxes in a $3 \times n$ grid (i.e., with 3 rows). We can also count this by splitting into the following 3 cases.
\begin{itemize}
\item All marks are in the same row (3 possibilities for the row, $\left(\begin{array}{l}n \\ 3\end{array}\right)$ ways of putting 3 identical marks in that row).
\item One row has two marks, another has 1 mark, the remaining has none. In this case there are 3 ! possible orderings of the rows and $n\left(\begin{array}{l}n \\ 2\end{array}\right)$ choices given that ordering.
\item One mark per row, $n^{3}$ possibilities.
\end{itemize}"
284,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Final Exam,Hidden Markov Model,2,d,1,Text,"Consider an HMM estimating the state of a propulsion system using IMU measurements. The propulsion system is either working $(W)$ or not working $(\neg W)$. The IMU measurements are accelerating $(A)$ or not accelerating $(\neg A)$. We can specify our HMM by the following model:
$\text {Prior } p\left(s_0\right)$:
\begin{aligned}
&\begin{array}{l|l}
s_t & p\left(s_t\right) \\
\hline W & .5 \\
\neg W & .5 \\
\end{array}
\end{aligned}
$P\left(s_{t+1} \mid s_t\right)$:
\begin{array}{lll|l} 
& s_t & s_{t+1} & P\left(s_{t+1} \mid s_t\right) \\
\hline & W & W & .75 \\
& W & \neg W & .25 \\
& \neg W & W & 0 \\
& \neg W & \neg W & 1 \\
\end{array}
$P\left(o_t \mid s_t\right)$:
\begin{array}{lll|l} 
& s_t & o_t & P\left(o_t \mid s_t\right) \\
\hline & W & A & .8 \\
& W & \neg A & .2 \\
& \neg W & A & .1 \\
& \neg W & \neg A & .9 \\
\end{array}
If there is no observation at time $t=0$, and the observation at time $t=1$ is $o_{1}=A$, please compute $p\left(s_{1} \mid o_{1}=A\right)$. You can express the probabilities as fractions if that is helpful.",Numerical,"$$
\begin{aligned}
p\left(s_{1} \mid o_{1}=A\right) & =\alpha p\left(o_{1}=A \mid s_{1}\right) \odot \sum p\left(s_{1} \mid s_{0}\right) p\left(s_{0}\right) \\
& =\alpha\left[\begin{array}{l}
.8 \\
.1
\end{array}\right] \odot\left[\begin{array}{l}
.75 \times .5+0 \times .5 \\
1 \times .5+.25 \times .5
\end{array}\right] \\
& =\alpha\left[\begin{array}{l}
.8 \\
.1
\end{array}\right] \odot\left[\begin{array}{l}
.375 \\
.625
\end{array}\right] \\
& =\alpha\left[\begin{array}{c}
.3 \\
.0625
\end{array}\right] \\
& =\left[\begin{array}{l}
.828 \\
.172
\end{array}\right]
\end{aligned}
$$","I use an HMM to model the state of my leftover food over time. The state space is $\{$tasty, smelly,furry $\}$. Initially, I'm sure they're tasty: $P\left(S_{0}=\right.$ tasty $)=1$. The state transition model is:
\begin{tabular}{cc|ccc} 
& & \multicolumn{3}{|c}{$S_{t+1}$} \\
& & tasty & smelly & furry \\
\hline \multirow{3}{*}{$S_{t}$} & tasty & $\frac{2}{3}$ & $\frac{1}{3}$ & 0 \\
& smelly & $\frac{1}{6}$ & $\frac{1}{2}$ & $\frac{1}{3}$ \\
& furry & 0 & 0 & 1
\end{tabular}
You decide to estimate $P\left(S_{2}\right)$ by forward (prior) sampling. You generate 100 sample trajectories of length 3 for your leftovers. Given those trajectories how can you construct an estimate of $P\left(S_{2}\right)$?","(number of trajectories ending in tasty / 100, number of trajectories ending in smelly / 100, number of trajectories ending in furry / 100)","I use an HMM to model the state of my leftover food over time. The state space is $\{$tasty, smelly,furry $\}$. Initially, I'm sure they're tasty: $P\left(S_{0}=\right.$ tasty $)=1$. The state transition model is:
\begin{tabular}{cc|ccc} 
& & \multicolumn{3}{|c}{$S_{t+1}$} \\
& & tasty & smelly & furry \\
\hline \multirow{3}{*}{$S_{t}$} & tasty & $\frac{2}{3}$ & $\frac{1}{3}$ & 0 \\
& smelly & $\frac{1}{6}$ & $\frac{1}{2}$ & $\frac{1}{3}$ \\
& furry & 0 & 0 & 1
\end{tabular}
What is $P\left(S_{2} \mid S_{0}=\right.$ tasty, $S_{4}=$ furry)? Just explain how to compute this using the messages you generated above (without numbers).","Multiply the messages coming in from $\phi_{12}$ and from $\phi_{23}$, then normalize.","I use an HMM to model the state of my leftover food over time. The state space is $\{$tasty, smelly,furry $\}$. Initially, I'm sure they're tasty: $P\left(S_{0}=\right.$ tasty $)=1$. The state transition model is:
\begin{tabular}{cc|ccc} 
& & \multicolumn{3}{|c}{$S_{t+1}$} \\
& & tasty & smelly & furry \\
\hline \multirow{3}{*}{$S_{t}$} & tasty & $\frac{2}{3}$ & $\frac{1}{3}$ & 0 \\
& smelly & $\frac{1}{6}$ & $\frac{1}{2}$ & $\frac{1}{3}$ \\
& furry & 0 & 0 & 1
\end{tabular}
What is the state distribution $P\left(S_{2} \mid S_{0}=\right.$ tasty)? Show your work. It's fine to leave numerical quantities in terms of expressions (e.g. $7 * 5 / 3)$.","$P\left(S_{1}\right)=\left(\frac{2}{3}, \frac{1}{3}, 0\right)$ obtained directly from the transition model. Now, we can compute the joint on $S_{1}, S_{2}$ by multiplying the this factor by the table, getting
\begin{tabular}{cc|ccc} 
& & \multicolumn{3}{|c}{$S_{2}$} \\
& & tasty & smelly & furry \\
\hline \multirow{3}{*}{$S_{1}$} & tasty & $\frac{2}{3} \times \frac{2}{3}$ & $\frac{1}{3} \times \frac{2}{3}$ & $0 \times \frac{2}{3}$ \\
& smelly & $\frac{1}{6} \times \frac{1}{3}$ & $\frac{1}{2} \times \frac{1}{3}$ & $\frac{1}{3} \times \frac{1}{3}$ \\
& furry & $0 \times 0$ & $0 \times 0$ & $1 \times 0$
\end{tabular}
Now, we marginalize out $S_{1}$ to get a factor on $S_{2}$ :
$$
\begin{array}{r}
\left(\frac{2}{3} \times \frac{2}{3}+\frac{1}{6} \times \frac{1}{3}, \frac{1}{3} \times \frac{2}{3}+\frac{1}{2} \times \frac{1}{3}, \frac{1}{3} \times \frac{1}{3}\right) \\
\left(\frac{1}{2}, \frac{7}{18}, \frac{1}{9}\right)
\end{array}
$$"
236,EECS,6.3,Signal Processing,"6.100A, 18.03",None,Final Exam,Discrete-Time Fourier Transforms,1,b,1,Text,"Each part of this problem describes a different discrete-time signal $f_{i}[n]$ and then asks you to determine the $k=3$ component of the DFT of that signal, where the DFT is computed with analysis window $N=16$:
$$
F_{i}[3]=\frac{1}{16} \sum_{n=0}^{15} f_{i}[n] e^{-j 2 \pi 3 n / 16}
$$
Let $f_{2}[n]=\cos (3 \pi n / 8)$. Enter a closed form expression for $F_{2}[3]$ below.",Expression,"$F_{2}[3] = \frac{1}{2}$.
$$
\begin{gathered}
f_{2}[n]=\cos (3 \pi n / 8)=\frac{e^{j 6 \pi n / 16}+e^{-j 6 \pi n / 16}}{2}=\sum_{k=0}^{15} F_{2}[k] e^{j 2 \pi k n / 16}
\end{gathered}
$$
Since the basis functions for the DFT are orthogonal, it follows that
$$
F_{2}[k]= \begin{cases}\frac{1}{2} & \text { if } k=3 \text { or } k=13 \\ 0 & \text { otherwise }\end{cases}
$$","Each part of this problem describes a different discrete-time signal $f_{i}[n]$ and then asks you to determine the $k=3$ component of the DFT of that signal, where the DFT is computed with analysis window $N=16$:
$$
F_{i}[3]=\frac{1}{16} \sum_{n=0}^{15} f_{i}[n] e^{-j 2 \pi 3 n / 16}
$$
Let $f_{3}[n]=\cos (3 \pi n / 8-9 \pi / 8)$. Enter a closed form expression for $F_{3}[3]$ below.","$$
\mathrm{F}_{3}[3]=\overline{\frac{1}{2} e^{-j 2 \pi 9 / 16}}
$$
Since
$$
f_{3}[n]=f_{2}[n-3]
$$
it follows that
$$
\mathrm{F}_{3}[\mathrm{k}]=\mathrm{e}^{-\mathrm{j} 2 \pi \mathrm{k} 3 / 16} \mathrm{~F}_{2}[\mathrm{k}]
$$
Therefore $F_{3}[3]=\frac{1}{2} e^{-j 2 \pi 9 / 16}$.","Each part of this problem describes a different discrete-time signal $f_{i}[n]$ and then asks you to determine the $k=3$ component of the DFT of that signal, where the DFT is computed with analysis window $N=16$:
$$
F_{i}[3]=\frac{1}{16} \sum_{n=0}^{15} f_{i}[n] e^{-j 2 \pi 3 n / 16}
$$
Let $f_{1}[n]=(-1)^{n}$ Enter a closed form expression for $F_{1}[3]$ below.","$F_{1}[3] = 0$.
The basis functions for DFTs of length $N=16$ are of the form $e^{-j 2 \pi k n / 16}$. Therefore $f_{1}[n]=(-1)^{n}=e^{-j 2 \pi 8 n / 16}$ contains a single basis function, and that basis function is at index $k=8$. Since the $k=8$ and $k=3$ basis functions are orthogonal, $F_{1}$[3] must be zero.
Mathematically:
$$
\begin{aligned}
F_{1}[k] & =\frac{1}{N} \sum_{n=0}^{N-1} f_{1}[n] e^{-j 2 \pi k n / N}=\frac{1}{N} \sum_{n=0}^{N-1}(-1)^{n} e^{-j 2 \pi k n / N}=\frac{1}{N} \sum_{n=0}^{N-1} e^{-j \pi n} e^{-j 2 \pi k n / N} \\
& =\frac{1}{N} \sum_{n=0}^{N-1} e^{-j \pi N n / N} e^{-j 2 \pi k n / N}=\frac{1}{N} \sum_{n=0}^{N-1} e^{-j \pi(2 k+N) n / N}=\frac{1}{16}\left(\frac{1-e^{-j \pi 22}}{1-e^{-j \pi 22 / 16}}\right)=0
\end{aligned}
$$","Each part of this problem describes a different discrete-time signal $f_{i}[n]$ and then asks you to determine the $k=3$ component of the DFT of that signal, where the DFT is computed with analysis window $N=16$:
$$
F_{i}[3]=\frac{1}{16} \sum_{n=0}^{15} f_{i}[n] e^{-j 2 \pi 3 n / 16}
$$
Determine a closed form expression for $F_{5}[3]$ where
$$
\begin{aligned}
& f_{5}[n]=\left(\frac{1}{2}\right)^{n} u[n] \\
\end{aligned}
$$","$$
F_{5}[3]=\frac{1}{16}\left(\frac{1-\left(\frac{1}{2}\right)^{16}}{1-\frac{1}{2} e^{-j 2 \pi 3 / 16}}\right)
$$
$$
\begin{aligned}
& F_{5}[k]=\frac{1}{N} \sum_{n=0}^{N-1}\left(\frac{1}{2}\right)^{n} e^{-j 2 \pi k n / N}=\frac{1}{N}\left(\frac{1-\left(\frac{1}{2}\right)^{N} e^{-j 2 \pi k N / N}}{1-\frac{1}{2} e^{-j 2 \pi k / N}}\right)=\frac{1}{N}\left(\frac{1-\left(\frac{1}{2}\right)^{N}}{1-\frac{1}{2} e^{-j 2 \pi k / N}}\right)
\end{aligned}
$$
Substituting $k=3$ and $\mathrm{N}=16$ yields
$$
F_{5}[3]=\frac{1}{16}\left(\frac{1-\left(\frac{1}{2}\right)^{16}}{1-\frac{1}{2} e^{-j 2 \pi 3 / 16}}\right)
$$"
398,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Problem Set 2,Regression,2,f,0.02314814815,Text,"We are interested in performing ordinary least squares regression given data $X, Y$ to find parameters $\theta, \theta_{0}$ that minimize the mean squared error objective: 
$$
J\left(\theta, \theta_{0}\right)=\frac{1}{n} \sum_{i=1}^{n} L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)
$$
where the squared loss is
$$
L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)=\left(\hat{y}^{(i)}-y^{(i)}\right)^{2}=\left(\theta^{T} x^{(i)}+\theta_{0}-y^{(i)}\right)^{2}
$$
Note that the $L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)$ notation here is used to emphasize that the loss depends on both the data sample $\left(x^{(i)}, y^{(i)}\right)$, and the parameters, $\theta$ and $\theta_{0}$. Compared to the $\mathcal{L}_{s}$ notation as used in some part of the notes and the lab, we see that $L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)=\mathcal{L}_{s}\left(h\left(x^{(i)} ; \theta, \theta_{0}\right), y^{(i)}\right)$, where $h\left(x^{(i)} ; \theta, \theta_{0}\right)=\theta^{T} x^{(i)}+\theta_{0}$.
$\tilde{Y}$ is the $n$ by 1 vector of target output values. Write an equation expressing the mean squared loss of $\theta$ in terms of $\tilde{X}$, $\tilde{Y}$, $n$, and $\theta$.
Enter your answer as a Python expression. You can use symbols $X_{-} t i l d e, Y_{-} t i l d e, n$ and theta. Recall that our expression syntax includes transpose ( $x)$ for transpose of an array, inverse( $x$ ) for the inverse of an array, and $x @ y$ to indicate a matrix product of two arrays.
$$
J(\theta)=
$$",Expression,(1/n)*(transpose(Y_tilde - X_tilde@theta)@(Y_tilde - X_tilde@theta)),"We are interested in performing ordinary least squares regression given data $X, Y$ to find parameters $\theta, \theta_{0}$ that minimize the mean squared error objective: 
$$
J\left(\theta, \theta_{0}\right)=\frac{1}{n} \sum_{i=1}^{n} L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)
$$
where the squared loss is
$$
L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)=\left(\hat{y}^{(i)}-y^{(i)}\right)^{2}=\left(\theta^{T} x^{(i)}+\theta_{0}-y^{(i)}\right)^{2}
$$
Note that the $L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)$ notation here is used to emphasize that the loss depends on both the data sample $\left(x^{(i)}, y^{(i)}\right)$, and the parameters, $\theta$ and $\theta_{0}$. Compared to the $\mathcal{L}_{s}$ notation as used in some part of the notes and the lab, we see that $L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)=\mathcal{L}_{s}\left(h\left(x^{(i)} ; \theta, \theta_{0}\right), y^{(i)}\right)$, where $h\left(x^{(i)} ; \theta, \theta_{0}\right)=\theta^{T} x^{(i)}+\theta_{0}$.
Just converting back to the data matrix format we have been using (not transposed), we have
$$
\begin{aligned}
& \theta^{*}= \\
(a) & \left(X Y^{T}\right)^{-1}\left(X X^{T}\right) \\
(b) & \left(X^{T} X\right)^{-1} X^{T} Y \\
(c) & \left(X X^{T}\right)^{-1} X Y^{T} \\
\end{aligned}
$$",(b) & \left(X^{T} X\right)^{-1} X^{T} Y \\,"We are interested in performing ordinary least squares regression given data $X, Y$ to find parameters $\theta, \theta_{0}$ that minimize the mean squared error objective: 
$$
J\left(\theta, \theta_{0}\right)=\frac{1}{n} \sum_{i=1}^{n} L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)
$$
where the squared loss is
$$
L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)=\left(\hat{y}^{(i)}-y^{(i)}\right)^{2}=\left(\theta^{T} x^{(i)}+\theta_{0}-y^{(i)}\right)^{2}
$$
Note that the $L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)$ notation here is used to emphasize that the loss depends on both the data sample $\left(x^{(i)}, y^{(i)}\right)$, and the parameters, $\theta$ and $\theta_{0}$. Compared to the $\mathcal{L}_{s}$ notation as used in some part of the notes and the lab, we see that $L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)=\mathcal{L}_{s}\left(h\left(x^{(i)} ; \theta, \theta_{0}\right), y^{(i)}\right)$, where $h\left(x^{(i)} ; \theta, \theta_{0}\right)=\theta^{T} x^{(i)}+\theta_{0}$.
Next we're interested in the gradient of the objective with respect to $\theta$, written $\nabla_{\theta} J$, but now for a whole data set $X$ (of dimensions $d$ by $n$).
Write an expression for $\nabla_{\theta} J$ using the symbols: $\mathrm{X}$ and $\mathrm{Y}$ for the full set of data, theta, theta_ $\theta$, and $\mathrm{n}$. Here $\mathrm{X}$ has dimensions $d$ by $n$, and $\mathrm{Y}$ has dimensions 1 by $n$. theta_ $\theta$ is a scalar that needs broadcasting, similar to the problem in Homework 1. Remember that you can use @ for matrix product, and you can use transpose(a) to transpose a vector or array.
The Appendix on matrix derivatives in the course notes might help. 
$$
\nabla_{\theta} J=
$$",(2/n)*X@transpose(transpose(theta)@X + theta_0 - Y),"We are interested in performing ordinary least squares regression given data $X, Y$ to find parameters $\theta, \theta_{0}$ that minimize the mean squared error objective: 
$$
J\left(\theta, \theta_{0}\right)=\frac{1}{n} \sum_{i=1}^{n} L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)
$$
where the squared loss is
$$
L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)=\left(\hat{y}^{(i)}-y^{(i)}\right)^{2}=\left(\theta^{T} x^{(i)}+\theta_{0}-y^{(i)}\right)^{2}
$$
Note that the $L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)$ notation here is used to emphasize that the loss depends on both the data sample $\left(x^{(i)}, y^{(i)}\right)$, and the parameters, $\theta$ and $\theta_{0}$. Compared to the $\mathcal{L}_{s}$ notation as used in some part of the notes and the lab, we see that $L_{s}\left(x^{(i)}, y^{(i)} ; \theta, \theta_{0}\right)=\mathcal{L}_{s}\left(h\left(x^{(i)} ; \theta, \theta_{0}\right), y^{(i)}\right)$, where $h\left(x^{(i)} ; \theta, \theta_{0}\right)=\theta^{T} x^{(i)}+\theta_{0}$.
If $X$ is $d$ by $n$ and $Y$ is 1 by $n$, what is the dimension of $\nabla_{\theta} J\left(\theta, \theta_{0}\right)$?",$\mathrm{d}$ by 1
24,Mathematics,18.01,Calculus I,None,None,Problem Set 1,Graphing,10,f,0.04525569467,Text,"Let $f(x)=(1 / 3) x^{3}-x$.
Based on your picture, how many different numbers $x$ solve the equation $(1 / 3) x^{3}-x=0$ ? How many different numbers $x$ solve the equation $(1 / 3) x^{3}-x=1 ?$",Numerical,"Now $f(x)=x^{3} / 3-x$.
The solutions to $f(x)=0$ are the $x$-axis intercepts, of which there are three. The solutions of $f(x)=1$ are the intersections of $f(x)$ with the horizontal line $y=1$. This line runs above the local maximum at $(-1,2 / 3)$, so there's only one intersection.","Let $f(x)=(1 / 3) x^{3}-x$.
There is only one number $x$ which solves the equation $(1 / 3) x^{3}-x=-10$. Is this number $x$ positive or negative? ","Now $f(x)=x^{3} / 3-x$.
This number is negative: The horizontal line $y=-10$ passes far below the minimum at $(1,-2 / 3)$, so $y=-10$ hits the $f(x)$ curve on its left (negative) portion.","Let $f(x)=(1 / 3) x^{3}-x$.
Sanity check. If $x$ is large, say $x>100$, is $f(x)$ positive or negative? How do you know? If $x$ is very negative, say $x<-100$, is $f(x)$ positive or negative? How do you know? Does this match your picture?","Now $f(x)=x^{3} / 3-x$.
When $|x|$ is large, the most important term in $f(x)$ is $x^{3} / 3$; and it has the same sign as $x$. Thus, when $x$ is large, $f(x)$ is positive. When $x$ is very negative, $f(x)$ is very negative. The graph has these characteristics.","Suppose that $f(x)=4 x^{3}-6 x^{2}+1$.
How many solutions are there to the equation $4 x^{3}-6 x^{2}+1=0$?","It can be seen from the above picture that $f(x)$ crosses the $x$ axis three times, which means that $f(x)=0$ has 3 solutions for $x$. "
264,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Lab 10,Recurrent Neural Network,4,a,0.1388888889,Text,"RNNs are often used to process language, for example to map from one sequence of words to another sequence of words.
RNNs, like other NNs, take vectors as input, so to get them to process words we need some way of turning words into vectors. One way to do this is with a one-hot encoding (as we did with characters in the previous problem). But there are lots of lower dimensional but more informative representations of words called ""word embeddings"". One popular technique for producing word embeddings is called word2vec. It assigns each word a vector embedding such that words that appear in similar sentence contexts have embeddings that are close in vector space. Typically, we create these embedding vectors through machine learning techniques (i.e., an embedding weight matrix of size [number of words $\mathrm{x}$ embedding size] is learned).
Here, we investigate a phenomenon that will affect any RNN that uses these embeddings. We've trained embeddings for all the words that appeared in a large dataset of news articles. Instead of loading embeddings for every word in this set (together they take up about $3 \mathrm{~GB} !$ ), we have pre-selected several words whose embeddings have interesting properties.
words = [""woman"", ""man"", ""boy"", ""girl"", ""doctor"", ""nurse"", ""programmer"", ""homemaker"", ""queen"", ""king"", ""receptionist"", ""librarian"", ""socialite"", ""hairdresser"", ""nanny"", ""bookkeeper"", ""stylist"", ""maestro"", ""protege"", ""philosopher"", ""captain"", ""architect"", ""surgeon"", ""brilliant"", ""mother"", ""father""]
The function below takes two lists of words and computes the cosine distance for every pair $\left(w_{1}, w_{2}\right)$ with $w_{1}$ drawn from the first list and $w_{2}$ drawn from the second:
$$
d\left(w_{1}, w_{2}\right)=1-\frac{w_{1} \cdot w_{2}}{\left\|w _ { 1 } \left|\left\|\mid w_{2}\right\|\right.\right.}
$$
For our word vector encodings, this cosine distance measure results in values near 0 when the words have similar meanings, and near 1 when the words have dissimilar meanings.
Use the function below to find the distances between various pairs of words from the above list. Compare the distances to each other. What do the relative distances seem to reflect? What unexpected distances do you notice?
def run():
return t1(w1list=[""woman"", ""man""], w2list=[""mother"", ""father""])",Open,"""mother"" is closer to ""woman"" than it is to ""man""; similarly, ""father"" is closer to ""man"" than to ""woman"". Same trend with ""king""/""queen"". However, non-gendered professions such as ""nanny"", ""programmer"" (!), ""architect"", and ""receptionist"" also show a gender bias.","RNNs are often used to process language, for example to map from one sequence of words to another sequence of words.
RNNs, like other NNs, take vectors as input, so to get them to process words we need some way of turning words into vectors. One way to do this is with a one-hot encoding (as we did with characters in the previous problem). But there are lots of lower dimensional but more informative representations of words called ""word embeddings"". One popular technique for producing word embeddings is called word2vec. It assigns each word a vector embedding such that words that appear in similar sentence contexts have embeddings that are close in vector space. Typically, we create these embedding vectors through machine learning techniques (i.e., an embedding weight matrix of size [number of words $\mathrm{x}$ embedding size] is learned).
What are some applications where using biased word embeddings may have a negative impact?","Students may come up with many answers. Aside from machine translation, another example application where such bias can lead to problematic results may be in resume processing, e.g. -- if someone had been a part of ""Society of Women Engineers,"" that might move the embedding of the resume away from ""programmer"".","RNNs are often used to process language, for example to map from one sequence of words to another sequence of words.
RNNs, like other NNs, take vectors as input, so to get them to process words we need some way of turning words into vectors. One way to do this is with a one-hot encoding (as we did with characters in the previous problem). But there are lots of lower dimensional but more informative representations of words called ""word embeddings"". One popular technique for producing word embeddings is called word2vec. It assigns each word a vector embedding such that words that appear in similar sentence contexts have embeddings that are close in vector space. Typically, we create these embedding vectors through machine learning techniques (i.e., an embedding weight matrix of size [number of words $\mathrm{x}$ embedding size] is learned).
This problem of biased word embeddings has long plagued Google Translate. A Google spokesperson explained, ""Translate works by learning patterns from many millions of examples of translations seen out on the web. Unfortunately, some of those patterns can lead to translations we're not happy with. We're actively researching how to mitigate these effects; these are unsolved problems in computer science, and ones we're working hard to address.""
See how Google translated (in 2019) the English sentence ""the doctor came to see me"" to Spanish. ""El"" is the masculine article.
Turkish is a gender neutral language, where ""o"" is the universal pronoun. See how Google (again in 2019) translated these Turkish phrases to English. 
How would you recommend Google respond to this problem?","Students may suggest a number of different things, including showing both the male and female translations for every phrase.","This part of the homework will experiment with different methods for learning word representations. For some of these questions, it may be helpful to plot the relevant analyses (e.g., for where we ask for the performance of non-pretrained vs. pretrained word embeddings as a function of labeled dataset size).
Learn representations with both Latent Semantic Analysis (i.e., SVD on TF-IDF of the term-document matrix) and Word2Vec. For Word2Vec we will be working with the continuous bag-of-words (CBOW) variant (see Figure 1.1.) Qualitatively, what do you observe about nearest neighbors in representation space? For example, what words are most similar to the, dog, 3, and good? How does the size of the representations (i.e., word embedding dimension) affect this behavior (if at all)?","We compute the 5 nearest neighbors (in feature space) of words the, dog, 3, and good using four different encoding schemes ( $U_{k}$ vs. $U_{k} \Sigma_{k}$ for features, both with and without TF-IDF normalization) holding rank constant at $k=100$. We then qualitatively compare the relationships captured by each scheme.
For each of the four encoding schemes, the term 3's five nearest neighbors included the terms 1,2, and per. All of 3's five nearest neighbors (for each scheme) are related to quantities, which suggests that each embedding scheme does a good job at capturing the numerical nature of words like 3.
With $d o g$, each of the embedding schemes associates words like foods, pets, and happier, which qualitatively matches intuitions that dog-related reviews might be related to pets, food, and happiness.
The common, non-specific term the has neighbors that are very common terms as well, including and, ., of, and to for all feature embeddings except unnormalized $U_{k}$.
For terms like good, there is a more significant disparity between the nearest neighbors across encoding schemes, where there is no single term that is shared as a nearest neighbor across all four schemes. In Table 2, we see that both $U_{k} \Sigma_{k}$ schemes encode common connecting words similarly to $\operatorname{good}$, but that the $U_{k}$ schemes associate good with other words that are plausibly more semantically relevant. From our qualitative evaluations of each encoding scheme, we decided to use the TF-IDF $U_{k}$ embeddings for the remainder of our experiments because it was the most consistent across terms.
\begin{tabular}{ll|ll}
\hline \multicolumn{2}{l|}{ No Normalization } & \multicolumn{2}{|c}{ TF-IDF } \\
\hline$U_{k}$ & $U_{k} \Sigma_{k}$ & $U_{k}$ & $U_{k} \Sigma_{k}$ \\
\hline good & good & good & good \\
gerber & $\cdot$ & crazy & $\cdot$ \\
luck & a & gerber & but \\
crazy & but & beat & a \\
flaxseed & , & homemade & and \\
suspect & the & tasting & is \\
\hline
\end{tabular}
Table 2: Five nearest neighbors of good for each encoding scheme.
To explore the impact that the LSA representation size has on the semantic similarity nearest neighbors have in embedding space, we produce $U_{k}$ TF-IDF embeddings for rank $k$ approximations for 60 values of $k$ sweeping from 0 to 3000. We also investigate low-rank embeddings, sweeping $k$ from 0 to 50 with a step size of 5. Interestingly, the semantic similarity of nearest neighbors is best captured at different values of $k$ for different types of words.
For example, some of the most semantically similar neighbors for $d o g$ were achieved with $k=15$ they are iams, dogs, pet, nutritious, and kibble. However, this performance deteriorates when $k$ is large (at $k=2500$, we get we, baby, i'd, product, and door). However, for $k=15$, 3's 5 nearest neighbors are considering, tart, fruits, berry, and claims - the quantitative semantics of the term are not captured until the dimension of the embedding space is increased to at least $k=45$.
For each word type, it seems as if the semantic similarity of neighbors in embedding space increases with $k$ to a point, then falls off once semantically irrelevant patterns from the training data are introduced.
We explore how learned representations help with review classification by sweeping over the dimension $k$ of the embedding space (with a step size of 10 from 0 to 3000) and performing logistic regression using the rank-$k$ TF-IDF-normalized LSA features. We compare these results to the accuracy achieved without using learned features, as well as to performance reached using a combination of the two types of features. In Figure 1, we see that that the performance for all three feature types is roughly equivalent through the first hundred examples, after which the LSA features begin to dominate. After around 1500 examples, the combo features begin to dominate, and remain on top for the full 3000-example training set. From this, we conclude that learned representations do help with review classification.
To characterize the relationship between the dimension of the feature embedding space and classifier performance, we vary the number of features $k$ (again using $U_{k}$ with TF-IDF normalization) used in the classification task and measure the accuracy for different sized training sets. As seen in Figure 2, for each of the training set sizes, adding features increases performance, to a point. However, for smaller training sets, we observe a drop-off in performance with more features, which is evidence of overfitting. This is a reasonable result, since the larger feature space will capture and express patterns in the smaller training sets that are random artifacts of the training data with no semantic relevance.
The embedding approach we consider is the continuous bag-of-words (CBOW) Word2Vec approach, which predicts a target word from its neighbors in a fixed-width sliding window. We embed features in a feature space with a linear operator $V^{\top}$ that acts on the average word vector of the context, which is the set of words within window_size from our target. We experimented with a ReLU activation at this point but did not find a boost in performance, so we abandoned the non-linearity. We then decode with an operator $U$ that maps from our embedding space to the space of words in our vocabulary before computing scores using softmax. We optimize a cross-entropy loss function to produce our embedding matrix $U$, which we use to construct embeddings of reviews for the classification task. This process is the same as for LSA features - we left-multiply our embedding matrix by a review word-count vector and normalize.
As before, we compute and compare the 5 nearest neighbors of terms the, $\operatorname{dog}, 3$, and good, but this time we use Word2Vec CBOW embeddings. In Table 3, we see that our embeddings do a good job capturing the semantic similarity of terms. Notably, each set of neighbors contains words of (nearly) all the same parts of speech, which suggests that the CBOW formulation is good at capturing the types of words that appear in particular local contexts. We perform the same computation with embedding dimensions of 10, 100, and 3000; all of these embeddings produce sets of neighbors that are qualitatively similar. Notably, with an embedding dimension of 10, good's five nearest neighbors are great, better, healthy, more, and nice, which is very impressive, and aligned with intuitive notions of word similarity.
\begin{tabular}{llll}
\hline the & dog & $\mathbf{3}$ & good \\
\hline a & cat & 5 & great \\
my & baby & four & decent \\
this & junk & 4 & bad \\
, & pouch & 6 & nice \\
their & pets & 9 & fine \\
\hline
\end{tabular}
Table 3: We compute the 5 nearest neighbors of four example words in embedding space, where we use a window size of 2 and an embedding dimension of 500."
53,Mathematics,18.100B,Real Analysis,18.02,None,Midterm Exam 2,Continuity,3,nan,5,Text,"If $\alpha:[0,1] \longrightarrow \mathbb{R}$ is given by
$$
\alpha(x)= \begin{cases}x-1 & 0 \leq x<\frac{1}{2} \\ x+1 & \frac{1}{2} \leq x \leq 1\end{cases}
$$
and $f=2 x$, explain why the Riemann-Stieltjes integral $\int_{0}^{1} f d \alpha$ exists and compute its value, justifying your arguments carefully.",Open,"Since $\alpha$ is an increasing function and $f$ is continuous the existence of the Riemann-Stieltjes integral follows from a basic result to this effect in class or Rudin's book.
To compute the integral, note that $\alpha=\alpha_{1}+\alpha_{2}$ where $\alpha_{1}=x-1$ and $\alpha_{2}=2 I\left(x-\frac{1}{2}\right)$ where
$$
I\left(x-\frac{1}{2}\right)= \begin{cases}0 & x<\frac{1}{2} \\ 1 & x \geq \frac{1}{2}\end{cases}
$$
is a step function. Both are increasing functions. From one of the basic properties of the integral from the book, $f \in \mathcal{R}\left(\alpha_{1}\right)$ and $f \in \mathcal{R}\left(\alpha_{2}\right)$, which follows again from the continuity of $f$, imply that
$$
\int_{0}^{1} f d \alpha=\int_{0}^{1} f d \alpha_{1}+\int_{0}^{1} f d \alpha_{2}
$$
Since addition of a constant to $\alpha$ does not change the definition of the integral, the first term here is a Riemann integral which can be evaluated by the fundamental theorem of calculus, since $2 x=\left(x^{2}\right)^{\prime}$
$$
\int_{0}^{1} f d \alpha_{1}=\int_{0}^{1} 2 x d x=(1)^{2}-0^{2}=1
$$
The integral when $\alpha$ is a step function is also evaluated in the book, as just being the product of the size of the jump and the value of the function, so
$$
\int_{0}^{1} f d \alpha_{1}=2\left(2 \times \frac{1}{2}\right)=2
$$
and finally
$$
\int_{0}^{1} f d \alpha=3
$$
Alternatively, some people divided the integral up using a choice of $0<$ $\epsilon<\frac{1}{2}$ to see that
$$
\int_{0}^{1} f d \alpha=\int_{0}^{\frac{1}{2}-\epsilon} f d \alpha+\int_{\frac{1}{2}-\epsilon}^{\frac{1}{2}} f d \alpha+\int_{\frac{1}{2}}^{1} f d \alpha
$$
As before the first and the last integrals are Riemann integrals which can be evaluated using the FTC. The middle integral can be bounded by sup and inf of the integrand and Stieltjes length of the interval
$$
(1-2 \epsilon)\left(\frac{3}{2}-\left(-\frac{1}{2}-\epsilon\right)\right) \leq \int_{\frac{1}{2}-\epsilon}^{\frac{1}{2}} f d \alpha \leq 1\left(\frac{3}{2}-\left(-\frac{1}{2}-\epsilon\right)\right) .
$$
This shows that as $\epsilon \rightarrow 0$ the second integral converges to 2 and the other two terms converge to $1 / 4$ and $3 / 4$ giving the same answer.
Comments: I did not expect you to prove the integrability of a continuous function. The major (and rather common) error was to ignore the jump in $\alpha$ by dividing the integral at $\frac{1}{2}$. The jump is still there, so the lower integral is NOT a Riemann integral - the function $\alpha$ is not differentiable on the closed interval. This probably goes back to a misunderstanding about the definition of differentiability on a closed interval - Rudin does demand differentiability at the end-points even though this is 'one-sided'.","Explain carefully why the Riemann-Stieltjes integral
$$
\int_{-1}^{1} x^{2} \exp \left(x^{3}\right) d \alpha
$$
exists for any increasing function $\alpha:[-1,1] \longrightarrow \mathbb{R}$.","The function $x^{2} \exp \left(x^{3}\right)$ is continuous since the polynomials $x^{2}$ and $x^{3}$ are continuous, as is exp so by composition and product theorem continuity follows. Since $\alpha$ is increasing, the Riemann-Stieltjes integrability follows from the theorem in Rudin that any continuous function on a compact interval is integrable. ","Evaluate this integral when
$$
\alpha= \begin{cases}x & x<0 \\ x+1 & x \geq 0\end{cases}
$$","By a decomposition result in Rudin if we write $\alpha=\alpha_{1}+\alpha_{2}$, where here $\alpha_{2}$ is the Heaviside function with jump at 0 and $\alpha_{1}(x)=x$ then
$$
\int_{-1}^{1} f d \alpha=\int_{-1}^{1} f d \alpha_{1}+\int_{-1}^{1} f d \alpha_{2}
$$
for any continuous function. The first integral is the Riemann integral and since $x^{2} \exp \left(x^{3}\right)=\frac{1}{3} \frac{d}{d x} \exp \left(x^{3}\right)$ this evaluates to $\frac{1}{3}\left(e-e^{-1}\right)$. On the other hand the value of $f$ at 0 is zero, so this in fact is the value of the integral.","If $f:[0,2] \longrightarrow \mathbb{R}$ is a continuous function, state a theorem which shows that $F(x)=\int_{0}^{x} f(s) d s$ is differentiable on $[0,2]$ (or prove it directly) and show that there exists $c \in(0,2)$ such that $\int_{0}^{2} f(x) d x=2 f(c)$.","The Fundamental Theorem of Calculus states that the integral of a Riemann integrable function $F(x)=\int_{0}^{x} f(s) d s$ is differentiable at each point of continuity of $f$ with derivative there $F^{\prime}(x)=f(x)$. Since $f$ is continuous everywhere on $[0,2], F$ is differentiable on [0,2] and by the Mean Value Theorem there exists $c \in(0,2)$ such that
$$
F(2)-F(0)=\int_{0}^{2} f(s) d s=f(c)(2-0)=2 f(c).
$$"
43,EECS,6.102,Elements of Software Construction,6.101,None,Midterm Exam 2,Concurrency,3,d,0.48,Text,"/**
* Immutable type representing a strand of DNA.
*/
class DNA {
       /** omitted */
       public constructor(bases: string) {
       // omitted
}
       /**
        * @returns zero-based index of first occurence of `dna` as a substring of this strand,
        * or undefined if `dna` never occurs.
        */
       public find(dna: DNA): number|undefined {
             // omitted
       }
       /**
        * @returns true iff this and that are observationally equivalent
        */
       public equalValue(that: DNA): boolean {
              // omitted
       }
       // other code omitted
}
/**
* Immutable type representing a gene-editing process.
*/
interface Crispr {
      /**
       * Simulates this gene-editing process entirely in software, without using chemicals or a lab.
       * @returns DNA strand that would result from this process
       */
      simulate(): DNA;
     /**
      * Run this gene-editing process using the given `lab`.
      * @returns the tube of `lab` in which the final DNA from this process
      * can be found.
      */
      async fabricate(lab: Lab): Promise<Tube>;
      // other code omitted
}
/**
* Represents an already-existing DNA strand (a ""precursor"") in a gene-editing
* process. Precursors are bought premade from a supplier.
*/
class Precursor implements Crispr {
/**
* Make a gene-splicing step that results in the given `dna` strand.
*/
       public constructor(private readonly dna: DNA) {
       }
       // other code omitted
}
/**
* Represents a gene-splicing step in a gene-editing process,
* which replaces all instances of one gene with another.
*/
class Splice implements Crispr {
       /**
        * Make a gene-splicing step that finds all occurrences of
        * oldGene in target and substitutes newGene in place of each one.
        */
       public constructor(
       private readonly target: Crispr,
       private readonly oldGene: Crispr,
       private readonly newGene: Crispr
       ) {
       }
       // other code omitted
}
/**
* Mutable type controlling an automated gene-editing machine.
*/
class Lab {
/**
* Modifies the DNA in targetTube to replace all occurrences of the DNA from oldGeneTube with the
* DNA from newGeneTube.
* @returns a promise that fulfills with the same tube as targetTube, after the process is complet
*/
       public async splice(targetTube: Tube, oldGeneTube: Tube, newGeneTube: Tube): Promise<Tube> {
              // omitted
       }
       private tubeMap: Map<Tube, DNA> = new Map();
        /**
         * @returns a tube containing DNA strands corresponding to `dna`
         */
        public async get(dna: DNA): Promise<Tube> {
                for (const tube of this.tubeMap.keys()) {
                      if (this.tubeMap.get(tube).equalValue(dna)) {
                          return tube;
                      }
                 }
                 const tube = new Tube();
                 this.tubeMap.set(tube, dna);
                 await this.load(tube, dna); // ""line 6a"" is the load() call, ""line 6b"" is the await
                 return tube;
         }
         /**
          * Ask a human to order premade DNA from a supplier
          * and load it into the tube.
          * @returns a promise that fulfills once this tube contains `dna`.
          */
         private async load(tube: Tube, dna: DNA): Promise<void> {
               // omitted
         }
         // other code omitted
}
/**
* Mutable type representing a test tube containing DNA.
*/
class Tube {
       /** Make a new Tube. */
       public constructor() {
       }
       // other code omitted
}
Suppose that:
• two different gene-editing processes A and B are running asynchronously using the same Lab
• A and B both call lab.get(dnaX) for the same precursor dnaX
• no other asynchronous processes are using lab
For each of the following interleavings, referring to the line numbers 1-7 in get() in the provided code, decide whether the
interleaving is impossible, leads to a race condition or deadlock, or runs safely; then explain your answer in one sentence.
A runs lines 1 and 4, then B runs lines 1 and 4, then A runs lines 5, 6, 7, then B runs lines 5, 6, 7.",Open,"impossible; A cannot lose control to B after line 4, it can only lose control at the await in line 6.","/**
* Immutable type representing a strand of DNA.
*/
class DNA {
       /** omitted */
       public constructor(bases: string) {
       // omitted
}
       /**
        * @returns zero-based index of first occurence of `dna` as a substring of this strand,
        * or undefined if `dna` never occurs.
        */
       public find(dna: DNA): number|undefined {
             // omitted
       }
       /**
        * @returns true iff this and that are observationally equivalent
        */
       public equalValue(that: DNA): boolean {
              // omitted
       }
       // other code omitted
}
/**
* Immutable type representing a gene-editing process.
*/
interface Crispr {
      /**
       * Simulates this gene-editing process entirely in software, without using chemicals or a lab.
       * @returns DNA strand that would result from this process
       */
      simulate(): DNA;
     /**
      * Run this gene-editing process using the given `lab`.
      * @returns the tube of `lab` in which the final DNA from this process
      * can be found.
      */
      async fabricate(lab: Lab): Promise<Tube>;
      // other code omitted
}
/**
* Represents an already-existing DNA strand (a ""precursor"") in a gene-editing
* process. Precursors are bought premade from a supplier.
*/
class Precursor implements Crispr {
/**
* Make a gene-splicing step that results in the given `dna` strand.
*/
       public constructor(private readonly dna: DNA) {
       }
       // other code omitted
}
/**
* Represents a gene-splicing step in a gene-editing process,
* which replaces all instances of one gene with another.
*/
class Splice implements Crispr {
       /**
        * Make a gene-splicing step that finds all occurrences of
        * oldGene in target and substitutes newGene in place of each one.
        */
       public constructor(
       private readonly target: Crispr,
       private readonly oldGene: Crispr,
       private readonly newGene: Crispr
       ) {
       }
       // other code omitted
}
/**
* Mutable type controlling an automated gene-editing machine.
*/
class Lab {
/**
* Modifies the DNA in targetTube to replace all occurrences of the DNA from oldGeneTube with the
* DNA from newGeneTube.
* @returns a promise that fulfills with the same tube as targetTube, after the process is complet
*/
       public async splice(targetTube: Tube, oldGeneTube: Tube, newGeneTube: Tube): Promise<Tube> {
              // omitted
       }
       private tubeMap: Map<Tube, DNA> = new Map();
        /**
         * @returns a tube containing DNA strands corresponding to `dna`
         */
        public async get(dna: DNA): Promise<Tube> {
                for (const tube of this.tubeMap.keys()) {
                      if (this.tubeMap.get(tube).equalValue(dna)) {
                          return tube;
                      }
                 }
                 const tube = new Tube();
                 this.tubeMap.set(tube, dna);
                 await this.load(tube, dna); // ""line 6a"" is the load() call, ""line 6b"" is the await
                 return tube;
         }
         /**
          * Ask a human to order premade DNA from a supplier
          * and load it into the tube.
          * @returns a promise that fulfills once this tube contains `dna`.
          */
         private async load(tube: Tube, dna: DNA): Promise<void> {
               // omitted
         }
         // other code omitted
}
/**
* Mutable type representing a test tube containing DNA.
*/
class Tube {
       /** Make a new Tube. */
       public constructor() {
       }
       // other code omitted
}
Suppose that:
• two different gene-editing processes A and B are running asynchronously using the same Lab
• A and B both call lab.get(dnaX) for the same precursor dnaX
• no other asynchronous processes are using lab
For each of the following interleavings, referring to the line numbers 1-7 in get() in the provided code, decide whether the
interleaving is impossible, leads to a race condition or deadlock, or runs safely; then explain your answer in one sentence.
A runs lines 1, 4, 5, 6, 7, then B runs lines 1, 4, 5, 6, 7.","impossible; After A runs line 5, there will be at least one tube in tubeMap, so B must proceed from line 1 to line 2.","/**
* Immutable type representing a strand of DNA.
*/
class DNA {
       /** omitted */
       public constructor(bases: string) {
       // omitted
}
       /**
        * @returns zero-based index of first occurence of `dna` as a substring of this strand,
        * or undefined if `dna` never occurs.
        */
       public find(dna: DNA): number|undefined {
             // omitted
       }
       /**
        * @returns true iff this and that are observationally equivalent
        */
       public equalValue(that: DNA): boolean {
              // omitted
       }
       // other code omitted
}
/**
* Immutable type representing a gene-editing process.
*/
interface Crispr {
      /**
       * Simulates this gene-editing process entirely in software, without using chemicals or a lab.
       * @returns DNA strand that would result from this process
       */
      simulate(): DNA;
     /**
      * Run this gene-editing process using the given `lab`.
      * @returns the tube of `lab` in which the final DNA from this process
      * can be found.
      */
      async fabricate(lab: Lab): Promise<Tube>;
      // other code omitted
}
/**
* Represents an already-existing DNA strand (a ""precursor"") in a gene-editing
* process. Precursors are bought premade from a supplier.
*/
class Precursor implements Crispr {
/**
* Make a gene-splicing step that results in the given `dna` strand.
*/
       public constructor(private readonly dna: DNA) {
       }
       // other code omitted
}
/**
* Represents a gene-splicing step in a gene-editing process,
* which replaces all instances of one gene with another.
*/
class Splice implements Crispr {
       /**
        * Make a gene-splicing step that finds all occurrences of
        * oldGene in target and substitutes newGene in place of each one.
        */
       public constructor(
       private readonly target: Crispr,
       private readonly oldGene: Crispr,
       private readonly newGene: Crispr
       ) {
       }
       // other code omitted
}
/**
* Mutable type controlling an automated gene-editing machine.
*/
class Lab {
/**
* Modifies the DNA in targetTube to replace all occurrences of the DNA from oldGeneTube with the
* DNA from newGeneTube.
* @returns a promise that fulfills with the same tube as targetTube, after the process is complet
*/
       public async splice(targetTube: Tube, oldGeneTube: Tube, newGeneTube: Tube): Promise<Tube> {
              // omitted
       }
       private tubeMap: Map<Tube, DNA> = new Map();
        /**
         * @returns a tube containing DNA strands corresponding to `dna`
         */
        public async get(dna: DNA): Promise<Tube> {
                for (const tube of this.tubeMap.keys()) {
                      if (this.tubeMap.get(tube).equalValue(dna)) {
                          return tube;
                      }
                 }
                 const tube = new Tube();
                 this.tubeMap.set(tube, dna);
                 await this.load(tube, dna); // ""line 6a"" is the load() call, ""line 6b"" is the await
                 return tube;
         }
         /**
          * Ask a human to order premade DNA from a supplier
          * and load it into the tube.
          * @returns a promise that fulfills once this tube contains `dna`.
          */
         private async load(tube: Tube, dna: DNA): Promise<void> {
               // omitted
         }
         // other code omitted
}
/**
* Mutable type representing a test tube containing DNA.
*/
class Tube {
       /** Make a new Tube. */
       public constructor() {
       }
       // other code omitted
}
Suppose that:
• two different gene-editing processes A and B are running asynchronously using the same Lab
• A and B both call lab.get(dnaX) for the same precursor dnaX
• no other asynchronous processes are using lab
For each of the following interleavings, referring to the line numbers 1-7 in get() in the provided code, decide whether the
interleaving is impossible, leads to a race condition or deadlock, or runs safely; then explain your answer in one sentence.
A runs lines 1, 4, 5, 6a, then B runs lines 1, 2, 3, then A finishes lines 6b and 7.","race condition; B returns the tube that A is loading before the tube has finished loading, violating the postcondition of get().","/**
* Immutable type representing a strand of DNA.
*/
class DNA {
       /** omitted */
       public constructor(bases: string) {
       // omitted
}
       /**
        * @returns zero-based index of first occurence of `dna` as a substring of this strand,
        * or undefined if `dna` never occurs.
        */
       public find(dna: DNA): number|undefined {
             // omitted
       }
       /**
        * @returns true iff this and that are observationally equivalent
        */
       public equalValue(that: DNA): boolean {
              // omitted
       }
       // other code omitted
}
/**
* Immutable type representing a gene-editing process.
*/
interface Crispr {
      /**
       * Simulates this gene-editing process entirely in software, without using chemicals or a lab.
       * @returns DNA strand that would result from this process
       */
      simulate(): DNA;
     /**
      * Run this gene-editing process using the given `lab`.
      * @returns the tube of `lab` in which the final DNA from this process
      * can be found.
      */
      async fabricate(lab: Lab): Promise<Tube>;
      // other code omitted
}
/**
* Represents an already-existing DNA strand (a ""precursor"") in a gene-editing
* process. Precursors are bought premade from a supplier.
*/
class Precursor implements Crispr {
/**
* Make a gene-splicing step that results in the given `dna` strand.
*/
       public constructor(private readonly dna: DNA) {
       }
       // other code omitted
}
/**
* Represents a gene-splicing step in a gene-editing process,
* which replaces all instances of one gene with another.
*/
class Splice implements Crispr {
       /**
        * Make a gene-splicing step that finds all occurrences of
        * oldGene in target and substitutes newGene in place of each one.
        */
       public constructor(
       private readonly target: Crispr,
       private readonly oldGene: Crispr,
       private readonly newGene: Crispr
       ) {
       }
       // other code omitted
}
/**
* Mutable type controlling an automated gene-editing machine.
*/
class Lab {
/**
* Modifies the DNA in targetTube to replace all occurrences of the DNA from oldGeneTube with the
* DNA from newGeneTube.
* @returns a promise that fulfills with the same tube as targetTube, after the process is complet
*/
       public async splice(targetTube: Tube, oldGeneTube: Tube, newGeneTube: Tube): Promise<Tube> {
              // omitted
       }
       private tubeMap: Map<Tube, DNA> = new Map();
        /**
         * @returns a tube containing DNA strands corresponding to `dna`
         */
        public async get(dna: DNA): Promise<Tube> {
                for (const tube of this.tubeMap.keys()) {
                      if (this.tubeMap.get(tube).equalValue(dna)) {
                          return tube;
                      }
                 }
                 const tube = new Tube();
                 this.tubeMap.set(tube, dna);
                 await this.load(tube, dna); // ""line 6a"" is the load() call, ""line 6b"" is the await
                 return tube;
         }
         /**
          * Ask a human to order premade DNA from a supplier
          * and load it into the tube.
          * @returns a promise that fulfills once this tube contains `dna`.
          */
         private async load(tube: Tube, dna: DNA): Promise<void> {
               // omitted
         }
         // other code omitted
}
/**
* Mutable type representing a test tube containing DNA.
*/
class Tube {
       /** Make a new Tube. */
       public constructor() {
       }
       // other code omitted
}
Suppose that:
• two different gene-editing processes A and B are running asynchronously using the same Lab
• A and B both call lab.get(dnaX) for the same precursor dnaX
• no other asynchronous processes are using lab
For each of the following interleavings, referring to the line numbers 1-7 in get() in the provided code, decide whether the
interleaving is impossible, leads to a race condition or deadlock, or runs safely; then explain your answer in one sentence.
A runs lines 1, 4, 5, 6a; then B runs lines 1, 4, 5, 6a; then A finishes lines 6b and 7, then B finishes lines 6b and 7.","impossible; After A runs line 5, there will be at least one tube in tubeMap, so B must proceed from line 1 to line 2."
76,EECS,6.121,Introduction to Algorithms,"6.100A, 6.1200",6.101,Mini Quiz 2,Runtime Analysis,1,nan,0.2222222222,Text,"The alien ship is scheduled to arrive to earth's orbit in exactly 3 hours. You have two algorithms to do a computation to set up the trajectory of the missile that will save the world from the arriving aliens. The first algorithm (algorithm A) runs in time $10 n \log n$ while the second algorithm (algorithm B) runs in time $\frac{1}{2} n^{2}$ ($n$ represents the number of parameters in the input to the algorithm and the runtimes are measure in terms of floating point operations). Your new laptop can do 5 petaFLOPS.
Choose all the correct answers:
1. You should always choose algorithm A.
2. The earth is doomed.
3. If $n$ is less than 4 billion, then you can use algorithm B if only barely.
4. Algorithm A can save the day even if $n$ is as big as 1000 trillion.",Multiple Choice,"1. You should always choose algorithm A.
Incorrect, for small $n$ (for example $n \leq 10$ ).,$\frac{1}{2} n^{2}<10 n \log n$
2. The earth is doomed.
Incorrect, maybe, but not because you will never be able to run either algorithm
3. If $n$ is less than 4 billion, then you can use algorithm B if only barely.
Correct. Just barely. If $n$ is less than 4 billion $=4 \times 10^{9}$, then algorithm B will perform $8 \times 10^{18}$ FLOPS which can be done in 8,000 seconds which is a bit over 2 hours but definitely less than 3 (3 hours $=10,800$ seconds).
4. Algorithm A can save the day even if $n$ is as big as 1000 trillion.
Correct. For $n=10^{15}$, algorithm A will perform $10 \times 10^{15} \times \log 10^{15}$ operations. Noticing that $\log 10<3.3, \log 10^{15}<50$ which means that algorithm A will need at most 500 seconds (slightly less than 9 minutes).","Please select True or False for the following.
Consider an $O\left(n^{2}\right)$-time Monte Carlo randomized algorithm for some problem, which uses 1000 randomly generated integers between 1 and 1000, and gives the correct answer with probability $\frac{2}{3}$. Then, there is also a $O\left(n^{2}\right)$-time deterministic algorithm for the same problem.","True. Simply try all $1000^{1000}$ possible random integers, and then take the majority answer. The runtime is $O\left(n^{2}\right)$ times $1000^{1000}=O(1)$, which is still $O\left(n^{2}\right)$.","Consider two algorithms for the same problem. Algorithm A has runtime $T(n)=3 T(n / 2)+\Theta\left(n^{2}\right)$. Algorithm B has runtime $T(n)=9 T(n / 3)+\Theta(n)$. Both algorithms run in time $\Theta(1)$ for $n \leq 3$. Which is a true statement?
(a) Algorithm A is asymptotically faster than B.
(b) Algorithm A is asymptotically slower than B.
(c) Algorithms A and B have the same asymptotic runtime.",(c). Both have similar runtimes of $\Theta\left(n^{2}\right)$ which can be verified using the Master Theorem.,"Please select True or False for the following.
A Las Vegas algorithm with expected $O(n)$ runtime may run in $\Omega\left(2^{n}\right)$ time in the worst case.",True.
70,Mathematics,18.02,Calculus II,18.01,None,Problem Set 8,Divergence Theorem,5,nan,0.641025641,Text,Assume that Gauss's law holds for a uniform solid ball of mass $M$ centered at the origin. Also assume by symmetry that the force $F$ exerted by this mass on an exterior particle of unit mass is directed toward the origin. Apply Gauss's law with $S$ being a sphere of radius $r$ to show that $|\mathbf{F}|=G M / r^2$ at each point of $S$. Thus it follows that the solid ball acts (gravitationally) like a single point-mass $M$ concentrated at its center.,Open,"Gauss's law tells us that for a sphere $S$ of radius $r$, with mass $4 \pi r^{2}$ distributed uniformly over the sphere, surrounding our mass $M$ we have $\iint_{S} \mathbf{F}_{g} \cdot \vec{n} d S=-4 \pi G M$. But note that the normal vector of $S$ and $\vec{n}$ point in opposite directions and that $\left|\mathbf{F}_{g}\right|$ is the same at each point of $S$ by symmetry. This tells us that $\iint_{S} \mathbf{F}_{g} \cdot \vec{n} d S=-\left|\mathbf{F}_{g}\right| \iiint_{S} d S=-4\left|\mathbf{F}_{g}\right| \pi r^{2}$. Setting the expressions equal to each other we get
$$
-4 \pi G M=-4\left|\mathbf{F}_{g}\right| \pi r^{2}
$$
which says precisely that $\left|\mathbf{F}_{g}\right|=\frac{G M}{r^{2}}$ at each point of $S$.","Place a point charge $Q$ at $(0,0,0)$. Let $\mathbf{E}=\mathbf{E}(x, y, z)$ be the electric field it creates. Coulomb's law states:
$$
\mathbf{E}=\frac{Q / 4 \pi \epsilon_{0}}{\rho^{2}} \frac{\mathbf{r}}{\rho},
$$
where $\epsilon_{0}$ is a constant.
Prove the Gauss's law for an electric field (also called the Gauss-Coulomb law): The electric flux across a closed surface $S$ equals the charge enclosed divided by $\epsilon_{0}$,
$$
\oiint_{S} \mathbf{E} \cdot d \mathbf{S}=\frac{Q}{\epsilon_{0}} .
$$
Hint: Think about the gravitational flux discussed in class.","Suppose $S$ didn't contain the point charge. Then $\nabla \cdot \mathbf{E}=0$ at every point in the region enclosed by $S$ and we get $\iint_{S} \mathbf{E} \cdot d \mathbf{S}=\iiint_{V} \nabla \cdot \mathbf{E} d V=0$. This is what we want to show for this case.
If $S$ contains the point charge $Q$, consider a small sphere of radius $a, S_{a}$, around our point charge. The sphere is small enough so that it sits inside $S$. Let $R$ be the region enclosed by the two surfaces and we have $\partial R=S$ and $-S_{a}$, negative because the normal vector points inwards. This means that
$$
\iint_{S} \mathbf{E} \cdot d \mathbf{S}-\iint_{S_{a}} \mathbf{E} \cdot d \mathbf{S}=\iiint_{R} \nabla \cdot \mathbf{E} d V=0
$$
since $\nabla \cdot \mathbf{E}=0$ at each point in the volume enclosed by the two surfaces. This means that $\iint_{S} \mathbf{E} \cdot d \mathbf{S}=\iint_{S_{a}} \mathbf{E} \cdot d \mathbf{S}$.
But we can compute $\iint_{S_{a}} \mathbf{E} \cdot d \mathbf{S}$ directly! Namely, the field $\mathbf{E}$ is the same at each point on the sphere, by symmetry, and the normal vector and $\mathbf{E}$ are also parallel at each point of the sphere. This means that
$$
\iint_{S_{a}} \mathbf{E} \cdot d \mathbf{S}=|\mathbf{E}| \iint_{S_{a}} d S=\frac{Q}{4 \pi \epsilon_{0}} \frac{1}{a^{2}}\left(4 \pi a^{2}\right)=\frac{Q}{\epsilon_{0}} .
$$","Now suppose that we have the same ball of radius 2 , and it has variable density, and the density near a point $(x, y, z)$ is $2+z$.
Write down an integral for the total mass of the ball.","$$
m=\int_{-2}^{2}(2+z)\left(4-z^{2}\right) \pi d z
$$","This problem is a variation on problem 2. Once again, suppose we have a disk of radius 3 meters. This time, near a point at distance $r$ from the center, the disk has density $r+1$ kilograms per square meter. This time, the densest part of the disk is on the edge, where the density is $4 \mathrm{~kg} / \mathrm{m}^{2}$. The least dense part of the disk is at the center, where the density is $1 \mathrm{~kg} / \mathrm{m}^{2}$.
Write an integral for the total mass of the disk.",$\int_{0}^{3} 2 \pi r(1+r) d r$.
153,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 4,Robot Motion Planning,4,biii,0.1157407407,Text,"For each of the following statements, indicate whether or not itʼs true for the standard RRT with linear-interpolation extensions.
Artie suggests the following new planning method for robots.
\begin{itemize}
\item Sample 1000 points randomly in a bounded configuration space. Include the start and goal points.
\item Test each pair of points to see whether they can be connected by a collision-free straight line in configuration space.
\item Search the resulting graph of connected points for a path from the start to the goal.
\item If a path cannot be found, throw away the current samples and graph, and return to the first step. Otherwise, return the path found.
\end{itemize}
For each of the following statements, indicate whether or not it's true for Artie's algorithm. 
True or False: Is Artie's algorithm the same as the Probabilistic Roadmap (PRM) algorithm that we have seen in the lecture?",Multiple Choice,False.,"For each of the following statements, indicate whether or not itʼs true for the standard RRT with linear-interpolation extensions.
Artie suggests the following new planning method for robots.
\begin{itemize}
\item Sample 1000 points randomly in a bounded configuration space. Include the start and goal points.
\item Test each pair of points to see whether they can be connected by a collision-free straight line in configuration space.
\item Search the resulting graph of connected points for a path from the start to the goal.
\item If a path cannot be found, throw away the current samples and graph, and return to the first step. Otherwise, return the path found.
\end{itemize}
For each of the following statements, indicate whether or not it's true for Artie's algorithm. 
Mark all that are true.
(a) The algorithm is probabilistically complete.
(b) The algorithm is correct (if a plan is found, it can be executed safely).
(c) There is a parameter you can tune to take advantage of information you might have about the tightest clearance in the problem.
(d) The algorithm will tend to put more samples near the start state than most other parts of the space.
(e) It is necessary to have a description of the shape of the obstacles in configuration space.
(f) It is applicable to robot arms.
(g) It is applicable to fixed-wing flying robots.
(h) It is applicable to cars.","(b) The algorithm is correct (if a plan is found, it can be executed safely).
(g) It is applicable to fixed-wing flying robots.","For each of the following statements, indicate whether or not itʼs true for the standard RRT with linear-interpolation extensions.
Mark all that are true.
(a) The algorithm is probabilistically complete.
(b) The algorithm is correct (if a plan is found, it can be executed safely).
(c) The algorithm will tend to put more samples near the start state than most other parts of the space.
(d) It is necessary to have a description of the shape of the obstacles in configuration space.
(e) It is applicable to robot arms.
(f) It is applicable to fixed-wing flying robots.
(g) It is applicable to cars.","(a) The algorithm is probabilistically complete.
(b) The algorithm is correct (if a plan is found, it can be executed safely).
(e) It is applicable to robot arms.","True or False: Consider the same complicated robot and environment. If a pure translation path exists in the original problem, a path exists in a problem with a point robot and all the dimensions of the obstacles increased by $r$ (each edge is pushed $r$ apart from the center).",False.
133,Mathematics,18.02,Calculus II,18.01,None,Final Exam,Lagrange Multiplier,7,nan,1.2,Text,"Let $\mathcal{P}$ be the plane with equation $A x+B y+C z=D$ and $P_0=\left(x_0, y_0, z_0\right)$ be a point which is not on $\mathcal{P}$. 
Use the Lagrange multiplier method to set up the equations satisfied by the point $(x, y, z)$ on $\mathcal{P}$ which is closest to $P_0$. (Do not solve.)",Expression,"$f(x, y, z)=\operatorname{dist}^2=\left(x-x_0\right)^2+\left(y-y_0\right)^2+\left(z-z_0\right)^2$
subject to $g(x, y, z)=A x+B y+C z=D$.
$\nabla f=2\left\langle x-x_0, y-y_0, z-z_0\right\rangle, \quad \nabla g=\langle A, B, C\rangle$.
$$
\boldsymbol{\nabla} f=\lambda \boldsymbol{\nabla} g, \text { and } g=D \Rightarrow \begin{aligned}
& 2\left(x-x_0\right)=\lambda A \\
& 2\left(y-y_0\right)=\lambda B \\
2\left(z-z_0\right)=\lambda C \\
A x+B y+C z=D .
\end{aligned}
$$","Find the equation in the form $A x+B y+C z=D$ of the plane $\mathcal{P}$ which contains the line $L$ given by $x=1-t, \quad y=1+2 t, \quad z=2-3 t$ and the point $(-1,1,2)$.","The equation of $P$ is 
$$
0(x-1)+6(y-1)+4(z-2)=0 \quad \text { or } \quad 6 y=4 z=14 \quad \text { or } \quad 3 y+2 z=7 .
$$","Let $L$ denote the line which passes through $(0,0,1)$ and is parallel to the line in the xy-plane given by $y=2 x$. 
Suppose that the point $P \neq(0,0,1)$ lies on $L$. Write down the method or formula you would use to find the point $P^*$ which is: (i) on $L$; (ii) the same distance away from the point $(0,0,1)$ as $P$; and is (iii) on the other side of $\mathcal{P}$ from $P$.","$P^*=(-t,-2 t, 1)$ since then $\operatorname{dist}\left(P_0, P\right)=\operatorname{dist}\left(P_0, P^*\right)=|t| \sqrt{5}$.","Set up the Lagrange multiplier equations for the points belonging to the sphere $x^2+y^2+z^2=4$ and that maximize and minimize the function $f(x, y, z)=2 x^2+y z+y^2$. (You do not need to solve the equations.)","The Lagrange multiplier equations take the form $g(x, y, z)=c$ for the constraint $g=c$, and $\nabla f=\lambda \nabla g$. Our constraint is $g(x, y, z)=x^2+y^2+z^2=4$. First, we take the partial derivatives to find:
$$
\begin{gathered}
\nabla f=\langle 4 x, 2 y+z, y\rangle \\
\nabla g=\langle 2 x, 2 y, 2 z\rangle
\end{gathered}
$$
Then the equations take the form:
$$
\left\{\begin{array}{l}
4 x=\lambda 2 x \\
2 y+z=\lambda 2 y \\
y=\lambda 2 z \\
x^2+y^2+z^2=4
\end{array}\right.
$$"
14,Mathematics,18.100B,Real Analysis,18.02,None,Problem Set 3,Cauchy Sequence,1,a,0.7142857143,Text,"Which ones of the statements below are correct:
$\left(x_{n}\right)$ is Cauchy if and only if there is an $N \in \mathbb{N}$ such that for all $\epsilon>0$, we have $\left|x_{n}-x_{m}\right|<\epsilon$ for all $m, n \geq N$.
Proof (if correct) or counterexample (if incorrect).",Open,"False. Let $x_{n}=\frac{1}{n}$. Then $\left(x_{n}\right)$ converges to 0 , hence it is Cauchy. On the other hand, let $N \in \mathbb{N}$ be given. Let $\varepsilon=\frac{1}{2 N}$. Then $\left|x_{N}-x_{2 N}\right|=\frac{1}{2 N}$. Therefore, such an $N$ does not exist.
Remark. The condition in the statement of the problem is strictly stronger than being Cauchy, so the ""if"" direction holds.","Which ones of the statements below are correct:
$\left(x_{n}\right)$ has a subsequence converging to $l$ if and only if the following holds. For every $\epsilon>0$ and for every $N \in \mathbb{N}$ there is an $n \geq N$ such that $\left|x_{n}-l\right|<\epsilon$.
Proof (if correct) or counterexample (if incorrect).","True. Using Lemma 2.14, it is enough to prove the following: given $\left(x_{n}\right)$, for any $\varepsilon>0$, there are infinitely many $n$ such that $\left|x_{n}-l\right|<\varepsilon$ if and only if for any $\varepsilon>0$, and for every $N \in \mathbb{N}$, there is an $n \geq N$ such that $\left|x_{n}-l\right|<\varepsilon$.
For the ""if"" direction, suppose for purpose of contradiction that there were only finitely many $n_{1} \leq n_{2} \leq \cdots \leq n_{k}$ such that $\left|x_{n_{i}}-l\right|<\varepsilon(1 \leq i \leq k)$. But this is a contradiction with $N=n_{k}+1$
For the ""only if"" direction, suppose for purpose of contradiction that there exists $N$ such that for every $n \geq N,\left|x_{n}-l\right| \geq \varepsilon$. Then there are at most $N$ natural numbers $n$ such that $\left|x_{n}-l\right|<\varepsilon$, which contradicts our assumption that there are infinitely many.","True or false? Give either a brief argument for why it's true, or a counterexample (no complete proofs are required here):
If $\left(x_{n}^{2}\right)$ converges, then $\left(x_{n}\right)$ converges.",False. Let $x_{n}=(-1)^{n}$. Then $x_{n}^{2}=1$ converges while $x_{n}$ does not.,"Suppose $u_{n} \in \mathcal{C}_{\mathrm{c}}(\mathbb{R})$ form an absolutely summable series with respect to the $L^{1}$ norm and set
$$
E=\left\{x \in \mathbb{R} ; \sum_{n}\left|u_{n}(x)\right|=\infty\right\}
$$
Deduce that if $\epsilon>0$ is given then there is an open set $O_{\epsilon} \supset E$ with $\sum_{n}\left|u_{n}(x)\right|>1 / \epsilon$ for each $x \in O_{\epsilon}$.","The subset $Z_{\epsilon}=\left\{x \in \mathbb{R} ; \sum_{n}\left|u_{n}(x)\right| \leq 1 / \epsilon\right\}$ is closed by 1 . Then $O_{\epsilon}=\mathbb{R} \backslash Z_{\epsilon}$ is open and, obviously, $E \subset O_{\epsilon}$."
59,EECS,6.121,Introduction to Algorithms,"6.100A, 6.1200",6.101,Problem Set 7,Convex Polygons,1,nan,0.625,Text,"A convex polygon is a polygon such that the line segment between any two points of the polygon is contained within the interior and the boundary of the polygon. Alternatively, any line that does not contain an edge of the polygon intersects the polygon in at most two points.
A chord is a line segment that connects any two vertices of a convex polygon, but that is not an edge of the polygon. Notably, a chord will split a convex polygon into two smaller convex polygons. A triangulation of a convex polygon is a decomposition of the polygon into a set of triangles. More formally, it is a set of $n-3$ chords that intersect only at the vertices of the polygon.
Alice is given a convex polygon $P$ consisting of $n$ points. Each point is given as a Cartesian coordinate, that is to say, as an $(x, y)$ pair for floating point values $x$ and $y$. Assume that the points are given in order, or in other words, the points are given in an ordering such that every two adjacent points form an edge of $P$ (and the first and the last point in this ordering form an edge of $P)$.
Alice would like to produce a triangulation of $P$ that minimizes the cost of the triangulation. The cost of the triangulation is defined to be the sum of the lengths of the chords that produce the triangulation. The length of a chord is the Euclidean distance between the two endpoints of the chord, i.e. for points $\left(x_{1}, y_{1}\right)$ and $\left(x_{2}, y_{2}\right)$, the distance is $\sqrt{\left(x_{1}-x_{2}\right)^{2}+\left(y_{1}-y_{2}\right)^{2}}$.
Give an algorithm that outputs the cost of the minimum cost triangulation in $O\left(n^{3}\right)$ time.",Open,"First, we note that the points are given in order, say $\left\{p_{0}, \ldots, p_{n-1}\right\}$. For $i, j \in[n]$ where $i<j$, we define $C(i, j)$ to be the minimum cost of triangulating the polygon given by the points $p_{i-1}, p_{i}, \ldots, p_{j}$. Let $d_{i, j}$ denote the length of the chord between $p_{i}$ and $p_{j}$, where $i<j$ and $j-i>1$. If $j-i \leq 1$, we define $d_{i, j}$ to be 0 . Then, $C(i, j)=\min _{i \leq k<j}\left(C(i, k)+C(k+1, j)+d_{i-1, k}+d_{k, j}\right)$. Note that for every $i, C(i, i)=0$, which forms our base case. Now, $C(1, n-1)$ gives the lowest cost triangulation.
More formally, here is the solution in the five steps, assuming the points given in order are $\left\{p_{0}, \ldots, p_{n-1}\right\}$
1. Subproblem: Let $C(i, j)$ denote the minimum cost of triangulating the polygon given by points $p_{i-1}, p_{i}, \ldots, p_{j}$. We need to compute $C(i, j)$ for any $1 \leq i \leq j<n$. There are $O\left(n^{2}\right)$ subproblems.
2. Relate: For any point $p_{k}$ where $i \leq k<j$, we can guess the triangle given by $p_{i-1}, p_{k}$, and $p_{j}$ to be part of the triangulation. This gives us $O(n)$ possibilities. Thus, we have $C(i, j)=$ $\min _{i \leq k<j}\left(C(i, k)+C(k+1, j)+d_{i-1, k}+d_{k, j}\right)$, where we let $d_{r, s}$ denote the length of the chord between $p_{r}$ and $p_{s}$, where $r<s$ and $s-r>1$. If $s-r \leq 1$, we define $d_{r, s}$ to be 0.
3. Topological order: We solve the subproblems in strictly increasing order of $j$, starting with $j=1$. Among subproblems with the same $j$, we solve these in strictly decreasing order of $i$, starting with $i=j$. We note that each subproblem depends on either subproblems with strictly smaller $j$ or on subproblems with equal $j$ but strictly greater $i$, so as such, it is acyclic.
4. Base case: For the base case, $C(i, i)=0$ for every $i$.
5. Original problem: The final output is $C(1, n-1)$, which is the minimum cost of triangulating the polygon given by the points $p_{0}, \ldots, p_{n-1}$.
6. Time: The final time complexity is $O\left(n^{3}\right)$, because we have $O\left(n^{2}\right)$ subproblems, and at each subproblem, we perform $O(n)$ work for the guesses.
Note that a correct solution may be written with different indices - for instance, we define $C(i, j)$ to include $p_{i-1}$, so that the base case is $C(i, i)$, instead of $C(i, i+1)$, but either are valid (e.g., $C(i, j)$ can simply include $p_{i}, \ldots, p_{j}$, and the base case can be appropriately modified). Alternatively, one may label the edges, and recurse on ranges of consecutive edges. Or, one may take $\left(p_{i}, p_{i+1}\right)$ as the edge to consider constructing a triangle with, rather than $\left(p_{i}, p_{j}\right)$. All of these are fine as long as edge cases are appropriately taken care of, and the sub-problem definition is written without errors.
There are also other ways to write the recursion that are just as valid. For instance, instead of considering each $p_{i}, p_{j}$ as an edge that must be contained within a triangle, one may consider for each polygon $p_{i}, \ldots, p_{j}$, there must exist a $k$ such that $p_{k-1}, p_{k}, p_{k+1}$ forms a triangle (taking each index $\bmod (j-i+1)$ and then summed with $i$, so that it remains within the range $p_{i}$ to $\left.p_{j}\right)$. Then, the recursion can be correctly written by drawing the chord from $p_{k-1}, p_{k+1}$, and recursing on the smaller polygon produced. Another way is to consider chords coming from each vertex $p_{i}$; either $p_{i}$ must initiate a chord that divides the polygon into two halves, or there must be a chord $p_{j}, p_{i+1}$ (note that it would be incorrect to say that each vertex $p_{i}$ must be an endpoint of a chord; there are valid triangulations with no chords out of certain vertices). Any of these methods are valid, as long as they are correctly formulated.","Recall the general form of quadratic programming with inequality constraints:
$$
\min _{z} \frac{1}{2} z^{T} P z+q^{T} z \quad \text { s.t. } \quad A z \leq b
$$
Consider the 2-dimensional square
$$
T=\left\{\left(x_{1}, x_{2}\right) \text { s.t. }\left|x_{1}\right| \leq 1,\left|x_{2}\right| \leq 1\right\}
$$
Given a point $y=\left(y_{1}, y_{2}\right)$ express the problem of finding the point $z \in T$ that is the closest in Euclidean distance to $y$ as a quadratic program as above. Argue that the solution is unique.","First we express $T$ as a system of linear inequalities, i.e.,
$$
T=\left\{\left(x_{1}, x_{2}\right): \quad-1 \leq x_{1} \leq 1, \quad-1 \leq x_{2} \leq 1\right\} .
$$
Let
$$
A=\left[\begin{array}{c}
I \\
-I
\end{array}\right]
$$
where $I$ is the $2 \times 2$ identity matrix, and
$$
b=\left[\begin{array}{c}
1 \\
1 \\
-1 \\
-1
\end{array}\right]
$$
Then $T=\{x: A x \leq b\}$. Now we can write the objective function as
$$
\|x-y\|_{2}^{2}=(x-y)^{T}(x-y)=x^{T} I x-2 y^{T} x+\|y\|_{2}^{2}
$$
Since the constant term $\|y\|_{2}^{2}$ only shifts the objective value, we can remove it. Then we get $P=2 I$ and $q=-2 y$. The solution is unique because $P$ is positive definite. ","For each of the sets $S_{1}, S_{2}, S_{3}, S_{4}$, say whether they are convex or not, and justify your answer.
Let $x_{1}, \ldots, x_{k}$ be points in $\mathbb{R}^{n}$, and define
$$
S_{2}=\left\{\sum_{i=1}^{k} c_{i} x_{i}: \sum_{i=1}^{k} c_{i}=1 \text { and } \forall i, c_{i} \geq 0\right\}.
$$","$S_{2}$ is convex. For any two points $a=\sum_{i} c_{i} x_{i}, a^{\prime}=\sum_{i} c_{i}^{\prime} x_{i}$ in $S_{2}$, we need to show that $\lambda a+(1-\lambda) a^{\prime} \in S_{2}$, for all $0 \leq \lambda \leq 1$. Combining the sums we get
$$
\lambda a+(1-\lambda) a^{\prime}=\sum_{i}\left(\lambda c_{i}+(1-\lambda) c_{i}^{\prime}\right) x_{i}.
$$
Letting $d_{i}=\lambda c_{i}+(1-\lambda) c_{i}^{\prime}$, we need to show that $d_{i} \geq 0$ and $\sum_{i} d_{i}=1$. The former is clear by definition, whereas the latter is true because $\sum_{i} d_{i}=\lambda+(1-\lambda)=1$.","Let $f(x, y)$ be a convex function. Then, the set
$$
\left\{(x, y) \in \mathbb{R}^{2}: f(x, y)+y^{4} \leq 0\right\}
$$
is a convex set.","True. The function $g(x, y)=f(x, y)+y^{4}$ is also convex, since it is the sum of two convex functions. Thus, its sublevel sets are convex."
8,EECS,6.3,Signal Processing,"6.100A, 18.03",None,Problem Set 2,Trigonometric Expansions,1,a,0.1875,Text,"In this problem, we compare two methods for expanding a function $f(\theta)$ as a series of the form
$$
f(\theta)=c_{0}+\sum_{k=1}^{\infty} c_{k} \cos (k \theta)+\sum_{k=1}^{\infty} d_{k} \sin (k \theta).
$$
Use the trigonometric identities provided on the last page of this homework assignment plus the rules of ordinary algebra to determine the values of the non-zero coefficients $c_{k}$ and $d_{k}$ needed to expand the function
$$
f_{1}(\theta)=\cos ^{5}(\theta).
$$",Numerical,"$$
\begin{aligned}
f_{1}(\theta) &=\cos ^{5}(\theta)=\cos ^{2}(\theta) \cos ^{2}(\theta) \cos (\theta) \\
&=\left(\frac{1+\cos (2 \theta)}{2}\right) \times\left(\frac{1+\cos (2 \theta)}{2}\right) \times \cos (\theta) \\
&=\left(\frac{1+2 \cos (2 \theta)+\cos ^{2}(2 \theta)}{4}\right) \times \cos (\theta) \\
&=\left(\frac{1+2 \cos (2 \theta)+\frac{1+\cos (4 \theta)}{2}}{4}\right) \times \cos (\theta) \\
&=\left(\frac{3}{8}+\frac{1}{2} \cos (2 \theta)+\frac{1}{8} \cos (4 \theta)\right) \cos (\theta) \\
&=\frac{3}{8} \cos (\theta)+\frac{1}{2} \cos (2 \theta) \cos (\theta)+\frac{1}{8} \cos (4 \theta) \cos (\theta) \\
&=\frac{3}{8} \cos (\theta)+\frac{1}{4} \cos (\theta)+\frac{1}{4} \cos (3 \theta)+\frac{1}{16} \cos (3 \theta)+\frac{1}{16} \cos (5 \theta) \\
&=\frac{5}{8} \cos (\theta)+\frac{5}{16} \cos (3 \theta)+\frac{1}{16} \cos (5 \theta)
\end{aligned}
$$
The coefficient $c_{1}=5 / 8, c_{3}=5 / 16$, and $c_{5}=1 / 16$. The other coefficients are zero.","In this problem, we compare two methods for expanding a function $f(\theta)$ as a series of the form
$$
f(\theta)=c_{0}+\sum_{k=1}^{\infty} c_{k} \cos (k \theta)+\sum_{k=1}^{\infty} d_{k} \sin (k \theta).
$$
Use the trigonometric identities provided on the last page of this homework assignment plus the rules of ordinary algebra to determine the values of the non-zero coefficients $c_{k}$ and $d_{k}$ needed to expand the function
$$
f_{2}(\theta)=\sin ^{5}(\theta) .
$$","$$
\begin{aligned}
f_{2}(\theta) &=\sin ^{5}(\theta)=\sin ^{2}(\theta) \sin ^{2}(\theta) \sin (\theta) \\
&=\left(\frac{1-\cos (2 \theta)}{2}\right) \times\left(\frac{1-\cos (2 \theta)}{2}\right) \times \sin (\theta) \\
&=\left(\frac{1-2 \cos (2 \theta)+\cos ^{2}(2 \theta)}{4}\right) \times \sin (\theta) \\
&=\left(\frac{1-2 \cos (2 \theta)+\frac{1+\cos (4 \theta)}{2}}{4}\right) \times \sin (\theta) \\
&=\left(\frac{3}{8}-\frac{1}{2} \cos (2 \theta)+\frac{1}{8} \cos (4 \theta)\right) \sin (\theta) \\
&=\frac{3}{8} \sin (\theta)-\frac{1}{2} \cos (2 \theta) \sin (\theta)+\frac{1}{8} \cos (4 \theta) \sin (\theta) \\
&=\frac{3}{8} \sin (\theta)-\frac{1}{4} \sin (3 \theta)+\frac{1}{4} \sin (\theta)+\frac{1}{16} \sin (5 \theta)-\frac{1}{16} \sin (3 \theta) \\
&=\frac{5}{8} \sin (\theta)-\frac{5}{16} \sin (3 \theta)+\frac{1}{16} \sin (5 \theta)
\end{aligned}
$$
The coefficient $d_{1}=5 / 8, d_{3}=-5 / 16$, and $d_{5}=1 / 16$. The other coefficients are zero.","In this problem, we compare two methods for expanding a function $f(\theta)$ as a series of the form
$$
f(\theta)=c_{0}+\sum_{k=1}^{\infty} c_{k} \cos (k \theta)+\sum_{k=1}^{\infty} d_{k} \sin (k \theta).
$$
An alternative to trigonometric identities is to use complex exponentials. Determine the non-zero coefficients $c_{k}$ and $d_{k}$ as in the previous part - but this time use Euler's formula and complex numbers, but no trigonometric identities.","We can use Euler's formula to rewrite the target function as
$$
f_{1}(\theta)=\left(\frac{e^{j \theta}+e^{-j \theta}}{2}\right)^{5} .
$$
Then we can expand the fifth power by repeated multiplication (or by using the binomial equation) to get 
$$
f_{1}(\theta)=\frac{1}{32}\left(e^{j 5 \theta}+5 e^{j 3 \theta}+10 e^{j \theta}+10 e^{-j \theta}+5 e^{-3 j \theta}+e^{-5 j \theta}\right).
$$
Finally, we can pair complex exponentials with their negative partners and use Euler's formula to obtain
$$
f_{1}(\theta)=\frac{5}{8} \cos (\theta)+\frac{5}{16} \cos (3 \theta)+\frac{1}{16} \cos (5 \theta).
$$
As before, the coefficient $c_{1}=5 / 8, c_{3}=5 / 16$, and $c_{5}=1 / 16$. The others are zero.","In this problem, we compare two methods for expanding a function $f(\theta)$ as a series of the form
$$
f(\theta)=c_{0}+\sum_{k=1}^{\infty} c_{k} \cos (k \theta)+\sum_{k=1}^{\infty} d_{k} \sin (k \theta).
$$
Determine the non-zero coefficients $c_{k}$ and $d_{k}$ as in the previous part - but this time use Euler's formula and complex numbers, but no trigonometric identities.","Use Euler's formula to rewrite the target function as
$$
f_{2}(\theta)=\left(\frac{e^{j \theta}-e^{-j \theta}}{2 j}\right)^{5} \text {. }
$$
Then expand the fifth power by repeated multiplication (or by using the binomial formula) to obtain
$$
f_{2}(\theta)=\frac{1}{32 j}\left(e^{j 5 \theta}-5 e^{j 3 \theta}+10 e^{j \theta}-10 e^{-j \theta}+5 e^{-3 j \theta}-e^{-5 j \theta}\right).
$$
Then pair the complex exponentials with their negative partners and use Euler's formula to obtain
$$
f_{2}(\theta)=\frac{5}{8} \sin (\theta)-\frac{5}{16} \sin (3 \theta)+\frac{1}{16} \sin (5 \theta).
$$
As before, the coefficient $d_{1}=5 / 8, d_{3}=-5 / 16$, and $d_{5}=1 / 16$. The others are zero."
139,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 4,Planning Heuristics,2,c,0.3472222222,Text,"Let's now compare different search algorithms and heuristics.
Let's consider two of the search algorithms available in pyperplan: astar, gbf.
And the following heuristics: blind, hadd, hmax, hff, lmcut. blind, hmax and lmcut are admissible; hadd and hff are not.
Unfortunately the documentation for pyperplan is limited at the moment, but if you are curious to learn more about its internals, the code is opensourced on this GitHub repo.
Consider the RPG construction algorithm discussed in class: Lec 7. Mark all that are true.
(a) If there exists a plan to achieve a goal with a single fact {g}, then that fact g must appear in some level of the relaxed planning graph (RPG).
(b) If there exists a plan to achieve a goal with a single fact {g}, then that fact g must appear in the last level of the RPG.
(c) The last level of the RPG is a superset of all of the facts that could ever be in the state by taking actions from the initial state.
(d) The initialization (initial state) of the RPG may affect the number of levels in the RPG, but it will not change the final set of facts in the last level of the RPG.
(e) If a fact g appears in some level of the RPG, then there exists a (non-relaxed) plan to achieve the goal {g}.",Multiple Choice,"(a) If there exists a plan to achieve a goal with a single fact {g}, then that fact g must appear in some level of the relaxed planning graph (RPG).
(b) If there exists a plan to achieve a goal with a single fact {g}, then that fact g must appear in the last level of the RPG.","Let's now compare different search algorithms and heuristics.
Let's consider two of the search algorithms available in pyperplan: astar, gbf.
And the following heuristics: blind, hadd, hmax, hff, lmcut. blind, hmax and lmcut are admissible; hadd and hff are not.
Unfortunately the documentation for pyperplan is limited at the moment, but if you are curious to learn more about its internals, the code is opensourced on this GitHub repo.
Consider the PDDL domain for logistics.
We create a delete-relaxed version of the logistics domain by dropping the negative effects from each operator.
Now we want to compute $h^{f f}$ for this initial state and goal
I = {truck(t), package(p), location(a), location(b),
location(c), location(d), location(e),
at(t, a), at(p, c),
road(a, b), road(b, c), road(c, d), road(a, e),
road(b, a), road(c, b), road(d, c), road(e, a)}
G = {at(t, a), at(p, d)}.
What are the actions in the relaxed plan that we would extract from the RPG for this problem, using the $h^{f f}$ algorithm? Enter the plan as a list of strings; ordering is not important.
Enter a list of strings, e.g. [""drive-truck(t,a,b)"", ""unload-truck(p,t,d)""].","['drive-truck(t,a,b)', 'drive-truck(t,b,c)', 'drive-truck(t,c,d)', 'load-truck(p,t,c)', 'unload-truck(p,t,d)']","Let's now compare different search algorithms and heuristics.
Let's consider two of the search algorithms available in pyperplan: astar, gbf.
And the following heuristics: blind, hadd, hmax, hff, lmcut. blind, hmax and lmcut are admissible; hadd and hff are not.
Unfortunately the documentation for pyperplan is limited at the moment, but if you are curious to learn more about its internals, the code is opensourced on this GitHub repo.
We have given you a set of blocks planning problem of different complexity BW_BLOCKS_PROBLEM_1 to BW_BLOCKS_PROBLEM_6 . You can use the function test_run_planning found in the Colab to test the different combinations of search and heuristic on different problems. There is also a helper function in the Colab to plot the result.
If planning takes more than 30 seconds, just kill the process.
Choose all that apply:
(a) Problems 1, 2 and 3 are easy (plan in less than 30 seconds) for all the methods.
(b) Problem 4 is easy (plan in less than 30 seconds) for all the non-blind heuristics.
(c) Problem 4 is easy (plan in less than 30 seconds) for all the non-blind heuristics, except hmax.
(d) The blind heuristic is generally hopeless for the bigger problems.
(e) hadd is generally much better (leads to faster planning) than hmax.
(f) gbf-lmcut will always find paths of the same length as astar-lmcut (given sufficient time).
(g) astar-lmcut will always find paths of the same length as astar-hmax (given sufficient time).
(h) astar-lmcut usually finds paths of the same length as astar-hff (in these problems).
(i) gbf-hff is a good compromise for planning speed and plan length (in these problems).","(a) Problems 1, 2 and 3 are easy (plan in less than 30 seconds) for all the methods.
(c) Problem 4 is easy (plan in less than 30 seconds) for all the non-blind heuristics, except hmax.
(d) The blind heuristic is generally hopeless for the bigger problems.
(e) hadd is generally much better (leads to faster planning) than hmax.
(g) astar-lmcut will always find paths of the same length as astar-hmax (given sufficient time).
(h) astar-lmcut usually finds paths of the same length as astar-hff (in these problems).
(i) gbf-hff is a good compromise for planning speed and plan length (in these problems).","Let's now compare different search algorithms and heuristics.
Let's consider two of the search algorithms available in pyperplan: astar, gbf.
And the following heuristics: blind, hadd, hmax, hff, lmcut. blind, hmax and lmcut are admissible; hadd and hff are not.
Unfortunately the documentation for pyperplan is limited at the moment, but if you are curious to learn more about its internals, the code is opensourced on this GitHub repo.
Consider the PDDL domain for logistics.
We create a delete-relaxed version of the logistics domain by dropping the negative effects from each operator.
Now we want to compute $h^{f f}$ for this initial state and goal
I = {truck(t), package(p), location(a), location(b),
location(c), location(d), location(e),
at(t, a), at(p, c),
road(a, b), road(b, c), road(c, d), road(a, e),
road(b, a), road(c, b), road(d, c), road(e, a)}
G = {at(t, a), at(p, d)}.
What is the value of the heuristic score of the initial state: $h^{f f}(I)$?
Enter an integer:",5
68,Mathematics,18.404,Theory of Computation,6.1210/18.200,None,Final Exam,Regular Language,1,a,0.2083333333,Text,"For each of the following statements, answer True, $\underline{\text { False }}$ or Open question according to our current state of knowledge of complexity theory, as described in class. Do not give reasons for your answers.
$\{A \mid A$ is a regular language $\} \subseteq \operatorname{TIME}(n)$.",Multiple Choice,"True, simulate the DFA.","For each of the following statements, answer True, $\underline{\text { False }}$ or Open question according to our current state of knowledge of complexity theory, as described in class. Do not give reasons for your answers.
$\{A \mid A$ is a CFL $\} \subseteq \operatorname{TIME}\left(n^{8}\right)$.","True, dynamic programming for $A_{\mathrm{CFG}}$ runs within time $O\left(n^{5}\right)$.","For each of the following statements, answer True, $\underline{\text { False }}$ or Open question according to our current state of knowledge of complexity theory, as described in class. Do not give reasons for your answers.
$\operatorname{TIME}\left(n^{2}\right) \subseteq\{A \mid A$ is a $C F L\}$.","False, $\left\{0^{k} 1^{k} 2^{k} \mid k \geq 0\right\} \in \operatorname{TIME}\left(n^{2}\right)$.","For each of the following statements, answer True, $\underline{\text { False }}$ or Open question according to our current state of knowledge of complexity theory, as described in class. Do not give reasons for your answers.
$\mathrm{P} \subseteq \operatorname{TIME}\left(n^{9}\right)$.","False, hierarchy theorem."
134,Mathematics,18.02,Calculus II,18.01,None,Final Exam,Chain Rule,8,a,1.2,Text,"Let $F(x, y, z)$ be a smooth function of three variables for which $\nabla F(1,-1, \sqrt{2})$ $\langle 1,2,-2\rangle$.
Use the Chain Rule to evaluate $\frac{\partial F}{\partial \phi}$ at $(\rho, \phi, \theta)=\left(2, \frac{\pi}{4},-\frac{\pi}{4}\right)$.
(Use $x=\rho \sin \phi \cos \theta, \quad y=\rho \sin \phi \sin \theta, \quad z=\rho \cos \phi$. )",Numerical,"$$
\begin{gathered}
\frac{\partial F}{\partial \phi}=\frac{\partial F}{\partial x} \frac{\partial x}{\partial \phi}+\frac{\partial F}{\partial y} \frac{\partial y}{\partial \phi}+\frac{\partial F}{\partial z} \frac{\partial z}{\partial \phi} \\
\frac{\partial x}{\partial \phi}=\rho \cos \phi \cos \theta \Rightarrow x_\phi(2, \pi / 4,-\pi / 4)=2 \cos (\pi / 4) \cos (-\pi / 4)=1 . \\
\frac{\partial y}{\partial \phi}=\rho \cos \phi \sin \theta \Rightarrow y_\phi(2, \pi / 4,-\pi / 4)=2 \cos (\pi / 4) \sin (-\pi / 4)=-1 . \\
\frac{\partial z}{\partial \phi}=-\rho \sin \phi \Rightarrow z_\phi(2, \pi / 4,-\pi / 4)=-2 \sin (\pi / 4)=-\sqrt{2} .
\end{gathered}
$$","Let $\vec{F}=\left(z^2-2\right) \hat{i}+3 y^2 \hat{j}+2 x z \hat{k}$ be a vector field. 
Show that if $f(x, y, z)=x z^2-2 x+y^3$ then $\vec{F}=\nabla f$.","$$
\begin{aligned}
\nabla f &=\left(\begin{array}{c}
f_x \\
f_y \\
f_z
\end{array}\right) \\
&=\left(\begin{array}{c}
z^2-2 \\
3 y^2 \\
2 x z
\end{array}\right) \\
&=\vec{F}
\end{aligned}
$$","$\mathbf{F}(x, y, z)=\left(y+y^2 z\right) \mathbf{i}+(x-z+2 x y z) \mathbf{j}+\left(-y+x y^2\right) \mathbf{k}$. Show that $\mathbf{F}(x, y, z)$ is a gradient field using the derivative conditions.","We have $\mathbf{F}=\langle P, Q, R\rangle$, where $P=y+y^2 z, \quad Q=x-z+2 x y z, \quad R=-y+x y^2$.
$$
\frac{\partial P}{\partial z}=y^2=\frac{\partial R}{\partial x} ; \quad \frac{\partial Q}{\partial z}=-1+2 x y=\frac{\partial R}{\partial y} ; \quad \frac{\partial P}{\partial y}=1+2 y z=\frac{\partial Q}{\partial x} .
$$","$\mathbf{F}(x, y, z)=\left(y+y^2 z\right) \mathbf{i}+(x-z+2 x y z) \mathbf{j}+\left(-y+x y^2\right) \mathbf{k}$. Find $\int_C \mathbf{F} \cdot d \mathbf{r}$, where $C$ is the straight line joining the points $(2,2,1)$ and $(1,-1,2)$ (in that order), using as little computation as possible.","$\int_{C} \mathbf{F} \cdot d \mathbf{r}=f(1,-1,2)-f(2,2,1)=-10+3=-7$."
137,Mathematics,18.01,Calculus I,None,None,Problem Set 4,Chain Rule,2,b,0.03959873284,Text,Apply the chain rule to $\frac{d}{d x}(\ln (f(x)))$.,Expression,$\frac{d}{d x}(\ln (f(x)))=\frac{f^{\prime}(x)}{f(x)}$.,Apply the chain rule to $\frac{d}{d x}\left(e^{f(x)}\right)$.,$\frac{d}{d x}\left(e^{f(x)}\right)=f^{\prime}(x) e^{f(x)}$.,"The integral of $\ln x$.
Use the product rule to compute the derivative of $x \ln x$.",$(x \ln x)^{\prime}=x(\ln x)^{\prime}+x^{\prime} \ln x=\frac{x}{x}+\ln x=1+\ln x$.,"Suppose that $f(x)=\ln \left(2 x^{4}-x^{3}\right)$. Remember that $\ln x$ is short for $\log _{e} x$, and $\frac{d}{d x} \ln x=\frac{1}{x}$
Suppose we want to approximate $f(1.01)$. It sounds pretty complicated at first, but we can do it using the things we know if we go in two steps.
Using linear approximation, estimate the value of $2 x^{4}-x^{3}$ when $x=1.01$.","Write $p(x)=2 x^{4}-x^{3}$ such that $f(x)=\ln (p(x))$. The goal is then to approximate $\ln (p(1.01))$, so we begin by approximating $p(1.01)$.
To get a linear approximation to $p$ we use $p(1)=1$ and $p^{\prime}(x)=8 x^{3}-3 x^{2}$ so $p^{\prime}(1)=5$. So we have
$$
p(1.01) \approx p(1)+.01 \cdot p^{\prime}(1)=1+.01 \cdot 5=1.05 .
$$"
119,EECS,6.122,Design and Analysis of Algorithms,6.121,None,Midterm Exam 2,Linear Programming,3,a,1.25,Text,"Each day of your work at Atem Inc. starts by you having to solve the following non-linear optimization problem, where the constants $\alpha, \beta, \gamma$ and $\delta$ change every day.
$$
\begin{array}{ll}
\text { maximize } & x^{2}+y \\
\text { subject to } & x^{2}+\alpha y \leq \beta \\
& \left|x^{2}+\gamma y\right| \leq \delta \\
& y \geq 0
\end{array}
$$
You have access to a linear programming solver, so why not try to make your life simpler and try to use it! Show how to transform the non-linear optimization problem above into a linear program that is guaranteed to have the same optimal value.",Open,"The following is a linear program with the same set of solutions as the given constraint system. Replace $x^{2}$ by a new variable $z$ and add a constraint that $z \geq 0$. Replace the constraint $\left|x^{2}+\gamma y\right| \leq \delta$ by two constraints $z+\gamma y \leq \delta$ and $-(z+\gamma y) \leq \delta$. This results in the following LP:
$$
\begin{array}{ll}
\operatorname{minimize} & z+y \\
\text { subject to } & z+\alpha y \leq \beta \\
& z+\gamma y \leq \delta \\
& -(z+\gamma y) \leq \delta \\
& z, y \geq 0
\end{array}
$$","Consider the following linear program and its dual
$$
\begin{array}{ccrl}
\operatorname{maximize} & 6 x+6 y & \text { minimize } & a+2 b \\
\text { subject to } & x+2 y=1 & \text { subject to } & a+3 b \geq 6, \\
& 3 x+y=2, & & 2 a+b \geq 6, \\
& x, y \geq 0, & &
\end{array}
$$
Infer from your answer to (b), the optimal solution to the primal.","We can use complementary slackness. We check that since the constraint $2 a+b \geq 6$ is not tight, we must have that $y=0$. We can then solve for $x$ and $z$ to get $x=z=\frac{1}{2}$ which is feasible and gets the objective value 5 as well.","Consider the following linear program and its dual
$$
\begin{array}{ccrl}
\operatorname{maximize} & 6 x+6 y & \text { minimize } & a+2 b \\
\text { subject to } & x+2 y=1 & \text { subject to } & a+3 b \geq 6, \\
& 3 x+y=2, & & 2 a+b \geq 6, \\
& x, y \geq 0, & &
\end{array}
$$
Suppose we add the constraint $a+b \geq 4$ to the dual. Fill in the corresponding primal
$$
\begin{array}{r}
\text { maximize } \\
\text { subject to }
\end{array}
$$
$$
\begin{array}{cc}
\operatorname{minimize} & a+2 b \\
\text { subject to } & a+3 b \geq 6, \\
& 2 a+b \geq 6, \\
& a+b \geq 4,
\end{array}
$$","The new primal and dual are
$$
\begin{aligned}
& \text { maximize } 6 x+6 y+4 z \quad \text { minimize } a+2 b \\
& \text { subject to } x+2 y+z=1 \quad \text { subject to } a+3 b \geq 6 \text {, } \\
& 3 x+y+z=2 \quad 2 a+b \geq 6 . \\
& x, y, z \geq 0, \quad a+b \geq 4,
\end{aligned}
$$","Consider the following linear program and its dual
$$
\begin{array}{ccrl}
\operatorname{maximize} & 6 x+6 y & \text { minimize } & a+2 b \\
\text { subject to } & x+2 y=1 & \text { subject to } & a+3 b \geq 6, \\
& 3 x+y=2, & & 2 a+b \geq 6, \\
& x, y \geq 0, & &
\end{array}
$$
Draw the feasible region of the new dual program, and find the optimal solution $(a, b)$ of the dual and its value.","The feasible region of the dual is unbounded, and the only vertices are $(3,1)$ and $(2,2)$. The optimal solution to the dual is $a=3$ and $b=1$, which obtains the objective value 5."
112,EECS,6.121,Introduction to Algorithms,"6.100A, 6.1200",6.101,Mini Quiz 9,Optimal Subproblem Property,4,nan,0.2222222222,Text,"Which is the correct Optimal Sub-Problem Property for the Activity Selection Problem? Assume that $A=\left\{a_{1}, \ldots, a_{n}\right\}$ and that $a$ is the activity with the earliest start time chosen by an optimal strategy $S$.
$\mathrm{a} \quad  S$ is optimal for $A \backslash\{a\}$.
$\mathrm{b} \quad S$ is optimal for $A^{\prime}$ where $A^{\prime}$ is the set of activities that start after $a$ starts.
$\mathrm{c} \quad S$ is optimal for $A^{\prime}$ where $A^{\prime}$ is the set of activities that end after $a$ ends.
$\mathrm{d} \quad S$ is optimal for $A^{\prime}$ where $A^{\prime}$ is the set of activities that start after $a$ ends.",Multiple Choice,"$\mathrm{d} \quad S$ is optimal for $A^{\prime}$ where $A^{\prime}$ is the set of activities that start after $a$ ends.
The strategy $S$, minus the first activity $a$, must be an optimal strategy for the set of all activities that do not overlap with $a$. Otherwise we could find a better strategy than $S$.","The Greedy Choice Property for the Activity Selection Problem guarantees that the activity with earliest finish time is in
$\mathrm{a} \quad$ Every solution for the problem.
$\mathrm{b} \quad$ Some solution for the problem.
$\mathrm{c} \quad$ Every optimal solution for the problem.
$\mathrm{d} \quad$ Some optimal solution for the problem.","$\mathrm{b} \quad$ Some solution for the problem.
$\mathrm{d} \quad$ Some optimal solution for the problem.
The Greedy Choice Property only guarantees that there is some optimal solution which selects the activity with earliest finish time (activity $a$). There may be other optimal solution that do not choose $a$. For example, assume that the activities are $\{[0,1),[0,2),[3,4)\}$. Then $[0,2),[3,4)$ is an optimal solution which does not contain $[0,1)$.","Which of the following sentences are correct about Dynamic Programming?
$\mathrm{a}$ DP allows us to compute the value of an optimization problem, but not the actual solution.
$\mathrm{b}$ The runtime of a DP solution is always the number of subproblems times the time to compute each sub-problem.
$\mathrm{c}$ The Optimal Subproblem Property is always necessary for DP to be applicable.
$\mathrm{d}$ None of the above.","$\mathrm{a}$ Incorrect. One can always maintain ""parent"" pointers to obtain the actual optimal solution.
$\mathrm{b}$ Incorrect. This is only true when all sub-problems have similar complexity.
$\mathrm{c}$ Correct. Without the Optimal Subproblem Property, we cannot guarantee that the solution of a problem is composed of optimal solutions for its sub-problems. Hence, we cannot apply recursion as needed.","Given $n$ intervals $\left\{l_{1}, \ldots, l_{n}\right\}$ of positive integers where each interval is of the form $l_{i}=\left[a_{i}, b_{i}\right]$. We say that a point $p$ hits an interval $l$ if $p \in l$. All points are assumed to be integers.
The goal is to compute the minimum size of a set $P$ of points where every interval is hit by some $p \in P$.
Which is a good choice for the Greedy Choice Property? Circle a unique answer.
(a) There is an optimal set of points that includes the start point of the interval with smallest end point.
(b) There is an optimal set of points that includes the point that hits the most intervals.
(c) There is an optimal set of points that includes the end point of the interval with smallest end point.
(d) There is an optimal set of points that includes the end point of the interval with smallest start point.
(e) There is an optimal set of points that includes the start point of the interval with smallest start point.
(f) There is an optimal set of points that includes any point in the interval with smallest end point.",(c) There is an optimal set of points that includes the end point of the interval with smallest end point.
451,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Problem Set 3,Gradient Descent,7,c,0.01785714286,Text,"Fairley is interested in using linear regression to make a prediction, but they have data from two different populations, $\mathcal{D}_{1}$ and $\mathcal{D}_{2}$, and they would prefer that the hypothesis have similar accuracy in both populations. There are $n_{\mathcal{D}_{1}}$ points in the first data set and $n_{\mathcal{D}_{2}}$ in the second. The $x$ values in both data sets have dimension $d \times 1$.
If we set $\lambda$ to have a very large magnitude, and used gradient descent to find the $\theta, \theta_{0}$ that optimize $J_{F}$, which of these would be true of the resulting hypothesis?
(a) It would definitely have close to the same values of $\mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{1}\right)$ and $\mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{2}\right)$.
(b) It might have close to the same values of $\mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{1}\right)$ and $\mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{2}\right)$.
(c) It would definitely have substantially different values of $\mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{1}\right)$ and $\mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{2}\right)$.",Multiple Choice,"(a) It would definitely have close to the same values of $\mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{1}\right)$ and $\mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{2}\right)$.","Fairley is interested in using linear regression to make a prediction, but they have data from two different populations, $\mathcal{D}_{1}$ and $\mathcal{D}_{2}$, and they would prefer that the hypothesis have similar accuracy in both populations. There are $n_{\mathcal{D}_{1}}$ points in the first data set and $n_{\mathcal{D}_{2}}$ in the second. The $x$ values in both data sets have dimension $d \times 1$.
If we set $\lambda$ to have a very large magnitude, and used gradient descent to find the $\theta, \theta_{0}$ that optimize $J_{F}$, which of these would be true of the resulting hypothesis?
(a) It would definitely have small values of $\mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{1}\right)$ and $\mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{2}\right)$
(b) It might have large values of $\mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{1}\right)$ and $\mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{2}\right)$
(c) It is likely to have at least one small value of $\mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{1}\right)$ or $\mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{2}\right)$.","(b) It might have large values of $\mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{1}\right)$ and $\mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{2}\right)$","Fairley is interested in using linear regression to make a prediction, but they have data from two different populations, $\mathcal{D}_{1}$ and $\mathcal{D}_{2}$, and they would prefer that the hypothesis have similar accuracy in both populations. There are $n_{\mathcal{D}_{1}}$ points in the first data set and $n_{\mathcal{D}_{2}}$ in the second. The $x$ values in both data sets have dimension $d \times 1$.
What is $\nabla_{\theta} J_{F}\left(\theta, \theta_{0}\right)?$ Write an expression for $\nabla_{\theta} J_{F}\left(\theta, \theta_{0}\right)$, using:
L1 to stand for $\mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{1}\right)$,
L2 to stand for $\mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{2}\right)$,
G1 to stand for $\nabla_{\theta} \mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{1}\right)$,
G2 to stand for $\nabla_{\theta} \mathcal{L}\left(\theta, \theta_{0} ; \mathcal{D}_{2}\right)$,
lambda to stand for $\lambda$
* for multiplication
$+$ for addition
- for subtraction","Solution 1: G1 + G2 + (2* lambda *(L1 - L2))* (G1 - G2)
Solution 2: G1 + G2 + (lambda *(L1 - L2))* (G1 - G2)
Solution 3: G1 + G2 + (2 *(L1 - L2))* (G1 - G2)
Solution 4: G1 + G2 + (L1 - L2) * (G1 - G2)","Fairley is interested in using linear regression to make a prediction, but they have data from two different populations, $\mathcal{D}_{1}$ and $\mathcal{D}_{2}$, and they would prefer that the hypothesis have similar accuracy in both populations. There are $n_{\mathcal{D}_{1}}$ points in the first data set and $n_{\mathcal{D}_{2}}$ in the second. The $x$ values in both data sets have dimension $d \times 1$.
Assume we have test data set $\mathcal{T}_{1}$ drawn from the same population as $\mathcal{D}_{1}$ and test data set $\mathcal{T}_{2}$ drawn from the same population as $\mathcal{D}_{2}$. Would you expect that putting a greater emphasis on the fairness term in the training objective $J_{F}$ would:
(a) increase prediction accuracy of the resulting hypothesis on both $\mathcal{T}_{1}$ and $\mathcal{T}_{2}$.
(b) decrease prediction accuracy of the resulting hypothesis on at least one of $\mathcal{T}_{1}$ and $\mathcal{T}_{2}$.
(c) Neither (i.e. have none of the effects listed above).",(b) decrease prediction accuracy of the resulting hypothesis on at least one of $\mathcal{T}_{1}$ and $\mathcal{T}_{2}$.
11,Mathematics,18.3,Principles of Continuum Applied Mathematics,"18.02, 18.03",None,Problem Set 1,Single Variable Implicit Differentiation,6,d,0.1215277778,Text,"In each case compute $y^{\prime}=\frac{d y}{d p}$ as a function of $y$ and $p$, given that $y=y(p)$ satisfies: $\cos ^{2}(y)=p$, for $p>0$.",Expression,"$\cos ^{2}(y)=p$, for $p>0$ implies: $-2 \cos y \sin y \frac{d y}{d p}=1$. Thus $\frac{d y}{d p}=-\frac{1}{\sin (2 y)}$.","In each case compute $y^{\prime}=\frac{d y}{d p}$ as a function of $y$ and $p$, given that $y=y(p)$ satisfies: $y=\sin (y+p)$.",$y=\sin (y+p)$ implies: $\frac{d y}{d p}=\left(\frac{d y}{d p}+1\right) \cos (y+p)$. Thus $\frac{d y}{d p}=\frac{\cos (y+p)}{1-\cos (y+p)}$.,"In each case compute $y^{\prime}=\frac{d y}{d p}$ as a function of $y$ and $p$, given that $y=y(p)$ satisfies: $p^{3}+p y+2=0$.",$p^{3}+p y+2=0$ implies: $3 p^{2}+y+p \frac{d y}{d p}=0$. Thus $\frac{d y}{d p}=-\frac{3 p^{2}+y}{p}$.,"In each case compute $y^{\prime}=\frac{d y}{d p}$ as a function of $y$ and $p$, given that $y=y(p)$ satisfies: $y=f(p-c y)$.
Note: in (5) and (6) $f$ is an arbitrary function, and $c$ is a constant.","$y=f(p-c y)$, where $f$ is an arbitrary function and $c$ is a constant implies:
$\frac{d y}{d p}=f^{\prime}(p-c y)\left(1-c \frac{d y}{d p}\right)$. Thus $\quad \frac{d y}{d p}=\frac{f^{\prime}(p-c y)}{1+c f^{\prime}(p-c y)}$."
26,EECS,6.100A,Introduction to Computer Science Programming in Python,None,None,Problem Set 4,Recursion and Caesar Cipher,1,b,1.071428571,Text,"We might be interested in the height of our trees (for example we could use it in determining if the tree is balanced). The height of a tree is the number of edges between the root and the furthest leaf. For example in the trees you initialized above tree 1 has a height of 2 and trees 2 and 3 have a height of 3. Write a recursive function, find_tree_height, that determines the depth of a tree. This function must be recursive; non-recursive implementations will receive a zero.
Hint: The following approach may prove to be helpful.
Given an input tree, T:
Base case: If T is a leaf it has a height of 0
Recursive Step: Recursively find the height of T's left and right subtrees and find the maximum of the two.
Increment the maximum height by one and return that value.
You should test your function using the variables from the previous part. For example:
find_tree_height(tree1) # should be 2
find_tree_height(tree2) # should be 3
find_tree_height(tree3) # should be 3
def find_tree_height(tree):
    '''
    Find the height of the given tree
    Input:
        tree: An element of type Node constructing a tree
    Output:
        The integer depth of the tree
    '''
    # TODO: Remove pass and write your code here
    pass",Programming,"def find_tree_height(tree):
    '''
    Find the height of the given tree
    Input:
        tree: An element of type Node constructing a tree
    Output:
        The integer depth of the tree
    '''
    # TODO: Remove pass and write your code here
    if not tree:
        return -1
    return max(find_tree_height(tree.get_left_child()), find_tree_height(tree.get_right_child())) + 1","Consider the tree $T$:
For a node $x$, let $f(x)= height(x) * depth(x)$. Which of the nodes maximize $f$? (Recall that the depth of the root is 0 and the height of any leaf is also 0).","Node $d$.
\begin{tabular}{|c|c|c|c|}
\hline node & height & depth & $f$ \\
\hline$a$ & 4 & 0 & 0 \\
$b$ & 0 & 1 & 0 \\
$c$ & 3 & 1 & 3 \\
$d$ & 2 & 2 & 4 \\
$e$ & 0 & 2 & 0 \\
$f$ & 0 & 3 & 0 \\
$g$ & 1 & 3 & 3 \\
$h$ & 0 & 4 & 0 \\
$i$ & 0 & 4 & 0 \\
\hline
\end{tabular}","A special type of trees are Heaps. There are two types - Max Heaps and Min Heaps. In a Max Heap if we consider a node N, then N is the maximum value in the tree rooted at N. This means that all of the elements stored in N's left and right subtrees are less than than the value stored in N. Conversely, in a Min Heap N is the minimum value in the tree rooted at N, so all of the elements stored in N's left and right subtrees are greater than the value stored in N.
Write the function is_heap to quickly determine if a tree is a max or min heap (depending on the compare_func parameter). The compare_func is a function that takes in two arguments, child_value and parent_value. For max heaps, this function will return True if child_value < parent_value and False otherwise. For min heaps, the function will return True if child_value > parent_value and False otherwise. Conceptually, this allows you to write one function that can determine max and min heaps based on a parameter, instead of writing two separate methods with very similar code. Below are examples of possible compare_func.
#max heap comparator
def compare_func(child_value, parent_value):
    if child_value < parent_value:
       return True
    return False
#min heap comparator
def compare_func(child_value, parent_value):
    if child value > parent_value:
       return True
    return False
Hint: The following approach may prove to be helpful.
Given an input tree, T:
Base case: If T is a leaf then it is a heap (max and min)
Recursive Step: For a node T, recursive check if T's right and left subtrees are also heaps and that T is the
max or min element (depending on compare_func) of its subtree. If so return True otherwise False.
def is_heap(tree,compare_func):
    '''
    Determines if the tree is a max or min heap depending on compare_func
    Inputs:
        tree: An element of type Node constructing a tree
        compare_func: a function that compares the child node value to the parent node value
            i.e. op(child_value,parent_value) for a max heap would return True if child_value < parent_value and False otherwise
                 op(child_value,parent_value) for a min meap would return True if child_value > parent_value and False otherwise
    Output:
        True if the entire tree satisfies the compare_func function; False otherwise
    '''
    # TODO: Remove pass and write your code here
    pass","def is_heap(tree,compare_func):
    '''
    Determines if the tree is a max or min heap depending on compare_func
    Inputs:
        tree: An element of type Node constructing a tree
        compare_func: a function that compares the child node value to the parent node value
            i.e. op(child_value,parent_value) for a max heap would return True if child_value < parent_value and False otherwise
                 op(child_value,parent_value) for a min meap would return True if child_value > parent_value and False otherwise
    Output:
        True if the entire tree satisfies the compare_func function; False otherwise
    '''
    # TODO: Remove pass and write your code here
    if not tree or not tree.get_left_child() and not tree.get_right_child():
        return True
    elif not tree.get_left_child():
        return is_heap(tree.get_right_child(), compare_func) and compare_func(tree.get_right_child().get_value(), tree.get_value())
    elif not tree.get_right_child():
        return is_heap(tree.get_left_child(), compare_func) and compare_func(tree.get_left_child().get_value(), tree.get_value())
    else:
        return is_heap(tree.get_left_child(), compare_func) and compare_func(tree.get_left_child().get_value(), tree.get_value()) and is_heap(tree.get_right_child(), compare_func) and compare_func(tree.get_right_child().get_value(), tree.get_value())","In this problem set, we will be using a provided Node object in tree.py to represent trees.
The following simple tree can be initialized with the Node object as follows:
example_tree = Node(1, Node(2), Node(5, Node(7), Node(8)))
A brief explanation of the Node class is below.
• You can initialize a node with the following Node(value, left_child, right_child). value holds the value held in the node, left_child optionally holds the Node constructing the left subtree, right_child does the same for the right subtree. If there is not a subtree either do not input that parameter or pass in None
• You can get the Node object holding the left or right subtrees with get_left_child() or get_right_child respectively. If there is no child this function returns None.
• You can get the value held by a Node with get_value().
We will practice initializing trees in this part. For the trees shown below, create objects accurately representing the data. Put them into the variables at the top of ps4a.py, named tree1, tree2, and tree3.
tree1 = None #TODO
tree2 = None #TODO
tree3 = None #TODO","tree1 = Node(8, Node(2, Node(1), Node(5)), Node(10)) #TODO
tree2 = Node(7, Node(2, Node(1), Node(5, Node(4), Node(6))), Node(9, Node(8), Node(10))) #TODO
tree3 = Node(5, Node(3, Node(2), Node(4)), Node(14, Node(12), Node(21, Node(19), Node(26)))) #TODO"
82,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Prelab Questions 7,Block Size,5,b,0.02,Text,"Let's now go back to running our program with N = 16 and A = 0x300. We will use a 64 word cache that is 2-way set associative but now the block size is 2. This means that there are 16 sets, each of which has 2 cache lines with 2 words per line.
Using this new cache configuration, what is the index of the j test instruction? Provide your answer in hexadecimal.",Numerical,"0x3.
The address of the j test instruction is 0x21C = 0b_0010_0001_1100. The bottom two bits are used for word alignment. The next bit, bit[2] is used for the block offset, so the block offset for this instruction is 1. Since there are now a total of 16 sets, there are only 4 index bits so bits[6:3] are used for the index. This means that this instruction maps to index 0b0011 = 0x3.","Let's now go back to running our program with N = 16 and A = 0x300. We will use a 64 word cache that is 2-way set associative but now the block size is 2. This means that there are 16 sets, each of which has 2 cache lines with 2 words per line.
Using this new cache configuration, what is the block offset of the j test instruction? Provide your answer in hexadecimal.","0x1.
The address of the j test instruction is 0x21C = 0b_0010_0001_1100. The bottom two bits are used for word alignment. Since the block size is 2, we need 1 bit to select one of the two blocks. Bit[2] is used for the block offset, so the block offset for this instruction is 1. Since there are now a total of 16 sets, there are only 4 index bits so bits[6:3] are used for the index. This means that this instruction maps to index 0b0011 = 0x3.","Let's now go back to running our program with N = 16 and A = 0x300. We will use a 64 word cache that is 2-way set associative but now the block size is 2. This means that there are 16 sets, each of which has 2 cache lines with 2 words per line.
Using this new cache configuration, what is the tag of the j test instruction? Provide your answer in hexadecimal.","0x4.
The address of the j test instruction is 0x21C = 0b_0010_0001_1100. The bottom 7 bits are used for word alignment, block offset, and the index. So the tag is all of the remaining bits which are bits[31:7] = 0b100 = 0x4.","We will be using the following program to examine our cache behavior. Let N = 16 be the size of data region, in words. Let A be an array of N elements, located initially at 0x240. Note that these values are hardcoded into the program below but we will be changing them later.
// A = 0x240, starting address of array
// N = 16, size of data region
// this program adds 16 words from array A, then repeats.
. = 0x200
test:
li a0, 16 // initialize loop index i
li a1, 0 // sum = 0
loop: // add up elements in array
addi a0, a0, -1 // decrement index
slli a2, a0, 2 // convert to index byte offset
lw a3, 0x240(a2) // load value of A[i]
add a1, a1, a3 // add to sum
bnez a0, loop // loop until all words are summed
j test // perform test again!
// Array
. = 0x240
.word ... // A[0]
.word ... // A[1]
...
.word ... // A[15]
Our cache has a total of 64 words. The initial configuration is direct mapped, with 1 word per line, so the cache has 64 lines numbered 0-63 (0x00 - 0x3F).
To achieve 100% steady state hit ratio, it must be the case that the instructions and array data can reside in the cache at the same time. Let's check if this is currently the case.
Since there are 64 lines in the cache, we need log2(64) = 6 index bits to select a cache line. Which cache line (index) does the first instruction li a0, 16 map to? Provide your answer in hexadecimal.","0x0.
The address of the first instruction is 0x200 = 0b_0010_0000_0000. The bottom two bits are used for word alignment. Since the cache has a block size of one, there are no block offset bits. Since there are 64 lines in the cache, there are 6 index bits (bits[7:2]). Since the index = 0x0 for the first instruction, this instruction will go in line 0x0 of the cache."
204,Mathematics,18.01,Calculus I,None,None,Problem Set 5,Second Derivatives,9,b,0.04751847941,Text,"A graphing problem using second derivatives. Let $f(x)=x e^{-x}$. We will graph $f(x)$ on the range $0 \leq x$. But first we compute some information about $f(x)$.
For which $x$ is $f^{\prime}(x)=0$ ? For which $x$ is $f^{\prime}(x)>0$ and for which $x$ is $f^{\prime}(x)<0$?",Expression,$f^{\prime}(x)=0$ (maximum) when $x=1 . f^{\prime}(x)>0$ (increasing) when $x<1 . f^{\prime}(x)<0$ (decreasing) when $x>1$.,"A graphing problem using second derivatives. Let $f(x)=x e^{-x}$. We will graph $f(x)$ on the range $0 \leq x$. But first we compute some information about $f(x)$.
For which $x$ is $f^{\prime \prime}(x)=0$ ? For which $x$ is $f^{\prime \prime}(x)>0$ and for which $x$ is $f^{\prime \prime}(x)<0$ ?",$f^{\prime \prime}(x)=0$ (inflection point) when $x=2 . f^{\prime \prime}(x)>0$ (concave up) when $x>2$. $f^{\prime \prime}(x)<0$ (concave down) when $x<2$.,"A graphing problem using second derivatives. Let $f(x)=x e^{-x}$. We will graph $f(x)$ on the range $0 \leq x$. But first we compute some information about $f(x)$.
Compute $f^{\prime}(x)$ and $f^{\prime \prime}(x)$.",$f^{\prime}(x)=(1-x) e^{-x}$ (product rule) and $f^{\prime \prime}(x)=(x-2) e^{-x}$ (product rule again).,"A graphing problem using second derivatives. Let $f(x)=x e^{-x}$. We will graph $f(x)$ on the range $0 \leq x$. But first we compute some information about $f(x)$.
For which value of $x$ is $f^{\prime}(x)$ the most negative?","When $f^{\prime}(x)$ is the most negative, $f^{\prime}(x)$ is at a minimum. Thus, $f^{\prime \prime}(x)$ must be zero, which happens only when $x=2$."
100,EECS,6.122,Design and Analysis of Algorithms,6.121,None,Midterm Exam 1,Competitive Analysis,1,h,0.5,Text,"Please select True or False for the following.
An algorithm $A$ is $k$-competitive for some constant $k$ if for any sequence $R$ of length greater than zero,
$$
C_{A}(R) \leq k C_{O p t}(R)+|R|
$$",Multiple Choice,"False, $|R|$ is not a constant.","Please select True or False for the following.
If there is a linear-time reduction from a decision problem $A$ to a decision problem $B$ and there is a $2^{o(n)}$-time algorithm for problem $B$ on instances of size $n$, there is a $2^{o(n)}$-time algorithm for problem $A$ on instances of size $n$.","True. Run the reduction on an $A$-instance of size $n$. The reduction will necessarily produce a $B$-instance of size $O(n)$. Now, run the $B$-algorithm which will run in time $2^{o(n)}$, and this will solve the $A$-instance. ","Please select True or False for the following.
Consider an $O\left(n^{2}\right)$-time Monte Carlo randomized algorithm for some problem, which uses 1000 randomly generated integers between 1 and 1000, and gives the correct answer with probability $\frac{2}{3}$. Then, there is also a $O\left(n^{2}\right)$-time deterministic algorithm for the same problem.","True. Simply try all $1000^{1000}$ possible random integers, and then take the majority answer. The runtime is $O\left(n^{2}\right)$ times $1000^{1000}=O(1)$, which is still $O\left(n^{2}\right)$.","Please select True or False for the following.
Suppose a data structure has amortized $O(\log n)$ running time for all operations, where $n$ is the number of operations performed. Then, it is possible for a sequence of $n$ operations to take $\omega(n \log n)$ time.","False. Amortization is a worst-case guarantee, so any $n$ operations must use at $\operatorname{most} O(n \log n)$ time."
123,EECS,18.C06,Linear Algebra and Optimization,18.02,None,Mini Project 1,Image Blurring,2,c,0.4,Text,"We can generalize the moving average to a weighted average with weights $K_{i}$, where the window in which we take the average is of length $2 \ell+1$ instead of 3 . Given weights $\left\{K_{-\ell}, \ldots, K_{\ell}\right\}$, we define the linear map
$$
y=\operatorname{conv}_{K}(x), \quad \text { where } \quad y_{i}=\sum_{j=-\ell}^{\ell} K_{j} x_{i+j}
$$
For example, if we choose $K=\left[\begin{array}{lll}1 / 4 & 2 / 4 & 1 / 4\end{array}\right]$, we get the moving average defined earlier.
The linear map $x \mapsto \operatorname{conv}_{K}(x)$ is also called a convolution with kernel $K \bigsqcup$. Convolutions are extensively used in signal and image processing, as well as neural networks for image classification.
Implement getM $(\mathrm{n}, \mathrm{K})$, where given a kernel $K$, returns a matrix $M \in$ $\mathbb{R}^{n \times n}$ so that $\operatorname{conv}_{K}(x)=M x$ for all $x \in \mathbb{R}^{n}$. You may assume that $K$ is symmetric (i.e., $K_{-j}=K_{j}$ ) and has odd length - also recall that indexing is circular.",Programming,"function getM(n, K)
    #### Your code here ####
    l = length(K)
    row = [K; zeros(n-l)]
    hcat([circshift(row, i-1-l÷2) for i in 1:n]...)
end","We can generalize the moving average to a weighted average with weights $K_{i}$, where the window in which we take the average is of length $2 \ell+1$ instead of 3 . Given weights $\left\{K_{-\ell}, \ldots, K_{\ell}\right\}$, we define the linear map
$$
y=\operatorname{conv}_{K}(x), \quad \text { where } \quad y_{i}=\sum_{j=-\ell}^{\ell} K_{j} x_{i+j}
$$
For example, if we choose $K=\left[\begin{array}{lll}1 / 4 & 2 / 4 & 1 / 4\end{array}\right]$, we get the moving average defined earlier.
The linear map $x \mapsto \operatorname{conv}_{K}(x)$ is also called a convolution with kernel $K \bigsqcup$. Convolutions are extensively used in signal and image processing, as well as neural networks for image classification.
Implement $\operatorname{smooth}(\mathrm{x}, \mathrm{p}, \mathrm{K})$, which takes in a signal $\mathrm{x}$, parameter $\mathrm{p}$ and kernel $\mathrm{K}$, and applies $\operatorname{conv}_{K}$ to $x$, exactly $p$ times (for instance, if $p=2$, you should compute $\left.\operatorname{conv}_{K}\left(\operatorname{conv}_{K}(x)\right)\right)$. Using getM, implement smooth, apply it to the signal provided in the Jupyter notebook for $p=1,5,25$ and plot the results.","#### Your code here ####
smooth(x; p=1, K=[1,2,1]/4) = getM(length(x), K)^p * x 
plot(smooth(x, p=1) , label=""smoothed1"")
plot!(smooth(x, p=5) , label=""smoothed5"")
plot!(smooth(x, p=25) , label=""smoothed25"")","In signal processing, it is often helpful to ""smooth"" a noisy signal. For instance, if the signal is the number of daily cases of an infectious disease, a smoothed signal would diminish daily random fluctuations and make long-term trends more obvious, helping public health officials to make better decisions. One commonly used smoothing operator is the moving average: if $x$ is a signal (vector) of length $n$, the smoothed signal $\bar{x}$ using a moving (weighted) average of length 3 is given by
$$
\bar{x}_{i}=\frac{1}{4}\left(x_{i-1}+2 x_{i}+x_{i+1}\right) .
$$
For simplicity, we suppose the signal $x$ is periodic, so that the indexing is circular: $x_{-1}=x_{n}$, $x_{n+1}=x_{1}$, etc. The figure below plots a random signal and the same signal smoothed using a moving average. 
Show that the moving average mapping $x$ to $\bar{x}$ is a linear operator.",It can be easily verified that satisfies the linearity properties (expand).,"In signal processing, it is often helpful to ""smooth"" a noisy signal. For instance, if the signal is the number of daily cases of an infectious disease, a smoothed signal would diminish daily random fluctuations and make long-term trends more obvious, helping public health officials to make better decisions. One commonly used smoothing operator is the moving average: if $x$ is a signal (vector) of length $n$, the smoothed signal $\bar{x}$ using a moving (weighted) average of length 3 is given by
$$
\bar{x}_{i}=\frac{1}{4}\left(x_{i-1}+2 x_{i}+x_{i+1}\right) .
$$
For simplicity, we suppose the signal $x$ is periodic, so that the indexing is circular: $x_{-1}=x_{n}$, $x_{n+1}=x_{1}$, etc. The figure below plots a random signal and the same signal smoothed using a moving average. 
Suppose $n=6$, find a matrix $M \in \mathbb{R}^{6 \times 6}$ so that $\bar{x}=M x$.","The matrix is
$$
M=\frac{1}{4}\left[\begin{array}{llllll}
2 & 1 & 0 & 0 & 0 & 1 \\
1 & 2 & 1 & 0 & 0 & 0 \\
0 & 1 & 2 & 1 & 0 & 0 \\
0 & 0 & 1 & 2 & 1 & 0 \\
0 & 0 & 0 & 1 & 2 & 1 \\
1 & 0 & 0 & 0 & 1 & 2
\end{array}\right]
$$"
44,Mathematics,18.701,Algebra I,18.100B,None,Problem Set 7,Orthogonal Group,1,a,0.4166666667,Text,"With coordinates $x_1, \ldots, x_n$ in $\mathbb{R}^n$ as usual, the set of points defined by the inequalities $-1 \leq x_i \leq+1$, for $i=1, \ldots, n$, is an $n$-dimensional hypercube $\mathcal{C}_n$. The 1-dimensional hypercube is a line segment and the 2-dimensional hypercube is a square. The 4-dimensional hypercube has eight face cubes, the 3-dimensional cubes defined by $\left\{x_i=1\right\}$ and by $\left\{x_i=-1\right\}$, for $i=1,2,3,4$, and it has 16 vertices $(\pm 1, \pm 1, \pm 1, \pm 1)$.
Let $G_n$ denote the subgroup of the orthogonal group $O_n$ of elements that send the hypercube to itself, the group of symmetries of $\mathcal{C}_n$, including the orientation-reversing symmetries. Permutations of the coordinates and sign changes are among the elements of $G_n$.
Use the counting formula and induction to determine the order of the group $G_n$.",Open,"Let $G_{n}$ be the group of orthogonal operators $M$ that are symmetries of the hypercube $C_{n}$, represented by orthogonal matrices. Let's call ""signed permutations"" the matrices that are obtained from permutation matrices by changing some entries 1 to $-1$. The signed permutations form a subgroup $H_{n}$ of $G_{n}$, of order $2^{n} \cdot n !$. We'll show by induction that $H_{n}=G_{n}$.
Let $F$ be the face hypercube of dimension $n-1$ of points at which $x_{n}=1$. The elements of $G_{n}$ that stabilize $F$ (that send $F$ to itself) are those that fix the last coordinate of a vector. They have block form $M=\left(\begin{array}{ll}A & 0 \\ C & 1\end{array}\right)$, where $A$ is an $(n-1) \times(n-1)$ matrix and $C$ is an $(n-1)$-dimensional row vector. Since $M$ is orthogonal, $C=0$, and $A$ is an orthogonal matrix. Since $M$ is a symmetry of the hypercube $C_{n}$ that sends $F$ to $F$, it defines a symmetry of $F$. Therefore $A$ is an element of $G_{n-1}$. By induction, $H_{n-1} \approx G_{n-1}$. So the stabilizer of $F$ has order $2^{n-1} \cdot(n-1) !$.
There are $n$ faces defined by $x_{i}=1$ and $n$ faces with $x_{i}=-1$. These $2 n$ faces form a $G_{n}$-orbit, and the counting formula shows that $\left|G_{n}\right|=2 n\left|G_{n-1}\right|=2^{n} \cdot n !=\left|H_{n}\right|$. Thus $H_{n}=G_{n}$.
The dihedral group of symmetries of the square is represented here in an interesting way, as the group whose elements are the eight signed permutation matrices $\left(\begin{array}{cc}\pm 1 & \\ & \pm 1\end{array}\right)$ and $\left(\begin{array}{ll} & \pm 1 \\ \pm 1\end{array}\right)$. ","The symmetric group $S_n$ operates on $\mathbb{C}^n$ by permuting the coordinates. Decompose this representation explicitly into irreducible representations.
Hint: I recommend against using the orthogonality relations. This problem is closely related to Exercise M.1 from Chapter 4.","As is true for any permutation representation, the trivial representation is the summand that corresponds to the invariant subspace $U$ spanned by $(1, \ldots, 1)^{t}$. Since permutation matrices are orthogonal, and therefore unitary, $W=U^{\perp}$ is an invariant subspace. It is the space of vectors $\left(a_{1}, \ldots, a_{n}\right)^{t}$ such that $\sum a_{i}=0$, and its dimension is $n-1$.
Let $w$ be an nonzero vector in $W$. In 18.701, in problem M1 of Chapter 4 , I hope that you proved that the span of the orbit of $w$ can have dimension $0,1, n-1$, or $n$, and that the first two cases occur when the vector is constant: $(a, a, \ldots, a)^{t}$. Since $w$ is in $W$, the sum of its entries is zero. So, since $w$ isn't zero, it isn't a constant vector. The dimension of its span is $n-1$. Every nonzero vector $w$ in $W$ spans $W$. Therefore $W$ is irreducible.","Don't use characters to work this problem. Just use linear algebra.
Here $G$ is the dihedral group $D_n$ of symmetries of an $n$-gon, with the usual generators and relations: $x^n=1, y^2=1, y x=x^{-1} y$.
Determine the one-dimensional representations of $G$.","Let $\rho$ be a representation of $G$. Then because $y x=x^{-1} y, \rho_{y} \rho_{x}=\rho_{x}^{-1} \rho_{y}$. If $\rho$ is one-dimensional, then because $G L_{1}=\mathbb{C}^{*}$ is abelian, $\rho_{x} \rho_{y}=\rho_{y} \rho_{x}=\rho_{x}^{-1} \rho_{y}$. Therefore $\rho_{x}^{2}=1$. We also have $x^{n}=1$, so $\rho_{x}^{n}=1$. If $n$ is odd, $\rho_{x}=1$, and if $n$ is even, $\rho_{x}=\pm 1$. And, $\rho_{y}=\pm 1$ because $y^{2}=1$. There are two one-dimensional representations when $n$ is odd, and four when $n$ is even.","Don't use characters to work this problem. Just use linear algebra.
Here $G$ is the dihedral group $D_n$ of symmetries of an $n$-gon, with the usual generators and relations: $x^n=1, y^2=1, y x=x^{-1} y$.
Determine the isomorphism classes of irreducible representations of dimension 2.
Hint for part $\mathbf{( d )}$ : It is convenient to begin with a basis of eigenvectors for $\rho_x$.","We start with a basis of eigenvectors for $\rho_{x}$. The matrix $R_{x}$ of $\rho_{x}$ will be diagonal: $R_{x}=\left(\begin{array}{cc}\lambda & \\ & \lambda^{\prime}\end{array}\right)$, where $\lambda, \lambda^{\prime}$ are $n$th roots of unity. Say that $R_{y}=\left(\begin{array}{ll}a & b \\ c & d\end{array}\right)$. Since $y^{2}=1$, $R_{y}^{2}=I$, but because $\rho$ is irreducible, $R_{y} \neq I$. Therefore trace $R_{y}=a+d=0$ and $\operatorname{det} R_{Y}=$ $a d-b c=-1$. The relation $y x=x^{-1} y$ reads $\left(\begin{array}{cc}a \lambda & b \lambda^{\prime} \\ c \lambda & d \lambda^{\prime}\end{array}\right)=\left(\begin{array}{cc}\lambda^{-1} a & \lambda^{-1} b \\ \lambda^{\prime}-1 c & \lambda^{\prime}-1 d\end{array}\right)$. If $b=c=0$ both $R_{x}$ and $R_{y}$ are diagonal and $\rho$ isn't irreducible. Therefore $\lambda^{\prime}=\lambda^{-1}$. Then since $\lambda \neq \lambda^{\prime}, a=d=0$, and $R_{y}=\left(\begin{array}{c}b \\ c\end{array}\right)$. Changing our basis changes $R_{x}, R_{y}$ by conjugation. Conjugating by $\left(\begin{array}{cc}1 & \\ & c^{-1}\end{array}\right)$ leaves $R_{x}$ unchanged and changes $R_{y}$ to $R_{y}^{\prime}=\left(\begin{array}{ll} & b c \\ 1 & \end{array}\right)$. Since $\operatorname{det} R_{y}^{\prime}=\operatorname{det} R_{y}=-1, b c=-1$. The representation depends only on the choice of the $n$th root of unity $\lambda$. "
371,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Problem Set 1,NumPy,1,evi,0.01736111111,Text,"A scalar number $x$ has an inverse $x^{-1}$, such that $x^{-1} x=1$, that is, their product is 1 . Similarly, a matrix $A$ may have a well-defined inverse $A^{-1}$, such that $A^{-1} A=I$, where matrix multiplication is used, and $I$ is the identity matrix. Such inverses generally only exist when $A$ is a square matrix, and just as 0 has no well defined multiplicative inverse, there are also cases when matrices are ""singular"" and have no well defined inverses.
Write a procedure that takes a matrix $A$ and returns its inverse, $A^{-1}$. Assume that $A$ is well-formed, such that its inverse exists. Feel free to use routines from np. linalg. 
import numpy as np
def matrix_inverse(A):
pass",Programming,"import numpy as np
def matrix_inverse(A):
return np.linalg.inv(A)","Suppose we start with a $3 \times 3$ matrix $A$ and we perform the following operations to put it into row echelon form.
(a) First we add 2 times the first row to the second row.
(b) Then we subtract the first row from the third row.
(c) And finally we swap the second and third rows.
After these operations we get
$$
B=\left[\begin{array}{lll}
1 & 2 & 0 \\
0 & 1 & 4 \\
0 & 0 & 2
\end{array}\right]
$$
What is $A^{-1}$ ?
Hint: First express $A=C B$ for some matrix $C$ that encodes the operations above.","First we compute $B^{-1}$. We use the following elementary operations to put it into rref: We multiply the third row by $1 / 2$. Then we subtract four times the third row from the second. Finally we subtract the second row from the first. To implement this as matrix multiplication we get
$$
B^{-1}=\left[\begin{array}{ccc}
1 & -2 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1
\end{array}\right]\left[\begin{array}{ccc}
1 & 0 & 0 \\
0 & 1 & -4 \\
0 & 0 & 1
\end{array}\right]\left[\begin{array}{ccc}
1 & 0 & 0 \\
0 & 1 & 0 \\
0 & 0 & 1 / 2
\end{array}\right]=\left[\begin{array}{ccc}
1 & -2 & 4 \\
0 & 1 & -2 \\
0 & 0 & 1 / 2
\end{array}\right]
$$
Now we find the matrix $T$ so that $T A=B$. We have
$$
T=\left[\begin{array}{lll}
1 & 0 & 0 \\
0 & 0 & 1 \\
0 & 1 & 0
\end{array}\right]\left[\begin{array}{ccc}
1 & 0 & 0 \\
0 & 1 & 0 \\
-1 & 0 & 1
\end{array}\right]\left[\begin{array}{lll}
1 & 0 & 0 \\
2 & 1 & 0 \\
0 & 0 & 1
\end{array}\right]=\left[\begin{array}{ccc}
1 & 0 & 0 \\
-1 & 0 & 1 \\
2 & 1 & 0
\end{array}\right]
$$
Thus we get
$$
A^{-1}=\left[\begin{array}{ccc}
11 & 4 & -2 \\
-5 & -2 & 1 \\
1 & 1 / 2 & 0
\end{array}\right]
$$","For the following matrix $A$, compute $\operatorname{det}(A)$ and find the inverse of $A$ :
$$
A=\left(\begin{array}{lll}
1 & 2 & 4 \\
5 & 2 & 2 \\
7 & 3 & 1
\end{array}\right)
$$","Using the Laplace expansion,
$$
|A|=1 \cdot\left|\left(\begin{array}{ll}
2 & 2 \\
3 & 1
\end{array}\right)\right|-2 \cdot\left|\left(\begin{array}{ll}
5 & 2 \\
7 & 1
\end{array}\right)\right|+4 \cdot\left|\left(\begin{array}{ll}
5 & 2 \\
7 & 3
\end{array}\right)\right|=(2-6)-2(5-14)+4(15-14)=18 \text {. }
$$
Since the determinant is not zero, it has the inverse matrix. Consider the augmented matrix
$$
\left(\begin{array}{lll|lll}
1 & 2 & 4 & 1 & 0 & 0 \\
5 & 2 & 2 & 0 & 1 & 0 \\
7 & 3 & 1 & 0 & 0 & 1
\end{array}\right)
$$
which is reduced by the Gauss-Jordan elimination to
$$
\left(\begin{array}{ccc|ccc}
1 & 0 & 0 & -2 / 9 & 5 / 9 & -2 / 9 \\
0 & 1 & 0 & 1 / 2 & -3 / 2 & 1 \\
0 & 0 & 1 & 1 / 18 & 11 / 18 & -4 / 9
\end{array}\right)
$$
so the inverse matrix is
$$
\left(\begin{array}{ccc}
-2 / 9 & 5 / 9 & -2 / 9 \\
1 / 2 & -3 / 2 & 1 \\
1 / 18 & 11 / 18 & -4 / 9
\end{array}\right)
$$
Another way to compute the determinant is backtracking your reduction above, where you divide the second row by $-8$ and the third row by $-9 / 4$. Other row operations do not affect the determinant, so the determinant of $A$ should be $(-8) \cdot(-9 / 4)=18$.","Let $A$ be an $n \times n$ matrix with integer entries $a_{i j}$. Prove that $A$ is invertible, and that its inverse $A^{-1}$ has integer entries, if and only if $\operatorname{det} A=\pm 1$.","The proofs of the two directions are different.
The determinant of an integer matrix is an integer. If $A$ has an integer inverse, the formula $(\operatorname{det} A)\left(\operatorname{det} A^{-1}\right)=\operatorname{det}\left(A A^{-1}\right)=\operatorname{det} I=1$ shows that $\operatorname{det} A$ divides 1 , and therefore is equal to $\pm 1$.
To show that an integer matrix with determinant 1 has an integer inverse, the simplest thing is to use the formula for the inverse in terms of the cofactor matrix. The cofactors will be integers. Another way would be to reduce $A$ to the identity using invertible integer row operations."
126,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Midterm Exam 1,RISC-V Calling Conventions,3,b,1.35,Text,"Guy and Dude are working on a project that requires them to code in RISC-V Assembly Language. Since this is their first time working in assembly, they are looking for a RISC-V expert to check whether their code is working correctly. As a friend of Guy and Dude, you volunteered to help them.
Please add or cross out appropriate instructions (either increment/decrement stack pointer, load word from stack, or save word to stack only) to make funcA and funcB follow the RISC$V$ calling convention. You may not change which registers are being used. If the procedure already follows the calling convention, write NO INSTRUCTIONS NEEDED. For full credit, you should only save registers that must be saved onto the stack and cross out unnecessary loads and stores.
Assume that all values are unsigned 32-bit integers.
You may assume that the funcA called below follows the calling conventions.
def funcB(array, max_iter):
    result = 0
    for i in range(0, max_iter):
        result += funcA(array[i], array[i+1])
    return result
// a0 is the starting address of array,
// a1 is the maximum number of iterations
funcB:
      addi sp, sp, -12
      sw s0, 0(sp)
      sw s1, 4(sp)
      sw s2, 8(sp)
      mv s0, zero
      mv s1, a0
      mv s2, a1
      mv t0, zero
while:
      bge s0, s2, end
      slli a2, s0, 2
      add a2, s1, a2
      lw a0, 0(a2)
      lw a1, 4(a2)
      call funcA
      add t0, t0, a0
      addi s0, s0, 1
      j while
end:
     mv a0, t0
     lw s0, 0(sp)
     lw s1, 4(sp)
     lw s2, 8(sp)
     addi sp, sp, 12
     ret",Programming,"def funcB(array, max_iter):
    result = 0
    for i in range(0, max_iter):
        result += funcA(array[i], array[i+1])
    return result
// a0 is the starting address of array,
// a1 is the maximum number of iterations
funcB:
      addi sp, sp, -20
      sw s0, 0(sp)
      sw s1, 4(sp)
      sw s2, 8(sp)
      sw ra, 12(sp)
      mv s0, zero
      mv s1, a0
      mv s2, a1
      mv t0, zero
while:
      bge s0, s2, end
      slli a2, s0, 2
      add a2, s1, a2
      lw a0, 0(a2)
      lw a1, 4(a2)
      sw t0, 16(sp)
      call funcA
      lw t0, 16(sp)
      add t0, t0, a0
      addi s0, s0, 1
      j while
end:
     mv a0, t0
     lw s0, 0(sp)
     lw s1, 4(sp)
     lw s2, 8(sp)
     lw ra, 12(sp)
     addi sp, sp, 20
     ret","Guy and Dude are working on a project that requires them to code in RISC-V Assembly Language. Since this is their first time working in assembly, they are looking for a RISC-V expert to check whether their code is working correctly. As a friend of Guy and Dude, you volunteered to help them.
Please add or delete appropriate instructions (either increment/decrement stack pointer, load word from stack, or save word to stack only) to make funcA and funcB follow the RISC$V$ calling convention. You may not change which registers are being used. If the procedure already follows the calling convention, write NO INSTRUCTIONS NEEDED. For full credit, you should only save registers that must be saved onto the stack and cross out unnecessary loads and stores.
Assume that all values are unsigned 32-bit integers.
def funcA(x,y):
    return x*y
//two arguments are stored in a0,a1
funcA:
     addi sp, sp, -8
     sw t0, 0(sp)
     sw t1, 4(sp)
     mv t0, zero
next:
     andi t1, a1, 1
     srli a1, a1, 1
     beq t1, zero, skip
     add t0, t0, a0
skip:
     slli a0, a0, 1
     bne a1, zero, next
     mv a0, t0
     lw t0, 0(sp)
     lw t1, 4(sp)
     addi sp, sp, 8
     ret","def funcA(x,y):
    return x*y
//two arguments are stored in a0,a1
funcA:
     mv t0, zero
next:
     andi t1, a1, 1
     srli a1, a1, 1
     beq t1, zero, skip
     add t0, t0, a0
skip:
     slli a0, a0, 1
     bne a1, zero, next
     mv a0, t0
     ret","Now, instead of 0x240, let's change the location of the array A in memory to be 0x300. This means our code will now be:
// A = 0x300, starting address of array
// N = 16, size of data region
// this program adds 16 words from array A, then repeats.
. = 0x200
test:
li a0, 16
li a1, 0
loop:
addi a0, a0, -1
slli a2, a0, 2
lw a3, 0x300(a2)
add a1, a1, a3
bnez a0, loop
j test
// Array
. = 0x300
.word ... // A[0]
.word ... // A[1]
...
.word ... // A[15]
Now, lets check which cache lines will now hold our array elements.
Since our array has 16 elements, we run through the main 5 lines of loop 16 times. We then have three additional instructions (the initial li a0, li a1, and j test), giving a total of 83 instructions.
In steady-state, what is the total number of instruction misses during one full iteration of the test loop?","8.
We know that A[0] through A[7] will collide with instructions of our inner loop, causing each instruction to miss one of its fetches. This results in 8 total misses. Note that even as the inner loop is repeated, any single instruction will only ever miss on one iteration of the inner loop.","After some searching, Ben has found the source of Carol's bug! The snippet below was intended to find the sum of an array stored at $\mathbf{0 x} \mathbf{7 4 0}$. However, the function does not work as intended. What value is loaded into a3 on the first three iterations of the loop?
start:
     li a0, 0x740 // a0 = start of array
     li a1, 4 // a1 = number of elements in array
     li a2, 0
loop:
     lw a3, 0(a0)
     add a2, a2, a3
     addi a1, a1, -1
     lw a0, 4(a0)
     bnez a1, loop
end:
     mv a0, a2
     ret
.=0x740
.word 0x000002EB
.word 0x00000748 
.word 0x000007F1
.word 0x00000740
What is the incorrect line of code above and provide a replacement instruction that will fix Carol’s function.","a3 (after 1st iteration): 0x2EB.
a3 (after 2nd iteration): 0x7F1.
a3 (after 3rd iteration): 0x2EB.
Incorrect instruction: lw a0, 4(a0)
Fixed instruction: addi a0, a0, 4"
93,EECS,18.C06,Linear Algebra and Optimization,18.02,None,Problem Set 5,Convex Sets,1,a,0.1851851852,Text,"For each of the sets $S_{1}, S_{2}, S_{3}, S_{4}$, say whether they are convex or not, and justify your answer.
$S_{1}=\left\{x \in \mathbb{R}^{n}: A x \leq 1\right\}$, where $A$ is a square matrix.",Open,"The set $S_{1}$ is convex. For any $x, y \in S_{1}$, we need to show that $\lambda x+(1-$ $\lambda) y \in S_{1}$, for all $0 \leq \lambda \leq 1$. This is true since $A(\lambda x+(1-\lambda) y)=\lambda A x+(1-\lambda) A y \leq$ $\lambda \mathbf{1}+(1-\lambda) \mathbf{1}=\mathbf{1}$.","For each of the sets $S_{1}, S_{2}, S_{3}, S_{4}$, say whether they are convex or not, and justify your answer.
Let $x_{1}, \ldots, x_{k}$ be points in $\mathbb{R}^{n}$, and define
$$
S_{2}=\left\{\sum_{i=1}^{k} c_{i} x_{i}: \sum_{i=1}^{k} c_{i}=1 \text { and } \forall i, c_{i} \geq 0\right\}.
$$","$S_{2}$ is convex. For any two points $a=\sum_{i} c_{i} x_{i}, a^{\prime}=\sum_{i} c_{i}^{\prime} x_{i}$ in $S_{2}$, we need to show that $\lambda a+(1-\lambda) a^{\prime} \in S_{2}$, for all $0 \leq \lambda \leq 1$. Combining the sums we get
$$
\lambda a+(1-\lambda) a^{\prime}=\sum_{i}\left(\lambda c_{i}+(1-\lambda) c_{i}^{\prime}\right) x_{i}.
$$
Letting $d_{i}=\lambda c_{i}+(1-\lambda) c_{i}^{\prime}$, we need to show that $d_{i} \geq 0$ and $\sum_{i} d_{i}=1$. The former is clear by definition, whereas the latter is true because $\sum_{i} d_{i}=\lambda+(1-\lambda)=1$.","For each of the sets $S_{1}, S_{2}, S_{3}, S_{4}$, say whether they are convex or not, and justify your answer.
$S_{3}=\left\{x \in \mathbb{R}: \sin (x) \leq \frac{1}{2}\right\}$.","$S_{3}$ is not convex. Let $x_{1}=\frac{\pi}{6}$ and $x_{2}=\frac{5 \pi}{6} . \sin \left(x_{1}\right)=\sin \left(x_{2}\right)=\frac{1}{2}$ showing that $x_{1}, x_{2} \in S_{3}$, but $\sin \left(\frac{x_{1}+x_{2}}{2}\right)=\sin (\pi / 2)=1$ showing that $\frac{x_{1}+x_{2}}{2} \notin S_{3}$. ","For each of the sets $S_{1}, S_{2}, S_{3}, S_{4}$, say whether they are convex or not, and justify your answer.
For $X, Y \subseteq \mathbb{R}^{n}$, let $X+Y=\{x+y: x \in X, y \in Y\}$. Let
$$
S_{4}=S_{1}+S_{2}.
$$","$S_{4}$ is convex. First we show that if $X$ and $Y$ are convex, then $X+Y$ is also convex. For any $z_{1}, z_{2} \in X+Y$, they can be written as $z_{1}=x_{1}+y_{1}, z_{2}=x_{2}+y_{2}$ for some $x_{1}, x_{2} \in X$ and $y_{1}, y_{2} \in Y$. Then for $0 \leq \lambda \leq 1, \lambda z_{1}+(1-\lambda) z_{2}=\lambda x_{1}+$ $(1-\lambda) x_{2}+\lambda y_{1}+(1-\lambda) y_{2}$. Since $X$ and $Y$ are convex, $\lambda x_{1}+(1-\lambda) x_{2} \in X$ and $\lambda y_{1}+(1-\lambda) y_{2} \in Y$. Therefore $\lambda z_{1}+(1-\lambda) z_{2} \in X+Y$, showing that it is convex. Since $S_{1}$ and $S_{2}$ are convex, so is $S_{4}=S_{1}+S_{2}$."
408,Mathematics,18.01,Calculus I,None,None,Problem Set 8,Probability Distributions,22,d,0.07919746568,Text,"Suppose that the probability distribution for $x$ is the uniform distribution on the interval from 1 to 9 . In other words, you can think of $x$ as the number given by a fair spinner which gives a number between 1 and 9 . Suppose $y=\sqrt{x}$.
Approximate Prob[$1<y<1+\Delta y$], when $\Delta y$ is small. Is it closest to $\Delta y$ or $(1 / 2) \Delta y$ or $(1 / 4) \Delta y$ or $(1 / 8) \Delta y$?",Multiple Choice,"Since $y^{2}=x$, define $\Delta x$ by $(1+\Delta y)^{2}=1+\Delta x$. Since $(1+\Delta y)^{2} \approx$ $1+2 \Delta y, 2 \Delta y \approx \Delta x$. Then
$$
\operatorname{Prob}[1<y<1+\Delta y]=\operatorname{Prob}[1<x<1+\Delta x]=\frac{\Delta x}{8} \approx \frac{2 \Delta y}{8}=\frac{\Delta y}{4} .
$$
Recall that the probability distribution for $x$ is $f(x) d x$ where
$$
f(x)= \begin{cases}0 & \text { if } x<1 \\ 1 / 8 & \text { if } 1 \leq x \leq 9 \\ 0 & \text { if } 9<x\end{cases}
$$
Suppose that $g(y) d y$ is the probability distribution for $y$. We know that
$$
\int_{a}^{b} g(y) d y=\operatorname{Prob}[a<y<b]=\operatorname{Prob}\left[a^{2}<x<b^{2}\right]=\int_{a^{2}}^{b^{2}} f(x) d x .
$$","Suppose that the probability distribution for $x$ is the uniform distribution on the interval from 1 to 9 . In other words, you can think of $x$ as the number given by a fair spinner which gives a number between 1 and 9 . Suppose $y=\sqrt{x}$.
Approximate Prob[1<y<1.1]. Is it closest to $\frac{1}{10}$ or $\frac{1}{20}$ or $\frac{1}{40}$?","Proceed in a similar way as in part a:
$$
\operatorname{Prob}[1<y<1.1] \approx \operatorname{Prob}[1<x<1.2]=\frac{1.2-1}{8}=\frac{1}{40} .
$$","Suppose that the probability distribution for $x$ is the uniform distribution on the interval from 1 to 9 . In other words, you can think of $x$ as the number given by a fair spinner which gives a number between 1 and 9 . Suppose $y=\sqrt{x}$.
If $y=1$, then $x=y^{2}=1$. If $y=1.1$, then $x$ is closest to which of the following: $1.1$ or $1.2$ or $1.4$?","Since $y=\sqrt{x}, x=(1.1)^{2}=(1+.1)^{2} \approx 1+2(.1)=1.2$.","Suppose that the probability distribution for $x$ is the uniform distribution on the interval from 1 to 9 . In other words, you can think of $x$ as the number given by a fair spinner which gives a number between 1 and 9 . Suppose $y=\sqrt{x}$.
What is $\operatorname{Prob}[1<y<2]$ ? What is $\operatorname{Prob}[2<y<3]$?","We have the following relationship between probabilities:
$$
\operatorname{Prob}[1<y<2]=\operatorname{Prob}[1<\sqrt{x}<2]=\operatorname{Prob}[1<x<4] \text {. }
$$
Since $x$ is the uniform distribution between 1 and 9 , the final probability equals $\frac{4-1}{8}=\frac{3}{8}$. Similarly, we have
$$
\operatorname{Prob}[2<y<3]=\operatorname{Prob}[2<\sqrt{x}<3]=\operatorname{Prob}[4<x<9]=\frac{9-4}{8}=\frac{5}{8} .
$$"
17,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Exercise 3,Gradient Descent,2,c,0.06944444444,Text,"In typical gradient descent, we take steps using a constant step size $\eta$, so that:
$$
\theta^{t+1}=\theta^{t}-\eta \nabla_{\theta} f\left(\theta^{t}\right).
$$
In the following, assume that $f$ is an arbitrary differentiable function.
Grady would like to pick a perfect step size on every step and proposes a new update rule that selects $\eta^{*}$ to be the value of step-size $\eta$ that decreases the objective as much as possible in the direction $\nabla_{\theta} f(\theta)$ and then uses $\eta^{*}$ as the step size: 
$$
\begin{gathered}
\eta^{*}=\arg \min _{\eta} f\left(\theta^{t}-\eta \nabla_{\theta} f\left(\theta^{t}\right)\right) \\
\theta^{t+1}=\theta^{t}-\eta^{*} \nabla_{\theta} f\left(\theta^{t}\right)
\end{gathered}
$$
For Grady's rule, what will generally be true?
(a) $f\left(\theta^{t}\right) \geq f\left(\theta^{t+1}\right)$
(b) $f\left(\theta^{t}\right) \leq f\left(\theta^{t+1}\right)$
(c) cannot say",Multiple Choice,"(a) $f\left(\theta^{t}\right) \geq f\left(\theta^{t+1}\right)$
The value of the function will decrease (or stay the same) with each step. This follows from the fact that before we take the step, we optimize for the best step value that will decrease the value of the function $f$ the most.","In typical gradient descent, we take steps using a constant step size $\eta$, so that:
$$
\theta^{t+1}=\theta^{t}-\eta \nabla_{\theta} f\left(\theta^{t}\right).
$$
In the following, assume that $f$ is an arbitrary differentiable function.
For very very small $\eta$, what will generally be true?
(a) $f\left(\theta^{t}\right) \geq f\left(\theta^{t+1}\right)$
(b) $f\left(\theta^{t}\right) \leq f\left(\theta^{t+1}\right)$
(c) cannot say","(a) $f\left(\theta^{t}\right) \geq f\left(\theta^{t+1}\right)$
For a very very small $\eta$, the gradient descent will never worsen (increase) the value of the function it is minimizing. Intuitively, there will always be a small enough step size such that a step in the direction of steepest descent decreases (or more precisely, does not increase) the function value.","In typical gradient descent, we take steps using a constant step size $\eta$, so that:
$$
\theta^{t+1}=\theta^{t}-\eta \nabla_{\theta} f\left(\theta^{t}\right).
$$
In the following, assume that $f$ is an arbitrary differentiable function.
For very very big $\eta$, what will generally be true?
(a) $f\left(\theta^{t}\right) \geq f\left(\theta^{t+1}\right)$
(b) $f\left(\theta^{t}\right) \leq f\left(\theta^{t+1}\right)$
(c) cannot say","(c) cannot say
For very very big $\eta$, we cannot say anymore whether the value of the function is going to decrease or increase. (Consider starting at $x=-1$ along $f(x)=x^{2}$ and taking $\eta=100$.)","Once we have defined a function, we can find a local minimum by using gradient descent! For practice's sake, in this section we will consider the function
$$
f(\theta)=(2 \theta+3)^{2}
$$
Note that here $\theta$ is a one dimensional input, but gradient descent can find local minima for higher dimensional $\theta$ too.
Now let's formulate the update rule that will be executed on every step when performing gradient descent on our specific $f(\theta)$ above, using $\eta$ as the step size parameter. You may use eta and theta in your Python expression, where eta represents $\eta$ and theta represents our current $\theta$. 
The updated $\theta^{new} = $ ","theta - eta*(8*theta + 12) or theta - eta*8*(theta + 1.5).
Using basic rules of differentiation we find $\nabla_{\theta} f(\theta)=\frac{d f(\theta)}{d \theta}=2 \cdot(2 \theta+3) \cdot 2$. Combining this with the update rule $\theta^{(1)}=\theta^{(0)}-\eta \nabla_{\theta} f\left(\theta^{(0)}\right)$, we get the expression above."
120,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 3,First-Order Logic Proof,5,bv,0.0637755102,Text,"Now, we will use the sentence you chose in part 5.1.3 as an assumption, also assume that Dr. Evil does not own a dog, and then prove from these assumptions that Dr. Evil is not an animal lover. The first step in doing a resolution proof is to convert the premises to clausal form. You already did part of that! Below, you will select each of the premises that we will need for a proof.
Clause 5 Now, we can actually do the proof, using FOL resoluton, starting with the four clauses above. We get another clause by resolving clauses 1 and 4.
Enter a clause as a list of lists of literal strings.",Expression,[['D(sk(DrE))']],"Now, we will use the sentence you chose in part 5.1.3 as an assumption, also assume that Dr. Evil does not own a dog, and then prove from these assumptions that Dr. Evil is not an animal lover. The first step in doing a resolution proof is to convert the premises to clausal form. You already did part of that! Below, you will select each of the premises that we will need for a proof.
Clause 7 We then resolve clauses 3 and 5.
Enter a clause as a list of lists of literal strings.","[['~O(DrE,sk(DrE))']]","Now, we will use the sentence you chose in part 5.1.3 as an assumption, also assume that Dr. Evil does not own a dog, and then prove from these assumptions that Dr. Evil is not an animal lover. The first step in doing a resolution proof is to convert the premises to clausal form. You already did part of that! Below, you will select each of the premises that we will need for a proof.
Clause 6 We get the next clause by resolving clauses 2 and 4.
Enter a clause as a list of lists of literal strings.","[['O(DrE,sk(DrE))']]","Now, we will use the sentence you chose in part 5.1.3 as an assumption, also assume that Dr. Evil does not own a dog, and then prove from these assumptions that Dr. Evil is not an animal lover. The first step in doing a resolution proof is to convert the premises to clausal form. You already did part of that! Below, you will select each of the premises that we will need for a proof.
Clause 4 We also need to negate the desired conclusion and convert it to clausal form.
Choose one:
(a) L(x4)
(b) ~L(x4)
(c) L(sk())
(d) ~L(sk())
(e) L(DrE)
(f) ~L(DrE)",(e) L(DrE)
74,EECS,6.18,Computer Systems Engineering,"6.1010, 6.1910",None,Midterm Exam 2,"Concurrency Control, Logging, and Recovery",5,b,0.3,Text,"Answer True or False for these statements:
A NO-FORCE policy causes more work during REDO than a FORCE policy.",Multiple Choice,True.,"Answer True or False for these statements:
Pessimistic concurrency control gets its name because it causes more aborted transactions.",False.,"Consider the following excerpt from a simple write-ahead log.
UPDATE records are of the form: UPDATE $<$ var name $>=<$ old value $>$; $<$ var name $>=<$ new value $>$. After entry 41, the system crashed.
True or False: The commit status of a transaction is determined by whether there is a COMMIT entry in the log, even in a system with a NO-FORCE policy.",True.,"Answer True or False for these statements:
Two-phase locking is required when using write-ahead logging.",False.
76,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Exercise 10,Neural Networks,2,a,0.06944444444,Text,"We are interested in making a neural network that can predict the next element in a sequence. For each of the sequences below, indicate all of the following models that could make correct predictions if its weights (and in case of the recurrent model, the dimension $d$) were set correctly - don't worry about learning. The possible models are:
\begin{itemize}
\item A bigram model, which is a feedforward network that takes sequence element $y_{t-1}$ as input and generates element $y_{t}$ as output.
\item A trigram model, which is a feedforward network that takes sequence elements $y_{t-2}$ and $y_{t-1}$ as input and generates element $y_{t}$ as output.
\item A simple recurrent model, with state $s_{t}$ of dimension $d \times 1$, governed by the equations: $s_{t}=\tanh \left(W^{s s} s_{t-1}+\right.$ $\left.W^{s x} y_{t-1}\right)$ and $y_{t}=\operatorname{softmax}\left(W^{o} s_{t}\right)$
\end{itemize}
1, 1, −1, 1, 1, −1, 1, 1, −1,...
(a) bigram.
(b) trigram.
(c) recurrent.",Multiple Choice,"(b) trigram.
(c) recurrent.
Notice that the 1, 1, -1 repeats every three numbers. We cannot determine the next number by looking back a single digit, but we can by looking back two digits. Therefore, the trigram and recurrent models can recognize this sequence, but the bigram model cannot. Note that the recurrent model has the ability to look back all the way to the start of the sequence due to maintaining the state $s_{t}$ with a sufficiently large dimension $d$.","We are interested in making a neural network that can predict the next element in a sequence. For each of the sequences below, indicate all of the following models that could make correct predictions if its weights (and in case of the recurrent model, the dimension $d$) were set correctly - don't worry about learning. The possible models are:
\begin{itemize}
\item A bigram model, which is a feedforward network that takes sequence element $y_{t-1}$ as input and generates element $y_{t}$ as output.
\item A trigram model, which is a feedforward network that takes sequence elements $y_{t-2}$ and $y_{t-1}$ as input and generates element $y_{t}$ as output.
\item A simple recurrent model, with state $s_{t}$ of dimension $d \times 1$, governed by the equations: $s_{t}=\tanh \left(W^{s s} s_{t-1}+\right.$ $\left.W^{s x} y_{t-1}\right)$ and $y_{t}=\operatorname{softmax}\left(W^{o} s_{t}\right)$
\end{itemize}
1, 1, 1, −1, 1, 1, 1, −1,...
(a) bigram.
(b) trigram.
(c) recurrent.","(c) recurrent.
There is a $-1$ for every four numbers, so neither the bigram nor trigram model can identify this sequence. Only the recurrent model can. Note that the recurrent model has the ability to look back all the way to the start of the sequence by maintaining the state $s_{t}$ (with a large enough $d$ ). You should ask yourself what the smallest $d$ would be that could handle this sequence.","We are interested in making a neural network that can predict the next element in a sequence. For each of the sequences below, indicate all of the following models that could make correct predictions if its weights (and in case of the recurrent model, the dimension $d$) were set correctly - don't worry about learning. The possible models are:
\begin{itemize}
\item A bigram model, which is a feedforward network that takes sequence element $y_{t-1}$ as input and generates element $y_{t}$ as output.
\item A trigram model, which is a feedforward network that takes sequence elements $y_{t-2}$ and $y_{t-1}$ as input and generates element $y_{t}$ as output.
\item A simple recurrent model, with state $s_{t}$ of dimension $d \times 1$, governed by the equations: $s_{t}=\tanh \left(W^{s s} s_{t-1}+\right.$ $\left.W^{s x} y_{t-1}\right)$ and $y_{t}=\operatorname{softmax}\left(W^{o} s_{t}\right)$
\end{itemize}
1, −1, 1, −1, 1, −1,...
(a) bigram.
(b) trigram.
(c) recurrent.","(a) bigram.
(b) trigram.
(c) recurrent.
The 1, -1 repeats every two numbers. Given any number, we can conclude exactly what the next number will be. Therefore, all three models work for this sequence.","In this question, we will look into using an RNN model to predict the next element in a sequence. We will focus on sequences of text characters (this is sometimes referred to as a ""language"" model). We will want to train on one or more sequences and then, given an initial character or sequence of characters, we want the RNN to predict what characters should come next. An example sequence might be the following:
$$
c=[' m ', ' i \text { ', 't' }]
$$
This sequence will be used both as input to an RNN and as desired output (offset by one time step), since we are training the RNN to produce the next character in the sequence.
Since the input to an RNN at each time step is encoded as a fixed-length vector, we will first encode each character of the sequence using a one-hot encoding. Let $\phi\left(c_{t}\right)$ represent the one-hot encoding of character $c_{t}$. We think of each $x_{t}$ and $y_{t}$, including the start and end characters, as being one-hot encoded. So, if there are $V$ possible values for $x_{t}$ or $y_{t}$, each $x_{t}$ or $y_{t}$ will be a vector of size $V$.
The inputs to the RNN, $x$, will consist of the encoded characters with a special start character. The output sequence of the RNN, $y$, will also consist of the encoded characters but have a special end character. In this lab, we will use '.' and ' $\backslash$ ' as the start and end character, respectively. This format will allow us to train an RNN to do character prediction (at time $t$, the RNN will have seen $c_{1}, \ldots, c_{t-1}$ and will try to predict $c_{t}$ ).
$x=\left[<\operatorname{start}>, \phi\left(c_{1}\right), \phi\left(c_{2}\right), \ldots, \phi\left(c_{n}\right)\right]$
$y=\left[\phi\left(c_{1}\right), \phi\left(c_{2}\right), \ldots, \phi\left(c_{n}\right),<\mathrm{end}>\right]$
In the diagram, we write SM to denote the softmax activation function. Note that $x$ and $y$ are shifted by one time step.
The following diagram unrolls the RNN and shows what $x$ and $y$ would be for the sequence $c=\left[\mathrm{m}^{\prime}\right.$ ' , ' $\mathrm{i}$ ', ' $\mathrm{t}$ ' $]$:
The particular form of the RNN that we will look at is:
$$
\begin{aligned}
& s_{t}=\tanh \left(W^{s s} s_{t-1}+W^{s x} x_{t}+W_{0}^{s s}\right) \\
& g_{t}=\operatorname{softmax}\left(W^{o} s_{t}+W_{0}^{o}\right)
\end{aligned}
$$
where $x_{t}$ is the encoded character sequence previously defined.
A. If any input character $c_{t}$ can be any lowercase letter in the English alphabet, what is the value of $V$ ?
B. What is the role of $s_{t}$ ?
C. How is $g_{t}$ related to $s_{t}$ ?
D. How is $y_{t}$ related to $g_{t}$ ?","\begin{itemize}
\item A. At each time step, both $\mathrm{x}$ and $\mathrm{y}$ are vectors of size $V$, a one-hot vector encoding of our characters (alphabet and two special characters). We need $V=26+2=28$ symbols.
\item B. $s_{t}$ keeps track of all the information about the sequence so far that is relevant for generating the output.
\item C. $g_{t}$ is the output of the RNN output activation, e.g., the softmax probabilities for a multi-class classifier based on the state $s_{t}$
\item D. $y_{t}$ is the output of the sequence associated with the input sequence $x_{t}$. While $g_{t}$ is the guess produced as the output activation of the RNN, $y_{t}$ might be either the actual output of a training sample, or a prediction of the actual output based on a decision using $g_{t}$ (e.g., picking the top-probability outputs from a softmax producing $g_{t}$ ).
\end{itemize}"
53,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 1,Monte-Carlo Tree Search,4,biii,0.1302083333,Text,"Consider MCTS on a problem where the initial state $s_{0}$ has actions two actions $a_{0}$ and $a_{1}$. The UCB parameter $C$ is $1.4$. Suppose the search has completed 8 full iterations:
\begin{itemize}
\item It selected action $a_{0} 3$ times, receiving utilities $[0.1,0.7,0.3]$.
\item It selected action $a_{1} 5$ times, receiving utilities $[0.4,0.4,0.4,0.4,0.4]$.
\end{itemize}
Which of the two actions will be selected on the 9-th iteration?
(a) $a_{0}$
(b) $a_{1}$",Multiple Choice,(a) $a_{0}$,"Consider MCTS on a problem where the initial state $s_{0}$ has actions two actions $a_{0}$ and $a_{1}$. The UCB parameter $C$ is $1.4$. Suppose the search has completed 8 full iterations:
\begin{itemize}
\item It selected action $a_{0} 3$ times, receiving utilities $[0.1,0.7,0.3]$.
\item It selected action $a_{1} 5$ times, receiving utilities $[0.4,0.4,0.4,0.4,0.4]$.
\end{itemize}
On the 9-th iteration, what is the UCB value for action $a_{1}$ when expanding from $s_{0}$? (Enter a number accurate to 2 decimal places).",1.303.,"Consider MCTS on a problem where the initial state $s_{0}$ has actions two actions $a_{0}$ and $a_{1}$. The UCB parameter $C$ is $1.4$. Suppose the search has completed 8 full iterations:
\begin{itemize}
\item It selected action $a_{0} 3$ times, receiving utilities $[0.1,0.7,0.3]$.
\item It selected action $a_{1} 5$ times, receiving utilities $[0.4,0.4,0.4,0.4,0.4]$.
\end{itemize}
On the 9-th iteration, what is the UCB value for action $a_{0}$ when expanding from $s_{0}$? (Enter a number accurate to 2 decimal places).",1.532.,"We explore the Q-learning algorithm using a deterministic MDP with two possible actions $(b$ and $c)$ and four states $(s 0$, $s 1$, $s 2$, s3). The transition model is
$$
\begin{aligned}
& T(s 0, b, s 1)=1 \\
& T(s 0, c, s 2)=1 \\
& T(s 1, *, s 0)=1 \\
& T(s 2, *, s 3)=1 \\
& T(s 3, *, s 3)=1
\end{aligned}
where $*$ represents either $b$ or $c$.
Some notes:
1. All other transitions have probability 0.
2. The goal state is $s 2$, and $s 3$ is a terminal state (similar to $\$$ in the grid-world question we have looked at).
3. Assume that if there are ties in the $Q$ function for actions $b$ and $c$ in a state, then we pick action $b$.
4. Assume the $Q$ function is initialized to 0 for every state-action pair and that, after every episode (sequence of actions) of length 10 , the agent is restarted in state $s 0$.
5. Assume a learning rate $(\alpha)$ of $0.5$.
6. Assume an $\epsilon$-greedy strategy with $\epsilon=0$.
7. Assume a discount factor of 1.
Note that we restart the agent in state $s 0$ after every 10 steps because otherwise it may reach $s 3$ and stay there forever.
In the goal-reward case, every action taken from the goal state $s 2$ gives an immediate positive reward of 1, and leads to a zero reward next state (in fact terminal state) $s 3$ that can never be escaped. Taking any action from any state other than the goal state provides zero reward. In other words, we have a reward function which outputs 0 for every state-action pair, except for $R(s 2, *)=1$.
What action will be selected the second time the agent encounters $s 0$ ? And why (explain why during the checkoff)? b or c?",b.
11,Mathematics,18.01,Calculus I,None,None,Problem Set 1,Linear Approximation,7,a,0.07919746568,Text,"Let $f(x)=x^{3}-x^{2}+x$. Using the linear approximation of $f$ around 1, approximate $f(1.1)$.",Numerical,"For both parts, $f(x)=x^{3}-x^{2}+x$.
For the linear approximation,
$$
f^{\prime}(x)=3 x^{2}-2 x+1 .
$$
At $x=1, f(1)=1$, and $f^{\prime}(1)=2$. Thus, around $x=1$, the linear approximation is
$$
f(1+\Delta x) \approx 1+2 \Delta x .
$$
For $x=1.1, \Delta x=0.1$. Thus,
$$
f(1.1) \approx 1+2 \times 0.1=1.2 \text {. }
$$","Let $f(x)=x^{3}+x$. Notice that $f(2)=10$.
Approximate $f(2.01)$ by using the linear approximation of $f(x)$ around $x=2$.","We have
$$
f^{\prime}(2)=3 x^{2}+\left.1\right|_{x=2}=13.
$$
Therefore,
$$
f(2.01) \approx f(2)+f^{\prime}(2) \cdot .01=\mathbf{10.13}
$$","Again let $f(x)=x^{3}-x^{2}+x$. From the formula we can check that $f(1)=1$. There is a number $x$ near 1 with $f(x)=1.1$. Approximate this number $x$. (Notice that you are approximately solving the equation $x^{3}-x^{2}+x=1.1$. This is an equation which is really complicated to solve exactly, but calculus lets us find a good approximation.)","For both parts, $f(x)=x^{3}-x^{2}+x$.
Now you want to ensure that
$$
f(1+\Delta x)=1.1 \text {. }
$$
You use the linear approximation to $f(1+\Delta x)$ and solve for $\Delta x$ :
$$
\begin{gathered}
1+2 \Delta x \approx 1.1, \\
\text { so } \Delta x \approx 0.05 . \text { Thus, } \\
f(1.05) \approx 1.1 .
\end{gathered}
$$
On my computer system, maxima (now-free software first written at the MIT AI Lab in the 1960s!) says that the true solution is $1.047673101479926 \ldots$ Our quick estimate of $1.05$ is very close.","Let $f(x)=x^{2}$. Using the linear approximation around $x=2$, approximate $f(2.03)$.","Here $f^{\prime}(x)=2 x$, so $f^{\prime}(2)=4$. Thus, the linear approximation to $f(x)$ around $x=2$ is
$$
f(2+\Delta x) \approx \underset{f(2)}{4}+\underset{f^{\prime}(2)}{4} \cdot \Delta x .
$$
For $f(2.03), \Delta x=0.03$ :
$$
f(2+\underbrace{0.03}_{\Delta x})=4+4 \times 0.03=4.12 .
$$"
269,Mathematics,18.01,Calculus I,None,None,Problem Set 6,Taylor Series,13,c,0.05279831045,Text,"Consider the differential equation $x^{\prime}(t)=1+t x(t)-x(t)^{2}$ with initial condition $x(0)=1$. This is a differential equation that cannot be solved by separation of variables.
Based on knowing $x^{\prime}(0)$ and $x^{\prime \prime}(0)$, do you expect that $x(.1)$ is bigger or smaller than 1? Explain your reasoning.",Open,"Since $x^{\prime}(0)=0$, the graph is flat very close to the origin. Since $x^{\prime \prime}(0)>0$, it is concave up (holds water), so the function is increasing just after $x=0$. Thus we expect $x(.1)$ to be larger than $x(0)=1$.","Consider the differential equation $x^{\prime}(t)=1+t x(t)-x(t)^{2}$ with initial condition $x(0)=1$. This is a differential equation that cannot be solved by separation of variables.
Find $x^{\prime}(0)$.",$x^{\prime}(0)=1+(0) x(0)-x(0)^{2}=1-1=0$.,"Consider the differential equation $x^{\prime}(t)=1+t x(t)-x(t)^{2}$ with initial condition $x(0)=1$. This is a differential equation that cannot be solved by separation of variables.
Find $x^{\prime \prime \prime}(0)$.","Differentiate our formula for $x^{\prime \prime}(t)$ from part (b): $x^{\prime \prime \prime}(t)=x^{\prime}(t)+\left(1-t x^{\prime}(t)\right) x^{\prime}(t)+$ $(t-2 x(t)) x^{\prime \prime}(t)$. Plug in $t=0$ :
$$
x^{\prime \prime \prime}(0)=x^{\prime}(0)+(1-0) x^{\prime}(0)+(-2 x(0)) x^{\prime \prime}(0)=-2 .
$$","Consider the differential equation $x^{\prime}(t)=1+t x(t)-x(t)^{2}$ with initial condition $x(0)=1$. This is a differential equation that cannot be solved by separation of variables.
Find a formula for $x^{\prime \prime}(t)$ and use it to find $x^{\prime \prime}(0)$.",$x^{\prime \prime}(t)=x(t)+t x^{\prime}(t)-2 x(t) x^{\prime}(t)=x(t)+(t-2 x(t)) x^{\prime}(t)$. Plugging in $t=0$ gives $x^{\prime \prime}(0)=x(0)+(0-2 x(0))\left(x^{\prime}(0)\right)=1$.
16,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Prelab Questions 1,Assembly,3,d,0.006060606061,Text,"Consider the following code segment which is independent from the code in the previous section.
li a0, 0x2000
li a7, 0
lw a1, 0(a0)
L1 :
andi a2, a1, 1
beq a2, zero, L2
addi a7, a7, 1
L2 :
srli a1, a1, 1
bnez a1, L1
unimp
. = 0x2000
.word 0x12345678
The program seems to be complicated, but we will try to break it down and understand it piece-by-piece. Once again assume that unimp is a special instruction that tells the processor to stop execution when it is reached.
Consider the following code snippet from the program above:
L1 :
andi a2, a1, 1
beq a2, zero, L2
addi a7, a7, 1
L2 :
srli a1, a1, 1
What is the value of register a7 after executing this code snippet if register a1 begins with a value of 0x84263A00 and the register a7 begins with a value of 0x00000003 (answer in 32-bit hexadecimal format like 0x0CDEF1AF)?",Numerical,"0x00000003.
We saw above that the andi a2, a1, 1 instruction writes a 1 to register a2 if the value of register a1 is odd and writes a 0 to register a2 if a1 is even. Since a1 is even in this case, a2 is written with the value 0. The branch beq a2, zero, L2 will now branch to the L2, skipping the addi a7, a7, 1 instruction, thus register a7 remains unchanged in this example. So it's value is still 0x00000003.","Consider the following code segment which is independent from the code in the previous section.
li a0, 0x2000
li a7, 0
lw a1, 0(a0)
L1 :
andi a2, a1, 1
beq a2, zero, L2
addi a7, a7, 1
L2 :
srli a1, a1, 1
bnez a1, L1
unimp
. = 0x2000
.word 0x12345678
The program seems to be complicated, but we will try to break it down and understand it piece-by-piece. Once again assume that unimp is a special instruction that tells the processor to stop execution when it is reached.
Consider the following code snippet from the program above:
L1 :
andi a2, a1, 1
beq a2, zero, L2
addi a7, a7, 1
L2 :
srli a1, a1, 1
Given the same initial values of register a1 with a value of 0x84263A01 and register a7 with a value of 0x00000003 before the execution of the code snippet, what will be written to register a7 after execution of these four lines of code (answer in 32-bit hexadecimal format like 0x0CDEF1AF)?","0x00000004.
The andi a2, a1, 1 performs a logical and of the contents of register a1 with the immediate value 1, which in 32-bit hexadecimal is 0x00000001. Performing a logical and operation with this immediate value results in ignoring all the bits except the least significant one. Another way of thinking of this is that it determines if the value in register a1 is even or odd. Since the last bit of a1 is 1, a2 is written with the value 1. The beq a2, zero, L2 instruction will branch to label L2 if the value of register a2 is equal to 0. However, the value in register a2 is 1 so it does not take the branch and instead executes the next instruction. The next instruction addi a7, a7, 1 adds 1 to the value of register a7. a7 was not modified by the previous instructions, thus this instruction updates register a7 to the value 0x00000004.","Consider the following code segment which is independent from the code in the previous section.
li a0, 0x2000
li a7, 0
lw a1, 0(a0)
L1 :
andi a2, a1, 1
beq a2, zero, L2
addi a7, a7, 1
L2 :
srli a1, a1, 1
bnez a1, L1
unimp
. = 0x2000
.word 0x12345678
The program seems to be complicated, but we will try to break it down and understand it piece-by-piece. Once again assume that unimp is a special instruction that tells the processor to stop execution when it is reached.
Consider the following code snippet from the program above:
L1 :
andi a2, a1, 1
beq a2, zero, L2
addi a7, a7, 1
L2 :
srli a1, a1, 1
Suppose register a1 has a value of 0x84263A01 and the register a7 has a value of 0x00000003 before the execution of this code snippet. What will be written to the register a1 after execution of these four lines of code (answer in 32-bit hexadecimal format like 0x0CDEF1AF)?","0x42131D00.
The only instruction in this code snippet which affects the value of register a1 is the srli a1, a1, 1 instruction. This instruction takes the original value of a1 and shifts it to the right by 1 bit, storing the result back into register a1.
We are told that a1 = 0x84263A01 initially. Converting this hexadecimal value to binary, we know that a1 = 0b1000 0100 0010 0110 0011 1010 0000 0001. We then shift every bit to the right by one. We shift a 0 into the most significant bit and the least significant bit is thrown away, resulting in 0b0100 0010 0001 0011 0001 1101 0000 0000. Converting this value back to hexadecimal, we find the value of register a1 after executing this code snippet is 0x42131d00.","Consider the following code segment which is independent from the code in the previous section.
li a0, 0x2000
li a7, 0
lw a1, 0(a0)
L1 :
andi a2, a1, 1
beq a2, zero, L2
addi a7, a7, 1
L2 :
srli a1, a1, 1
bnez a1, L1
unimp
. = 0x2000
.word 0x12345678
The program seems to be complicated, but we will try to break it down and understand it piece-by-piece. Once again assume that unimp is a special instruction that tells the processor to stop execution when it is reached.
Consider the following code snippet from the program above:
L1 :
andi a2, a1, 1
beq a2, zero, L2
addi a7, a7, 1
L2 :
srli a1, a1, 1
Now suppose that register a1 has an initial value of 0x84263A00 and while register a7 once again has a value of 0x00000003 before execution of the code snippet. What will be written to the register a1 after execution of these four lines of code (answer in 32-bit hexadecimal format like 0x0CDEF1AF)?","0x42131D00.
As, we saw above, the only instruction in this code snippet which affects the value of register a1 is the srli a1, a1, 1 instruction. This instruction takes the original value of a1 and shifts it to the right by 1 bit, storing the result back into register a1.
If a1 used to have the value of 0b1000 0100 0010 0110 0011 1010 0000 0000, the shifted-by-1 version of a1 will be still be 0b0100 0010 0001 0011 0001 1101 0000 0000 which is 0x42131d00."
464,Mathematics,18.01,Calculus I,None,None,Final Exam,Derivatives,1,b,1.09375,Text,"Compute the derivative of the following function:
$x \sin \left(x^{2}\right)$.",Expression,"$$
\begin{aligned}
\left(x \sin \left(x^{2}\right)\right)^{\prime} & =\sin \left(x^{2}\right)+x\left(\sin \left(x^{2}\right)\right)^{\prime} \\
& =\sin \left(x^{2}\right)+x \cdot 2 x \cos \left(x^{2}\right) \\
& =\sin \left(x^{2}\right)+2 x^{2} \cos \left(x^{2}\right) .
\end{aligned}
$$","Compute the derivative of the following function:
$x \sin x$.","$$
(x \sin x)^{\prime}=(x)^{\prime} \sin x+x(\sin x)^{\prime}=\sin x+x \cos x \text {. }
$$","Using the product rule, compute the derivative of each of the following functions.
$x^{2} \sin x$.",$\frac{d}{d x} x^{2} \sin x=2 x \sin x+x^{2} \cos x$.,"What are the derivatives of the following functions:
$x \sin (x)$.",$\frac{d}{d x}(x \sin (x))=(1) \sin x+x \cos x=\sin x+x \cos x$.
83,Mathematics,18.01,Calculus I,None,None,Problem Set 2,Integration,13,a,0.03959873284,Text,"Now suppose that we have the same ball of radius 2 , and it has variable density, and the density near a point $(x, y, z)$ is $2+z$.
Approximate the mass of the part of the ball where $z$ is between 1 and 1.1.",Expression,"Volume of the ""coin"" $\approx(.3) \pi$ as in problem 12.a. Density $\approx 3$. Mass $\approx(.3) \pi \cdot 3=(.9) \pi$.","Now suppose that we have the same ball of radius 2 , and it has variable density, and the density near a point $(x, y, z)$ is $2+z$.
Approximate the mass of the part of the ball where the $z$ coordinate is between $z$ and $z+\Delta z$.","Volume $\left(4-z^{2}\right) \pi \Delta x$ as in problem 12 .b. Density $\approx 2+z$. Mass of the ""coin""
$$
\Delta m \approx(2+z)\left(4-z^{2}\right) \pi \Delta x .
$$","Now suppose that we have the same ball of radius 2 , and it has variable density, and the density near a point $(x, y, z)$ is $2+z$.
Write down an integral for the total mass of the ball.","$$
m=\int_{-2}^{2}(2+z)\left(4-z^{2}\right) \pi d z
$$","Now suppose that we have the same ball of radius 2 , and it has variable density, and the density near a point $(x, y, z)$ is $2+z$.
Compute the integral. ","$$
m=2 \underbrace{\int_{-2}^{2}\left(4-z^{2}\right) d z}_{\frac{32}{3} \pi}+\pi \int_{-2}^{2} \underbrace{\left(4-z^{2}\right) z}_{\text {odd function } \mathrm{f}(-\mathrm{x})=-\mathrm{f}(\mathrm{x})} d z=\frac{64}{3} \pi .
$$"
442,Mathematics,18.01,Calculus I,None,None,Midterm Exam 2,Taylor Series,5,a,0.875,Text,"Let $f(x)=1-x^{2}-\cos x$.
Compute the 2nd order Taylor series of $f$ around $x=0$. ",Expression,"First we find the first and second derivative. We have $f(x)=1-x^{2}-\cos (x)$. This tells us that $f^{\prime}(x)=-2 x+\sin (x)$.
We then find that $f^{\prime \prime}(x)=-2+\cos (x)$.
Plugging in $x=0$ gives $f(0)=1-0^{2}-\cos (0)=1-1=0$.
Similarly, $f^{\prime}(0)=-2 \times 0+\sin (0)=0+0=0$.
Finally, $f^{\prime \prime}(0)=-2+\cos (0)=-2+1=-1$.
This means that the first two terms of the Taylor series are zero, and the third term is given by $\frac{-1}{2 !} x^{2}$. This gives us a final answer of $T_{2}(x)=\frac{-x^{2}}{2}$.",Compute the degree 2 Taylor series of the function $f(x)=1 / x$ around $x=1$.,"The formula for the degree 2 Taylor series involves $f(1), f^{\prime}(1), f^{\prime \prime}(1)$, so first we calculate these.
$$
\begin{aligned}
f(x)=\frac{1}{x} \quad & \longrightarrow \quad f(1)=1 . \\
f^{\prime}(x)=\frac{-1}{x^{2}} & \longrightarrow \quad f^{\prime}(1)=-1 \\
f^{\prime \prime}(x)=\frac{2}{x^{3}} & \longrightarrow \quad f^{\prime \prime}(1)=2 .
\end{aligned}
$$
Use the formula for degree 2 Taylor series to obtain
$$
T(x)=1+(-1)(x-1)+\frac{1}{2}(2)(x-1)^{2}=x^{2}-3 x+3 .
$$","Let $f(x)=\sin (x)$.
Compute the degree 3 Taylor series of $\sin x$ around $x=0$.","$$
\begin{aligned}
f(0) & =0 \\
f^{\prime}(0) & =1 \\
f^{\prime \prime}(0) & =0 \\
f^{\prime \prime \prime}(0) & =-1
\end{aligned}
$$
Therefore, the degree 3 Taylor series is
$$
\sin x \approx 0+1 \cdot x+0 \cdot \frac{x^{2}}{2}+(-1) \cdot \frac{x^{3}}{6}=\mathbf{x}-\frac{\mathbf{x}^{\mathbf{3}}}{\mathbf{6}}.
$$","Let $f(x)=1-x^{2}-\cos x$.
Which of the following pictures shows the graph of $f(x)$? (Use the Taylor series you found in part a to guide you.)","Based on 5a, we get the correct graph being the one in the top right. On the one hand it is a negative quadratic, which is what we are looking for. Notice also that for $x=.2$ we get $\frac{-.2^{2}}{2}=\frac{-.04}{2}=-.02$, the top right graph being the only one satisfying tis desired property. "
95,Mathematics,18.01,Calculus I,None,None,Problem Set 3,Integration,3,a,0.02639915523,Text,"This problem is a variation on problem 2. Once again, suppose we have a disk of radius 3 meters. This time, near a point at distance $r$ from the center, the disk has density $r+1$ kilograms per square meter. This time, the densest part of the disk is on the edge, where the density is $4 \mathrm{~kg} / \mathrm{m}^{2}$. The least dense part of the disk is at the center, where the density is $1 \mathrm{~kg} / \mathrm{m}^{2}$.
Before computing the mass of the disk, guess how it compares to the mass of the disk from Problem 2. Which one is bigger or are they equal? Briefly explain why.",Open,"We might guess that they are close to equal since the smallest density on both is 1 and the largest density is 4. However, the area corresponding to the largest density in the first problem was a small disk around the origin (say of radius $0.1$, so the area is $\left.2 \pi(0.1)^{2}\right)$, whereas the area corresponding to density $\approx 4$ in the second problem is the annulus from $2.9$ to 3 , which has area approximately $2 \pi(2.9)(.1)$ (so the second disk has high density for a larger area).","This problem is a variation on problem 2. Once again, suppose we have a disk of radius 3 meters. This time, near a point at distance $r$ from the center, the disk has density $r+1$ kilograms per square meter. This time, the densest part of the disk is on the edge, where the density is $4 \mathrm{~kg} / \mathrm{m}^{2}$. The least dense part of the disk is at the center, where the density is $1 \mathrm{~kg} / \mathrm{m}^{2}$.
If your guess in part i. was wrong, then reflect on it again and make a second attempt to explain which disk has more mass.","We might guess that they are close to equal since the smallest density on both is 1 and the largest density is 4. However, the area corresponding to the largest density in the first problem was a small disk around the origin (say of radius $0.1$, so the area is $\left.2 \pi(0.1)^{2}\right)$, whereas the area corresponding to density $\approx 4$ in the second problem is the annulus from $2.9$ to 3 , which has area approximately $2 \pi(2.9)(.1)$ (so the second disk has high density for a larger area).","This problem is a variation on problem 2. Once again, suppose we have a disk of radius 3 meters. This time, near a point at distance $r$ from the center, the disk has density $r+1$ kilograms per square meter. This time, the densest part of the disk is on the edge, where the density is $4 \mathrm{~kg} / \mathrm{m}^{2}$. The least dense part of the disk is at the center, where the density is $1 \mathrm{~kg} / \mathrm{m}^{2}$.
Approximate the mass of the part of the disk where the distance to the center is between $r$ meters and $r+\Delta r$ meters.","The area is $2 \pi r \Delta r$ and the density is $(1+r)$, so the approximate mass is $2 \pi r \Delta r(1+r)$.","This problem is a variation on problem 2. Once again, suppose we have a disk of radius 3 meters. This time, near a point at distance $r$ from the center, the disk has density $r+1$ kilograms per square meter. This time, the densest part of the disk is on the edge, where the density is $4 \mathrm{~kg} / \mathrm{m}^{2}$. The least dense part of the disk is at the center, where the density is $1 \mathrm{~kg} / \mathrm{m}^{2}$.
Approximate the mass of the part of the disk where the distance to the center is between 2 meters and $2.1$ meters. Which is the best approximation: $4 \pi k g$ or $2 \pi k g$ or $(1.2) \pi k g$ or $(.8) \pi k g$ or $(.4) \pi k g$ or $(.2) \pi k g$?","The area is the same as in 2a: $\approx 2 \pi \cdot 2 \cdot 0.1=0.4 \pi$. The density is now $\approx 1+(2)=3$, so the approximate mass is $1.2 \pi$ (in $\mathrm{kg}$)."
26,EECS,6.8611,Quantitative Methods for Natural Language Processing,"6.3900, 18.06/18.C06",None,Final Project,Individual Idea,1,nan,1,Text,"As mentioned on the course website and in class, for Phase 0, each student is expected to identify a distinct potential research problem they would like to work on. Even if you already have a self-formed team of classmates you would like to work with, each student must draft a unique idea for Phase 0. The idea should center around a tangible research question you would like to answer.
We ask each student to submit a short write-up (plain text or upload a .txt or .pdf) that includes the following details. We encourage you to adopt the style of list format when submitting your items:
• research problem (~2 sentences)
• dataset(s) you plan to use (1 sentence)
• metric(s) to assess the success of your idea/model (1 sentence)
• idea(s) for an initial approach or model (1-2 sentences)",Open,"Example Submission
Research Problem:
Recent prompt engineering research has provided insights into what large, generative LMs like GPT-2 are able to learn, yet no prior work has studied this toward the difficult, important task of coreference resolution. Here, we question what type of coreferences are resolvable by GPT-2 without additional fine-tuning, are there any particular patterns, and how well do these results compare to existing state-of-the-art (SOTA) models?
dataset(s) you plan to use (1 sentence):
ECB+, which is the canonical dataset for coreference resolution.
metric(s) to assess the success of your idea/model (1 sentence):
CoNLL F1 score, which is an aggregate of CEAF F1, B^3 F1, and MUC F1
idea(s) for an initial approach or model (1-2 sentences)
We have drafted 5 basic templates for prompts (not shown here), all of which are first addressing the easier problem of mention detection -- they prompt GPT-2 who the mentions are, in various ways, as opposed to the grand problem of who is co-referring to whom. Based on these results, we will compare with existing Coref systems' Mention Detection parts and tweak our prompts until results are satisfactory, then aim for the larger problem of Coref Resolution.","Refine your research project idea and write a 1-2 page proposal. Specifically, you must: 
• describes the problem in terms of why it’s an important one (every published paper’s abstract/intro accomplishes this. so, we’re looking for something similar, not ground-breaking claims like how it will impact society)
• lists a few (3-5) related papers and any commentary you may wish to include
• details the measurement for success (e.g., BLEU score, F1 score, a novel comparison, etc)
• list the pertinent dataset(s)
• describe a few ideas (1-2) you have for approaching/solving the problem","Example Submission
Humor is an essential and pervasive component of human language that requires a deep semantic understanding of text. In recent years, the ability to automatically detect humor has gained attention due to the desire for human-machine interaction systems to be able to differentiate the user’s implied meaning from the literal meaning. However, the lack of consensus between individuals on the extent to which they sense humor makes it difficult for models to understand the degree associated with funniness.
Previous work in computational humor has mainly focused on the task of binary classification: humor or not-humor. Chen and Soo (2018) proposed a convolutional neural network architecture with high way networks to distinguish between humorous and non-humorous content. Weller and Seppi (2019) assessed whether or not a joke was humorous using Transformer architecture. Annamoradnejad and Zoghi (2022) presented a method for detecting and rating humor that separates sentences of the given text and uses BERT to generate embeddings for each one. While these are reasonable approaches, the nature of humor is non-binary, so we will approach humor
recognition using regression, which is a far more nuanced task. 
There are many approaches to model language to identify humor. We will analyze the performance of different techniques within seq2seq, a family of machine learning approaches for natural language processing (NLP), and identify the models that are the best at detecting humor. Such techniques include using various recurrent neural network (RNN) architectures, such as long short-term memory (LSTM) units and gated recurrent units (GRU). We will also investigate optimizations to these standard NLP models, including attention, beam search, and bucketing. We will implement these techniques on Google Colab GPUs with the help of PyTorch, a Python machine learning library that provides the framework for these architectures.
In order to train our models, we will use training data obtained from the following source: https://github.com/taivop/joke-dataset. The database contains JSON files with about 208,000 jokes, including 195,000 Reddit jokes that have a user-assigned “score” from 1 to 5 representing how funny the joke is. In addition, we will scrape normal, nonhumorous sentences from Reddit or other sources with a default score of 0 for more contrasting data to train our models with.
Since we are experimenting with both regression models and text generation models, we will utilize different evaluation metrics for each task. We will also differentiate between the usage of metrics for both training and testing, proposing which metric to use in each case.
For regression models that aim to predict a real number which corresponds to how humorous a piece of text is, we can apply metrics like mean squared loss (L2) or mean absolute error (L1) during training. We may evaluate both metrics to determine whether there are a non-negligible amount of outliers within the dataset, and how that would affect the model’s accuracy. For testing, we can choose to report a mean loss to see how far the prediction value differs from the target value, on average. This will give us a good way to benchmark our performance on each model, as the quality of regression can only be evaluated by its error.
For language models that aim to generate a humorous statement, we can apply metrics similar to cross entropy loss during training. This is valid since given a sequence of characters, the model aims to predict the class of the next character which comes after the given sequence. For evaluation, we can use a metric like perplexity to determine how well the model was trained. Of course, we may also simply qualitatively observe the text generated and determine if it seems to be humorous or not.
References
[1] Issa Annamoradnejad and Gohar Zoghi. 2022. Computational Humor Using BERT Sentence
Embedding in Parallel Neural Networks. arXiv preprint arXiv:2004.12765.
[2] Peng-Yu Chen and Von-Wun Soo. 2018. Humor Recognition Using Deep Learning.
Proceedings of the 2018 Conference of the North American Chapter of the Association for
Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pp. 113-
117.
[3] Orion Weller and Kevin Seppi. 2019. Humor Detection: A Transformer Gets the Last Laugh.
Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and
the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pp.
3621-3625.","You will start new sections describing your Models and Experiments/Results. Specifically, you are expected to explain your system in any way you see fit, which is usually in a section titled Models or Methodology. Your experiments section should describe your exact setup, along with your baseline model’s results (usually in a sub-section titled Results). Again, it is okay if these results aren’t good yet, as nobody can perfectly predict the outcome. This is the nature of science and research. However, we do expect to see a reasonable approach for a baseline model, one that is not expected to perform very well but is a simple yet sensible initial approach to the problem. As a reminder, baseline results are critical to your work as they will help inform you of future directions to take, and they will serve as a reference point for your later results. That is, if you later develop a complicated, technical solution, how should one interpret its results? How will we know if its particular accuracy score is actually good? The baseline model provides that contrast and puts all future experiments into perspective.
We will grade your progress on Introduction, Related Works, and Models/Results.","Example Submission
Introduction
Humor is an essential and pervasive component of human language that requires a deep semantic understanding of text. While there have been many attempts to define the inner workings of humor, from Sigmund Freuds’ explanation of humor as a process of relieving pent-up nervous energy to René Descartes’ consideration of laughter to be an expression of scorn, there does not exist an all-encompassing definition of humor. Most modern humor theories in philosophy and psychology make use of the term incongruity, which frames humor as a setup and punchline, with the former serving to create an expectation and the latter serving to violate that expectation [1].
In recent years, the ability to automatically detect humor has gained attention due to the desire for human-machine interaction systems to be able to differentiate the user’s implied meaning from the literal meaning. Given that humor is an intrinsically human trait, it may initially seem insensible for machines to possess a sense of humor. Furthermore, the lack of consensus between individuals on the extent to which they sense humor makes it even more difficult for models to understand the degree associated with funniness.
Related Works
Previous work in computational humor has mainly focused on the task of binary classification: humor or not-humor. Chen and Soo (2018) proposed a convolutional neural network architecture with high way networks to distinguish between humorous and non-humorous content [2]. Weller and Seppi (2019) assessed whether or not a joke was humorous using Transformer architecture [3]. Annamoradnejad and Zoghi (2022) presented a method for detecting and rating humor that separated sentences of the given text and used BERT to generate embeddings for each one [4]. While these were all reasonable approaches, the underlying nature of humor is subjective and non-binary, so we will approach humor recognition using regression, which is a far more nuanced task that will help us gain more insights into this unique human trait.
Methodology
There are many approaches to model language to identify humor. We will analyze the performance of different techniques within Seq2Seq, a family of machine learning approaches for natural language processing (NLP), and identify the models that are the best at detecting humor. Such techniques include using various recurrent neural network (RNN) architectures, such as long short-term memory (LSTM) units and gated recurrent units (GRU). We will also investigate optimizations to these standard NLP models, including attention, beam search, and bucketing. We will implement these techniques on Google Colab GPUs with the help of PyTorch, a common Python machine learning library that provides support for these architectures.
In order to train our models, we will use training data obtained from the following source: https://github.com/taivop/joke-dataset. The database contains JSON files with approximately 208,000 jokes, including 195,000 Reddit jokes that have a user-assigned “score” from 1 to 5 representing how funny the joke is. In addition, we will scrape normal, nonhumorous sentences from Reddit or other sources with a default score of 0 for more contrasting data to train our models with.
Since we are experimenting with both regression models and text generation models, we will utilize different evaluation metrics for each task. We will also differentiate between the usage of metrics for both training and testing, proposing which metric to use in each case.
For regression models that aim to predict a real number which corresponds to how humorous a piece of text is, we will apply metrics like mean squared loss (L2) or mean absolute error (L1) during training. We will evaluate both metrics to determine whether there are a non-negligible amount of outliers within the dataset, and how that would affect the model’s accuracy. For testing, we intend to report a mean loss to see how far the prediction value differs from the target value, on average. This will give us a statistical way to benchmark our performance on each model, as the quality of regression can only be evaluated by its error.
Baseline Experiments and Results
Our reference for baseline results will be Weller and Seppi’s 2019 results, as their research most closely resembles our project’s goal and utilizes the same dataset of jokes. They used a pre-trained BERT model to determine whether or not a joke was humorous with a 72.4% accuracy rate. These results serve as a baseline reference to help us tell whether or not our model is performing at least as well as previous research. If we do reach that level, we will then aim to improve upon it by training it to perform regression. Weller and Seppi’s results also validate the use of our dataset, since they reported that a model trained on this dataset was able to perform with high accuracy on other joke datasets as well.
We have implemented a basic recurrent neural network (RNN) class that we will use to experiment with the different RNN frameworks highlighted above. In order to train these models, we have curated a dataset of jokes and scraped both the joke content and the user rating score from the dataset. Then, we implemented a data loader compatible with our training framework for efficient iteration through the dataset.","Please upload a brief (few sentences to a paragraph) answering the following questions about the guest lecture.
1. What is one thing that you learned from the guest lecture that you did not know before?
2. Do you have any questions for the guest lecturer?
If you are unable to attend the guest lecture, please write a one-page summary of the following paper:
https://arxiv.org/abs/2205.12689.","One thing that I learned from the guest lecture that I did not know before is that according to the American Journal of Emergency Medicine study, an ER doctor has to make approximately 4000 computer clicks over the course of a single shift to surface the necessary information for documentation. One question I have for the guest lecturer is where do you see the future for natural language processing in healthcare as well as what trends do you predict we will see in the next five to ten years."
40,Mathematics,18.01,Calculus I,None,None,Problem Set 1,Exponentials and Logarithms,19,b,0.07919746568,Text,"In this problem, we will combine all the ideas in this section in order to approximate the number $(1.01)^{100}$. Let $s$ denote this number.
Use linear approximation in some way to approximate this expression.",Numerical,"With $\log 1.01 \approx 0.01$ (the linear approximation),
$$
\log s \approx 100 \times 0.01=1 .
$$","In this problem, we will combine all the ideas in this section in order to approximate the number $(1.01)^{100}$. Let $s$ denote this number.
Once you have an approximation of $\log s$, use it to approximate $s$. ","Thus, $s \equiv e^{\log s} \approx e^{1}=e$.","In this problem, we will combine all the ideas in this section in order to approximate the number $(1.01)^{100}$. Let $s$ denote this number.
Write an expression for $\log s$, and try to make it as simple as possible.","With $s \equiv 1.01^{100}$,
$$
\log s=100 \log 1.01 \text {. }
$$","Suppose that Larry wants to approximate $(1.01)^{10}$. Let $g(x)=x^{10}$.
Find the linear approximation of $g(x)$ around $x=1$, and use it to approximate $(1.01)^{10}$.","$$
\begin{gathered}
g^{\prime}(1)=\left.10 x^{9}\right|_{x=1}=10 . \\
(1.01)^{10}=g(1.01) \approx g(1)+.01 g^{\prime}(1)=\mathbf{1.1}.
\end{gathered}
$$"
139,Mathematics,18.01,Calculus I,None,None,Problem Set 4,Chain Rule,3,b,0.07919746568,Text,"Fill in the blank in the following equations:
$\frac{f^{\prime}(x)}{f(x)}=\frac{d}{d x}(\quad)$. ",Expression,$\frac{f^{\prime}(x)}{f(x)}=\frac{d}{d x}(\ln (f(x)))$,"Fill in the blank in the following equations:
$f(x) f^{\prime}(x)=\frac{d}{d x}(\quad)$.","$\frac{d}{d x}\left(f(x)^{2}\right)=2 f^{\prime}(x) f(x)$ by either the chain rule or the product rule, so
$$
f^{\prime}(x) f(x)=\frac{d}{d x}\left(\frac{1}{2} f(x)^{2}\right)
$$","In this problem, we work out the derivative of $f(x)=\frac{1}{x}$ by finding a nice approximation of $f(x+\Delta x)$. We know that
$$
f(x+\Delta x)=\frac{1}{x+\Delta x} .
$$
Because $\Delta x$ is in the denominator, this expression is a little complicated. There's a trick that makes it easier to approximate: multiply top and bottom by $x-\Delta x$.
$$
\frac{1}{x+\Delta x}=\frac{1}{x+\Delta x} \cdot \frac{x-\Delta x}{x-\Delta x}=\frac{x-\Delta x}{x^{2}-(\Delta x)^{2}} .
$$
Use this approximation to find $f^{\prime}(x)$. Remember $f(x+\Delta x) \approx f(x)+f^{\prime}(x) \Delta x$, so try to write your answer to part a. in this form.","We have $f^{\prime}(x) \approx \frac{x-\Delta x}{x^{2}}=\frac{1}{x}-\frac{1}{x^{2}} \Delta x$, so $f^{\prime}(x)=\frac{-1}{x^{2}}$.","In this problem, we work out the derivative of $f(x)=\frac{1}{x}$ by finding a nice approximation of $f(x+\Delta x)$. We know that
$$
f(x+\Delta x)=\frac{1}{x+\Delta x} .
$$
Because $\Delta x$ is in the denominator, this expression is a little complicated. There's a trick that makes it easier to approximate: multiply top and bottom by $x-\Delta x$.
$$
\frac{1}{x+\Delta x}=\frac{1}{x+\Delta x} \cdot \frac{x-\Delta x}{x-\Delta x}=\frac{x-\Delta x}{x^{2}-(\Delta x)^{2}} .
$$
Which of the following is a better approximation of $\frac{x-\Delta x}{x^{2}-(\Delta x)^{2}}$ when $\Delta x$ is really small? Briefly explain your reasoning.
$$
\frac{x-\Delta x}{x^{2}} \text { or } \frac{x}{x^{2}-(\Delta x)^{2}} .
$$",$\frac{x-\Delta x}{x^{2}}$ is the better approximation because $x-\Delta x$ is further from $x$ than $x^{2}-(\Delta x)^{2}$ is from $x^{2}$.
504,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Problem Set 4,Logistic Regression,5,a,0.04464285714,Text,"Assume we are doing multi-class logistic regression with three possible categories. What probability distribution over the categories is represented by $z=[-1,0,1]^{T}$, where $z$ is the vector of inputs to the softmax transformation?
Enter a distribution (a list of three non-negative numbers adding up to 1) for the three categories. Your answers should be numeric (please enter numbers, and do not use the symbol $e$):",Expression,"[0.09, 0.245, 0.665]","Recall that the output of a logistic regression model given an input $x$ has the form:
$$
g=\sigma\left(\theta^{T} x+\theta_{0}\right)
$$
where
$$
\sigma(z)=\frac{1}{1+e^{-z}}
$$
is the sigmoid function. You start with the following set of points in two dimensions.
$$
\begin{array}{cc}
\text { Inputs } x^{(i)} & \text { Labels } y^{(i)} \\
{[1,1]^{T}} & 0 \\
{[0,0]^{T}} & 0 \\
{[1,0]^{T}} & 1 \\
{[0,1]^{T}} & 0
\end{array}
$$
Assume $\theta=[1,0]^{T}$ and $\theta_{0}=-0.5$. You may find it useful to sketch the dataset and the linear separator $\theta, \theta_{0}$.
What are the values of $z=\theta^{T} x+\theta_{0}$ for each value of $x^{(i)}$? Give an answer as a list of four numbers (to max of two decimal places).","$[0.5,-0.5,0.5,-0.5]$.
We plug each $x$ into the formula $z=\theta^{T} x+\theta_{0}$ with $\theta=[1,0]^{T}$ and $\theta_{0}=-0.5$. Plotting the separator reveals that it is a vertical line at $x=0.5$. Also plotting the points $(x, y)$ reveals that the points to the left of the line have a negative $z$ value, and the points to the right of the line have a positive $z$ value.","Recall that the output of a logistic regression model given an input $x$ has the form:
$$
g=\sigma\left(\theta^{T} x+\theta_{0}\right)
$$
where
$$
\sigma(z)=\frac{1}{1+e^{-z}}
$$
is the sigmoid function. You start with the following set of points in two dimensions.
$$
\begin{array}{cc}
\text { Inputs } x^{(i)} & \text { Labels } y^{(i)} \\
{[1,1]^{T}} & 0 \\
{[0,0]^{T}} & 0 \\
{[1,0]^{T}} & 1 \\
{[0,1]^{T}} & 0
\end{array}
$$
Assume $\theta=[1,0]^{T}$ and $\theta_{0}=-0.5$. You may find it useful to sketch the dataset and the linear separator $\theta, \theta_{0}$.
What are the corresponding values of $\sigma(z)$ ? Give an answer as a list of four numbers (to max of two decimal places)?","$[0.62245933,0.37754067,0.62245933,0.37754067]$.
Plugging into the formula $\sigma(z)=\frac{1}{1+e^{-z}}$ where $z^{\prime}$ s are found in question 1.1. Remember that in logistic regression, we can interpret these $\sigma(z)$ values as modeling the probability of the point having a label of 1.","Recall that the output of a logistic regression model given an input $x$ has the form:
$$
g=\sigma\left(\theta^{T} x+\theta_{0}\right)
$$
where
$$
\sigma(z)=\frac{1}{1+e^{-z}}
$$
is the sigmoid function. You start with the following set of points in two dimensions.
$$
\begin{array}{cc}
\text { Inputs } x^{(i)} & \text { Labels } y^{(i)} \\
{[1,1]^{T}} & 0 \\
{[0,0]^{T}} & 0 \\
{[1,0]^{T}} & 1 \\
{[0,1]^{T}} & 0
\end{array}
$$
Assume $\theta=[1,0]^{T}$ and $\theta_{0}=-0.5$. You may find it useful to sketch the dataset and the linear separator $\theta, \theta_{0}$.
With the threshold at $0.5$, what are the corresponding predicted labels of these points? Give an answer as a list of four numbers (and recall that the label options are 1 or 0).","$[1,0,1,0]$.
Points whose $\sigma(z) \leq 0.5$ are classified as 0. Points whose $\sigma(z)>0.5$ are classified as 1."
83,Mathematics,18.6,Probability and Random Variables,18.02,None,Problem Set 7,Markov's Inequality,3,a,0.15,Text,"From past experience, a professor knows that the test score of a student taking her final examination is a random variable with mean $75$.
Give an upper bound for the probability that a student’s test score will exceed $85$.",Numerical,"Let the random variable $X$ be the student's test score. By using Markov's Inequality, an upper bound for the probability that a student's test score will exceed $85$ is given by 
\begin{center}
$P\{X \geq 85\} \leq \dfrac{E[X]}{85} = \dfrac{75}{85} = \dfrac{15}{17}$.
\end{center}","From past experience, a professor knows that the test score of a student taking her final examination is a random variable with mean $75$.
Suppose, in addition, that the professor knows that the variance of a student’s test score is equal to $25$. What can be said about the probability that students will score between $65$ and $85$?","Let the random variable $X$ be the student's test score. By using Chebyshev's Inequality, the probability that students will score between $65$ and $85$ is given by 
\begin{center}
$P\{65 < X < 85\} = 1 - P\{|X - 75| \geq 10\} \geq 1 - \dfrac{Var(X)}{10^2} = 1 - \dfrac{25}{100} = \dfrac{3}{4}$.
\end{center}","From past experience, a professor knows that the test score of a student taking her final examination is a random variable with mean $75$.
How many students would have to take the examination to ensure, with probability at least $0.9$, that the class average would be within $5$ of $75$? Do not use the central limit theorem.","Let $n$ be the number of students who would have to take the examination, the random variables $X_1,...,X_n$ be their test scores, and the random variable $Y = \dfrac{1}{n} \mathlarger{\sum\limits^{n}_{i = 1}} X_i$ be the class average.
\begin{center}
$E[Y] = \dfrac{1}{n} \mathlarger{\sum\limits^{n}_{i = 1}} E[X_i] = 75$.
\end{center}
\begin{center}
$Var(Y) = \dfrac{1}{n^2} \mathlarger{\sum\limits^{n}_{i = 1}} \mathlarger{\sum\limits^{n}_{j = 1}}Cov(X_i, X_j) = \dfrac{25}{n}$.
\end{center}
Using Chebyshev's Inequality, the probability that the class average would be within $5$ of $75$ is given by
\begin{center}
$P\{|Y - 75| < 5\} = 1 - P\{|X - 75| \geq 5\} \geq 1 - \dfrac{Var(X)}{5^2} = 1 - \dfrac{25/n}{25} = 1 - \dfrac{1}{n}$.
\end{center}
Thus, the number of students that would have to take the examination to ensure, with probability at least $0.9$, that the class average would be within $5$ of $75$ is given by
\begin{center}
$P\{|Y - 75| < 5\} = 1 - \dfrac{1}{n} = 0.9$.
\end{center}
\begin{center}
$n = 10$.
\end{center}","From past experience, a professor knows that the test score of a student taking her final examination is a random variable with mean $75$.
Redo part (c) by approximating the appropriate quantity using the central limit theorem.","Let $n$ be the number of students who would have to take the examination, the random variables $X_1,...,X_n$ be their test scores, and the standard normal random variable $Z = \dfrac{1}{n} \mathlarger{\sum\limits^{n}_{i = 1}} X_i$ be the class average.
\begin{center}
$E[Z] = \dfrac{1}{n} \mathlarger{\sum\limits^{n}_{i = 1}} E[X_i] = 75$.
\end{center}
\begin{center}
$Var(Z) = \dfrac{1}{n^2} \mathlarger{\sum\limits^{n}_{i = 1}} \mathlarger{\sum\limits^{n}_{j = 1}}Cov(X_i, X_j) = \dfrac{25}{n}$.
\end{center}
Using the Central Limit Theorem, the probability that the class average would be within $5$ of $75$ is given by
\begin{center}
$P\{|Z - 75| < 5\} = P\{70 < Z < 80\} = \phi(\dfrac{80 - 75}{\sqrt{25/n}}) - \phi(\dfrac{70 - 75}{\sqrt{25/n}}) = \phi(\sqrt{n}) - \phi(-\sqrt{n}) = 2\phi(\sqrt{n}) - 1$.
\end{center}
Thus, the number of students that would have to take the examination to ensure, with probability at least $0.9$, that the class average would be within $5$ of $75$ is given by
\begin{center}
$P\{|Z - 75| < 5\} = 2\phi(\sqrt{n}) - 1 = 0.9$.
\end{center}
\begin{center}
$\phi(\sqrt{n}) = 0.95$.
\end{center}
\begin{center}
$\sqrt{n} = 1.645$.
\end{center}
\begin{center}
$n = 3$.
\end{center}"
71,EECS,18.C06,Linear Algebra and Optimization,18.02,None,Problem Set 3,Linear Systems,7,a,0.4938271605,Text,"A UFO is in outer space, hovering at the fixed position $(-30,0,30)$. It then begins traveling on a straight line trajectory along the direction parallel to the vector $(1,2,2)$, towards the mysterious star Bunnyelgeuse. All distances are measured in parsecs (a certain unit of distance used in astronomy, its specific value is irrelevant for this problem).
Let $S$ be the set of all points in the trajectory of the UFO. Find a system of linear equations $A x=b$, such that its solution set is exactly equal to $S$.",Expression,"The set is
$$
S=\left\{\left[\begin{array}{c}
-30 \\
0 \\
30
\end{array}\right]+\alpha\left[\begin{array}{l}
1 \\
2 \\
2
\end{array}\right], \text { for all } \alpha \in \mathbb{R}\right\}
$$
The general solution of a linear system $A x=b$ is $x_{0}+N(A)$, where $x_{0}$ is a particular solution (i.e., $\left.A x_{0}=b\right)$. Thus, we must find a matrix $A$ for which $N(A)=\operatorname{span}\{(1,2,2)\}$. Since this vector satisfies $y=z$ and $2 x=y$ (and these are linearly independent), one such matrix is
$$
A=\left[\begin{array}{ccc}
-2 & 1 & 0 \\
0 & -1 & 1
\end{array}\right]
$$
Defining $b=A[-30,0,30]^{T}=[60,30]^{T}$, this gives $S$ as the solution set of the equations
$$
\left[\begin{array}{ccc}
-2 & 1 & 0 \\
0 & -1 & 1
\end{array}\right]\left[\begin{array}{l}
x \\
y \\
z
\end{array}\right]=\left[\begin{array}{l}
60 \\
30
\end{array}\right]
$$
Another approach is to start from the equations
$$
x=-30+\alpha, \quad y=2 \alpha, \quad z=30+2 \alpha,
$$
and to simply eliminate $\alpha$. For instance, from the second equation we get $\alpha=y / 2$; replacing in the other two equations we obtain
$$
x-y / 2=-30, \quad z-y=30.
$$","A UFO is in outer space, hovering at the fixed position $(-30,0,30)$. It then begins traveling on a straight line trajectory along the direction parallel to the vector $(1,2,2)$, towards the mysterious star Bunnyelgeuse. All distances are measured in parsecs (a certain unit of distance used in astronomy, its specific value is irrelevant for this problem).
How close will the first UFO get to Alpha Leporis, and what are the coordinates of that point?","Now we want to project the point $y$ (Alpha Leporis) onto a line that is parallel to $T$, but passes through the point $x_{0}=(-30,0,30)$. Notice that this is not a subspace, since this line does not contain the origin. Nevertheless, it is easy to see geometrically that such a projection is given by $x_{0}+P\left(y-x_{0}\right)$ (why?). Thus, the coordinates of the point closest to Alpha Leporis are
$$
x^{\star}=\left[\begin{array}{c}
-30 \\
0 \\
30
\end{array}\right]+P\left(\left[\begin{array}{c}
90 \\
180 \\
270
\end{array}\right]-\left[\begin{array}{c}
-30 \\
0 \\
30
\end{array}\right]\right)=\frac{1}{3}\left[\begin{array}{c}
230 \\
640 \\
730
\end{array}\right]=\left[\begin{array}{c}
76.66 \\
213.33 \\
243.33
\end{array}\right]
$$
and the minimum distance $\left\|y-x^{\star}\right\|$ is $\sqrt{2000}=44.72$ parsecs.","A UFO is in outer space, hovering at the fixed position $(-30,0,30)$. It then begins traveling on a straight line trajectory along the direction parallel to the vector $(1,2,2)$, towards the mysterious star Bunnyelgeuse. All distances are measured in parsecs (a certain unit of distance used in astronomy, its specific value is irrelevant for this problem).
A second UFO starts at the position (0,0,0), and also travels on a straight line, along the same direction $(1,2,2)$. Let $T$ be the smallest subspace containing this trajectory. Compute a matrix $P \in \mathbb{R}^{3 \times 3}$ such that, given a point $x \in \mathbb{R}^{3}$, the point in $T$ that is closest to $x$ is equal to $P x$.","Letting $v=[1,2,2]^{T}$, since $T=\operatorname{span}\{v\}$, the required matrix is the orthogonal projection onto $T$, i.e.,
$$
P=v\left(v^{T} v\right)^{-1} v^{T}=\frac{1}{9}\left[\begin{array}{ccc}
1 & 2 & 2 \\
2 & 4 & 4 \\
2 & 4 & 4
\end{array}\right] \text {. }
$$
Notice that as expected, we have $P^{2}=P$.","A UFO is in outer space, hovering at the fixed position $(-30,0,30)$. It then begins traveling on a straight line trajectory along the direction parallel to the vector $(1,2,2)$, towards the mysterious star Bunnyelgeuse. All distances are measured in parsecs (a certain unit of distance used in astronomy, its specific value is irrelevant for this problem).
Alpha Leporis is the brightest star in the constellation Lepus, and has coordinates $(90,180,270)$. How close will the second UFO get to this star?","Since Alpha Leporis is at position $y=[90,180,270]^{T}$, the closest point to it on $T$ is given by the orthogonal projection of $y$ onto the subspace $T$, i.e., $y^{\star}=P y=$ $[110,220,220]^{T}$. Notice that, as expected, $y-y^{\star}=[-20,-40,50]^{T}$ is orthogonal to $v$ (sanity check!). The distance between the two points is $\left\|y-y^{\star}\right\|=\sqrt{20^{2}+40^{2}+50^{2}}=$ $\sqrt{4500}=67.08$ parsecs."
59,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Prelab Questions 6,Single Cycle RISC-V Processor Implementation,1,c,0.05833333333,Text,"For which instruction types must bits [31:25] be checked? Select all correct answers.
(a) OP.
(b) OPIMM.
(c) LOAD.
(d) STORE.
(e) BRANCH.
(f) JAL.
(g) JALR.
(h) LUI.",Multiple Choice,"(a) OP.
(b) OPIMM.
As we saw in the previous question, the top 7 bits (31:25) are hardcoded and must match for all of the OP instructions as well as for the shift immediate OPIMM operations. All other instruction types use these bits to encode part of their immediate values.","Which instruction types encode an immediate value as part of the instruction encoding? Select all correct answers.
(a) OP.
(b) OPIMM.
(c) LOAD.
(d) STORE.
(e) BRANCH.
(f) JAL.
(g) JALR.
(h) LUI.","(b) OPIMM.
(c) LOAD.
(d) STORE.
(e) BRANCH.
(f) JAL.
(g) JALR.
(h) LUI.
The only type of instruction that does not use any immediate bits is the OP type. You can verify this by looking at the encodings in the ISA handout and noting that the only instructions that do not specify an immediate value are the OP instructions from ADD to AND. Note that the shamt field in the OPIMM shift instructions is also an immediate value.","Which instruction types do not write to the register file? Select all correct answers.
(a) OP.
(b) OPIMM.
(c) LOAD.
(d) STORE.
(e) BRANCH.
(f) JAL.
(g) JALR.
(h) LUI.","(d) STORE.
(e) BRANCH.
Store and branch instructions are the only instruction types that do not update the register file. If you look at their encoding in the ISA handout, you see that they are the only instructions that do not have specify an rd field. The reason they don't specify one is because they do not write to any destination registers.","Which of the following instruction types use the PC value in the calculation of the data to be written to the register file? Select all correct answers.
(a) OP.
(b) OPIMM.
(c) LOAD.
(d) BRANCH.
(e) JAL.
(f) JALR.","(e) JAL.
(f) JALR.
The JAL and JALR instructions store the value of PC + 4 in the destination register so that it can be used to jump back to the original code. If you look at the execution portion of the ISA handout, you can see that the JAL and JALR instructions are the only ones whose rd register value depends on the value of the PC."
355,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Problem Set 1,NumPy,1,bvii,0.01488095238,Text,"Let A be a $4 \times 2$ numpy array, B be a $4 \times 3$ array, and C be a $4 \times 1$ array. For each of the following expressions, indicate the shape of the result as a tuple of integers (recall python tuples use parentheses, not square brackets, which are for lists, and a tuple with just one item $x$ in it is written as $(x$, ) with a comma). Write ""none"" (as a Python string with quotes) if the expression is illegal.
For example,
\begin{itemize}
\item If the result array was $[45,36,75]$, the shape is $(3$,
\item If the result array was $[[1,2,3],[4,5,6]]$, the shape is $(2,3)$
\end{itemize}
Hint: If you get stuck, code and run these expressions (with array values of your choosing), then print out the shape using A. shape.
Reminder: $A$ is $4 \times 2$, B is $4 \times 3$, and $C$ is $4 \times 1$.
np.dot(A.T, B)",Expression,"(2, 3)","Let A be a $4 \times 2$ numpy array, B be a $4 \times 3$ array, and C be a $4 \times 1$ array. For each of the following expressions, indicate the shape of the result as a tuple of integers (recall python tuples use parentheses, not square brackets, which are for lists, and a tuple with just one item $x$ in it is written as $(x$, ) with a comma). Write ""none"" (as a Python string with quotes) if the expression is illegal.
For example,
\begin{itemize}
\item If the result array was $[45,36,75]$, the shape is $(3$,
\item If the result array was $[[1,2,3],[4,5,6]]$, the shape is $(2,3)$
\end{itemize}
Hint: If you get stuck, code and run these expressions (with array values of your choosing), then print out the shape using A. shape.
Reminder: $A$ is $4 \times 2$, B is $4 \times 3$, and $C$ is $4 \times 1$.
np.dot(np.transpose(C), C)","(1, 1)","Let A be a $4 \times 2$ numpy array, B be a $4 \times 3$ array, and C be a $4 \times 1$ array. For each of the following expressions, indicate the shape of the result as a tuple of integers (recall python tuples use parentheses, not square brackets, which are for lists, and a tuple with just one item $x$ in it is written as $(x$, ) with a comma). Write ""none"" (as a Python string with quotes) if the expression is illegal.
For example,
\begin{itemize}
\item If the result array was $[45,36,75]$, the shape is $(3$,
\item If the result array was $[[1,2,3],[4,5,6]]$, the shape is $(2,3)$
\end{itemize}
Hint: If you get stuck, code and run these expressions (with array values of your choosing), then print out the shape using A. shape.
Reminder: $A$ is $4 \times 2$, B is $4 \times 3$, and $C$ is $4 \times 1$.
np.dot(C, C)",none',"Let A be a $4 \times 2$ numpy array, B be a $4 \times 3$ array, and C be a $4 \times 1$ array. For each of the following expressions, indicate the shape of the result as a tuple of integers (recall python tuples use parentheses, not square brackets, which are for lists, and a tuple with just one item $x$ in it is written as $(x$, ) with a comma). Write ""none"" (as a Python string with quotes) if the expression is illegal.
For example,
\begin{itemize}
\item If the result array was $[45,36,75]$, the shape is $(3$,
\item If the result array was $[[1,2,3],[4,5,6]]$, the shape is $(2,3)$
\end{itemize}
Hint: If you get stuck, code and run these expressions (with array values of your choosing), then print out the shape using A. shape.
Reminder: $A$ is $4 \times 2$, B is $4 \times 3$, and $C$ is $4 \times 1$.
np.dot(np.transpose(C), C)
np.dot(A, B)",none'
322,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Final Exam,Markov Decision Process,9,f,0.5,Text,"Consider a family of discrete MDPs, each with 1000 states. (In the following, use modular arithmetic, so state $-1$ is the same as state 999 , and state 1000 is the same as state 0.)
\begin{itemize}
\item There are two actions, $A$ and $B$.
\item The reward for entering entering state 0 is $+99$.
\item The reward for entering state 999 is $-99$.
\item All other rewards are 0.
\item The discount factor is $1.0$.
\end{itemize}
MDPs in this family are parameterized by an integer $k \in\{0, \ldots, 100\}$, which governs the transition model as follows:
\begin{itemize}
\item Action A: State $i$ transitions with probability $1 /(2 k+1)$ to each state in $\{i-k+1, \ldots, i+k+1\}$.
\item Action B: State $i$ transitions with probability $1 /(2 k+1)$ to each state in $\{i-k-1, \ldots, i+k-1\}$.
\end{itemize}
So, action A produces an uniform distribution centered at $i+1$ and action B produces an uniform distribution centered at $i-1$, both of width $2 k+1$. For example,
\begin{itemize}
\item When $k=0$, action A moves deterministically one step ""up"" and action B moves deterministically one step ""down"".
\item When $k=1$, action A moves with equal probability ""up"" 2, ""up"" 1, or stays in the original state; action B moves with equal probability ""down"" 2, ""down"" 1, or stays in the original state.
\item When $k=2$, action A moves with equal probability ""up"" 3, ""up"" 2, ""up"" 1 , stays in the original state, or moves ""down"" 1; action B moves with equal probability ""down"" 3, ""down"" 2, ""down"" 1 , stays in the original state, or moves ""up"" 1.
\end{itemize}
Consider the case of $k=100$ and horizon 10. We might prefer to use a sampling based method (sparse sampling or MCTS). Explain why.",Open,Even the AODAG will be too huge to evaluate all of and so sampling will be the only plausible strategy.,"Consider a family of discrete MDPs, each with 1000 states. (In the following, use modular arithmetic, so state $-1$ is the same as state 999 , and state 1000 is the same as state 0.)
\begin{itemize}
\item There are two actions, $A$ and $B$.
\item The reward for entering entering state 0 is $+99$.
\item The reward for entering state 999 is $-99$.
\item All other rewards are 0.
\item The discount factor is $1.0$.
\end{itemize}
MDPs in this family are parameterized by an integer $k \in\{0, \ldots, 100\}$, which governs the transition model as follows:
\begin{itemize}
\item Action A: State $i$ transitions with probability $1 /(2 k+1)$ to each state in $\{i-k+1, \ldots, i+k+1\}$.
\item Action B: State $i$ transitions with probability $1 /(2 k+1)$ to each state in $\{i-k-1, \ldots, i+k-1\}$.
\end{itemize}
So, action A produces an uniform distribution centered at $i+1$ and action B produces an uniform distribution centered at $i-1$, both of width $2 k+1$. For example,
\begin{itemize}
\item When $k=0$, action A moves deterministically one step ""up"" and action B moves deterministically one step ""down"".
\item When $k=1$, action A moves with equal probability ""up"" 2, ""up"" 1, or stays in the original state; action B moves with equal probability ""down"" 2, ""down"" 1, or stays in the original state.
\item When $k=2$, action A moves with equal probability ""up"" 3, ""up"" 2, ""up"" 1 , stays in the original state, or moves ""down"" 1; action B moves with equal probability ""down"" 3, ""down"" 2, ""down"" 1 , stays in the original state, or moves ""up"" 1.
\end{itemize}
Treesa wants to use sparse sampling with 50 samples at each node. In the case when $k=100$, horizon is just 1 and the state is 101, what difficulty might Treesa's method face?","The optimal action in that case is B, but to see that, you have to ""hit"" a single outcome out of 100, and that is unlikely to happen with only 50 samples.","Consider a family of discrete MDPs, each with 1000 states. (In the following, use modular arithmetic, so state $-1$ is the same as state 999 , and state 1000 is the same as state 0.)
\begin{itemize}
\item There are two actions, $A$ and $B$.
\item The reward for entering entering state 0 is $+99$.
\item The reward for entering state 999 is $-99$.
\item All other rewards are 0.
\item The discount factor is $1.0$.
\end{itemize}
MDPs in this family are parameterized by an integer $k \in\{0, \ldots, 100\}$, which governs the transition model as follows:
\begin{itemize}
\item Action A: State $i$ transitions with probability $1 /(2 k+1)$ to each state in $\{i-k+1, \ldots, i+k+1\}$.
\item Action B: State $i$ transitions with probability $1 /(2 k+1)$ to each state in $\{i-k-1, \ldots, i+k-1\}$.
\end{itemize}
So, action A produces an uniform distribution centered at $i+1$ and action B produces an uniform distribution centered at $i-1$, both of width $2 k+1$. For example,
\begin{itemize}
\item When $k=0$, action A moves deterministically one step ""up"" and action B moves deterministically one step ""down"".
\item When $k=1$, action A moves with equal probability ""up"" 2, ""up"" 1, or stays in the original state; action B moves with equal probability ""down"" 2, ""down"" 1, or stays in the original state.
\item When $k=2$, action A moves with equal probability ""up"" 3, ""up"" 2, ""up"" 1 , stays in the original state, or moves ""down"" 1; action B moves with equal probability ""down"" 3, ""down"" 2, ""down"" 1 , stays in the original state, or moves ""up"" 1.
\end{itemize}
What is the optimal horizon 2 policy for the $k=1 \mathrm{MDP}$, starting at state 2?","S2: Take action B (move left)
Then:
If S0: Take action A (move right)
If S1: Doesn’t matter
If S2: Take action B (move left)","Consider a family of discrete MDPs, each with 1000 states. (In the following, use modular arithmetic, so state $-1$ is the same as state 999 , and state 1000 is the same as state 0.)
\begin{itemize}
\item There are two actions, $A$ and $B$.
\item The reward for entering entering state 0 is $+99$.
\item The reward for entering state 999 is $-99$.
\item All other rewards are 0.
\item The discount factor is $1.0$.
\end{itemize}
MDPs in this family are parameterized by an integer $k \in\{0, \ldots, 100\}$, which governs the transition model as follows:
\begin{itemize}
\item Action A: State $i$ transitions with probability $1 /(2 k+1)$ to each state in $\{i-k+1, \ldots, i+k+1\}$.
\item Action B: State $i$ transitions with probability $1 /(2 k+1)$ to each state in $\{i-k-1, \ldots, i+k-1\}$.
\end{itemize}
So, action A produces an uniform distribution centered at $i+1$ and action B produces an uniform distribution centered at $i-1$, both of width $2 k+1$. For example,
\begin{itemize}
\item When $k=0$, action A moves deterministically one step ""up"" and action B moves deterministically one step ""down"".
\item When $k=1$, action A moves with equal probability ""up"" 2, ""up"" 1, or stays in the original state; action B moves with equal probability ""down"" 2, ""down"" 1, or stays in the original state.
\item When $k=2$, action A moves with equal probability ""up"" 3, ""up"" 2, ""up"" 1 , stays in the original state, or moves ""down"" 1; action B moves with equal probability ""down"" 3, ""down"" 2, ""down"" 1 , stays in the original state, or moves ""up"" 1.
\end{itemize}
How many leaves are there in the expectimax tree for horizon 3 in the MDP with $k=100$? (It is fine to write an unevaluated expression).",$402^{3}$.
64,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 1,Monte-Carlo Tree Search,4,div,0.09765625,Text,"Consider the following scenarios:
\begin{itemize}
\item An early trajectory has a terrible outcome and the algorithm never try its initial action again.
\item The algorithm behaves very similarly to a systematic enumeration of all possible paths.
\item The algorithm behaves very similarly to a systematic enumeration of all possible path prefixes, with each followed by a random completion.
\end{itemize}
For each of the scenarios, indicate whether:
\begin{itemize}
\item It is likely to happen when $C$ is too high.
\item It is likely to happen when $C$ is too low.
\item It is unlikely to happen in MCTS.
\end{itemize}
The algorithm behaves very similarly to a systematic enumeration of all possible path prefixes, with each followed by a random completion.
(a) It is likely to happen when $C$ is too high.
(b) It is likely to happen when $C$ is too low.
(c) It is unlikely to happen in MCTS.",Multiple Choice,(a) It is likely to happen when $C$ is too high.,"Consider the following scenarios:
\begin{itemize}
\item An early trajectory has a terrible outcome and the algorithm never try its initial action again.
\item The algorithm behaves very similarly to a systematic enumeration of all possible paths.
\item The algorithm behaves very similarly to a systematic enumeration of all possible path prefixes, with each followed by a random completion.
\end{itemize}
For each of the scenarios, indicate whether:
\begin{itemize}
\item It is likely to happen when $C$ is too high.
\item It is likely to happen when $C$ is too low.
\item It is unlikely to happen in MCTS.
\end{itemize}
The algorithm behaves very similarly to a systematic enumeration of all possible paths.
(a) It is likely to happen when $C$ is too high.
(b) It is likely to happen when $C$ is too low.
(c) It is unlikely to happen in MCTS.",(c) It is unlikely to happen in MCTS.,"Consider the following scenarios:
\begin{itemize}
\item An early trajectory has a terrible outcome and the algorithm never try its initial action again.
\item The algorithm behaves very similarly to a systematic enumeration of all possible paths.
\item The algorithm behaves very similarly to a systematic enumeration of all possible path prefixes, with each followed by a random completion.
\end{itemize}
For each of the scenarios, indicate whether:
\begin{itemize}
\item It is likely to happen when $C$ is too high.
\item It is likely to happen when $C$ is too low.
\item It is unlikely to happen in MCTS.
\end{itemize}
An early trajectory has a terrible outcome and we never try its initial action again.
(a) It is likely to happen when $C$ is too high.
(b) It is likely to happen when $C$ is too low.
(c) It is unlikely to happen in MCTS.",(b) It is likely to happen when $C$ is too low.,"Now, for each of the problems defined in get_fractal_problems, let us compare the performances of MCTS vs. UCS empirically by running run_mcts_search and run_uniform_cost_search. In particular, you should:
\begin{itemize}
\item Fix step_budget for both algorithms to 2500. Set iteration_budget for MCTS to infinity.
\item Run MCTS 20 times and record the average cumulative reward.
\item Run UCS once:
\begin{itemize}
\item If it fails (due to running out of step budget), record the cumulative reward as 0 .
\item If it succeeds, record the obtained cumulative reward. Hint: you might need to recover rewards from path costs
\end{itemize}
\item Repeat the above for all three problems in get_fractal_problems.
\end{itemize}
MCTS tends to be a better choice than UCS when: (choose all that apply)
(a) There is a single high-valued state and everything else has value 0.
(b) The value of the first part of a path gives you information about the value of its completions.
(c) You would rather have an ""okay"" answer soon than the optimal answer after a longer period of time.","(b) The value of the first part of a path gives you information about the value of its completions.
(c) You would rather have an ""okay"" answer soon than the optimal answer after a longer period of time."
38,Mathematics,18.702,Algebra II,18.701,None,Problem Set 4,Product Rings,4,d,0.2651515152,Text,"Let $I$ and $J$ be ideals of a ring $R$ such that $I+J=R$.
Describe the idempotents corresponding to the product decomposition in (c).",Open,"In $R_{1} \times R_{2}$, the idempotents that describe the product decomposition are $(1,0)$ and $(0,1)$. The inverse images of these elements in $R$ are the idempotents $r$ and $s$. ","Let $I$ and $J$ be ideals of a ring $R$ such that $I+J=R$.
Prove that if $I J=0$, then $R$ is isomorphic to the product ring $(R / I) \times(R / J)$.","Let $R_{1}=R / I$ and $R_{2}=R / J$. The kernel of the map $\pi=\left(\pi_{1}, \pi_{2}\right): R \rightarrow R_{1} \times R_{2}$ that sends an element $x$ to the pair $\left(x_{1}, x_{2}\right)$ of its residues is $I \cap J$, which is equal to $I J=0$. Therefore $\pi$ is injective. Let $(\bar{a}, \bar{b})$ be an element of $R_{1} \times R_{2}$, and let $a, b$ be elements that $\operatorname{map}$ to $\bar{a}, \bar{b}$. With $1=r+s$ as above, $(1,1)=\pi(1)=\pi(s)+\pi(r)=\left(\pi_{1}(s), 0\right)+\left(0, \pi_{2}(r)\right)$. So $\pi(s)=(1,0)$ and $\pi(r)=(0,1)$. Then $\pi(s a+r b)=\left(\pi_{1}(a), 0\right)+\left(0, \pi_{2}(b)\right)=(\bar{a}, \bar{b})$.","Let $I$ and $J$ be ideals of a ring $R$ such that $I+J=R$.
Prove that $I J=I \cap J$ (see Exercise 3.13).","For any ideals $I$ and $J$, it is true that $I J \subset I$ and $I J \subset J$. So $I J \subset I \cap J$. Suppose that $I+J=R$. Then we can write $1=r+s$ with $r \in I$ and $s \in J$. If $x \in I \cap J, r x$ is in $I J$ and $s x$ is in $J I=I J$. Therefore $x=x a+x b$ is in $I J$. So $I \cap J \subset I J$.","Let $I$ and $J$ be ideals of a ring $R$ such that $I+J=R$.
Prove the Chinese Remainder Theorem: For any pair $a, b$ of elements of $R$, there is an element $x$ such that $x \equiv a$ modulo $I$ and $x \equiv b$ modulo $J$. (The notation $x \equiv a$ modulo $I$ means $x-a \in I$.","Writing $x=r x+s x$, where $r+s=1, r \in I$ and $s \in J$, does the trick."
49,Mathematics,18.102,Introduction to Functional Analysis,"18.C06, 18.100B",None,Problem Set 6,Lp Spaces,5,nan,0.5,Text,"If $K \in \mathcal{C}([0,1] \times[0,1])$ is a continuous function of two variables, show that
$$
(A f)(x)=\int K(x, y) f(y)
$$
defines a compact linear operator on $L^{2}(0,1)$. ",Open,"Proof. As in problem 3, the function $K(x, y)$ is uniformly continuous. In particular, for each $\varepsilon$, there exist $\delta$ such that $\left|K\left(x_{1}, y\right)-K\left(x_{2}, y\right)\right|<\varepsilon$ for any $\left|x_{1}-x_{2}\right|<\delta$. For any $x_{0} \in[0,1]$ and $\left|x-x_{0}\right|<\delta$, we compute
$$
\left|A f(x)-A f\left(x_{0}\right)\right|=\left|\int\left(K(x, y)-K\left(x_{0}, y\right)\right) f(y)\right| \leq \varepsilon \int|f(y)|.
$$
This shows $A f(x)$ is continuous. In fact, it shows more: if $\|f(y)\|_{L^{1}} \leq 1$, then $\{A f(x)\}$ is equicontinuous. Furthermore, if $\|f(y)\|_{L^{1}} \leq 1$, then
$$
|(A f)(x)|=\left|\int K(x, y) f(y)\right| \leq \operatorname{Max}\{K(x, y)\}\|f(y)\|_{L^{1}} \leq \operatorname{Max}\{K(x, y)\}
$$
Therefore the operator $A: L^{2}(0,1) \rightarrow \mathcal{C}[0,1]$ maps the unit ball in $L^{2}(0,1)$ to a subset of $\mathcal{C}[0,1]$ that is bounded and equicontinuous. By the previous problem, this set has compact closure. This finishes the proof.","Show that if $K \in \mathcal{C}\left([0,1]^{2}\right)$ is a continuous function of two variables, then the integral operator
$$
A u(x)=\int_{0}^{1} K(x, y) u(y) d y
$$
(given by a Riemann integral) is a bounded operator, i.e. a continous linear map, from $\mathcal{C}([0,1])$ to itself with respect to the supremum norm.","A continuous function on a compact set, such as $[0,1]^{2}$, is uniformly continuous, so given $\epsilon$ there exists $\delta>0$ such that
$$
\left|x-x^{\prime}\right|+\left|y-y^{\prime}\right|<\delta \Longrightarrow\left|K(x, y)-K\left(x^{\prime}, y^{\prime}\right)\right|<\epsilon
$$
If $u \in \mathcal{C}([0,1])$ is fixed then the integrand in (1) is continuous for each fixed $x \in[0,1]$ so $A u:[0,1] \longrightarrow \mathbb{C}$ is well-defined as a Riemann integral. Moreover
$\left|A u(x)-A u\left(x^{\prime}\right)\right|=\mid \int_{0}^{1}\left(K(x, y)-K\left(x^{\prime}, y\right) u(y) d y\left|\leq \sup _{y}\right| K(x, y)-K\left(x^{\prime}, y\right)|\sup | u \mid\right.$
by standard properties of the Riemann integral. Using (2) it follows that
$$
\left|x-x^{\prime}\right|<\delta \Longrightarrow\left|A u(x)-A u\left(x^{\prime}\right)\right| \leq \sup |u| \epsilon
$$
so $A u$ is continuous on $[0,1]$ and (1) defines a map
$$
A: \mathcal{C}([0,1]) \longrightarrow \mathcal{C}([0,1])
$$
The linearity of this map follows from the linearity of the Riemann integral and
$$
|u(x)| \leq \sup |K| \sup |u| \forall x \in [0,1]
$$
shows that it is bounded, i.e. continuous.","Let $K \subset \mathbb{R}^{2}$ be a closed and bounded set and let $f:[0,1] \times K \longrightarrow \mathbb{C}$ be a continuous function on this subset of $\mathbb{R}^{3}$ (all with respect to the Euclidean metric). Show that the set of functions $\left\{g_{s}\right\}_{s \in[0,1]}$ where
$$
g_{s}(x)=f(s, x)
$$
is equicontinuous on $K$.","The subset $[0,1] \times K \subset \mathbb{R}^{3}$ is compact, as the product of two compact sets. To see this consider a sequence in $[0,1] \times K$ which consists of a pair of sequences, one in $[0,1]$ and the other in $K$. The first has a convergent subsequence with limit in $[0,1]$ by the Heine-Borel theorem and taking the corresponding subsequence of the second this has in turn a convergent subsequence by the compactness of $K$ and a result to this effect from Rudin. Or recall that we proved that the product of two compact sets is compact, or use Heine-Borel more directly. Since $f$ is continuous on this compact metric space, by a result in Rudin, it is uniformly continuous. Thus, given $\epsilon>0$ there exists $\delta>0$ such that
$$
\left|s_{1}-s_{2}\right|^{2}+\left|y-y^{\prime}\right|^{2}<\delta^{2} \Longrightarrow\left|f\left(s_{1}, y\right)-f\left(s_{2}, y^{\prime}\right)\right|<\epsilon
$$
Taking $s_{1}-s_{2}$ this is precisely what is needed to show that the collection of functions $g_{s}$ is equicontinuous.
Comments. Quite a few people got to uniform continuity and then did not see that it gave equicontinuity of the $g_{s}$. Some people tried to bluff their way through. Some people used the continuity of the map $[0,1] \ni s \longmapsto g_{s} \in \mathcal{C}(K)$, Heine-Borel and Ascoli-Arzelà. This works if you prove continuity of the map, which is pretty much precisely the equicontinuity we want but okay.",Show that if $K \subset \mathbb{R}$ is compact then its characteristic function is an element of $\mathcal{L}^{1}(\mathbb{R})$.,"Proof. The subset $K \subset \mathbb{R}$ is compact if and only if it is bounded and closed. Thus, $K \subset(-R, R)$ for some $R$ and the complement $U=(-R, R) \backslash K$ is bounded open set. Then $\chi_{U} \in \mathcal{L}^{1}(\mathbb{R})$ and evidently $\chi_{(-R, R)} \in \mathcal{L}^{1}(\mathbb{R})$. Now $\chi_{K}=\chi_{(-R, R)}-\chi_{U} \in \mathcal{L}^{1}(\mathbb{R})$ and the statement follows."
203,Mathematics,18.01,Calculus I,None,None,Problem Set 5,Second Derivatives,9,a,0.04751847941,Text,"A graphing problem using second derivatives. Let $f(x)=x e^{-x}$. We will graph $f(x)$ on the range $0 \leq x$. But first we compute some information about $f(x)$.
Compute $f^{\prime}(x)$ and $f^{\prime \prime}(x)$.",Expression,$f^{\prime}(x)=(1-x) e^{-x}$ (product rule) and $f^{\prime \prime}(x)=(x-2) e^{-x}$ (product rule again).,"A graphing problem using second derivatives. Let $f(x)=x e^{-x}$. We will graph $f(x)$ on the range $0 \leq x$. But first we compute some information about $f(x)$.
For which $x$ is $f^{\prime}(x)=0$ ? For which $x$ is $f^{\prime}(x)>0$ and for which $x$ is $f^{\prime}(x)<0$?",$f^{\prime}(x)=0$ (maximum) when $x=1 . f^{\prime}(x)>0$ (increasing) when $x<1 . f^{\prime}(x)<0$ (decreasing) when $x>1$.,"A graphing problem using second derivatives. Let $f(x)=x e^{-x}$. We will graph $f(x)$ on the range $0 \leq x$. But first we compute some information about $f(x)$.
For which $x$ is $f^{\prime \prime}(x)=0$ ? For which $x$ is $f^{\prime \prime}(x)>0$ and for which $x$ is $f^{\prime \prime}(x)<0$ ?",$f^{\prime \prime}(x)=0$ (inflection point) when $x=2 . f^{\prime \prime}(x)>0$ (concave up) when $x>2$. $f^{\prime \prime}(x)<0$ (concave down) when $x<2$.,"A graphing problem using second derivatives. Let $f(x)=x e^{-x}$. We will graph $f(x)$ on the range $0 \leq x$. But first we compute some information about $f(x)$.
Sketch the graph of $f(x)$ for $x$ in the range $0 \leq x \leq 4$. Your graph doesn't have to be beautiful, but it should take into account the information you learned in the parts above.","Here is a graph below that follows the constraints about the maximum, about increasing and decreasing regions, and about concavity, in addition to enforc$\operatorname{ing} f(0)=0$ and $f(\infty)=0$."
224,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Lab 8,Neural Networks,3,aii,0.06944444444,Text,"Now we'll switch gears away from autoencoders and explore the generalization properties of neural networks (which apply generally to other machine-learning mechanisms) via an idea called ""adversarial examples."" The idea is this: once we have trained a neural network to perform well on training and even test data, we would still like to know how it performs on unseen new inputs from its original input space. To understand the network's performance, we try to trick it, by finding an example that looks like a positive training example, but that the network classifies as negative (or vice versa).
We will explore this idea first with a very simple example to build intuition, and then with the digit images.
How do we find an adversarial example? We freeze the neural network weights, but now use gradient descent to try to find an input $x$ that is misclassified by the network.
In normal neural-network training, we use gradient descent to adjust the weights to minimize a loss function. Now, to find an example that fools our network, we are going to freeze the weights of the network and use gradient descent to find an example that the network misclassifies.
In this part, we'll consider a linear logistic classifier, $h(x)$. As we saw earlier in the course, we interpret the output of $h(x)$ as the probability that example $x$ is assigned to one class (e.g., as the ""positive"" class with label 1). Correspondingly, $1-h(x)$ is the probability that $x$ is assigned to the other class (e.g., as the ""negative"" class with label -1).
Using this interpretation of the classifier output $h(x)$, our strategy for finding an adversarial example will be to start with an example that $h(x)$ classifies correctly as negative, and use gradient ascent on $x$ to increase the value of $h(x)$ until we find an $x$ that is classified as positive. (We can, similarly, start with an example that is correctly classified as positive and adjust the $x$ by gradient descent to decrease the value of $h(x)$ until the example is classified as negative.)
Note: here $h(x)$ indicates a linear logistic classifier, not the $h$ in the output layer in the figure at the top of this lab, and not the decoder $h$ in the autoencoder figure.
What is $\nabla_{x} h(x)?$
Remember that the output of a linear logistic classifier has the form $h(x)=\sigma\left(\theta^{T} x+\theta_{0}\right)$, and write an expression in terms of $\sigma(\cdot), x$, and $\theta$, assuming $\theta_{0}=0$. Hint: Use the chain rule and the following fact: $\frac{\partial}{\partial z} \sigma(z)=\sigma(z)(1-\sigma(z))$.",Expression,$\sigma\left(\theta^{T} x\right)\left(1-\sigma\left(\theta^{T} x\right)\right) \theta$ What does this gradient tell us? Ans: how to change $\mathrm{x}$ to make it be classified more positively.,"Now we'll switch gears away from autoencoders and explore the generalization properties of neural networks (which apply generally to other machine-learning mechanisms) via an idea called ""adversarial examples."" The idea is this: once we have trained a neural network to perform well on training and even test data, we would still like to know how it performs on unseen new inputs from its original input space. To understand the network's performance, we try to trick it, by finding an example that looks like a positive training example, but that the network classifies as negative (or vice versa).
We will explore this idea first with a very simple example to build intuition, and then with the digit images.
How do we find an adversarial example? We freeze the neural network weights, but now use gradient descent to try to find an input $x$ that is misclassified by the network.
In normal neural-network training, we use gradient descent to adjust the weights to minimize a loss function. Now, to find an example that fools our network, we are going to freeze the weights of the network and use gradient descent to find an example that the network misclassifies.
In this part, we'll consider a linear logistic classifier, $h(x)$. As we saw earlier in the course, we interpret the output of $h(x)$ as the probability that example $x$ is assigned to one class (e.g., as the ""positive"" class with label 1). Correspondingly, $1-h(x)$ is the probability that $x$ is assigned to the other class (e.g., as the ""negative"" class with label -1).
Using this interpretation of the classifier output $h(x)$, our strategy for finding an adversarial example will be to start with an example that $h(x)$ classifies correctly as negative, and use gradient ascent on $x$ to increase the value of $h(x)$ until we find an $x$ that is classified as positive. (We can, similarly, start with an example that is correctly classified as positive and adjust the $x$ by gradient descent to decrease the value of $h(x)$ until the example is classified as negative.)
Note: here $h(x)$ indicates a linear logistic classifier, not the $h$ in the output layer in the figure at the top of this lab, and not the decoder $h$ in the autoencoder figure.
To increase the value of $h(x)$, what update rule should we use?
(a) $x^{(t)}=x^{(t-1)}-\eta \nabla_{x} h\left(x^{(t-1)}\right)$
(b) $x^{(t)}=x^{(t-1)}+\eta \nabla_{x} h\left(x^{(t-1)}\right)$",Second one. We're trying to increase $h(x)$ so we move in the positive direction of the gradient.,"Now we'll switch gears away from autoencoders and explore the generalization properties of neural networks (which apply generally to other machine-learning mechanisms) via an idea called ""adversarial examples."" The idea is this: once we have trained a neural network to perform well on training and even test data, we would still like to know how it performs on unseen new inputs from its original input space. To understand the network's performance, we try to trick it, by finding an example that looks like a positive training example, but that the network classifies as negative (or vice versa).
We will explore this idea first with a very simple example to build intuition, and then with the digit images.
How do we find an adversarial example? We freeze the neural network weights, but now use gradient descent to try to find an input $x$ that is misclassified by the network.
Here's a simple dataset with two inputs and two labels:
x1 = np.array([[ 1. , -0.1]]).T
y1 = 1
x2 = np.array([[-1. , 0.1]]).T
y2 = -1
We found the following weights for a linear logistic regression model:
theta = np.array([[ .01, -20]]).T
theta0 = 0
What can we do to be sure our $\mathrm{x}$ stays as close as it can to the example we started with? Why do we want to do that, in order to create an adversarial example?","By stopping as soon as our example is classified with the wrong label, we try to keep from changing it too much. This is important to make the example adversarial--we want it to still ""seem like"" the example we started with.","Now we'll switch gears away from autoencoders and explore the generalization properties of neural networks (which apply generally to other machine-learning mechanisms) via an idea called ""adversarial examples."" The idea is this: once we have trained a neural network to perform well on training and even test data, we would still like to know how it performs on unseen new inputs from its original input space. To understand the network's performance, we try to trick it, by finding an example that looks like a positive training example, but that the network classifies as negative (or vice versa).
We will explore this idea first with a very simple example to build intuition, and then with the digit images.
How do we find an adversarial example? We freeze the neural network weights, but now use gradient descent to try to find an input $x$ that is misclassified by the network.
What could we do to make our models more robust to adversarial examples?","Students will come up with a myriad of proposed solutions - including things like:
\begin{itemize}
\item Adding adversarial examples to the training set and re-training the network
\item Checking whether the data is in-distribution, perhaps by using the latent space of a VAE (relating to the first half of the lab)
\end{itemize}"
107,EECS,6.411,"Representation, Inference, and Reasoning in AI","6.1010, 6.1210, 18.600",None,Problem Set 3,Propositional Proof,4,ai,0.1116071429,Text,"There are three suspects for a murder: Adams, Brown, and Clark.
1. Adams says ""I didn't do it. The victim was an old acquaintance of Brown's. But Clark hated him.""
2. Brown states ""I didn't do it. I didn't know the guy. Besides I was out of town all week.""
3. Clark says ""I didn't do it. I saw both Adams and Brown in town around the victim that day; one of them must have done it.""
4. We know that exactly one of the suspects is guilty.
Assume that the two innocent people are telling the truth, but that the guilty people might not be. So, the statements from the suspects can be encoded as ""If suspect_is_innocent, then some other facts are true"".
Let the propositional variables have the following definitions:
\begin{itemize}
\item $A=$ Adams is innocent
\item $B=$ Brown is innocent
\item $C=$ Clark is innocent
\item $X=$ Brown knew the victim
\item $Y=$ Brown was out of town
\item $Z=$ Adams was out of town
\item $W=$ Clark hated the victim
\end{itemize}
We can write down propositional logic axioms for each of the four statements defining this problem. For propositional resolution, we need to convert these sentences to CNF. We will ask you to convert one sentence at a time. Enter one CNF formula corresponding to the specified sentence in each of the answer spaces below.
Enter each CNF formula as a list of lists of literal strings. A literal string is either a propositional symbol, e.g. 'A' or the negation of a propositional symbol, e.g. ' $A$ '. A typical clause will look like: $\left[{ }^{\prime} A ', ' \sim B\right.$ ', ' $\left.\sim C '\right]$. And a CNF formula is a list of clauses. Do not include any spaces in the strings. 
The first axiom is: $A \Rightarrow(X \wedge W)$
Enter the CNF as a formula following the syntax described above.",Expression,"[['~A', 'X'], ['~A', 'W']]","There are three suspects for a murder: Adams, Brown, and Clark.
1. Adams says ""I didn't do it. The victim was an old acquaintance of Brown's. But Clark hated him.""
2. Brown states ""I didn't do it. I didn't know the guy. Besides I was out of town all week.""
3. Clark says ""I didn't do it. I saw both Adams and Brown in town around the victim that day; one of them must have done it.""
4. We know that exactly one of the suspects is guilty.
Assume that the two innocent people are telling the truth, but that the guilty people might not be. So, the statements from the suspects can be encoded as ""If suspect_is_innocent, then some other facts are true"".
Let the propositional variables have the following definitions:
\begin{itemize}
\item $A=$ Adams is innocent
\item $B=$ Brown is innocent
\item $C=$ Clark is innocent
\item $X=$ Brown knew the victim
\item $Y=$ Brown was out of town
\item $Z=$ Adams was out of town
\item $W=$ Clark hated the victim
\end{itemize}
We can write down propositional logic axioms for each of the four statements defining this problem. For propositional resolution, we need to convert these sentences to CNF. We will ask you to convert one sentence at a time. Enter one CNF formula corresponding to the specified sentence in each of the answer spaces below.
Enter each CNF formula as a list of lists of literal strings. A literal string is either a propositional symbol, e.g. 'A' or the negation of a propositional symbol, e.g. ' $A$ '. A typical clause will look like: $\left[{ }^{\prime} A ', ' \sim B\right.$ ', ' $\left.\sim C '\right]$. And a CNF formula is a list of clauses. Do not include any spaces in the strings. 
The second axiom is: $B \Rightarrow(\neg X \wedge Y)$
Enter the CNF as a formula following the syntax described above.","[['~B', '~X'], ['~B', 'Y']]","There are three suspects for a murder: Adams, Brown, and Clark.
1. Adams says ""I didn't do it. The victim was an old acquaintance of Brown's. But Clark hated him.""
2. Brown states ""I didn't do it. I didn't know the guy. Besides I was out of town all week.""
3. Clark says ""I didn't do it. I saw both Adams and Brown in town around the victim that day; one of them must have done it.""
4. We know that exactly one of the suspects is guilty.
Assume that the two innocent people are telling the truth, but that the guilty people might not be. So, the statements from the suspects can be encoded as ""If suspect_is_innocent, then some other facts are true"".
Let the propositional variables have the following definitions:
\begin{itemize}
\item $A=$ Adams is innocent
\item $B=$ Brown is innocent
\item $C=$ Clark is innocent
\item $X=$ Brown knew the victim
\item $Y=$ Brown was out of town
\item $Z=$ Adams was out of town
\item $W=$ Clark hated the victim
\end{itemize}
We can write down propositional logic axioms for each of the four statements defining this problem. For propositional resolution, we need to convert these sentences to CNF. We will ask you to convert one sentence at a time. Enter one CNF formula corresponding to the specified sentence in each of the answer spaces below.
Enter each CNF formula as a list of lists of literal strings. A literal string is either a propositional symbol, e.g. 'A' or the negation of a propositional symbol, e.g. ' $A$ '. A typical clause will look like: $\left[{ }^{\prime} A ', ' \sim B\right.$ ', ' $\left.\sim C '\right]$. And a CNF formula is a list of clauses. Do not include any spaces in the strings. 
The third axiom is: $C \Rightarrow(\neg Y \wedge \neg Z \wedge(\neg A \vee \neg B))$
Enter the CNF as a formula following the syntax described above.","[['~C', '~Y'], ['~C', '~Z'], ['~C', '~A', '~B']]","There are three suspects for a murder: Adams, Brown, and Clark.
1. Adams says ""I didn't do it. The victim was an old acquaintance of Brown's. But Clark hated him.""
2. Brown states ""I didn't do it. I didn't know the guy. Besides I was out of town all week.""
3. Clark says ""I didn't do it. I saw both Adams and Brown in town around the victim that day; one of them must have done it.""
4. We know that exactly one of the suspects is guilty.
Assume that the two innocent people are telling the truth, but that the guilty people might not be. So, the statements from the suspects can be encoded as ""If suspect_is_innocent, then some other facts are true"".
Let the propositional variables have the following definitions:
\begin{itemize}
\item $A=$ Adams is innocent
\item $B=$ Brown is innocent
\item $C=$ Clark is innocent
\item $X=$ Brown knew the victim
\item $Y=$ Brown was out of town
\item $Z=$ Adams was out of town
\item $W=$ Clark hated the victim
\end{itemize}
We can write down propositional logic axioms for each of the four statements defining this problem. For propositional resolution, we need to convert these sentences to CNF. We will ask you to convert one sentence at a time. Enter one CNF formula corresponding to the specified sentence in each of the answer spaces below.
Enter each CNF formula as a list of lists of literal strings. A literal string is either a propositional symbol, e.g. 'A' or the negation of a propositional symbol, e.g. ' $A$ '. A typical clause will look like: $\left[{ }^{\prime} A ', ' \sim B\right.$ ', ' $\left.\sim C '\right]$. And a CNF formula is a list of clauses. Do not include any spaces in the strings. 
The fourth axiom is: $(\neg A \vee \neg B \vee \neg C) \wedge((A \wedge B) \vee(A \wedge C) \vee(B \wedge C))$
Enter the CNF as a formula following the syntax described above.","[['~C', '~A', '~B'], ['A', 'C'], ['A', 'B'], ['B', 'C'], ['A', 'B', 'C']]"
345,EECS,6.39,Introduction to Machine Learning,"6.1010/6.1210, 18.06/18.C06",None,Lab 13,Nearest Neighbors,3,bv,0.04166666667,Text,Is it important to standardize data before we use it to train a kNN predictor? Why or why not? Does your answer change if there is 1 feature or more than 1 feature?,Open,"If we are using Euclidean distance and the number of features is more than 1: yes, it is important to standardize! If the features are not standardized, then the chosen units can dramatically change how the different features are weighted (and that weighting is basically arbitrary).
If there is just 1 feature, we'll get the same result regardless of feature shifting and scaling. So it's not necessary. But, as we discussed for trees, it doesn't hurt, and it's a good standard practice.","For this section, please refer to this week's notes for a refresher on bootstrap aggregation and random forests.
Bootstrap aggregation is a technique for reducing estimation error by (a) making multiple different random samples using our training data, (b) training a new predictor on each of the samples, and then (c) combining all the different predictors to end up with a single predictor. Usually we combine all the different predictors by taking some sort of ""average"" or ""vote.""
Is it important to standardize data before we use it to train a random forest? Why or why not? Hint: It might help to recall your answer from above about decision trees.",Random forests inherit the same answer as for decision trees above (it's not necessary to standardize features but it doesn't hurt). They're just an average or vote over decision trees.,"For each of the following features, pick what might be the best encoding for linear classification, among the choices provided. In each part below, you should assume that the dataset has several other features. The questions mention what we're trying to predict, but we're really just asking about the input encoding here.
The point of this question is to think about alternatives; there are several options, many not mentioned here.
A person's weight (in $\mathrm{kg}$) for predicting life expectancy (e.g., live for longer than 50 years vs. live for less than 50 years). Assume there is also a real-valued feature in the dataset encoding height in meters that we would like to use later on.
(a) A real-valued feature: weight in kg.
(b) A standardized real-valued feature.
(c) 3 (one-hot) features for categories (< 40 kg, 40-80 kg, >80 kg).","(b) A standardized real-valued feature.
If we assume that weight is correlated with life-expectancy, we do want to preserve ordering information, so one-hot encoding is probably not good. So, that argues for one of the first two. It is often the case that making the range of values of features similar is helpful in linear classification. In this case, the clearly related height feature is going to be a number less than three, which is significantly less than weight in kilograms. Hence, it is a good idea to scale the weight to aid linear classification. The standardized real-valued feature would be scaled and shifted such that this feature's distribution is now centered on 0 with standard deviation of 1.","What if we instead use features that are the squares of the number of dark pixels in a row, and squares of the number of dark pixels in a column? Let's plot these features adjacent to the gameboard to see some examples from the data below. 
Do you expect these new features to be able to separate lines from corners using a linear classifier? If so, explain the rule in English. If not, explain why not.","Yes, because the sum of the row and column sums squared for a line is $9+1+1+1=12$ whereas the sum of the row and column sums squared for a corner is $4+4+1+1=10$. It's a line if the sum of the squared row and column sums is greater than 10."
34,Mathematics,18.01,Calculus I,None,None,Problem Set 1,Exponentials and Logarithms,16,a,0.07919746568,Text,"Given that $\log _{2} 10=3.32 \ldots$, give a reasonable approximation for $\log _{2} 100 ?$ What about $\log _{2} 10^{10} ?$",Numerical,"First,
$$
\log _{2} 100=\log _{2} 10^{2}=2 \times \underbrace{\log _{2} 10}_{\approx 3.32} \approx 6.64 .
$$
Similarly,
$$
\log _{2} 10^{10}=10 \log _{2} 10 \approx 33.2 \text {. }
$$","If $2^{100}=10^{t}$, which of the following is the best approximation of $t: 10$ or 20 or 30 or 40 or $50 ?$ (If you want, you can use that $\log _{2} 10=3.32 \ldots$)","In words, $\log _{2} 10 \approx 3.32$ means that there are approximately $3.32$ factors of 2 in a factor of 10 . Thus, 100 factors of 2 are, approximately, 100/3.32 $\approx 30$ factors of 10.
$$
2^{100} \approx 10^{30} .
$$","In this problem, we will combine all the ideas in this section in order to approximate the number $(1.01)^{100}$. Let $s$ denote this number.
Once you have an approximation of $\log s$, use it to approximate $s$. ","Thus, $s \equiv e^{\log s} \approx e^{1}=e$.","Using the linear approximation of $\log x$ around $x=1$, approximate $\log 1.01$.","The slope (derivative) of $\log x$ is $1 / x$. Thus, at $x=1$, the slope is 1 . The linear approximation is therefore
$$
\log (1+\Delta x) \approx f(1)+1 \cdot \Delta x .
$$
Because $\log 1=0$,
$$
\log (1+\Delta x) \approx \Delta x .
$$
In terms of $x$ (standing for $1+\Delta x$ ),
$$
\log x \approx x-1 .
$$
So, $\log 1.01 \approx 0.01$."
19,EECS,6.191,Computation Structures,"6.100A, 8.02",None,Prelab Questions 1,Assembly,3,g,0.006060606061,Text,"Now let's look back at the main code.
li a0, 0x2000
li a7, 0
lw a1, 0(a0)
// start of the code piece
L1 :
andi a2, a1, 1
beq a2, zero, L2
addi a7, a7, 1
L2 :
srli a1, a1, 1
// end of the code piece
bnez a1, L1
unimp
. = 0x2000
.word 0x12345678
Now assume that the code runs until it reaches the bnez a1, L1 instruction for the first time.
What is the value in the register a7 when the bnez a1, L1 instruction is reached for the first time (answer in 32-bit hexadecimal format like 0x0CDEF1AF)?",Numerical,"0x00000000.
Since a1 is initially even, the first time through the code, a7 is not incremented so it remains 0.","Now let's look back at the main code.
li a0, 0x2000
li a7, 0
lw a1, 0(a0)
// start of the code piece
L1 :
andi a2, a1, 1
beq a2, zero, L2
addi a7, a7, 1
L2 :
srli a1, a1, 1
// end of the code piece
bnez a1, L1
unimp
. = 0x2000
.word 0x12345678
Now assume that the code runs until it reaches the bnez a1, L1 instruction for the first time.
What is the value in the register a1 when the bnez a1, L1 instruction is reached for the first time (answer in 32-bit hexadecimal format like 0x0CDEF1AF)?","0x091A2B3C.
We learned above that the inner four instructions of this code shift the contents of register a1 to the right by 1-bit, and add 1 to a7 whenever the least significant bit of a1 is 1 (i.e., the number is odd). a1 is initialized to 0x12345678 which in binary is 0b0001 0010 0011 0100 0101 0110 0111 1000. Shifting this value to the right by 1 results in 0b0000 1001 0001 1010 0010 1011 0011 1100 which is 0x091a2b3c in hexadecimal.","Now let's look back at the main code.
li a0, 0x2000
li a7, 0
lw a1, 0(a0)
// start of the code piece
L1 :
andi a2, a1, 1
beq a2, zero, L2
addi a7, a7, 1
L2 :
srli a1, a1, 1
// end of the code piece
bnez a1, L1
unimp
. = 0x2000
.word 0x12345678
Now consider running the code to completion when it reaches the unimp instruction.
What will be the value inside the register a7 when the execution reaches the unimp instruction (answer in 32-bit hexadecimal format like 0x0CDEF1AF)?","0x0000000D.
This code shifts a1 by 1 bit to the right and adds 1 to a7 (if the last bit of a1 is 1). Thus a7 is keeping track of the number of 1's in the original value of a1. The number of 1's was 13, thus a7 will be 0x0000000D which is equal to 13 when this code completes execution.","Now let's look back at the main code.
li a0, 0x2000
li a7, 0
lw a1, 0(a0)
// start of the code piece
L1 :
andi a2, a1, 1
beq a2, zero, L2
addi a7, a7, 1
L2 :
srli a1, a1, 1
// end of the code piece
bnez a1, L1
unimp
. = 0x2000
.word 0x12345678
Now consider the execution of bnez a1, L1 for the first time.
In which of the following situation will the branching not occur?
(a) When a7 reaches 0.
(b) When a1 reaches 0.","(b) When a1 reaches 0.
The `bnez a1, L1` instruction branches to label (`L1`) as long as the value inside `a1` is not `0`."